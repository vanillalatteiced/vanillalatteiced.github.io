{"0": {
    "doc": "Terraform Basics",
    "title": "Terraform Basics",
    "content": "# Terraform Basics {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## Install Terraform ```zsh brew tap hashicorp/tap brew install hashicorp/terraform terraform -version ``` --- ## Configuration The set of files used to declare infrastructure. Such files have an extension of `.tf` and are required to be in its own working directory. ```zsh mkdir tf-aws-instance cd tf-aws-instance touch main.tf ``` The following is an example configuration `main.tf`: ```tf terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~> 3.27\" } } required_version = \">= 0.14.9\" } provider \"aws\" { profile = \"default\" region = \"us-west-2\" } resource \"aws_instance\" \"app_server\" { ami = \"ami-830c94e3\" instance_type = \"t2.micro\" tags = { Name = \"ExampleAppServerInstance\" } } ``` {: .note} Terraform also provides `terraform fmt` and `terraform validate` for formatting configuration files and checking its syntax. `terraform fmt` does not produce any output if no modification is made. For details, see [Terraform Configuration](/docs/terraform/terraform-config.html). --- ## Initialize After creating a configuration or checking out an existing configuration, initialize directory with ```zsh # Installs providers in .terraform folder and also creates .terraform.lock.hcl terraform init ``` --- ## Create infrastructure and inspect state To see the execution plan, ```zsh terraform plan ``` To actually apply, ```zsh # Will print an execution plan, type yes to perform the actions terraform apply # OR terraform apply --auto-approve ``` A Terraform state file `terraform.tfstate` will be generated. The file contains sensitive info, so share with only those trusted. ```zsh # Inspect the current state terraform show ``` For manual/advanced state management, use `terraform state`. One example of the command is, ```zsh # List resources in state terraform state list ``` --- ## Output file You can query data after `apply` using an output file. Create a file called `output.tf` (*name doesn't matter*) with the following ```tf output \"instance_id\" { description = \"ID of the EC2 instance\" value = aws_instance.app_server.id } output \"instance_public_ip\" { description = \"Public IP address of the EC2 instance\" value = aws_instance.app_server.public_ip } ``` You will see the queried output when you run `terraform apply`. You can also inspect the output by ```zsh # Call after `terraform apply` terraform output ``` --- ## Destroy infrastructure The following terminates all resources managed with project state ```zsh # Just like apply, shows you the execution plan. Type yes to destroy. terraform destroy # OR terraform destroy --auto-approve ``` --- References: - [Terraform: AWS Get Started](https://learn.hashicorp.com/collections/terraform/aws-get-started) - [Terraform Registry: AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs) --- ",
    "url": "/docs/terraform/basics.html",
    "relUrl": "/docs/terraform/basics.html"
  },"1": {
    "doc": "Docker Container",
    "title": "Docker Container",
    "content": "# Docker Container {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## Start an existing container in background (detached) The container will run in background and you will not see its `stdout`/`stderr` ```zsh docker start my-container ``` --- ## Attach container If you want to see outputs from the container in your terminal (ie. logging), you would want to run the container in attached mode. You can either run it in attached mode to begin with by ```zsh docker start my-container --attach # OR docker start my-container -a ``` Or you can attach a running container later ```zsh docker attach my-container ``` ",
    "url": "/docs/docker/container.html",
    "relUrl": "/docs/docker/container.html"
  },"2": {
    "doc": "Dangling Images",
    "title": "Dangling Images",
    "content": "# Docker Dangling Images {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## What are dangling images? When you do ```zsh docker images -a | grep '' # OR docker image ls -a | grep '' ``` Or check the **Images** tab in Docker Desktop, you may see a bunch of images with the name and tag of ``. This is a residue / intermediate image created from previous image builds. It seems they exist as a cached layer for subsequent builds. But it is safe to delete them. You can remove these dangling images by ```zsh docker image prune ``` {: .note} `docker image prune -a` not only removes dangling images but also any unused images. This can come in handy, but if you're keeping any pulled Docker registry images (unused in containers at the moment) in your local storage for some reason, this is not what you want. --- ## Docker Image / Images You may have noticed that there are two Docker CLI commands that seem similar - `docker image` - `docker images` There is a bit of a difference between the two. --- ### Docker Image Actually builds, pulls, and removes images. This command is used to physically manage the images. You can of course list images as well. ```zsh docker image ls ``` ### Docker Images This has to do with displaying in a high-level fashion what kind of images exist. Primary purpose is to display image metadata. ```zsh docker images ``` --- ",
    "url": "/docs/docker/dangling.html",
    "relUrl": "/docs/docker/dangling.html"
  },"3": {
    "doc": "With docker-compose",
    "title": "With docker-compose",
    "content": "{: .note} To be added. ",
    "url": "/docs/demo/flask-login-app/docker-compose.html",
    "relUrl": "/docs/demo/flask-login-app/docker-compose.html"
  },"4": {
    "doc": "Git",
    "title": "Git",
    "content": "# Git {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## Fix previous commit This comes in handy when you make a small change in your code after you've committed, but you realize you probably wanted it included in your last commit. ```zsh # Modify commit message as well git commit --amend ``` ```zsh # Keep the commit message git commit --amend --no-edit ``` {: .note} If you already pushed the commit to a remote before the `ammend`, then you need to force push the new changes by `git push -f origin master`. ",
    "url": "/docs/git/git.html",
    "relUrl": "/docs/git/git.html"
  },"5": {
    "doc": "GitHub",
    "title": "GitHub",
    "content": "# GitHub {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## Use multiple GitHub accounts with SSH First navigate to `~/.ssh`. For organization, create a directory and name it `github`. All private and public keys for GitHub connection will be placed here. --- ### Generate a new SSH key Follow the `ssh-keygen` prompt. It will ask you to decide on a name for the file, passphrase, etc. ```zsh # If Ed25519 algorithm is supported ssh-keygen -t ed25519 -C \"your_github@email.com\" ``` ```zsh # Legacy RSA ssh-keygen -t rsa -b 4096 -C \"your_github@email.com\" ``` --- ### Add the new SSH key to GitHub account Easiest part. Refer to [GitHub documentation][addssh] for step-by-step screencaps. --- ### Modify config Suppose I have two GitHub accounts each associated with `personal_email@address.com` and `work_email@address.com`. I'll assume the private keys are named `github-personal` and `github-work` respectively. Now append the following to `~/.ssh/config` ``` Host github-personal HostName github.com User git IdentityFile ~/.ssh/github/github-personal Host github-work HostName github.com User git IdentityFile ~/.ssh/github/github-work ``` You can define custom host for both as such or have one of them keep the default `github.com`. --- ### Local config per repository First start a local repo with ```zsh git init ``` Then config local name and email that will be used for that repo ```zsh git config --local user.name \"work_name\" git config --local user.email \"work_email@address.com\" ``` --- ### Add remote Normally you would add an ssh remote by ```zsh git remote add origin git@github.com:github_username:repo_name # OR git remote add origin github.com:github_username:repo_name ``` But this time, ```zsh git remote add origin github-work:work_username:repo_name ``` --- References: - [GitHub: SSH](https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent) [addssh]: https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account ",
    "url": "/docs/git/github.html",
    "relUrl": "/docs/git/github.html"
  },"6": {
    "doc": "Others",
    "title": "Others",
    "content": "# List of All Documentations ",
    "url": "/docs/others/",
    "relUrl": "/docs/others/"
  },"7": {
    "doc": "AWS",
    "title": "AWS",
    "content": "# AWS ",
    "url": "/docs/aws/",
    "relUrl": "/docs/aws/"
  },"8": {
    "doc": "Home",
    "title": "Home",
    "content": "# Blood Sweat and Tears of a Novice Programmer {: .fs-8 } Personal documentation of itty bitties and all the hacky decisions I've made throughout my learning (and maybe life). {: .fs-5 .fw-300 } --- ## Intro ### Why? Learning is always fun; I love jamming new things into my head. However, I've noticed that my long-term memory is in fact not long enough to guide me back after a while. Hence, the docs: I can't do anything about the things that have already left my head, but I am hoping that I can at least keep a nice documentation of my future learnings. ### Disclaimer The information contained in this document is not necessarily correct or comprehensive. It will be biased in many ways and may contain naive and pitiful approaches made by a novice. Its sole purpose is to document my footsteps. ",
    "url": "/",
    "relUrl": "/"
  },"9": {
    "doc": "Demo",
    "title": "Demo",
    "content": "# Demo ",
    "url": "/docs/demo/",
    "relUrl": "/docs/demo/"
  },"10": {
    "doc": "Flask",
    "title": "Flask",
    "content": "# Flask ",
    "url": "/docs/flask/",
    "relUrl": "/docs/flask/"
  },"11": {
    "doc": "Terraform",
    "title": "Terraform",
    "content": "# Terraform ## What is Terraform? **Infrastructure as Code (IaC)**: Terraform is a software tool that codes the infrastructure with a declarative configuration language. Your entire infrastructure is managed through a set of declarations. The benefit of IaC is that everything is collected within a single tool. This gets rid of the pain of having to jump to different tools every time you want to configure your resources. ",
    "url": "/docs/terraform/",
    "relUrl": "/docs/terraform/"
  },"12": {
    "doc": "Docker",
    "title": "Docker",
    "content": "# Docker ## Explained in a really dumb way You build an image that contains all the resources that compose a project. This packaging makes porting really easy because all the resources that made your project run at one time is now completely captured in it. You could think of this as a snapshot of your project. This image can be run in a docker container. A container is basically a process isolated from your computer. Think of it as a mini sandbox that mimics your system. Inside a container resources will be downloaded, installed, and copied just as you would normally, but whatever that happened during a container execution will not meddle with your actual computer (unless you specifically configure it to). ",
    "url": "/docs/docker/",
    "relUrl": "/docs/docker/"
  },"13": {
    "doc": "Jekyll",
    "title": "Jekyll",
    "content": "# Jekyll {: .no_toc } And GitHub Pages {: .text-delta } 1. TOC {:toc} --- ## Ruby installation with rbenv I've decided to use `rbenv` only because I didn't want to mess with the system `ruby` that comes with OSX (I am currently using Catalina). Assuming you have [Homebrew](https://brew.sh/) installed. ```bash # Install rbenv and ruby-build brew install rbenv # Set up rbenv integration with your shell rbenv init # Then follow the instruction that appears on screen ``` ```zsh # rbenv init will ask you to add the following to .zshrc eval \"$(rbenv init -)\" ``` Now that you have installed `rbenv`, create a folder that will contain your Jekyll site. I will refer to the folder as `blog`. Once created, move into `blog`. ```zsh cd blog # List latest stable versions rbenv install -l # I chose 3.0.0 rbenv install 3.0.0 rbenv rehash # Following creates .ruby-version in cwd rbenv local 3.0.0 # Confirm ruby version in folder ruby -v ``` All the `ruby` versions are installed in `~/.rbenv`. --- ## Install Jekyll Before installing the gems, check where they are being installed via ```zsh # Refer to INSTALLATION DIRECTORY / GEM PATHS gem env # OR gem env home ``` Now, the Jekyll documentation tells you to do a local install with the `--user-install` flag. If you're not using `rbenv` this is indeed more desirable as it does not require `sudo`. However, with `rbenv` it was unnecessary for my purpose. As you'll notice by inspecting the `gem env` outputs, it will install the gems outside of the `~/.rbenv` directory to some local folder (`USER INSTALLATION DIRECTORY`). It still works, but you have to add it to `PATH` to execute the gems. With `rbenv`, \"global\" (it really isn't global anymore) installation is more convenient because it installs them in `~/.rbenv` (so no `sudo` and additional path config required). ```zsh gem install jekyll bundler ``` --- ## Create a Jekyll blog First create a new Jekyll project by ```zsh # Assuming you're still in the blog folder jekyll new . ``` It will create a default website you can test locally. ```zsh # Will generate a static html site in _site bundle exec jekyll serve # With live-reloading bundle exec jekyll serve --livereload ``` {: .note} If you get any errors regarding `webrick`: `cannot load such file -- webrick (LoadError)`, add `webrick` by `bundle add webrick`. This is due to `ruby 3.0.0` excluding `webrick` as a default bundled gem. --- ## Bundle Clean ```zsh bundle clean [--dry-run] [--force] ``` ",
    "url": "/docs/others/jekyll/",
    "relUrl": "/docs/others/jekyll/"
  },"14": {
    "doc": "MongoDB",
    "title": "MongoDB",
    "content": "# MongoDB {: .no_toc } On-prem community edition {: .text-delta } 1. TOC {:toc} --- ## Install MongoDB (locally) ```zsh brew tap mongodb/brew brew install mongodb-community@4.4 ``` This installs - `mongod` server - `mongos` sharded cluster query router - `mongo` shell And also - `/usr/local/etc/mongod.conf` configuration file - `/usr/local/var/log/mongodb` log directory - `/usr/local/var/mongodb` data directory And finally [MongoDB Database Tools](https://docs.mongodb.com/database-tools/) {: .note} Location varies by system. Check with `brew --prefix`. --- ## Run and stop MongoDB (locally) Run MongoDB as a macOS service (recommended) ```zsh brew services start mongodb-community@4.4 # Verify it is running (should be in started status) brew service list | grep mongodb-community ``` You can then use the mongo shell via ```zsh mongo ``` Stop MongoDB ```zsh brew services stop mongodb-community@4.4 ``` --- References: - [MongoDB: Install](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/) ",
    "url": "/docs/others/mongodb/",
    "relUrl": "/docs/others/mongodb/"
  },"15": {
    "doc": "Git/GitHub",
    "title": "Git/GitHub",
    "content": "# Git/GitHub ## You probably already know what this is. Version control system; awesome stuff. ",
    "url": "/docs/git/",
    "relUrl": "/docs/git/"
  },"16": {
    "doc": "Docker Networks",
    "title": "Docker Networks",
    "content": "# Docker Networks {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## Some useful commands ```zsh # List all networks docker network ls ``` ```zsh docker network inspect network-name ``` ```zsh # Disconnect any containers using this network docker network disconnect network-name my-container docker network rm network-name ``` ```zsh # Remove unused networks docker network prune ``` [Link to documentation][dockernetwork]. --- ## How do I talk to the container? When a container is created, none of the ports inside the container are exposed. In order for the Docker host (your computer) or other containers to talk to it, it must first publish a port. The following maps a port 1234 inside a container to 4321 on Docker host. ``` docker create -p 1234:4321 ``` Now you can communicate with the container via `http://localhost:4321`. --- ## How can containers talk to each other? If the containers are running on the **same Docker daemon host** (ie. all running on your computer), then the easiest way is to put them on the same bridge network. --- ### Default bridge network Check the existing docker networks with ```zsh docker network ls ``` You will see a network with the name `bridge`. That is the default bridge network. Every started container is **automatically added** to the default bridge network if you didn't specify anything else. With the default bridge you talk to other containers by using their **IP Address**. ```zsh docker inspect my-container | grep IPAddress ``` **Downsides** to using the default bridge network: - Using IP address sucks (*at least in my opinion*): it is not immediate which container I'm referring to. - Every container can talk to every other container, which may cause security issues. --- ### User-defined bridge network You can add a user-defined bridge network. It still uses the same `bridge` driver, but unlike the default bridge not everyone is invited to it. #### Docker-compose ```yaml services: my-container: image: some-db-image networks: - backend networks: backend: driver: bridge ``` #### Or via Terminal ```zsh docker network create my-bridge # You can add after container creation docker network connect my-bridge my-container # Or when you create it docker create --network my-bridge ``` In user-defined bridge network, you can talk to the container using the container name as hostname. So if my container was named `my-db` with port published at `1234`, then url would be ``` http://my-db:1234 ``` --- References: - [Docker Networking](https://docs.docker.com/network/) [dockernetwork]: https://docs.docker.com/engine/reference/commandline/network/ ",
    "url": "/docs/docker/networks.html",
    "relUrl": "/docs/docker/networks.html"
  },"17": {
    "doc": "Terraform Configuration",
    "title": "Terraform Configuration",
    "content": "# Terraform Configuration {: .no_toc } With AWS (As of now) {: .text-delta } 1. TOC {:toc} --- ## Terraform Block It contains the Terraform settings and has the basic structure of the following ```tf terraform { required_providers { mylocalname = { source = \"source/address\" version = \"~> 1.0\" } } required_version = \">= 0.14.9\" } ``` Throughout the module, Terraform refers to providers using a **local name**. Here I've given it a name of `mylocalname`. Source address takes the form of `[Hostname/]Namespace/Type`. If `Hostname` is ommitted, it defaults to `registry.terraform.io` which is Terraform's default provider install source. `hashicorp/aws` is a shorthand for `registry.terraform.io/hashicorp/aws`. For the version constraint syntax, refer to [Version Constraint Syntax](https://www.terraform.io/docs/language/expressions/version-constraints.html). --- ## Provider You can configure each provider using the local name you have provided in the `required_providers` of the Terraform block. For example, ```tf provider \"mylocalname\" { # ... } ``` Reference [Provider Configuration](https://www.terraform.io/docs/language/providers/configuration.html) for details. --- ## Resource Basic syntax is as follows, ```tf resource \"aws_instance\" \"my_server\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" } ``` The example block above declares a **resource type** `\"aws_instance\"` and gives it a **local name** of `\"my_server\"`. Just like the provider local name, resource local name is used to refer to this resource throughout the module. In addition, the **unique ID** for the resource becomes `aws_instance.my_server`. The resource configuration arguments within the block body are specific to each resource type. For example, refer to documentation [here](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance) for `aws_instance`. --- ## Using variables To avoid using hard-coded values in configuration, create a new file `variables.tf` (*name of the file can be anything you want*) with the following, ```tf variable \"variable_name\" { description = \"Some description of what this is\" type = string default = \"This is the value of the variable\" } ``` You can then use the variables in other `.tf` files as, ```tf var.variable_name ``` You can also pass in a new variable value for testing by ```zsh terraform apply -var 'variable_name=SomeOtherValue' ``` It will modify the state so that all the variables use the new value. {: .note} This does not update the original variable declaration. If you run `terraform apply` again without the `-var` flag, the state will be modified using the original value. --- References: - [Terraform: Terraform Settings](https://www.terraform.io/docs/language/settings/index.html) - [Terraform: Providers](https://www.terraform.io/docs/language/providers/index.html) - [Terraform: Resources](https://www.terraform.io/docs/language/resources/index.html) - [Terraform: Version Constraint Syntax](https://www.terraform.io/docs/language/expressions/version-constraints.html) --- ",
    "url": "/docs/terraform/terraform-config.html",
    "relUrl": "/docs/terraform/terraform-config.html"
  },"18": {
    "doc": "Provision with Terraform",
    "title": "Provision with Terraform",
    "content": "# Provision with Terraform {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## Configuration Folder structure ```zsh flask-mongodb ├── backend │   ├── .gitignore │   ├── .dockerignore │   ├── app.py │   ├── back.dev.Dockerfile │   ├── requirements.txt │   └── venv │   └── flaskmongo └── terraform ├── main.tf └── providers.tf ``` We are going to be using a docker provider. ```tf # flask-mongodb/terraform/main.tf terraform { required_providers { docker = { source = \"kreuzwerker/docker\" version = \"~> 2.11.0\" } } required_version = \"~> 0.15.3\" } ``` ```tf # flask-mongodb/terraform/providers.tf provider \"docker\" { host = \"unix:///var/run/docker.sock\" } resource \"docker_container\" \"backend_tf\" { name = \"backend-tf\" image = docker_image.flask_back.latest volumes { container_path = \"/www\" host_path = \"/full/path/to/flask-mongodb/backend\" read_only = true } ports { internal = 5000 external = 5000 } } resource \"docker_image\" \"flask_back\" { name = \"flask-back:latest\" build { path = \"../backend\" dockerfile = \"back.dev.Dockerfile\" force_remove = true } } ``` Now initialize to download and install providers in `.terraform` and apply to create ```zsh terraform init terraform apply --auto-approve ``` To verify that docker image has been built and container is running ```zsh docker images | grep flask-back docker ps | grep backend-tf ``` Because `volume` is mounted, any change in directory `backend` will be reflected in the container. To destroy all resources created ```zsh terraform destroy ``` ",
    "url": "/docs/demo/flask-login-app/terraform.html",
    "relUrl": "/docs/demo/flask-login-app/terraform.html"
  },"19": {
    "doc": "Docker Volumes",
    "title": "Docker Volumes",
    "content": "# Docker Volumes {: .no_toc } {: .text-delta } 1. TOC {:toc} --- ## What is a Docker volume In short, it maps the volume inside a container with some local directory on your computer. If you set the volume to read-only, every change in local directory will be reflected in the container but not vice versa. If you set read-only to false, the contents inside the container and the local directory will remain same throughout the container execution. --- ## Cases where Docker volume comes in handy ### You want some live-reloading features During development, it is really painful if you have to rebuild or rerun everytime you make a change. By mapping your container volume to a local build context, the container will update itself everytime you make a change to your local code. ### You want to persist data upon container shutdown For example if you're running a DB as a container without a volume mapped, each time the container restarts, the contents of the DB will be erased. However, if you map your container volume to a local directory, the data will be kept even after shutdown. --- ",
    "url": "/docs/docker/volumes.html",
    "relUrl": "/docs/docker/volumes.html"
  }
}
