{"0": {
    "doc": "GitHub Actions",
    "title": "GitHub Actions",
    "content": ". | Add a workflow | Basic workflow syntax | Repository secrets | Self-hosted runner | Add a self-hosted runner | Run self-hosted runner . | To run as a service | . | . ",
    "url": "/docs/git-hub/github/actions.html",
    
    "relUrl": "/docs/git-hub/github/actions.html"
  },"1": {
    "doc": "GitHub Actions",
    "title": "Add a workflow",
    "content": "Navigate to a GitHub repo. Go to Actions and click on New workflow. You can either create a new workflow from scratch or use a template recommended for your project. You will have to commit your workflow yaml to the main branch. ",
    "url": "/docs/git-hub/github/actions.html#add-a-workflow",
    
    "relUrl": "/docs/git-hub/github/actions.html#add-a-workflow"
  },"2": {
    "doc": "GitHub Actions",
    "title": "Basic workflow syntax",
    "content": "See details here. Example: . name: Workflow Name on: push: branches: - main pull_request: branches: - main jobs: my-job: name: Job Name timeout-minutes: 10 runs-on: [self-hosted, macOS, X64] env: ENV_NAME: ${{ secrets.MyEnv }} steps: - uses: actions/checkout@v2 - name: Step Name run: | echo $ENV_NAME . ",
    "url": "/docs/git-hub/github/actions.html#basic-workflow-syntax",
    
    "relUrl": "/docs/git-hub/github/actions.html#basic-workflow-syntax"
  },"3": {
    "doc": "GitHub Actions",
    "title": "Repository secrets",
    "content": "In order to prevent sensitive environment variables from being committed with the workflow file, you can use Actions secrets. Navigate to Settings -&gt; Secrets: Actions . Click on New repository secret. Naming for secrets: . | Must not start with GITHUB_ prefix | Must not start with numbers | Must be alphanumeric + underscores (a-z, A-Z, 0-9, _) | Are not case sensitive | . Created secrets can then be used in workflow files as . ${{ secrets.MySecretName }} # Since secrets are not case sensitive, you could've just used # ${{ secrets.mysecretname }} as well. ",
    "url": "/docs/git-hub/github/actions.html#repository-secrets",
    
    "relUrl": "/docs/git-hub/github/actions.html#repository-secrets"
  },"4": {
    "doc": "GitHub Actions",
    "title": "Self-hosted runner",
    "content": "By default, GitHub Action Runners are machines managed by the GitHub. However, because you are borrowing a shared resource, your workflow may take a longer time to execute due to the wait time. Or you may be wanting to use GitHub Actions to automate on-prem deployment. To solve any one of these issues, you can add your own machine as a self-hosted runner on GitHub. See details here. ",
    "url": "/docs/git-hub/github/actions.html#self-hosted-runner",
    
    "relUrl": "/docs/git-hub/github/actions.html#self-hosted-runner"
  },"5": {
    "doc": "GitHub Actions",
    "title": "Add a self-hosted runner",
    "content": "Navigate to a GitHub repo. Go to Settings -&gt; Actions: Runners. Click on New self-hosted runner and follow the instructions. While running ./config.sh --url &lt;repo&gt; --token &lt;token&gt;, you will be asked to configure a label. This label is used to identify a specific runner, in the case you have multiple self-hosted runners. This value can be changed later in GitHub. ",
    "url": "/docs/git-hub/github/actions.html#add-a-self-hosted-runner",
    
    "relUrl": "/docs/git-hub/github/actions.html#add-a-self-hosted-runner"
  },"6": {
    "doc": "GitHub Actions",
    "title": "Run self-hosted runner",
    "content": "The simplest way to have the runner listening for jobs is to ./run.sh . To run as a service . To have the runner listening as a background job and have it restart itself upon machine failure, install it as a service and start it. sudo ./svc.sh install sudo ./svc.sh start sudo ./svc.sh stop sudo ./svc.sh status sudo ./svc.sh uninstall . To see this usage do: . sudo ./svc.sh . ",
    "url": "/docs/git-hub/github/actions.html#run-self-hosted-runner",
    
    "relUrl": "/docs/git-hub/github/actions.html#run-self-hosted-runner"
  },"7": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "Add Two Numbers",
    "content": ". | Problem | Solution . | Simultaneous traversal | Which linked list is longer? | Leftover carry | . | . ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html#add-two-numbers",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html#add-two-numbers"
  },"8": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "Problem",
    "content": "You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order, and each of their nodes contains a single digit. Add the two numbers and return the sum as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Input: l1 = [2,4,3], l2 = [5,6,4] Output: [7,0,8] Explanation: 342 + 465 = 807. ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html#problem"
  },"9": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "Solution",
    "content": "So basically the number 123 is represented as a linked list 3 -&gt; 2 -&gt; 1, and the number 456 is represented as a linked list 6 -&gt; 5 -&gt; 4. The answer should be 579, which is represented as a linked list 9 -&gt; 7 -&gt; 5. Things to note: . | The two linked lists may not have the same length. | We don’t know the length of the linked lists. | The answer may have at most one more digit than the longer linked list (because of the carry). | . The code consists of three parts: . | Traverse the two linked lists simultaneously and add the corresponding digits. | Check which linked list is longer. | If there is a carry, we need to do leftover work on the longer linked list. | . ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html#solution"
  },"10": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "Simultaneous traversal",
    "content": "We do not create a separate linked list for the answer. The answer is stored in-place in both linked lists. // Keep track of the head of both linked lists. ListNode ans1 = l1; ListNode ans2 = l2; // Why both? // Because we don't know which one is longer, // and we want to use the longer one for the answer. // Keep track of the previous node of both linked lists. ListNode l1_prev = null; ListNode l2_prev = null; // Why? In case we need to add a new node to the end of the linked list. int carry = 0; // Go on until one of the linked lists is exhausted. while (l1 != null &amp;&amp; l2 != null) { int sum = l1.val + l2.val + carry; carry = sum / 10; // Save for later // In-place update on both l1.val = sum % 10; l2.val = sum % 10; l1_prev = l1; l2_prev = l2; l1 = l1.next; l2 = l2.next; } . ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html#simultaneous-traversal",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html#simultaneous-traversal"
  },"11": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "Which linked list is longer?",
    "content": "Now that we’re out of the loop, either l1 or l2, or both, is null. // Tracking candidates for leftover work ListNode ans; // Head to return for the answer ListNode prev; // In case carry requires new node ListNode curr; // Where to start leftover work if (l1 != null) { ans = ans1; prev = l1_prev; curr = l1; } else { ans = ans2; prev = l2_prev; curr = l2; } . ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html#which-linked-list-is-longer",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html#which-linked-list-is-longer"
  },"12": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "Leftover carry",
    "content": "// Carry could go on until the end of the longer list while (carry &gt; 0) { // If we're at the end of the longer list, if (curr == null) { // This is why we had to keep track of the previous node prev.next = new ListNode(1); break; } // Same thing as before, just with one linked list int sum = curr.val + carry; carry = sum / 10; curr.val = sum % 10; prev = curr; curr = curr.next; } // Return the head of the answer return ans; . Complexity is $O(n)$ where $n$ is the length of the longer linked list. ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html#leftover-carry",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html#leftover-carry"
  },"13": {
    "doc": "2 - Add Two Numbers - Medium",
    "title": "2 - Add Two Numbers - Medium",
    "content": " ",
    "url": "/docs/compsci/leetcode/add-two-numbers.html",
    
    "relUrl": "/docs/compsci/leetcode/add-two-numbers.html"
  },"14": {
    "doc": "Adjugate Matrix / Minor / Cofactor",
    "title": "Adjugate Matrix / Minor / Cofactor",
    "content": ". | What is an adjugate matrix . | Product of a matrix and its adjugate matrix | . | Cofactor matrix . | Minor | Cofactor | . | . ",
    "url": "/docs/linalg/notes/adjugate.html",
    
    "relUrl": "/docs/linalg/notes/adjugate.html"
  },"15": {
    "doc": "Adjugate Matrix / Minor / Cofactor",
    "title": "What is an adjugate matrix",
    "content": "The adjugate matrix of a $n \\times n$ square matrix $\\boldsymbol{A}$, denoted by $\\operatorname{adj}(\\boldsymbol{A})$ is defined as the transpose of the cofactor matrix $\\boldsymbol{C}$ of $\\boldsymbol{A}$. $$ \\operatorname{adj}(\\boldsymbol{A}) = \\boldsymbol{C}^\\top $$ . Every square matrix has an adjugate matrix. ",
    "url": "/docs/linalg/notes/adjugate.html#what-is-an-adjugate-matrix",
    
    "relUrl": "/docs/linalg/notes/adjugate.html#what-is-an-adjugate-matrix"
  },"16": {
    "doc": "Adjugate Matrix / Minor / Cofactor",
    "title": "Product of a matrix and its adjugate matrix",
    "content": "One important property of the adjugate matrix: . The product of a matrix and its adjugate matrix is a diagonal matrix whose diagonal elements are all equal to the determinant of the matrix. $$ \\boldsymbol{A} \\operatorname{adj}(\\boldsymbol{A}) = \\operatorname{adj}(\\boldsymbol{A}) \\boldsymbol{A} = \\det(\\boldsymbol{A}) \\boldsymbol{I}_n $$ . ",
    "url": "/docs/linalg/notes/adjugate.html#product-of-a-matrix-and-its-adjugate-matrix",
    
    "relUrl": "/docs/linalg/notes/adjugate.html#product-of-a-matrix-and-its-adjugate-matrix"
  },"17": {
    "doc": "Adjugate Matrix / Minor / Cofactor",
    "title": "Cofactor matrix",
    "content": " ",
    "url": "/docs/linalg/notes/adjugate.html#cofactor-matrix",
    
    "relUrl": "/docs/linalg/notes/adjugate.html#cofactor-matrix"
  },"18": {
    "doc": "Adjugate Matrix / Minor / Cofactor",
    "title": "Minor",
    "content": "To understand the cofactor matrix, we first need to understand the minor of a matrix. Technically, this is the first minor of a matrix. The $(i,j)$ minor of a $n \\times n$ square matrix $\\boldsymbol{A}$, denoted . $$ \\boldsymbol{M}_{ij} $$ . is the determinant of the $(n-1) \\times (n-1)$ submatrix obtained by removing the $i$-th row and $j$-th column of $\\boldsymbol{A}$. There are $n^2$ ways to choose the $i$-th row and $j$-th column of $\\boldsymbol{A}$ of which to remove. So these $n^2$ minors can be arranged in a $n \\times n$ matrix $\\boldsymbol{M}$. Example Given a $3 \\times 3$ matrix $\\boldsymbol{A}$, . \\[\\boldsymbol{A} = \\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{bmatrix}\\] The $(3, 2)$ minor of $\\boldsymbol{A}$ is: . \\[\\boldsymbol{M}_{32} = \\det \\begin{vmatrix} 1 &amp; 3 \\\\ 4 &amp; 6 \\end{vmatrix} = 1 \\times 6 - 3 \\times 4 = -6\\] ",
    "url": "/docs/linalg/notes/adjugate.html#minor",
    
    "relUrl": "/docs/linalg/notes/adjugate.html#minor"
  },"19": {
    "doc": "Adjugate Matrix / Minor / Cofactor",
    "title": "Cofactor",
    "content": "The $(i,j)$ cofactor of a $n \\times n$ square matrix $\\boldsymbol{A}$ is: . $$ \\boldsymbol{C}_{ij} = (-1)^{i+j} \\boldsymbol{M}_{ij} $$ . i.e. the minor of $\\boldsymbol{A}$ multiplied by $(-1)^{i+j}$. Example continued Continuing from the example above, we have $\\boldsymbol{M}_{32} = -6$. Then: . \\[\\boldsymbol{C}_{32} = (-1)^{3+2} \\boldsymbol{M}_{32} = -(-6) = 6\\] ",
    "url": "/docs/linalg/notes/adjugate.html#cofactor",
    
    "relUrl": "/docs/linalg/notes/adjugate.html#cofactor"
  },"20": {
    "doc": "AIC and BIC",
    "title": "AIC and BIC",
    "content": ". | Akaike Information Criterion (AIC) . | When Error is Normally Distributed | . | Bayesian Information Criterion (BIC) . | Special case | . | . ",
    "url": "/docs/data-science/notes/aic-bic.html",
    
    "relUrl": "/docs/data-science/notes/aic-bic.html"
  },"21": {
    "doc": "AIC and BIC",
    "title": "Akaike Information Criterion (AIC)",
    "content": "AIC assesses goodness of fit of a model based on maximum likelihood. $$ \\text{AIC} = -2 \\log L^\\ast + 2p $$ . | $L^\\ast$: Maximized likelihood of the model | $p$: Number of parameters in the model | . Lower AIC values indicate better models. If likelihood is maximized, AIC is minimized. $2p$ is a penalty on complexity. ",
    "url": "/docs/data-science/notes/aic-bic.html#akaike-information-criterion-aic",
    
    "relUrl": "/docs/data-science/notes/aic-bic.html#akaike-information-criterion-aic"
  },"22": {
    "doc": "AIC and BIC",
    "title": "When Error is Normally Distributed",
    "content": "We know that OLS estimator is equivalent to MLE when the error is normally distributed. Therefore, Mallows’ $C_p$ is almost equivalent to AIC when the error is normally distributed (they differ by some constant factors). ",
    "url": "/docs/data-science/notes/aic-bic.html#when-error-is-normally-distributed",
    
    "relUrl": "/docs/data-science/notes/aic-bic.html#when-error-is-normally-distributed"
  },"23": {
    "doc": "AIC and BIC",
    "title": "Bayesian Information Criterion (BIC)",
    "content": "BIC is similar to AIC but has a stronger penalty on complexity when the sample size is large. $$ \\text{BIC} = -2 \\log L^\\ast + p \\log n $$ . | $L^\\ast$: Maximized likelihood of the model | $p$: Number of parameters in the model | . Lower BIC values indicate better models. ",
    "url": "/docs/data-science/notes/aic-bic.html#bayesian-information-criterion-bic",
    
    "relUrl": "/docs/data-science/notes/aic-bic.html#bayesian-information-criterion-bic"
  },"24": {
    "doc": "AIC and BIC",
    "title": "Special case",
    "content": "Similar to AIC, when the error is normally distributed, BIC is equivalent to: . $$ \\text{BIC} = \\frac{1}{n} \\left( \\text{RSS} + \\log(n)p\\sigma^2 \\right) $$ . Where $\\sigma^2$ is the variance of the error term. Notice that it is very similar to Mallows’ $C_p$. But since it places a stronger penalty on complexity when $n$ is large, it tends to select simpler models than $C_p$. ",
    "url": "/docs/data-science/notes/aic-bic.html#special-case",
    
    "relUrl": "/docs/data-science/notes/aic-bic.html#special-case"
  },"25": {
    "doc": "Angles and Orthogonality",
    "title": "Angles and Orthogonality",
    "content": ". | Angle Between Vectors | Orthogonality . | Orthonormal | . | Orthogonal Matrix . | Inverse of Orthogonal Matrix | Orthogonal Transformation | Determinant of Orthogonal Matrix | . | Orthonormal Basis . | Finding Orthonormal Basis | Gram-Schmidt Process | . | . ",
    "url": "/docs/linalg/basics/angles-orthogonality.html",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html"
  },"26": {
    "doc": "Angles and Orthogonality",
    "title": "Angle Between Vectors",
    "content": "Cauchy-Schwarz Inequality states that induced norms satisfy the following inequality: . \\[|\\langle\\mathbf{x},\\mathbf{y}\\rangle| \\leq \\|\\mathbf{x}\\| \\|\\mathbf{y}\\|\\] From this inequality, we can derive the following: . \\[-1 \\leq \\frac{\\langle\\mathbf{x},\\mathbf{y}\\rangle}{\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|} \\leq 1\\] Remember that for $\\omega \\in [0, \\pi]$, $\\cos \\omega$ ranges from $-1$ to $1$. So there exists $\\omega \\in [0, \\pi]$ such that . $$ \\cos \\omega = \\frac{\\langle\\mathbf{x},\\mathbf{y}\\rangle}{\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|} $$ . When our inner product is the dot product, this $\\omega$ is the geometric (or Euclidean) angle between $\\mathbf{x}$ and $\\mathbf{y}$. ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#angle-between-vectors",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#angle-between-vectors"
  },"27": {
    "doc": "Angles and Orthogonality",
    "title": "Orthogonality",
    "content": "Two vectors $\\mathbf{x}$ and $\\mathbf{y}$ are orthogonal, denoted as $\\mathbf{x} \\perp \\mathbf{y}$, if their inner product is zero: . $$ \\langle\\mathbf{x},\\mathbf{y}\\rangle = 0 \\iff \\mathbf{x} \\perp \\mathbf{y} $$ . Zero vector is orthogonal to every vector. Remember that orthogonality is respect to a specific inner product. ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#orthogonality",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#orthogonality"
  },"28": {
    "doc": "Angles and Orthogonality",
    "title": "Orthonormal",
    "content": "In addition to being orthogonal, two vectors $\\mathbf{x}$ and $\\mathbf{y}$ are orthonormal if they are unit vectors: . $$ \\langle\\mathbf{x},\\mathbf{y}\\rangle = 0 \\wedge \\|\\mathbf{x}\\| = \\|\\mathbf{y}\\| = 1 $$ . ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#orthonormal",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#orthonormal"
  },"29": {
    "doc": "Angles and Orthogonality",
    "title": "Orthogonal Matrix",
    "content": "A square matrix $A$ is orthogonal if and only if its columns are orthonormal. In other words, . $$ \\mathbf{A}^T \\mathbf{A} = \\mathbf{I} = \\mathbf{A} \\mathbf{A}^T $$ . By convention, we say orthogonal matrix, but it is actually orthonormal matrix. ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#orthogonal-matrix",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#orthogonal-matrix"
  },"30": {
    "doc": "Angles and Orthogonality",
    "title": "Inverse of Orthogonal Matrix",
    "content": "The above definition implies that . $$ \\mathbf{A}^{-1} = \\mathbf{A}^T $$ . ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#inverse-of-orthogonal-matrix",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#inverse-of-orthogonal-matrix"
  },"31": {
    "doc": "Angles and Orthogonality",
    "title": "Orthogonal Transformation",
    "content": "Suppose an orthogonal matrix $\\mathbf{A}$ is a transformation matrix of some linear transformation. Then, for any $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$, this transformation preserves the inner product and is called an orthogonal transformation: . $$ \\langle\\mathbf{A}\\mathbf{x},\\mathbf{A}\\mathbf{y}\\rangle = \\langle\\mathbf{x},\\mathbf{y}\\rangle $$ . Because orthogonal transformation preserves the inner product, it also preserves the length of vectors and the angle between vectors. $$ \\|\\mathbf{A}\\mathbf{x}\\| = \\|\\mathbf{x}\\| \\wedge \\frac{\\langle\\mathbf{A}\\mathbf{x},\\mathbf{A}\\mathbf{y}\\rangle} {\\|\\mathbf{A}\\mathbf{x}\\| \\|\\mathbf{A}\\mathbf{y}\\|} = \\frac{\\langle\\mathbf{x},\\mathbf{y}\\rangle} {\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|} $$ . ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#orthogonal-transformation",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#orthogonal-transformation"
  },"32": {
    "doc": "Angles and Orthogonality",
    "title": "Determinant of Orthogonal Matrix",
    "content": "If $A$ is an orthogonal matrix, its determinant is: . $$ \\lvert\\det(\\mathbf{A})\\rvert = 1 $$ . Why is the absolute value 1? \\[\\begin{align*} \\det(I) &amp;= \\det(A^\\top A) \\tag*{Definition of orthogonal matrix} \\\\ &amp;= \\det(A^\\top)\\det(A) \\tag*{Multiplicativity of determinant} \\\\ &amp;= \\det(A)\\det(A) \\tag*{Property of determinant} \\\\ &amp;= 1 \\tag*{Determinant of identity matrix} \\end{align*}\\] Therefore, $\\det(A) = \\pm 1$. ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#determinant-of-orthogonal-matrix",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#determinant-of-orthogonal-matrix"
  },"33": {
    "doc": "Angles and Orthogonality",
    "title": "Orthonormal Basis",
    "content": "Review the concepts of basis here. Let $V$ be an n-dimensional inner product space with basis $B = \\{\\mathbf{b}_1, \\dots, \\mathbf{b}_n\\}$. $B$ is an orthonormal basis if: . $$ \\begin{cases} \\langle\\mathbf{b}_i, \\mathbf{b}_j\\rangle = 0 &amp; \\text{if } i \\neq j \\\\[1em] \\langle\\mathbf{b}_i, \\mathbf{b}_i\\rangle = 1 &amp; (\\|\\mathbf{b}_i\\| = 1) \\end{cases} $$ . If only the first condition is satisfied, then $B$ is an orthogonal basis. ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#orthonormal-basis",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#orthonormal-basis"
  },"34": {
    "doc": "Angles and Orthogonality",
    "title": "Finding Orthonormal Basis",
    "content": "Given a set of non-orthonormal basis vectors $\\tilde{B}$, we can construct an orthonormal basis $B$ by performing Gaussian elimination on . \\[[\\tilde{B} \\tilde{B}^T \\mid \\tilde{B}]\\] ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#finding-orthonormal-basis",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#finding-orthonormal-basis"
  },"35": {
    "doc": "Angles and Orthogonality",
    "title": "Gram-Schmidt Process",
    "content": "To be added . Given a set of linearly independent vectors $\\{\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_n\\}$, there exists an orthogonal set $\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n\\}$ such that . \\[\\operatorname{span}(\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_n) = \\operatorname{span}(\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n)\\] and the process to find such $\\boldsymbol{v}_i$ is called the Gram-Schmidt process. By additionally normalizing $\\boldsymbol{v}_i$, we can also find an orthonormal set. Which leads to the following: . Every vector space has an orthonormal basis, because we can always turn any basis into an orthonormal basis. ",
    "url": "/docs/linalg/basics/angles-orthogonality.html#gram-schmidt-process",
    
    "relUrl": "/docs/linalg/basics/angles-orthogonality.html#gram-schmidt-process"
  },"36": {
    "doc": "Analysis of Variance",
    "title": "Analysis of Variance (ANOVA)",
    "content": ". | General Idea of ANOVA . | Predictor and Response Variables | Omnibus Test | . | F-Statistic (For One-Way ANOVA) . | Sum of Squares . | Total Sum of Squares (SS) | Sum of Squares Between (SSB) | Sum of Squares Within (SSW) | . | Mean Square . | Mean Square Between (MSB) | Mean Square Error (MSE) | . | F-Statistic | . | One-Way ANOVA . | F-Test | One-Way ANOVA Summary Table | . | Two-Way ANOVA | . ",
    "url": "/docs/statistics/basics/anova.html#analysis-of-variance-anova",
    
    "relUrl": "/docs/statistics/basics/anova.html#analysis-of-variance-anova"
  },"37": {
    "doc": "Analysis of Variance",
    "title": "General Idea of ANOVA",
    "content": "ANOVA is a hypothesis test that compares the means of three or more groups. Just like how t-tests use the t-statistics, ANOVA uses the F-test/F-statistic to compare the means of the groups. ANOVA is a parametric test on quantitative data. ",
    "url": "/docs/statistics/basics/anova.html#general-idea-of-anova",
    
    "relUrl": "/docs/statistics/basics/anova.html#general-idea-of-anova"
  },"38": {
    "doc": "Analysis of Variance",
    "title": "Predictor and Response Variables",
    "content": "You can think of ANOVA as a comparison of effects of different factors. | Categorical predictor variable: the variable that is manipulated and independent | Continuous response variable: the variable that is measured and dependent | . The type of ANOVA depends on the number of predictor variables (input / factor of influence) and the number of response variables (output / data measured). ",
    "url": "/docs/statistics/basics/anova.html#predictor-and-response-variables",
    
    "relUrl": "/docs/statistics/basics/anova.html#predictor-and-response-variables"
  },"39": {
    "doc": "Analysis of Variance",
    "title": "Omnibus Test",
    "content": "ANOVA is an omnibus test, meaning it tests for the overall. We would know that at least one pair of means are different, but it doesn’t tell us exactly which pair of means are different. We need to perform post-hoc test to find the specific pair. ",
    "url": "/docs/statistics/basics/anova.html#omnibus-test",
    
    "relUrl": "/docs/statistics/basics/anova.html#omnibus-test"
  },"40": {
    "doc": "Analysis of Variance",
    "title": "F-Statistic (For One-Way ANOVA)",
    "content": "The exact formulas for the F-statistic is tailored for one-way ANOVA. However, the general feel of the F-statistic is the same for all ANOVA tests. When there are multiple groups, we have two different sources of variation: . | Variation between groups | Variation within groups | . The F-statistic for ANOVA uses the ratio of these two variations: . $$ \\frac{\\text{Average variation between groups}}{\\text{Average variation within groups}} $$ . The above figure illustrates the logic behind the F-statistic. Say the red bar is the calculated mean of the data, and the blue dots are scattered data points around the mean. Between situation A and B, in which situtation does the difference between the two means seem more significant? . It is clear that the difference is more prominent in situation B, because there is more variation between the red bar, and less variation within the blue dots. This ratio makes their differences seem clear, and this is roughly what the F-statistic is trying to measure. Hence, if the F-statistic is large, it means the difference between the groups is more significant. ",
    "url": "/docs/statistics/basics/anova.html#f-statistic-for-one-way-anova",
    
    "relUrl": "/docs/statistics/basics/anova.html#f-statistic-for-one-way-anova"
  },"41": {
    "doc": "Analysis of Variance",
    "title": "Sum of Squares",
    "content": "The F-statistic is calculated using the sum of squares. Let us first define the following: . | $k$: number of groups | $n_j$: number of data points in group $j$ | $n$: sum of $n_j$ for all $j$ | $x_{ij}$: $i$th data point in group $j$ | $\\bar{x}_j$: sample mean of group $j$ | $\\bar{x}$: mean of all data points (overall mean) | . Total Sum of Squares (SS) . Total sum of squares is the sum of squared differences between each data point and the overall mean: . $$ SS_{Total} = \\sum_{j=1}^k \\sum_{i=1}^{n_j} (x_{ij} - \\bar{x})^2 $$ . $SS_{Total}$ can be decomposed into two parts: . $$ SS_{Total} = SS_{Between} + SS_{Within} $$ . Sum of Squares Between (SSB) . Sum of squares between is the sum of squared differences between each group mean and the overall mean: . $$ \\begin{equation*} \\label{eq:ssb} \\tag{SSB} SS_{Between} = \\sum_{j=1}^k \\sum_{i=1}^{n_j} (\\bar{x}_j - \\bar{x})^2 = \\sum_{j=1}^k n_j (\\bar{x}_j - \\bar{x})^2 \\end{equation*} $$ . Sum of Squares Within (SSW) . Sum of squares within is the sum of squared differences between each data point and its group mean: . $$ \\begin{equation*} \\label{eq:ssw} \\tag{SSW} SS_{Within} = \\sum_{j=1}^k \\sum_{i=1}^{n_j} (x_{ij} - \\bar{x}_j)^2 \\end{equation*} $$ . This is also known as the residual sum of squares or the error sum of squares. ",
    "url": "/docs/statistics/basics/anova.html#sum-of-squares",
    
    "relUrl": "/docs/statistics/basics/anova.html#sum-of-squares"
  },"42": {
    "doc": "Analysis of Variance",
    "title": "Mean Square",
    "content": "But we cannot compare the sum of squares directly. Because the sum becomes larger as the sample size increases, we want to take the sample size into account to make the comparison more meaningful. We instead use a modified version called mean square, which is the sum of squares divided by the degrees of freedom. Mean Square Between (MSB) . The degrees of freedom for $\\eqref{eq:ssb}$ is $k-1$. Very roughly, think of this as: the outcome of this formula is already fixed, there’s an overall mean, and we have $k$ group means that affect the overall mean. We are free to choose $k-1$ of the group means, but the last group mean is determined by the rest. Therefore, the mean square between is: . $$ MSB = \\frac{SS_{Between}}{k-1} $$ . Mean Square Error (MSE) . The degrees of freedom for $\\eqref{eq:ssw}$ is $n-k$. Again, roughly we are using all $n$ data points, but the $k$ group means are determined by the $n$ data points. So we lose $k$ degrees of freedom. $$ MSE = \\frac{SS_{Within}}{n-k} $$ . ",
    "url": "/docs/statistics/basics/anova.html#mean-square",
    
    "relUrl": "/docs/statistics/basics/anova.html#mean-square"
  },"43": {
    "doc": "Analysis of Variance",
    "title": "F-Statistic",
    "content": "The F-value is calculated as follows: . $$ F = \\frac{MSB}{MSE} $$ . Now we compare this F-value to the F-distribution (with $k-1$ and $n-k$ degrees of freedom) to obtain the p-value. ",
    "url": "/docs/statistics/basics/anova.html#f-statistic",
    
    "relUrl": "/docs/statistics/basics/anova.html#f-statistic"
  },"44": {
    "doc": "Analysis of Variance",
    "title": "One-Way ANOVA",
    "content": " ",
    "url": "/docs/statistics/basics/anova.html#one-way-anova",
    
    "relUrl": "/docs/statistics/basics/anova.html#one-way-anova"
  },"45": {
    "doc": "Analysis of Variance",
    "title": "Why is it called “one-way”?",
    "content": "It is called “one-way” because this test deals with data with a single factor of influence (predictor variable). For example, if we wanted to compare the effects of three different fertilizers on plant growth, type of fertilizers will be the single predictor variable and plant height will be the response variable. Notice that the predictor is categorical. Each subject (e.g. plant) is allocated to one and only one group (e.g. fertilizer). ",
    "url": "/docs/statistics/basics/anova.html#why-is-it-called-one-way",
    
    "relUrl": "/docs/statistics/basics/anova.html#why-is-it-called-one-way"
  },"46": {
    "doc": "Analysis of Variance",
    "title": "Assumptions",
    "content": "One-way ANOVA requires the following assumptions: . | Continuous dependent variable: the dependent variable is continuous (quantitative) | Categorial independent variable: no overlapping subjects between groups | No significant outliers: must be accounted for | Normality: each dependent variable is approximately normal . | Although one-way ANOVA is robust to violations of normality to a certain degree, it is still a good idea to check the normality of the residuals | . | Equal variance: each dependent variable has the same variance | . ",
    "url": "/docs/statistics/basics/anova.html#assumptions",
    
    "relUrl": "/docs/statistics/basics/anova.html#assumptions"
  },"47": {
    "doc": "Analysis of Variance",
    "title": "F-Test",
    "content": "Given $k$ groups, one-way ANOVA tests the following null hypothesis: . $$ H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_k $$ . In this case, the alternative hypothesis is: . $$ \\text{At least one pair of means are significantly different} $$ . When the null hypothesis true, the F-statistic follows the F-distribution with $k-1$ and $n-k$ degrees of freedom. When our null hypothesis is true (the groups are not significantly different), two variations are approximately equal so the F-ratio will be closer to 1. Hence the peak of the F-distribution is at $\\le 1$ (1 ideally, but slightly less than 1 for small degrees of freedom), and being further away to the right means the groups are more significantly different. We place the F-value on the F-distribution and calculate the p-value. ",
    "url": "/docs/statistics/basics/anova.html#f-test",
    
    "relUrl": "/docs/statistics/basics/anova.html#f-test"
  },"48": {
    "doc": "Analysis of Variance",
    "title": "One-Way ANOVA Summary Table",
    "content": "Typically, we use the following table to summarize the results of ANOVA: . These results from ANOVA are often reused in post-hoc tests. ",
    "url": "/docs/statistics/basics/anova.html#one-way-anova-summary-table",
    
    "relUrl": "/docs/statistics/basics/anova.html#one-way-anova-summary-table"
  },"49": {
    "doc": "Analysis of Variance",
    "title": "Two-Way ANOVA",
    "content": "To be added . ",
    "url": "/docs/statistics/basics/anova.html#two-way-anova",
    
    "relUrl": "/docs/statistics/basics/anova.html#two-way-anova"
  },"50": {
    "doc": "Analysis of Variance",
    "title": "Why is it called “two-way”?",
    "content": "It is called “two-way” because this test deals with data with two factors of influence (predictor variables). For example, if we wanted to compare the effects of three different fertilizers and two different types of soil on plant growth, type of fertilizers and type of soil will be the predictor variables, and plant height will be the response variable. ",
    "url": "/docs/statistics/basics/anova.html#why-is-it-called-two-way",
    
    "relUrl": "/docs/statistics/basics/anova.html#why-is-it-called-two-way"
  },"51": {
    "doc": "Analysis of Variance",
    "title": "Assumptions",
    "content": "Same as one-way ANOVA. ",
    "url": "/docs/statistics/basics/anova.html#assumptions-1",
    
    "relUrl": "/docs/statistics/basics/anova.html#assumptions-1"
  },"52": {
    "doc": "Analysis of Variance",
    "title": "Analysis of Variance",
    "content": " ",
    "url": "/docs/statistics/basics/anova.html",
    
    "relUrl": "/docs/statistics/basics/anova.html"
  },"53": {
    "doc": "Autoregressive (AR) Model",
    "title": "Autoregressive (AR) Model",
    "content": "As the name suggests, autoregressive (AR) models are based on the idea that future values can be predicted from past values. | Univariate autoregressive model . | $AR(1)$ | Lag operator | $AR(p)$ | . | . ",
    "url": "/docs/data-science/notes/ar-model.html",
    
    "relUrl": "/docs/data-science/notes/ar-model.html"
  },"54": {
    "doc": "Autoregressive (AR) Model",
    "title": "Univariate autoregressive model",
    "content": " ",
    "url": "/docs/data-science/notes/ar-model.html#univariate-autoregressive-model",
    
    "relUrl": "/docs/data-science/notes/ar-model.html#univariate-autoregressive-model"
  },"55": {
    "doc": "Autoregressive (AR) Model",
    "title": "$AR(1)$",
    "content": "The simplest AR model is the $AR(1)$ where the $1$ indicates a lag of $1$ time step: . \\[y_t = \\phi_0 + \\phi_1 y_{t-1} + \\varepsilon_t\\] where $\\varepsilon_t$ is the white noise term with constant variance. We calculate the expected value and variance of $y_t$ given $y_{t-1}$: . \\[\\begin{gather*} \\E[y_t \\mid y_{t-1}] = \\phi_0 + \\phi_1 y_{t-1} + \\varepsilon_t \\\\[1em] \\Var[y_t \\mid y_{t-1}] = \\Var[\\varepsilon_t] = \\sigma_\\varepsilon^2 \\end{gather*}\\] ",
    "url": "/docs/data-science/notes/ar-model.html#ar1",
    
    "relUrl": "/docs/data-science/notes/ar-model.html#ar1"
  },"56": {
    "doc": "Autoregressive (AR) Model",
    "title": "Lag operator",
    "content": "Lag operator (denoted by $L$) is a convenient notation for autoregressive models. It is also called a backshift operator and is denoted by $B$ in some literature. The lag operator can be raised to an arbitrary power $k$ to indicate a time series lagged by $k$ time steps: . $$ L^k y_t = y_{t-k} $$ . ",
    "url": "/docs/data-science/notes/ar-model.html#lag-operator",
    
    "relUrl": "/docs/data-science/notes/ar-model.html#lag-operator"
  },"57": {
    "doc": "Autoregressive (AR) Model",
    "title": "$AR(p)$",
    "content": "The general form of $AR(p)$ (read “AR model of order $p$”) is: . $$ y_t = \\sum_{i=1}^p \\phi_i y_{t-i} + \\varepsilon_t $$ . We often simplify the notation by using the lag polynomial notation: . $$ \\phi(L) y_t = \\varepsilon_t $$ . Polynomial notation \\[\\begin{gather*} y_t = \\sum_{i=1}^p \\phi_i y_{t-i} + \\varepsilon_t \\\\[1em] y_t - \\sum_{i=1}^p \\phi_i y_{t-i} = \\varepsilon_t \\\\[1em] (1 - \\sum_{i=1}^p \\phi_i L^i) y_t = \\varepsilon_t \\\\[1em] \\phi(L) y_t = \\varepsilon_t \\end{gather*}\\] ",
    "url": "/docs/data-science/notes/ar-model.html#arp",
    
    "relUrl": "/docs/data-science/notes/ar-model.html#arp"
  },"58": {
    "doc": "Asymptotically Optimal (Efficient)",
    "title": "Asymptotically Optimal (Efficient)",
    "content": ". | Asymptotic Relative Efficiency (ARE) | . ",
    "url": "/docs/statistics/notes/asymptotically-optimal.html",
    
    "relUrl": "/docs/statistics/notes/asymptotically-optimal.html"
  },"59": {
    "doc": "Asymptotically Optimal (Efficient)",
    "title": "Asymptotic Relative Efficiency (ARE)",
    "content": "When we have two estimators $T_n$ and $U_n$ for the same parameter, we can compare their variances to see which one is more efficient. Obviously, the smaller the variance, the better the estimator. The asymptotic relative efficiency (ARE) of $U_n$ to $T_n$ is defined as: . $$ \\text{ARE}(U_n, T_n) = \\frac{\\Var(T_n)}{\\Var(U_n)} $$ . If $\\text{ARE}(U_n, T_n) \\leq 1$, then $T_n$ is more efficient than $U_n$. ",
    "url": "/docs/statistics/notes/asymptotically-optimal.html#asymptotic-relative-efficiency-are",
    
    "relUrl": "/docs/statistics/notes/asymptotically-optimal.html#asymptotic-relative-efficiency-are"
  },"60": {
    "doc": "Autocorrelation",
    "title": "Autocorrelation",
    "content": ". | What is autocorrelation? | ACF and PACF . | Autocorrelation Function (ACF) . | Periodicity of ACF . | Additive property | . | Identifying stationarity with ACF | Statistical significance of sample ACF . | Standard normal white noise | General hypothesis test | . | . | Partial Autocorrelation Function (PACF) . | PACF is not periodic | Identifying non-stationarity with PACF | Statistical significance of sample PACF | . | . | . ",
    "url": "/docs/data-science/notes/autocorrelation.html",
    
    "relUrl": "/docs/data-science/notes/autocorrelation.html"
  },"61": {
    "doc": "Autocorrelation",
    "title": "What is autocorrelation?",
    "content": "Autocorrelation is a measure of how correlated a time series data is with the lagged version of itself. While regular correlation measure the relationship between two different variables, autocorrelation measures the relationship between variables $X_t$ and $X_{t-k}$, where $k$ is the lag. \\[\\rho(k) = \\frac{\\Cov[X_t, X_{t-k}]}{\\sqrt{\\Var[X_t] \\Var[X_{t-k}]}}\\] But assuming that the process is stationary (i.e. mean and variance are constant), the autocorrelation can be simplified to: . $$ \\rho(k) = \\frac{\\Cov[X_t, X_{t-k}]}{\\Var[X_t]} $$ . ",
    "url": "/docs/data-science/notes/autocorrelation.html#what-is-autocorrelation",
    
    "relUrl": "/docs/data-science/notes/autocorrelation.html#what-is-autocorrelation"
  },"62": {
    "doc": "Autocorrelation",
    "title": "ACF and PACF",
    "content": "Correlogram . ",
    "url": "/docs/data-science/notes/autocorrelation.html#acf-and-pacf",
    
    "relUrl": "/docs/data-science/notes/autocorrelation.html#acf-and-pacf"
  },"63": {
    "doc": "Autocorrelation",
    "title": "Autocorrelation Function (ACF)",
    "content": "Autocorrelation Function (ACF) is autocorrelation as a function of lagged difference. So obviously, at lag $0$, ACF is always $1$. This trivial result is disregarded. ACF includes both direct correlation and indirect/conditional correlation between $X_t$ and $X_{t-k}$. For example, in calculation of ACF for lag $2$, the direct correlation between $X_t$ and $X_{t-2}$, as well as the indirect correlation between $X_t$ and $X_{t-1}$ and between $X_{t-1}$ and $X_{t-2}$, all contribute to the ACF. ACF is symmetric for positive and negative lags, so only positive lags are plotted. Periodicity of ACF . ACF of a periodic process has the same periodicity as the original process. Therefore there can be repeating patterns in ACF (take a look at the correlogram above). Additive property . For two periodic process $X_t$ and $Y_t$, $ACF(X_t + Y_t) = ACF(X_t) + ACF(Y_t)$. Identifying stationarity with ACF . For stationary process, ACF quickly decays to $0$ as lag increases. If it does not, the process is non-stationary. In that case you should try things like plotting the ACF of the differenced data (remove trend). Statistical significance of sample ACF . Correlograms are often plotted with bands which indicate the critical values for statistical significance of AC. Due to randomness in the data, we rarely get exactly zero for AC. Even for white noise data, we get non-zero values even though there is no autocorrelation between the data points. Therefore, for some significance level, ACs that fall within the confidence interval are considered to be $0$ and thus not statistically significant. Standard normal white noise . For standard normal white noise . \\[X_t \\sim \\mathcal{N}(0, 1)\\] theoretically AC is expected to be $0$. So the 95 confidence interval for AC is . \\[0 \\pm {1.96} \\times \\frac{1}{\\sqrt{n}}\\] where $n$ is the sample size or the length of time series. Although this calculation is based on the assumptions of standard normality (standard error of the mean is $\\frac{1}{\\sqrt{n}}$), seems like it is quite often used as a test of randomness on other time series data as well. Without enough sample size, this test becomes too conservative. General hypothesis test . In general, the statistical significance of AC under the null hypothesis that AC is zero (there is no correlation) and significance level $\\alpha$ is estimated with: . $$ \\pm z_{\\alpha/2} \\times SE(\\hat{\\rho}(k)) $$ . where $\\hat{\\rho}(k)$ is the sample autocorrelation at lag $k$. The standard error depends on the actual sample AC of the data and there are approximation methods to estimate it. These are usually represented by shaded areas in ACF plots. ",
    "url": "/docs/data-science/notes/autocorrelation.html#autocorrelation-function-acf",
    
    "relUrl": "/docs/data-science/notes/autocorrelation.html#autocorrelation-function-acf"
  },"64": {
    "doc": "Autocorrelation",
    "title": "Partial Autocorrelation Function (PACF)",
    "content": "Partial Autocorrelation Function (PACF) is basically ACF with the indirect/conditional correlation removed. Unlike ACF, PACF only considers the direct correlation between $X_t$ and $X_{t-k}$. PACF controls other intermediate lags by including them as regressors. For example, for lag $2$, PACF fits the following regression model: . \\[y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\epsilon_t\\] Then outpus $\\beta_2$ as the PACF for lag $2$, the direct effect of $y_{t-2}$ on $y_t$. Because of this, PACF is used as a heuristic to determine the order of AR models. However, this heuristic can be used only if data is stationary. For data with a lot of random noise, PACF gets harder to interpret because it won’t diminish. PACF is not periodic . Unlike ACF which carries the periodicity of the original process, PACF does not carry this redundancy. Therefore sum of two periodic processes is not additive unlike ACF. Identifying non-stationarity with PACF . For a trending non-stationary process, the value at lag $1$ is often positive and large and the values at other lags are not statistically significant. This can be interpreted as that the only thing affecting each data point is the previous data point. The previous point contains all the information that is needed to predict the next point, which typically indicates a trend. Statistical significance of sample PACF . It is calculated in the same way as ACF. ",
    "url": "/docs/data-science/notes/autocorrelation.html#partial-autocorrelation-function-pacf",
    
    "relUrl": "/docs/data-science/notes/autocorrelation.html#partial-autocorrelation-function-pacf"
  },"65": {
    "doc": "AWS CLI",
    "title": "AWS CLI",
    "content": ". | Install | Set up AWS CLI . | Configure credentials | Show configuration | . | Upload file to S3 | . ",
    "url": "/docs/aws/aws-cli.html",
    
    "relUrl": "/docs/aws/aws-cli.html"
  },"66": {
    "doc": "AWS CLI",
    "title": "Install",
    "content": "brew install awscli . ",
    "url": "/docs/aws/aws-cli.html#install",
    
    "relUrl": "/docs/aws/aws-cli.html#install"
  },"67": {
    "doc": "AWS CLI",
    "title": "Set up AWS CLI",
    "content": "Configure credentials . To create a named profile: . $ aws configure --profie ${profile_name} AWS Access Key ID [None]: ... AWS Secret Access Key [None]: ... Default region name [None]: ... Default output format [None]: json . You can create multiple profiles. Your configuration is saved in two files: ~/.aws/config and ~/.aws/credentials. To modify an existing profile you can either modify it directly in the files or use the aws configure command again: . $ aws configure set region ${value_to_set} --profile ${profile_name} . Show configuration . To see the list of all profiles: . aws configure list-profiles . To see the configuration of a specific profile: . aws configure list --profile ${profile_name} . To see the value of a specific variable of a specific profile: . aws configure get region --profile ${profile_name} . ",
    "url": "/docs/aws/aws-cli.html#set-up-aws-cli",
    
    "relUrl": "/docs/aws/aws-cli.html#set-up-aws-cli"
  },"68": {
    "doc": "AWS CLI",
    "title": "Upload file to S3",
    "content": "To upload a folder to a subdirectory in a bucket: . aws s3 cp ${dir_name} s3://${bucket_name}/${sub_dir}/${dir_name} --recursive --profile ${profile} . References: . | AWS CLI: Named profiles | AWS CLI: Configuration and credential file settings | . ",
    "url": "/docs/aws/aws-cli.html#upload-file-to-s3",
    
    "relUrl": "/docs/aws/aws-cli.html#upload-file-to-s3"
  },"69": {
    "doc": "Basic Preprocessing",
    "title": "Basic Time Series Preprocessing",
    "content": ". | Missing Data . | Different types of missing data . | Random | Systematic | . | Common ways to handle missing data . | Imputation . | Forward fill | Moving average (MA) | Interpolation | . | Delete data with missing values | . | . | Downsampling and Upsampling . | Downsampling . | Reasons to downsample . | Redundant recordings | Focus on a specific time scale | Match frequency to other data | . | . | Upsampling . | Reasons to upsample . | Irregularly sampled data | To match frequency to other data | Prior knowledge about data | . | . | . | Smoothing Data . | Reasons to smooth data . | Visualization | Data preparation | Feature generation | Prediction . | Mean reversion | . | . | Methods to smooth data . | Moving average | Exponential smoothing | Other methods | . | . | Dealing with Seasonality | Beware of Time Zones | Beware of Lookahead | . ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#basic-time-series-preprocessing",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#basic-time-series-preprocessing"
  },"70": {
    "doc": "Basic Preprocessing",
    "title": "Missing Data",
    "content": "It is quite common to have missing data due to the longitudinal nature of time series data. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#missing-data",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#missing-data"
  },"71": {
    "doc": "Basic Preprocessing",
    "title": "Different types of missing data",
    "content": "Random . Could occur due to multiple reasons: . | Recording malfunction | Human error | Data corruption | Unforeseen circumstances… | . Systematic . Could occur due to multiple reasons: . | Defined events (i.e. holidays) | Data collection process (i.e. only weekdays) | Policy and regulations | Basically on purpose… | . ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#different-types-of-missing-data",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#different-types-of-missing-data"
  },"72": {
    "doc": "Basic Preprocessing",
    "title": "Common ways to handle missing data",
    "content": "Imputation . Most common way to fix missing data. Depending on the type of missing data (random or systematic), each following method shows different performance. Whether you include future values in imputation also impacts performance, but needs caution due to lookahead. Forward fill . Fill with the last known value before the missing value. Pros: . | Computationally cheap | Can be easily applied to live-streamed data | . Cons: . | Susceptible to introducing unwanted noise / outliers | . Backward fill goes the opposite way. However, since it is a case of lookahead, it should not be used for prediction training and be used only if it makes sense via domain knowledge. Moving average (MA) . Fill with the average of some window of values near the missing value. Calculation is not limited to arithmetic mean. It can be weighted, geometric, etc. It is also called rolling mean. Whether the window should include future values is up to discretion. Including future values is a case of lookahead, but it does improve the estimation of the missing value. One suggestion is to include future values for visualization and exploration, but exclude them for prediction training. Pros: . | Good for noisy data | . Cons: . | Moving average reduces variance. So it must be kept in mind when evaluating model accuracy with $R^2$ or other error statistics because it leads to overestimation of model performance. | . Using total mean to fill missing values is often not a good choice for time series data although it is common for some other data analysis. Also, it is again a case of a lookahead. Interpolation . Using nearby neighbors to decide how missing point should behave. What defines a neighbor is up to decision. For example, linear interpolation uses neighbors to constrain missing point to a linear fit. Just like moving average, you want to decide whether to include future values in imputation. Pros: . | Interpolation is especially useful if you know how the data behaves or prior knowledge about the data (e.g. trend, seasonality). | . Cons: . | If you don’t have prior knowledge or it doesn’t make sense to expect a known behavior, it’s not very helpful. | . When is interpolation better than moving average? As previously mentioned, interpolation is useful if you have prior knowledge. For example if you know there is an upward trend, using moving average will systematically underestimate the missing value. Interpolation can avoid this. Delete data with missing values . Aside from imputation, you could also decide not to use portions of data with missing values. It is not desirable because you would lose that much data, but it is a valid option if you have to patch up too many missing values. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#common-ways-to-handle-missing-data",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#common-ways-to-handle-missing-data"
  },"73": {
    "doc": "Basic Preprocessing",
    "title": "Downsampling and Upsampling",
    "content": " ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#downsampling-and-upsampling",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#downsampling-and-upsampling"
  },"74": {
    "doc": "Basic Preprocessing",
    "title": "Downsampling",
    "content": "Reasons to downsample . Redundant recordings . Redundant recordings with not much new information takes up storage space and processing time. Possible downsampling method is to select every $n$th data point. Focus on a specific time scale . For data with seasonal cycle, you may want to downsample to certain months (i.e. only January) to focus on the season of interest for your analysis. Match frequency to other data . If you have multiple time series data, analysis becomes difficult if they are recorded at varying frequencies. So you may choose to downsample to the lower frequency among the data. Rather than simply selecting and dropping points, it is better to perform aggregation (i.e. mean, sum, weighted mean etc.). ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#downsampling",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#downsampling"
  },"75": {
    "doc": "Basic Preprocessing",
    "title": "Upsampling",
    "content": "This is not exactly the opposite of downsampling, in the sense that you can’t really create new data points out of thin air. However, you can choose to label/timestamp data at a higher frequency than the original recording frequency. Beware of creating lookahead when upsampling. Reasons to upsample . Irregularly sampled data . If you want to convert irregularly sampled data to regularly sampled data, you can upsample the data by upsampling the lags between data points. To match frequency to other data . Same with downsampling, you may upsample to align data points. Prior knowledge about data . If you have prior knowledge about the data and you intend to upsample, you can use interpolation just like imputation. This would actually be in some sense “creating new data” unlike other upsampling methods. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#upsampling",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#upsampling"
  },"76": {
    "doc": "Basic Preprocessing",
    "title": "Smoothing Data",
    "content": "Smoothing is related to imputing missing data, so some of the methods (like moving average) apply when smoothing data. In addition, you must be cautious about lookahead just like imputation. It is a good idea to check that smoothing does not compromise any assumptions your model may have (i.e. model assumes noisy data). ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#smoothing-data",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#smoothing-data"
  },"77": {
    "doc": "Basic Preprocessing",
    "title": "Reasons to smooth data",
    "content": "Visualization . | Most trivial reason | To understand the data better before analysis | . Data preparation . | Eliminate noise and outliers (i.e. via moving average). | Remove seasonality | . Feature generation . | In order to effectively summarize data, you may want to smooth or essentially simplify the data to a lower dimension or a less complex form to generate characteristic features. | . Prediction . Simplest form of prediction comes from smoothing data. Mean reversion . Mean reversion is a financial theory that states that even though price seems to deviate in the short term, it eventually remains close to its long-term mean. So if you smooth a wave-like time series data, you would get a line and you could predict that future price will remain near that line. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#reasons-to-smooth-data",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#reasons-to-smooth-data"
  },"78": {
    "doc": "Basic Preprocessing",
    "title": "Methods to smooth data",
    "content": "Moving average . See above . Exponential smoothing . It is similar to a weighted moving average, but it differs in that it gives more weight to recent data points and less weight to older data points. It also differs from moving average in that it uses all past data points (aggregated in a single forecast value) unlike moving average which uses only a window of data points. The simplest form of exponential smoothing is as follows: . Given some smoothing factor $\\alpha$, the simplest smoothed value $S_t$ at time $t$ is defined as: . $$ \\begin{cases} S_0 = y_0 \\\\[1em] S_t = \\alpha y_t + (1 - \\alpha) S_{t-1} \\end{cases} $$ . With direct substitution, this recursion expands to weights of . \\[1, 1 - \\alpha, (1 - \\alpha)^2, (1 - \\alpha)^3, \\dots\\] And past values are associated with higher order weights making them less significant. Hence the name exponential smoothing. Simple exponential smoothing doesn’t work well on data with a trend. Use Holt’s Method for data with trend and Holt-Winters for data with trend and seasonality. Other methods . | Kalman filter | LOESS (locally estimated scatterplot smoothing) | . Both are more computationally expensive and are cases of lookahead because they incorporate both past and future values. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#methods-to-smooth-data",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#methods-to-smooth-data"
  },"79": {
    "doc": "Basic Preprocessing",
    "title": "Dealing with Seasonality",
    "content": "Read more here . ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#dealing-with-seasonality",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#dealing-with-seasonality"
  },"80": {
    "doc": "Basic Preprocessing",
    "title": "Beware of Time Zones",
    "content": "Not much to say here, but beware of time zones because time zone, daylight savings, etc. can be a pain. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#beware-of-time-zones",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#beware-of-time-zones"
  },"81": {
    "doc": "Basic Preprocessing",
    "title": "Beware of Lookahead",
    "content": "During training or evaluation of a model, it is important to avoid using data that would not have been available at the time of the prediction. (If you already know the future, the prediction is gonna be easy, but that’s not what we want to do.) . Any knowledge of the future used in a model is called lookahead. If you have a lookahead you would find tht your model does not perform as well in real life as it did in training. Lookahead does not only pertain to calendar time. Some preprocessing steps such as imputing or smoothing may introduce lookahead, so you want to make sure if this is desirable for your purpose and make sure it is not used for prediction training. ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html#beware-of-lookahead",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html#beware-of-lookahead"
  },"82": {
    "doc": "Basic Preprocessing",
    "title": "Basic Preprocessing",
    "content": " ",
    "url": "/docs/data-science/time-series/basic-preprocessing.html",
    
    "relUrl": "/docs/data-science/time-series/basic-preprocessing.html"
  },"83": {
    "doc": "Basic Probability",
    "title": "Basic Probability Theory",
    "content": ". | Sample Spaces and Events . | Mutually Exclusive | Partition | . | Probability . | Interpretation of Probability | . | Random Variable | Probability Distribution . | Discrete Probability Distribution . | Probability Mass Function | . | Continuous Probability Distribution . | Probability Density Function | . | Cumulative Distribution Function . | Properties of CDF | . | . | Quantile Function | Expected Value . | Expected Value of Discrete Random Variable | Expected Value of Continuous Random Variable | . | Variance and Standard Deviation . | Variance of Discrete Random Variable | Variance of Continuous Random Variable | . | Joint Probability . | Independent Random Variables | Conditional Probability | . | Common Probability Distributions . | Normal Distribution (Gaussian Distribution) . | Characteristics of Normal Distribution | . | Standard Normal Distribution . | Z-Score | Z-Score Table | . | Others | . | . ",
    "url": "/docs/statistics/basics/basic-probs.html#basic-probability-theory",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#basic-probability-theory"
  },"84": {
    "doc": "Basic Probability",
    "title": "Sample Spaces and Events",
    "content": "The sample space is the set of all possible outcomes of an experiment. It is often denoted by $\\Omega$. Elements $\\omega \\in \\Omega$ are called realizations or outcomes. An event is a subset of the sample space. ",
    "url": "/docs/statistics/basics/basic-probs.html#sample-spaces-and-events",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#sample-spaces-and-events"
  },"85": {
    "doc": "Basic Probability",
    "title": "Mutually Exclusive",
    "content": "Let $A_i$ be events. Then $A_i$ are mutually exclusive or disjoint if: . $$ A_i \\cap A_j = \\emptyset \\quad \\forall i \\neq j $$ . Disjoint events are not the same as independent events. ",
    "url": "/docs/statistics/basics/basic-probs.html#mutually-exclusive",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#mutually-exclusive"
  },"86": {
    "doc": "Basic Probability",
    "title": "Partition",
    "content": "A partition of a sample space $\\Omega$ is a set of mutually exclusive events whose union is $\\Omega$: . $$ \\bigcup_{i} A_i = \\Omega $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#partition",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#partition"
  },"87": {
    "doc": "Basic Probability",
    "title": "Probability",
    "content": "Probability is a function that maps an event to a real number: $P: \\Omega \\rightarrow \\mathbb{R}$. In general, we use the following notation for probability of an event $A$: . $$ P(A) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#probability",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#probability"
  },"88": {
    "doc": "Basic Probability",
    "title": "Interpretation of Probability",
    "content": ". | Frequentist interpretation: The probability of an event is the limit of the relative frequency of the event as the number of trials goes to infinity. | Bayesian interpretation: The probability of an event is the degree of belief. | . ",
    "url": "/docs/statistics/basics/basic-probs.html#interpretation-of-probability",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#interpretation-of-probability"
  },"89": {
    "doc": "Basic Probability",
    "title": "Random Variable",
    "content": "Let $X$ be a random variable. Probability of $X$ taking a value $x$ is denoted by: . $$ P(X = x) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#random-variable",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#random-variable"
  },"90": {
    "doc": "Basic Probability",
    "title": "Probability Distribution",
    "content": "Let $X$ be a random variable. A probability distribution is a function that maps each value of $X$ to its probability. In inferential statistics, we assume a certain probability distribution for the population. Then the samples become random variables that follow the same probability distribution. ",
    "url": "/docs/statistics/basics/basic-probs.html#probability-distribution",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#probability-distribution"
  },"91": {
    "doc": "Basic Probability",
    "title": "Discrete Probability Distribution",
    "content": "The probability distribution of a discrete random variable $X$, is essentially the probability of each value of $X$. Probability Mass Function . The probability mass function (PMF) of a discrete variable $X$ is denoted by: . $$ p_{X}(x) $$ . This function maps each value of $X$ to its exact probability. For discrete random variables, the PMF is the probability distribution. $$ P(X = x) = p_{X}(x) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#discrete-probability-distribution",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#discrete-probability-distribution"
  },"92": {
    "doc": "Basic Probability",
    "title": "Continuous Probability Distribution",
    "content": "The probability distribution of a continuous random variable $X$, is the area under the curve of the probability density function (PDF) of $X$ for a given interval. Probability Density Function . The probability density function (PDF) of a continuous variable $X$ is denoted by . $$ f_{X}(x) $$ . The absolute probability of $X$ taking a specific value is zero, since there are infinitely many values that $X$ can take. Therefore, the PDF of $X$ is not an absolute probability, but a relative probability per unit range. Let $f_{X}(x)$ be the PDF of $X$. Then the probability that $X$ takes a value in the interval $[a, b]$ is: . $$ P(a \\leq X \\leq b) = \\int_{a}^{b} f_{X}(x) dx $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#continuous-probability-distribution",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#continuous-probability-distribution"
  },"93": {
    "doc": "Basic Probability",
    "title": "Cumulative Distribution Function",
    "content": "The cumulative distribution function (CDF) of a random variable $X$ is a non-decreasing function denoted by: . $$ F_{X}(x) = P(X \\leq x) $$ . CDF contains all the information about the probability distribution of $X$. Therefore, for two random variables $X$ and $Y$, if their CDFs are the same, i.e.: . \\[F_{X}(x) = F_{Y}(x) \\quad \\forall x \\in \\mathbb{R}\\] then $X$ and $Y$ have the same probability distribution. Properties of CDF . | $P(X = x) = F_{X}(x) - F_{X}(x^{-})$ where $x^{-}$ is the largest value less than $x$ (left-limit) | $P(a &lt; X \\leq b) = F_{X}(b) - F_{X}(a)$ | $P(X &gt; x) = 1 - F_{X}(x)$ | . ",
    "url": "/docs/statistics/basics/basic-probs.html#cumulative-distribution-function",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#cumulative-distribution-function"
  },"94": {
    "doc": "Basic Probability",
    "title": "Quantile Function",
    "content": "Let $X$ be a random variable with CDF $F_{X}(x)$. The quantile function or inverse CDF of $X$ is: . $$ F_{X}^{-1}(q) = \\inf \\{ x : F_{X}(x) &gt; q \\} $$ . where $q \\in [0, 1]$. ",
    "url": "/docs/statistics/basics/basic-probs.html#quantile-function",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#quantile-function"
  },"95": {
    "doc": "Basic Probability",
    "title": "Expected Value",
    "content": "The expected value of a quantitative random variable $X$ is denoted by: . $$ E(X) $$ . It is a weighted average of the values of $X$, where the weights are the probabilities of each value. ",
    "url": "/docs/statistics/basics/basic-probs.html#expected-value",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#expected-value"
  },"96": {
    "doc": "Basic Probability",
    "title": "Expected Value of Discrete Random Variable",
    "content": "Let $X$ be a discrete random variable. Then: . $$ E(X) = \\sum_{x} x \\cdot p_{X}(x) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#expected-value-of-discrete-random-variable",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#expected-value-of-discrete-random-variable"
  },"97": {
    "doc": "Basic Probability",
    "title": "Expected Value of Continuous Random Variable",
    "content": "Let $X$ be a continuous random variable. Then: . $$ E(X) = \\int x \\cdot f_{X}(x) dx $$ . The range of the integral is the entire range of $X$. ",
    "url": "/docs/statistics/basics/basic-probs.html#expected-value-of-continuous-random-variable",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#expected-value-of-continuous-random-variable"
  },"98": {
    "doc": "Basic Probability",
    "title": "Variance and Standard Deviation",
    "content": "Variance and standard deviation measures how much the values of a random variable $X$ are spread out from the expected value. Standard deviation is the square root of variance. ",
    "url": "/docs/statistics/basics/basic-probs.html#variance-and-standard-deviation",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#variance-and-standard-deviation"
  },"99": {
    "doc": "Basic Probability",
    "title": "Variance of Discrete Random Variable",
    "content": "Let $X$ be a discrete random variable. Then: . $$ V(X) = \\sum_{x} (x - E(X))^{2} \\cdot p_{X}(x) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#variance-of-discrete-random-variable",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#variance-of-discrete-random-variable"
  },"100": {
    "doc": "Basic Probability",
    "title": "Variance of Continuous Random Variable",
    "content": "Let $X$ be a continuous random variable. Then: . $$ V(X) = \\int (x - E(X))^{2} \\cdot f_{X}(x) dx $$ . Some interesting properties of the variance/standard deviation: . | $V(X) \\geq 0$ | $V(X) = 0$ if and only if $X$ is a constant | Higher the value, higher the dispersion from the expected value | . ",
    "url": "/docs/statistics/basics/basic-probs.html#variance-of-continuous-random-variable",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#variance-of-continuous-random-variable"
  },"101": {
    "doc": "Basic Probability",
    "title": "Joint Probability",
    "content": "Let $X$ and $Y$ be two random variables. The joint probability of $X$ and $Y$ is denoted by: . $$ P(X, Y) $$ . Also $P(X \\cap Y)$, $P(XY)$. ",
    "url": "/docs/statistics/basics/basic-probs.html#joint-probability",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#joint-probability"
  },"102": {
    "doc": "Basic Probability",
    "title": "Independent Random Variables",
    "content": "Two random variables $X$ and $Y$ are independent if: . $$ P(X, Y) = P(X) \\cdot P(Y) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#independent-random-variables",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#independent-random-variables"
  },"103": {
    "doc": "Basic Probability",
    "title": "Conditional Probability",
    "content": "The conditional probability of $X$ given $Y$ is denoted by $P(X | Y)$. $$ P(X | Y) = \\frac{P(X, Y)}{P(Y)} $$ . You could say that the sample space has changed from $\\Omega$ to $Y$. $P(X | Y) \\neq P(Y | X)$ in general. If $X$ and $Y$ are independent, then: . $$ P(X | Y) = P(X) $$ . ",
    "url": "/docs/statistics/basics/basic-probs.html#conditional-probability",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#conditional-probability"
  },"104": {
    "doc": "Basic Probability",
    "title": "Common Probability Distributions",
    "content": "As described earlier, we assume a certain probability distribution for the population. Each probability distribution has its own set of parameters. These parameters determine the shape of the distribution. Therefore, knowing the parameters is equivalent to understanding the population. Below are some common probability distributions and their parameters. ",
    "url": "/docs/statistics/basics/basic-probs.html#common-probability-distributions",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#common-probability-distributions"
  },"105": {
    "doc": "Basic Probability",
    "title": "Normal Distribution (Gaussian Distribution)",
    "content": "The normal distribution, also known as the Gaussian distribution, is a continuous probability distribution. It is the most common distribution in statistics. The normal distribution is characterized by two parameters: . | $\\mu$: Mean (location of distribution) | $\\sigma$: Standard deviation (width of distribution) | . The notation for the normal distribution is: . $$ X \\sim N(\\mu, \\sigma^{2}) $$ . The PDF of the normal distribution is: . $$ f_{X}(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} $$ . Hard to see the exponent in the PDF? $$ -\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}} $$ . Characteristics of Normal Distribution . | Symmetric around the mean | Mean, median, and mode are equal | . | 68% of the values are approximately within $\\mu \\pm 1 \\sigma$ | 95% of the values are approximately within $\\mu \\pm 2 \\sigma$ | 99.7% of the values are approximately within $\\mu \\pm 3 \\sigma$ | . ",
    "url": "/docs/statistics/basics/basic-probs.html#normal-distribution-gaussian-distribution",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#normal-distribution-gaussian-distribution"
  },"106": {
    "doc": "Basic Probability",
    "title": "Standard Normal Distribution",
    "content": "The normal distribution of $x$ against the probability density transformed into $z$ against the probability density is the standard normal distribution. We can denote the standard normal distribution as: . $$ Z \\sim N(0, 1) $$ . Z-Score . Standardization or z-score normalization is the process of normalizing a dataset so that . $$ \\begin{align*} \\mu &amp;= 0 \\\\ \\sigma &amp;= 1 \\end{align*} $$ . We do this by obtaining the standard score or z-score of each value by: . $$ z = \\frac{x - \\mu}{\\sigma} $$ . Z-score is essentially calculating how many $\\sigma$ a value is away from the mean. Higher the z-score, higher the value is from the mean. Z-Score Table . Below is a part of the z-score table. This table specifically, is for the left-tailed z-score. It shows the probability of a value being less than a certain z-score. Since the normal distribution is symmetric, the logic can be applied to the right-tailed z-score as well. | Z | .00 | .01 | .02 | .03 | .04 | .05 | .06 | .07 | .08 | .09 | . | … | … | … | … | … | … | … | … | … | … | … | . | -2.1 | .01786 | .01743 | .01700 | .01659 | .01618 | .01578 | .01539 | .01500 | .01463 | .01426 | . | -2.0 | .02275 | .02222 | .02169 | .02118 | .02068 | .02018 | .01970 | .01923 | .01876 | .01831 | . | -1.9 | .02872 | .02807 | .02743 | .02680 | .02619 | .02559 | .02500 | .02442 | .02385 | .02330 | . | … | … | … | … | … | … | … | … | … | … | … | . Let’s use the z-score of 1.96 (absolute) as an example. | Find the row with the z-score of $1.9$ | Find the column with the z-score of $0.06$ | You can see that the probability is $0.025$ | . Since the normal distribution is symmetric, we know that the probability of a value being greater than $1.96$ is also $0.025$. Hence, the probability of a z-score falling outside of $\\pm 1.96$ is $0.05$. ",
    "url": "/docs/statistics/basics/basic-probs.html#standard-normal-distribution",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#standard-normal-distribution"
  },"107": {
    "doc": "Basic Probability",
    "title": "Others",
    "content": "To be added . Other common probability distributions include: . | Discrete Uniform distribution (discrete) | Binomial distribution (discrete) | Poisson distribution (discrete) | Geometry distribution (discrete) | Negative binomial distribution (discrete) | Uniform distribution (continuous) | Exponential distribution (continuous) | etc. | . ",
    "url": "/docs/statistics/basics/basic-probs.html#others",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html#others"
  },"108": {
    "doc": "Basic Probability",
    "title": "Basic Probability",
    "content": " ",
    "url": "/docs/statistics/basics/basic-probs.html",
    
    "relUrl": "/docs/statistics/basics/basic-probs.html"
  },"109": {
    "doc": "SSH Basics",
    "title": "SSH Basics",
    "content": ". | Create a key pair | Copy public key to remote server | . ",
    "url": "/docs/security/ssh/basics.html",
    
    "relUrl": "/docs/security/ssh/basics.html"
  },"110": {
    "doc": "SSH Basics",
    "title": "Create a key pair",
    "content": "Base command structure is as follows: . ssh-keygen -t &lt;algorithm&gt; -C &lt;comments&gt; . Then follow the prompt. Do not use ssh-rsa algorithm as it is rejected by modern OpenSSH servers. Use rsa-sha2-256, rsa-sha2-512, ed25519, etc. instead. ",
    "url": "/docs/security/ssh/basics.html#create-a-key-pair",
    
    "relUrl": "/docs/security/ssh/basics.html#create-a-key-pair"
  },"111": {
    "doc": "SSH Basics",
    "title": "Copy public key to remote server",
    "content": "The following command will copy your public key to remote server’s authorized_keys file. It will also check for duplicate keys and will not add the key if it is. ssh-copy-id -i &lt;path_to_pub_key&gt; &lt;remote_host&gt; . References: . | Comparing SSH Keys | . ",
    "url": "/docs/security/ssh/basics.html#copy-public-key-to-remote-server",
    
    "relUrl": "/docs/security/ssh/basics.html#copy-public-key-to-remote-server"
  },"112": {
    "doc": "Basics",
    "title": "Kubernetes Basics",
    "content": ". | What is Kubernetes? | Installation | Managed Kubernetes services from cloud providers | . ",
    "url": "/docs/kubernetes/basics.html#kubernetes-basics",
    
    "relUrl": "/docs/kubernetes/basics.html#kubernetes-basics"
  },"113": {
    "doc": "Basics",
    "title": "What is Kubernetes?",
    "content": ". | Container orchestration system | Declarative API | . ",
    "url": "/docs/kubernetes/basics.html#what-is-kubernetes",
    
    "relUrl": "/docs/kubernetes/basics.html#what-is-kubernetes"
  },"114": {
    "doc": "Basics",
    "title": "Installation",
    "content": "Details here. brew install kubernetes-cli . Check installation via kubectl version --output=yaml. ",
    "url": "/docs/kubernetes/basics.html#installation",
    
    "relUrl": "/docs/kubernetes/basics.html#installation"
  },"115": {
    "doc": "Basics",
    "title": "Managed Kubernetes services from cloud providers",
    "content": ". | Google Kubernetes Engine (GKE) | Amazon Elastic Kubernetes Service (Amazon EKS) | Azure Kubernetes Service (AKS) | . ",
    "url": "/docs/kubernetes/basics.html#managed-kubernetes-services-from-cloud-providers",
    
    "relUrl": "/docs/kubernetes/basics.html#managed-kubernetes-services-from-cloud-providers"
  },"116": {
    "doc": "Basics",
    "title": "Basics",
    "content": " ",
    "url": "/docs/kubernetes/basics.html",
    
    "relUrl": "/docs/kubernetes/basics.html"
  },"117": {
    "doc": "Vault Server Basics",
    "title": "Vault Server Basics",
    "content": ". | Vault server | Initialization . | GnuPG | Vault init | . | Unseal / Seal . | Unseal | Seal | . | Enabling authentication . | Enable userpass | . | Policies . | Create a policy | Add a policy | . | . ",
    "url": "/docs/security/vault/basics.html",
    
    "relUrl": "/docs/security/vault/basics.html"
  },"118": {
    "doc": "Vault Server Basics",
    "title": "Vault server",
    "content": "When you first start the server with vault server, you need to first initialize and unseal it. One option is to use the web UI, but you can also use the vault CLI. You can access the web UI at http://localhost:8200/ui. ",
    "url": "/docs/security/vault/basics.html#vault-server",
    
    "relUrl": "/docs/security/vault/basics.html#vault-server"
  },"119": {
    "doc": "Vault Server Basics",
    "title": "Initialization",
    "content": "In the beginning, Vault server is in a sealed state. There needs to be a master key to unseal it. Upon initialization, Vault will attempt to split this key into pieces, and you will get to decide how many pieces it’ll be. You will also have to decide the threshold of number of pieces that need to be put together in order to access the final key and unseal Vault. One security hole of Vault was that the root initializer receives a raw text of all these keys. Therefore, a recommended practice is that you encrypt these keys using a PGP key. Have a PGP key for each piece of the key. GnuPG . One way to do acquire a PGP key is with GnuPG. # Follow prompts to create a PGP key gpg --full-generate-key # Export to disk as base64 gpg --export &lt;key-id&gt; | base64 &gt; my-name.asc . Vault init . Now define a key share number and the threshold, and provide your PGP keys. vault operator init \\ -key-shares=3 \\ -key-threshold=2 \\ -pgp-keys=\"person1.asc,person2.asc,person3.asc\" -root-token-pgp-key=\"some.asc\" . Then you will get, in this example, three PGP encrypted keys and a root token in your console. Remember these encrypted keys and token. The order in which you put pgp-keys matter. The first PGP key will be used to decrypt the first unseal key, the second will be used to decrypt the second, and so on. ",
    "url": "/docs/security/vault/basics.html#initialization",
    
    "relUrl": "/docs/security/vault/basics.html#initialization"
  },"120": {
    "doc": "Vault Server Basics",
    "title": "Unseal / Seal",
    "content": "Unseal . To decrypt an unseal key, . echo \"whatever that was printed during init\" | base64 --decode | gpg -dq . The output will be the decrypted key. Then unseal vault, . vault operator unseal # Enter decrypted key on prompt . Seal . vault operator seal . ",
    "url": "/docs/security/vault/basics.html#unseal--seal",
    
    "relUrl": "/docs/security/vault/basics.html#unseal--seal"
  },"121": {
    "doc": "Vault Server Basics",
    "title": "Enabling authentication",
    "content": "You can always login with a root token, . vault login &lt;root-token&gt; . But it is generally a bad idea to persist a root token. Therefore, we instead enable different authentication methods to login to Vault. The simplest auth method is userpass. Enable userpass . # By default it is mounted to auth/userpass vault auth enable userpass # You can set your own path though vault auth enable -path=my-path-here userpass . Before you enable any other auth methods, initially you’ll have to be logged in with your root token. Then create a user by: . vault write auth/userpass/users/&lt;username&gt; \\ password=&lt;password&gt; \\ policies=\"list,of,policies,separated,by,comma\" . You can now login with the created user: . vault login -method=\"userpass\" username=\"&lt;username&gt;\" . ",
    "url": "/docs/security/vault/basics.html#enabling-authentication",
    
    "relUrl": "/docs/security/vault/basics.html#enabling-authentication"
  },"122": {
    "doc": "Vault Server Basics",
    "title": "Policies",
    "content": "Create a policy . Create an .hcl file. The name is irrelevant. Details of what goes into this file can be found here. Add a policy . To add a policy: . vault policy write &lt;policy-name&gt; some-policy.hcl . References: . | Vault Server | Vault PGP | Vault Auth Methods | Vault Policies | . ",
    "url": "/docs/security/vault/basics.html#policies",
    
    "relUrl": "/docs/security/vault/basics.html#policies"
  },"123": {
    "doc": "Terraform Basics",
    "title": "Terraform Basics",
    "content": ". | Install Terraform | Configuration | Initialize | Create infrastructure and inspect state | Output file | Destroy infrastructure | Refresh infrastructure | Workspaces . | To create a new workspace | To switch to a workspace | . | Import remote infrastructure | To see the current configuration state of a resource | To delete a resource from the state | . ",
    "url": "/docs/terraform/basics.html",
    
    "relUrl": "/docs/terraform/basics.html"
  },"124": {
    "doc": "Terraform Basics",
    "title": "Install Terraform",
    "content": "brew tap hashicorp/tap brew install hashicorp/terraform terraform -version . ",
    "url": "/docs/terraform/basics.html#install-terraform",
    
    "relUrl": "/docs/terraform/basics.html#install-terraform"
  },"125": {
    "doc": "Terraform Basics",
    "title": "Configuration",
    "content": "The set of files used to declare infrastructure. Such files have an extension of .tf and are required to be in its own working directory. mkdir tf-aws-instance cd tf-aws-instance touch main.tf . The following is an example configuration main.tf: . terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~&gt; 3.27\" } } required_version = \"&gt;= 0.14.9\" } provider \"aws\" { profile = \"default\" region = \"us-west-2\" } resource \"aws_instance\" \"app_server\" { ami = \"ami-830c94e3\" instance_type = \"t2.micro\" tags = { Name = \"ExampleAppServerInstance\" } } . Terraform also provides terraform fmt and terraform validate for formatting configuration files and checking its syntax. terraform fmt does not produce any output if no modification is made. For details, see Terraform Configuration. ",
    "url": "/docs/terraform/basics.html#configuration",
    
    "relUrl": "/docs/terraform/basics.html#configuration"
  },"126": {
    "doc": "Terraform Basics",
    "title": "Initialize",
    "content": "After creating a configuration or checking out an existing configuration, initialize directory with . # Installs providers in .terraform folder and also creates .terraform.lock.hcl terraform init . ",
    "url": "/docs/terraform/basics.html#initialize",
    
    "relUrl": "/docs/terraform/basics.html#initialize"
  },"127": {
    "doc": "Terraform Basics",
    "title": "Create infrastructure and inspect state",
    "content": "To see the execution plan, . terraform plan . To actually apply, . # Will print an execution plan, type yes to perform the actions terraform apply # OR terraform apply --auto-approve # With variables terraform apply -var-file=variables.tfvars . A Terraform state file terraform.tfstate will be generated. The file contains sensitive info, so share with only those trusted. # Inspect the current state terraform show . For manual/advanced state management, use terraform state. One example of the command is, . # List resources in state terraform state list . ",
    "url": "/docs/terraform/basics.html#create-infrastructure-and-inspect-state",
    
    "relUrl": "/docs/terraform/basics.html#create-infrastructure-and-inspect-state"
  },"128": {
    "doc": "Terraform Basics",
    "title": "Output file",
    "content": "You can query data after apply using an output file. Create a file called output.tf (name doesn’t matter) with the following . output \"instance_id\" { description = \"ID of the EC2 instance\" value = aws_instance.app_server.id } output \"instance_public_ip\" { description = \"Public IP address of the EC2 instance\" value = aws_instance.app_server.public_ip } . You will see the queried output when you run terraform apply. You can also inspect the output by . # Call after `terraform apply` terraform output . ",
    "url": "/docs/terraform/basics.html#output-file",
    
    "relUrl": "/docs/terraform/basics.html#output-file"
  },"129": {
    "doc": "Terraform Basics",
    "title": "Destroy infrastructure",
    "content": "The following terminates all resources managed with project state: . # Just like apply, shows you the execution plan. Type yes to destroy. terraform destroy # OR terraform destroy --auto-approve # With variables terraform destroy -var-file=variables.tfvars . ",
    "url": "/docs/terraform/basics.html#destroy-infrastructure",
    
    "relUrl": "/docs/terraform/basics.html#destroy-infrastructure"
  },"130": {
    "doc": "Terraform Basics",
    "title": "Refresh infrastructure",
    "content": "The following updates terraform’s state file to match the configuration in remote: . terraform refresh terraform refresh -var-file=variables.tf . ",
    "url": "/docs/terraform/basics.html#refresh-infrastructure",
    
    "relUrl": "/docs/terraform/basics.html#refresh-infrastructure"
  },"131": {
    "doc": "Terraform Basics",
    "title": "Workspaces",
    "content": "If you want to work on multiple stages, use workspaces to manage different states. By default, you work in a workspace named default. All the other non-default workspace states are stored in a directory named terraform.tfstate.d. To create a new workspace . terraform workspace new my-dev . To switch to a workspace . terraform workspace select default . ",
    "url": "/docs/terraform/basics.html#workspaces",
    
    "relUrl": "/docs/terraform/basics.html#workspaces"
  },"132": {
    "doc": "Terraform Basics",
    "title": "Import remote infrastructure",
    "content": "To import a remote infrastructure into a local state file, first create an appropriate empty resource in a configuration file: . resource \"aws_s3_bucket\" \"my_bucket\" { } . Then, import the remote resource into the local state file: . terraform import aws_s3_bucket.my_bucket my-remote-bucket-name . Note that the id/key used for an import varies per provider/resource. Refer to the documentation for the provider to see the correct syntax. However, doing so does not actually update the configuration itself, but only updates the state file. To actually bring the remote resource under Terraform’s management, you must copy over the configurations and run terraform apply. Easiest way to see the current configuration is to use terraform state show. ",
    "url": "/docs/terraform/basics.html#import-remote-infrastructure",
    
    "relUrl": "/docs/terraform/basics.html#import-remote-infrastructure"
  },"133": {
    "doc": "Terraform Basics",
    "title": "To see the current configuration state of a resource",
    "content": "terraform state show aws_s3_bucket.my_bucket . ",
    "url": "/docs/terraform/basics.html#to-see-the-current-configuration-state-of-a-resource",
    
    "relUrl": "/docs/terraform/basics.html#to-see-the-current-configuration-state-of-a-resource"
  },"134": {
    "doc": "Terraform Basics",
    "title": "To delete a resource from the state",
    "content": "terraform state rm aws_s3_bucket.my_bucket . References: . | Terraform: AWS Get Started | Terraform Registry: AWS Provider | . ",
    "url": "/docs/terraform/basics.html#to-delete-a-resource-from-the-state",
    
    "relUrl": "/docs/terraform/basics.html#to-delete-a-resource-from-the-state"
  },"135": {
    "doc": "Basis and Rank",
    "title": "Basis and Rank",
    "content": ". | Generating Set . | Span | Minimal Generating Set | . | Basis . | Dimension of Vector Space | Finding Basis from a Generating Set | Example: Standard Basis of $\\mathbb{R}^3$ | Example: Other Bases of $\\mathbb{R}^3$ | . | Ordered Basis . | Coordinate Vector | Standard Basis | With Respect to Other Ordered Bases | Change of Basis Matrix | . | Rank . | Full Rank | Rank-Nullity Theorem | . | . ",
    "url": "/docs/linalg/basics/basis-rank.html",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html"
  },"136": {
    "doc": "Basis and Rank",
    "title": "Generating Set",
    "content": "Let $V = (\\mathcal{V}, +, \\cdot)$ be a vector space and set of vectors $\\mathcal{A} \\subseteq \\mathcal{V}$. If every $v \\in \\mathcal{V}$ can be expressed as a linear combination of $\\mathbf{x}_i \\in \\mathcal{A}$, then $\\mathcal{A}$ is a generating set of $V$. Generating set does not have to be linearly independent. ",
    "url": "/docs/linalg/basics/basis-rank.html#generating-set",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#generating-set"
  },"137": {
    "doc": "Basis and Rank",
    "title": "Span",
    "content": "The span of $\\mathcal{A}$ is the set of all linear combinations of $\\mathcal{A}$. When $\\mathcal{A}$ is a generating set of $V$, we say that $\\mathcal{A}$ spans $V$. $$ V = \\mathrm{span}[\\mathcal{A}] $$ . ",
    "url": "/docs/linalg/basics/basis-rank.html#span",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#span"
  },"138": {
    "doc": "Basis and Rank",
    "title": "Minimal Generating Set",
    "content": "If there is no smaller subset of $\\mathcal{V}$ that spans $V$, then $\\mathcal{A}$ is a minimal generating set of $V$. ",
    "url": "/docs/linalg/basics/basis-rank.html#minimal-generating-set",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#minimal-generating-set"
  },"139": {
    "doc": "Basis and Rank",
    "title": "Basis",
    "content": "Every linearly independent generating set of $V$ is minimal. Such a set is called a basis of $V$. | The difference from generating set is that basis is linearly independent. | Every vector space has a basis, but it is not unique. | The number of basis vectors, called the dimension of the vector space, is the same for all bases of a vector space. | A basis is a minimal generating set and also a maximal linearly independent set of vectors in $\\mathcal{V}$. | Every linear combination of a basis is unique. | . ",
    "url": "/docs/linalg/basics/basis-rank.html#basis",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#basis"
  },"140": {
    "doc": "Basis and Rank",
    "title": "Dimension of Vector Space",
    "content": "For a finite-dimensional vector space $V$, the dimension of $V$ is the number of basis vectors of $V$. Denoted: . $$ \\dim(V) $$ . | $U \\subseteq V \\implies \\dim(U) \\leq \\dim(V)$ | $\\dim(U) = \\dim(V) \\iff U = V$ | . ",
    "url": "/docs/linalg/basics/basis-rank.html#dimension-of-vector-space",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#dimension-of-vector-space"
  },"141": {
    "doc": "Basis and Rank",
    "title": "Finding Basis from a Generating Set",
    "content": "If $\\mathcal{A} = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_n\\}$ is a generating set of $V$, then we can find a basis of $V$ by: . | Form a matrix $A = [\\mathbf{x}_1\\, \\dots\\, \\mathbf{x}_n]$ whose columns are the spanning vectors in $\\mathcal{A}$. | Find the row echelon form of $A$. | The spanning vectors corresponding to the pivot columns of the reduced row echelon form of $A$ form a basis of $V$. | . ",
    "url": "/docs/linalg/basics/basis-rank.html#finding-basis-from-a-generating-set",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#finding-basis-from-a-generating-set"
  },"142": {
    "doc": "Basis and Rank",
    "title": "Example: Standard Basis of $\\mathbb{R}^3$",
    "content": "The canonical or standard basis of $\\mathbb{R}^3$ is: . \\[\\mathcal{B} = \\left\\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\right\\}\\] . | It is true that we can generate any vector in $\\mathbb{R}^3$ with $\\mathcal{B}$. | It is true that there is no smaller set that can span $\\mathbb{R}^3$. | It is true that $\\mathcal{B}$ is linearly independent. | It is true that there is no other vector we can add to the set without making it linearly dependent. | . ",
    "url": "/docs/linalg/basics/basis-rank.html#example-standard-basis-of-mathbbr3",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#example-standard-basis-of-mathbbr3"
  },"143": {
    "doc": "Basis and Rank",
    "title": "Example: Other Bases of $\\mathbb{R}^3$",
    "content": "\\[\\mathcal{B}' = \\left\\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\right\\}\\] . ",
    "url": "/docs/linalg/basics/basis-rank.html#example-other-bases-of-mathbbr3",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#example-other-bases-of-mathbbr3"
  },"144": {
    "doc": "Basis and Rank",
    "title": "Ordered Basis",
    "content": "While a basis is a set of vectors expressed $\\mathcal{B} = \\{\\mathbf{b}_1, \\dots, \\mathbf{b}_n\\}$, an ordered basis is expressed with a tuple of specific order. $$ B = (\\mathbf{b}_1, \\dots, \\mathbf{b}_n) $$ . ",
    "url": "/docs/linalg/basics/basis-rank.html#ordered-basis",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#ordered-basis"
  },"145": {
    "doc": "Basis and Rank",
    "title": "Coordinate Vector",
    "content": "Why would we want to order the basis? It is useful when representing a coordinate system. Let $V$ be a vector space with an ordered basis $B = (\\mathbf{b}_1, \\dots, \\mathbf{b}_n)$. Any vector $\\mathbf{x} \\in V$ can be expressed as a linear combination of $B$: . \\[\\mathbf{x} = \\alpha_1 \\mathbf{b}_1 + \\dots + \\alpha_n \\mathbf{b}_n\\] Then . \\[\\boldsymbol{\\alpha} = \\begin{bmatrix} \\alpha_1 \\\\ \\vdots \\\\ \\alpha_n \\end{bmatrix}\\] is the coordinate vector of $\\mathbf{x}$ with respect to $B$, and this vector is unique to $\\mathbf{x}$. A fixed ordering is important in having a consistent representation of coordinates. ",
    "url": "/docs/linalg/basics/basis-rank.html#coordinate-vector",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#coordinate-vector"
  },"146": {
    "doc": "Basis and Rank",
    "title": "Standard Basis",
    "content": "Standard basis is an example of an ordered basis. When we talk about some vector $\\mathbf{x} \\in \\mathbb{R}^n$, we often implicitly refer to the coordinate vector of $\\mathbf{x}$ with respect to the standard basis. ",
    "url": "/docs/linalg/basics/basis-rank.html#standard-basis",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#standard-basis"
  },"147": {
    "doc": "Basis and Rank",
    "title": "With Respect to Other Ordered Bases",
    "content": "A coordinate vector can be expressed with respect to any ordered basis. We denote the coordinate vector of $\\mathbf{x}$ with respect to some $B$ as: . $$ [\\mathbf{x}]_B $$ . Example If $B = ([1, 2]^\\top, [3, 4]^\\top)$ is an ordered basis of $\\mathbb{R}^2$, then the coordinate vector of $\\mathbf{x} = [1, 0]^\\top$ with respect to $B$ is: . \\[\\mathbf{x} = -2 \\cdot [1, 2]^\\top + 1 \\cdot [3, 4]^\\top\\] \\[[\\mathbf{x}]_B = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\] . | $[\\mathbf{x} + \\mathbf{y}]_B = [\\mathbf{x}]_B + [\\mathbf{y}]_B$ | $[c \\mathbf{x}]_B = c [\\mathbf{x}]_B$ | . ",
    "url": "/docs/linalg/basics/basis-rank.html#with-respect-to-other-ordered-bases",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#with-respect-to-other-ordered-bases"
  },"148": {
    "doc": "Basis and Rank",
    "title": "Change of Basis Matrix",
    "content": "A change of basis matrix $P$ is a matrix that transforms the coordinate vector of $\\mathbf{x}$ with respect to some $B$ ($[\\mathbf{x}]_B$) to the coordinate vector of $\\mathbf{x}$ with respect to some other basis $C$ ($[\\mathbf{x}]_C$). When $B = (\\mathbf{b}_1, \\dots, \\mathbf{b}_n)$, the change of basis matrix is: . $$ P_{C \\leftarrow B} = [\\, [\\mathbf{b}_1]_C\\, \\dots\\, [\\mathbf{b}_n]_C\\,] $$ . Every change of basis matrix is invertible. If we have the coordinate vector of $\\mathbf{x}$ with respect to $B$, we can find the coordinate vector of $\\mathbf{x}$ with respect to $C$: . \\[P [\\mathbf{x}]_B = [\\mathbf{x}]_C\\] Example Let $B = ([1, 2]^\\top, [3, 4]^\\top)$ and $C$ be the standard basis of $\\mathbb{R}^2$. We showed above that the coordinate vector of $\\mathbf{x} = [1, 0]^\\top$ with respect to $B$ is: . \\[[\\mathbf{x}]_B = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\] The change of basis matrix is: . \\[P_{C \\leftarrow B} = \\begin{bmatrix} 1 &amp; 3 \\\\ 2 &amp; 4 \\end{bmatrix}\\] Then the coordinate vector of $\\mathbf{x}$ with respect to $C$ is: . \\[P_{C \\leftarrow B} [\\mathbf{x}]_B = \\begin{bmatrix} 1 &amp; 3 \\\\ 2 &amp; 4 \\end{bmatrix} \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = [\\mathbf{x}]_C\\] When converting to a standard basis, the change of basis matrix has the basis vectors of old basis as columns. ",
    "url": "/docs/linalg/basics/basis-rank.html#change-of-basis-matrix",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#change-of-basis-matrix"
  },"149": {
    "doc": "Basis and Rank",
    "title": "Rank",
    "content": "The rank of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is the number of linearly independent columns of $A$. Also called column rank. It is denoted: . $$ \\mathrm{rank}(A) \\quad \\mathrm{or} \\quad \\mathrm{rk}(A) $$ . | Column rank is the same as row rank: $\\mathrm{rank}(A) = \\mathrm{rank}(A^T)$ | The columns of $A$ span any subspace $U \\subseteq \\mathbb{R}^m$ where $\\mathrm{rank}(A) = \\dim(U)$ . This column space is called image/range. | The rows of $A$ (or columns of $A^T$) span any subspace $W \\subseteq \\mathbb{R}^n$ where $\\mathrm{rank}(A) = \\dim(W)$ | $\\forall A \\in \\mathbb{R}^{m \\times m}$, $A$ is invertible $\\iff \\mathrm{rank}(A) = m$ | $\\forall A \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{b} \\in \\mathbb{R}^m$, the system $A \\mathbf{x} = \\mathbf{b}$ has a solution $\\iff \\mathrm{rank}(A) = \\mathrm{rank}(A \\mid \\mathbf{b})$ . Where $A \\mid \\mathbf{b}$ is the augmented matrix. | For $A \\in \\mathbb{R}^{m \\times n}$, the solution space of a homogeneous system ($A \\mathbf{x} = \\mathbf{0}$) is a vector subspace of $\\mathbb{R}^n$ with dimension $n - \\mathrm{rank}(A)$ . This solution space is called kernel/nullspace. | . ",
    "url": "/docs/linalg/basics/basis-rank.html#rank",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#rank"
  },"150": {
    "doc": "Basis and Rank",
    "title": "Full Rank",
    "content": "A matrix $A \\in \\mathbb{R}^{m \\times n}$ has full rank if $\\mathrm{rank}(A) = \\min(m, n)$. Otherwise, it is rank deficient. ",
    "url": "/docs/linalg/basics/basis-rank.html#full-rank",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#full-rank"
  },"151": {
    "doc": "Basis and Rank",
    "title": "Rank-Nullity Theorem",
    "content": "See here . ",
    "url": "/docs/linalg/basics/basis-rank.html#rank-nullity-theorem",
    
    "relUrl": "/docs/linalg/basics/basis-rank.html#rank-nullity-theorem"
  },"152": {
    "doc": "Bayes' Theorem",
    "title": "Bayes’ Theorem",
    "content": ". | Marginal Probability | The Law of Total Probability . | Marginalization | . | Interpreting Bayes’ Theorem . | Prior | Posterior | Marginal | . | . ",
    "url": "/docs/statistics/notes/bayes-theorem.html#bayes-theorem",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#bayes-theorem"
  },"153": {
    "doc": "Bayes' Theorem",
    "title": "Marginal Probability",
    "content": "A marginal probability is the probability of an event occurring, irrespective of other events. So simply put, it is the probability of an event without any conditions. This term is used in contrast to a conditional probability, which is the probability of an event that depends on other events. ",
    "url": "/docs/statistics/notes/bayes-theorem.html#marginal-probability",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#marginal-probability"
  },"154": {
    "doc": "Bayes' Theorem",
    "title": "The Law of Total Probability",
    "content": "The law of total probability is a theorem that relates marginal probabilities to conditional probabilities. If $A_i$ is a partition of a sample space $\\Omega$, then for any event $B$ in $\\Omega$, . $$ P(B) = \\sum_{i} P(B|A_i)P(A_i) $$ . ",
    "url": "/docs/statistics/notes/bayes-theorem.html#the-law-of-total-probability",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#the-law-of-total-probability"
  },"155": {
    "doc": "Bayes' Theorem",
    "title": "Marginalization",
    "content": "Marginalization is the process of summing over all possible values of a variable to find the marginal distribution of another variable. $$ P(B) = \\sum_{i} P(B, A_i) $$ . So it’s basically the same idea as the law of total probability, but without the conditionals. ",
    "url": "/docs/statistics/notes/bayes-theorem.html#marginalization",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#marginalization"
  },"156": {
    "doc": "Bayes' Theorem",
    "title": "Interpreting Bayes’ Theorem",
    "content": "Let $A_i$ be a partition of a sample space $\\Omega$. Then for any event $B$ in $\\Omega$, Bayes’ theorem states that: . $$ P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{P(B)} = \\frac{P(B|A_i)P(A_i)}{\\sum_{j} P(B|A_j)P(A_j)} $$ . In Bayesian statistics, probability is interpreted as a measure of belief. So this rule tells us how our beliefs are updated given new observations. ",
    "url": "/docs/statistics/notes/bayes-theorem.html#interpreting-bayes-theorem",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#interpreting-bayes-theorem"
  },"157": {
    "doc": "Bayes' Theorem",
    "title": "Prior",
    "content": "A prior is a probability distribution that represents our beliefs prior to observing any new data. So in our case $P(A_i)$ is the prior. In Bayesian inference, the prior is often initialized to a uniform distribution as a non-informative prior (i.e. no prior knowledge, less bias). ",
    "url": "/docs/statistics/notes/bayes-theorem.html#prior",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#prior"
  },"158": {
    "doc": "Bayes' Theorem",
    "title": "Posterior",
    "content": "A posterior is a probability distribution that represents our beliefs after observing new data. In our case $P(A_i | B)$ is the posterior. The new observation is represented by $B$, and $P(A_i | B)$ is our updated belief about $A_i$. ",
    "url": "/docs/statistics/notes/bayes-theorem.html#posterior",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#posterior"
  },"159": {
    "doc": "Bayes' Theorem",
    "title": "Marginal",
    "content": "In real life, we often have no direct way to solve for $P(B)$. In this case, the entire posterior is approximated using methods such as MCMC (Markov Chain Monte Carlo). ",
    "url": "/docs/statistics/notes/bayes-theorem.html#marginal",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html#marginal"
  },"160": {
    "doc": "Bayes' Theorem",
    "title": "Bayes' Theorem",
    "content": " ",
    "url": "/docs/statistics/notes/bayes-theorem.html",
    
    "relUrl": "/docs/statistics/notes/bayes-theorem.html"
  },"161": {
    "doc": "Elastic Beanstalk",
    "title": "AWS Elastic Beanstalk (EB)",
    "content": ". | What is Elastic Beanstalk? | Elastic Beanstalk Application | Environment Tier . | Web Server Environment | Worker Environment | . | Deployment . | In-Place Deployment Policies . | All at once | Rolling | Rolling with additional batch | Immutable | Traffic Splitting | . | Blue/Green Deployment Policy | . | Configuring Environments . | Order of Precedence | Configuration Files (.ebextensions) . | Option Settings | Linux Server | . | Environment Manifest (env.yaml) | . | EB CLI | . ",
    "url": "/docs/aws/beanstalk.html#aws-elastic-beanstalk-eb",
    
    "relUrl": "/docs/aws/beanstalk.html#aws-elastic-beanstalk-eb"
  },"162": {
    "doc": "Elastic Beanstalk",
    "title": "What is Elastic Beanstalk?",
    "content": "Elastic Beanstalk is a Platform as a Service (PaaS) that helps you deploy web apps with little knowledge about what kind of infrastructure is managed underneath. It configures its components to provide an environment for your application to run on. EB is basically a Cloudformation template with a UI. ",
    "url": "/docs/aws/beanstalk.html#what-is-elastic-beanstalk",
    
    "relUrl": "/docs/aws/beanstalk.html#what-is-elastic-beanstalk"
  },"163": {
    "doc": "Elastic Beanstalk",
    "title": "Elastic Beanstalk Application",
    "content": "An Elastic Beanstalk application is a logical collection of application version and environments. ",
    "url": "/docs/aws/beanstalk.html#elastic-beanstalk-application",
    
    "relUrl": "/docs/aws/beanstalk.html#elastic-beanstalk-application"
  },"164": {
    "doc": "Elastic Beanstalk",
    "title": "Environment Tier",
    "content": "When you create an EB application, you are asked to choose an environment tier. This tier determines which resources EB should provision to form your environment. When creating a web app, you often require both environment tiers. Web Server Environment . Key resources launched in the EB container: . | Elastic Load Balancer | EC2 (Auto Scaling Group, Security Group) | . A web server environment serves HTTP requests. Web server environment is given a URL of myapp.region.elasticbeanstalk.com. This environment creates an Elastic Load Balancer with a URL of of elb-id.region.elb.amazonaws.com. In Amazon Route 53, this ELB URL has a CNAME Record to the environment URL. This ELB sits in front of EC2 instances in a Auto Scaling Group (ASG). The stack on EC2 instances depends on which platform you chose (eg. Python 3.8 running on 64bit Amazon Linux 2). However, in each instance sits one common component called the host manager (HM). HM manages all sorts of monitoring, deploying, and metrics related to the instance. By default, EC2 instances are placed in a security group which allows all connection through port 80 (HTTP). Additional security groups maybe configured as needed. Worker Environment . Key resources launched in EB container: . | SQS | EC2 (Auto Scaling Group), Sqsd | Cloudwatch | . Worker environment is usually set up for long running tasks to run in the background. A worker environment sets up an Amazon SQS queue. This queue often consists of messages from a web server environment. On each EC2 instance runs a Sqsd daemon and a processing application. The daemon reads the message from the SQS queue and sends it as an HTTP POST request to the processing application. Upon a 200 OK response from the processing application, Sqsd sends a delete message call to SQS. EC2 instances publish their metrics to Amazon Cloudwatch. Auto Scaling retrieves usage data from Cloudwatch and scales instances accordingly. ",
    "url": "/docs/aws/beanstalk.html#environment-tier",
    
    "relUrl": "/docs/aws/beanstalk.html#environment-tier"
  },"165": {
    "doc": "Elastic Beanstalk",
    "title": "Deployment",
    "content": "Each deployment is identified with a deployment ID which increments from 1. In-Place Deployment Policies . All at once . Every instance is killed and updated at the same time. The deployment is quick in that sense, but it results in a short loss of service. Also, it can be dangerous in case of a failure to deploy, and may be tricky to rollback. Rolling . Updates one batch of instances at a time. So a batch can be down during an update which may result in reduced availability for a short time. However, there is no downtime unlike ‘All at once’, but the entire deployment process takes a longer time. Rolling with additional batch . To avoid any reduced bandwidth in regular rolling deployment, an extra batch of instances is launched and rolling update is performed there. Hence, the number of instances up during deployment stays the same. This takes longer time. Immutable . Instead of updating instances, a complete new Auto Scaling Group set of instances is created. This is even slower. Traffic Splitting . Create a new set of instances and test it with a portion of the incoming traffic, while the rest of the traffic is still going to the old deployment version. This is as slow as ‘Immutable’. Blue/Green Deployment Policy . One additional deployment option is the Blue/Green deployment. All the other deployment policies above performs an In-Place deployment, which means the update happens within an EB environment. However, Blue/Green deployment goes beyond the instances inside the environment. To avoid downtime, your deployment is launched to a complete new set of environment and then the CNAMEs of old and new environments are swapped to redirect traffic instantly. ",
    "url": "/docs/aws/beanstalk.html#deployment",
    
    "relUrl": "/docs/aws/beanstalk.html#deployment"
  },"166": {
    "doc": "Elastic Beanstalk",
    "title": "Configuring Environments",
    "content": "There are many different ways to configure environments. Order of Precedence . | Settings applied directly during create/update environment | Saved configuration objects in S3 | Configuration files (.ebextensions, env.yaml) | Default values | . Configuration Files (.ebextensions) . You can place .config files in a folder .ebextensions at the root of the application source bundle. Each .config files are applied in alphabetical order. YAML is recommended for configuration files but both YAML and JSON are supported. Option Settings . Use option_settings key to configure environment options . option_settings: - namespace: namespace option_name: option name value: option value . Linux Server . You can also configure the software running on your instances. Check these link1, link2 for details. Environment Manifest (env.yaml) . Place an env.yaml file at the root of the application source bundle to configure the environment. You can configure the name, solution stack, and links to other environments. There are some overlaps between .configs and env.yaml. It seems env.yaml is more environment specific, while .config files can handle overall configuration of the application. Check the link for details. ",
    "url": "/docs/aws/beanstalk.html#configuring-environments",
    
    "relUrl": "/docs/aws/beanstalk.html#configuring-environments"
  },"167": {
    "doc": "Elastic Beanstalk",
    "title": "EB CLI",
    "content": "EB CLI is an open-source project hosted in this repository. To use the CLI application, however, clone this setup repository instead. References: . | Web Server Environment] | Worker Environment] | Deployments | Configuring Environment | EB CLI | . ",
    "url": "/docs/aws/beanstalk.html#eb-cli",
    
    "relUrl": "/docs/aws/beanstalk.html#eb-cli"
  },"168": {
    "doc": "Elastic Beanstalk",
    "title": "Elastic Beanstalk",
    "content": " ",
    "url": "/docs/aws/beanstalk.html",
    
    "relUrl": "/docs/aws/beanstalk.html"
  },"169": {
    "doc": "Bias-Variance Tradeoff",
    "title": "Bias-Variance Tradeoff",
    "content": ". | Explanation | Mean Squared Error (MSE) Decomposition | . ",
    "url": "/docs/data-science/ml-dl/bias-variance-trade.html",
    
    "relUrl": "/docs/data-science/ml-dl/bias-variance-trade.html"
  },"170": {
    "doc": "Bias-Variance Tradeoff",
    "title": "Explanation",
    "content": "Bias-variance tradeoff describes a dilemma in model training. When a model is more complex, it becomes more flexible and lowers the bias of the model. Remember that bias is the difference between the expected value of the estimator and the true value $\\E[\\hat{\\theta}] - \\theta$. So basically, the error in regression. However, as the model becomes more complex, sensitivity to different training data increases, which increases the variance of the model. High variance of a model can be a sign of overfitting. On the other hand, if you aim for low variance in training, you end up with a high bias. Summary: . | Flexible: Low bias, high variance | Rigid: High bias, low variance | . As the number of observations increases, the chance of overfitting, and thus variance, decreases. So if we have a lot of data, complex and flexible models generally perform better. ",
    "url": "/docs/data-science/ml-dl/bias-variance-trade.html#explanation",
    
    "relUrl": "/docs/data-science/ml-dl/bias-variance-trade.html#explanation"
  },"171": {
    "doc": "Bias-Variance Tradeoff",
    "title": "Mean Squared Error (MSE) Decomposition",
    "content": ". | See also MSE of an estimator. | . We know that the difference between the estimation and true value is often measured by the mean squared error (MSE). As explained in the above link, MSE is decomposed into bias and variance of the estimator: . $$ \\text{MSE}(\\hat{y}) = \\text{bias}^2(\\hat{y}) + \\Var(\\hat{y}) $$ . Remember that $bias(\\hat{y}) = \\E[\\hat{y}] - y$. Irreducible Error In model training there is an additional error called irreducible error, which is the variance of the noise term $\\epsilon$ in the model: . \\[\\text{MSE}(\\hat{y}) = \\text{bias}^2(\\hat{y}) + \\Var(\\hat{y}) + \\boldsymbol{\\Var(\\epsilon)}\\] As mentioned in regression function, $\\text{bias}^2(\\hat{y}) + \\Var(\\hat{y})$ is the reducible error, and we try to minimize this part. Ideally, we’d like to minimize MSE by decreasing both bias and variance, but bias-variance tradeoff tells us that you cannot have both worlds. Attempt to lower the bias of an estimator $\\hat{y}$ (reduce error, overfit) increases the variance of the estimator, and vice versa. Therefore, MSE does not get any better by simply reducing one of them. Instead, MSE is minimized when the bias and variance are balanced. ",
    "url": "/docs/data-science/ml-dl/bias-variance-trade.html#mean-squared-error-mse-decomposition",
    
    "relUrl": "/docs/data-science/ml-dl/bias-variance-trade.html#mean-squared-error-mse-decomposition"
  },"172": {
    "doc": "Binomial Test",
    "title": "Binomial Test",
    "content": ". | Binomial Distribution . | Probability Mass Function | Sum of Binomial Random Variables | . | Hypothesis Test . | Null Hypothesis | Calculating the p-value | . | . ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html"
  },"173": {
    "doc": "Binomial Test",
    "title": "Binomial Distribution",
    "content": "Binomial distribution is a discrete probability distribution that describes the probability of a success in a binomial (yes-no) experiment. Each binomial experiment is also called a Bernoulli trial: . | Each trial has binary outcome: success or failure | Each trial is independent of each other | The probability of success is the same for each trial, denoted as $p$ | The number of trials is fixed, denoted as $n$ | . When probability of success $p$ is: . | $p = 0.5$, the distribution is symmetric | $p &lt; 0.5$, the distribution is skewed to the left | $p &gt; 0.5$, the distribution is skewed to the right | . ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html#binomial-distribution",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html#binomial-distribution"
  },"174": {
    "doc": "Binomial Test",
    "title": "Probability Mass Function",
    "content": "Let $X$ be the random variable that represents the number of successes in $n$ trials, and $p$ be the probability of success in each trial. Then, the probability mass function of $X$ is: . $$ Pr\\left[X = k\\right] = \\binom{n}{k} p^k (1-p)^{n-k} $$ . Binomial Coefficient \\[\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\] where $k$ is the number of successes in $n$ trials. Then we say that $X$ follows a binomial distribution with parameters $n$ and $p$: . $$ X \\sim \\text{Binomial}(n, p) $$ . ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html#probability-mass-function",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html#probability-mass-function"
  },"175": {
    "doc": "Binomial Test",
    "title": "Sum of Binomial Random Variables",
    "content": "If $X_1 \\sim \\text{Binomial}(n_1, p)$ and $X_2 \\sim \\text{Binomial}(n_2, p)$, . $$ X_1 + X_2 \\sim \\text{Binomial}(n_1 + n_2, p) $$ . ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html#sum-of-binomial-random-variables",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html#sum-of-binomial-random-variables"
  },"176": {
    "doc": "Binomial Test",
    "title": "Hypothesis Test",
    "content": " ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html#hypothesis-test",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html#hypothesis-test"
  },"177": {
    "doc": "Binomial Test",
    "title": "Null Hypothesis",
    "content": "Let $P$ be the probability of success in a binomial experiment. Supose we were testing whether a coin is fair or not. Then, the null hypothesis would be: . $$ H_0: P = 0.5 $$ . Meaning the chances of getting heads or tails are equal. ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html#null-hypothesis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html#null-hypothesis"
  },"178": {
    "doc": "Binomial Test",
    "title": "Calculating the p-value",
    "content": "When the null hypothesis is true, we can plug in $P = 0.5$ into the probability mass function: . \\[Pr\\left[X = k\\right] = \\binom{n}{k} 0.5^n\\] Suppose our sample had 21 heads out of 30 trials. Now we want to calculate our p-value which is the probability of observing an outcome as extreme as the one we observed, in a binomial distribution with $n = 30$ and $p = 0.5$. The probability of this extreme case is the sum of the probabilities of getting 21 or more heads or 9 or less heads: . \\[Pr\\left[X \\geq 21\\right] + Pr\\left[X \\leq 9\\right] = \\sum_{k=21}^{30} \\binom{30}{k} 0.5^{30} + \\sum_{k=0}^{9} \\binom{30}{k} 0.5^{30} \\approx 0.043\\] Remember, with two-tailed test, we need to take both extremes into account. Based on the results, we can reject the null hypothesis as $0.043 &lt; 0.05$. ",
    "url": "/docs/statistics/basics/hypothesis-test/binomial-test.html#calculating-the-p-value",
    
    "relUrl": "/docs/statistics/basics/hypothesis-test/binomial-test.html#calculating-the-p-value"
  },"179": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Bivariate Distribution",
    "content": ". | Joint Mass Function | Joint Densitity Function | Marginal Mass Function | Marginal Density Function | Independence . | With Density Functions? | . | . ",
    "url": "/docs/statistics/notes/bivariate-dist.html#bivariate-distribution",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#bivariate-distribution"
  },"180": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Joint Mass Function",
    "content": "Let $X$ and $Y$ be two discrete random variables. | Discrete case: joint mass function | . $$ p_{X,Y}(x,y) = P(X=x, Y=y) $$ . ",
    "url": "/docs/statistics/notes/bivariate-dist.html#joint-mass-function",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#joint-mass-function"
  },"181": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Joint Densitity Function",
    "content": "Let $X$ and $Y$ be two continuous random variables. | Continuous case: joint density function | . $$ f_{X,Y}(x,y) $$ . Remember, unlike mass functions, density functions are not probabilities. ",
    "url": "/docs/statistics/notes/bivariate-dist.html#joint-densitity-function",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#joint-densitity-function"
  },"182": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Marginal Mass Function",
    "content": "If $X$ and $Y$ are joint distributions with joint function $p_{X,Y}(x,y)$, . | Discrete case: marginal mass function | . $$ p_X(x) = P(X=x) = \\sum_{y} p_{X,Y}(x,y) $$ . ",
    "url": "/docs/statistics/notes/bivariate-dist.html#marginal-mass-function",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#marginal-mass-function"
  },"183": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Marginal Density Function",
    "content": "If $X$ and $Y$ are joint distributions with joint density function $f_{X,Y}(x,y)$, . | Continuous case: marginal density function | . $$ f_X(x) = \\int f_{X,Y}(x,y) dy $$ . ",
    "url": "/docs/statistics/notes/bivariate-dist.html#marginal-density-function",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#marginal-density-function"
  },"184": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Independence",
    "content": "Let $X$ and $Y$ be two random variables. $X$ and $Y$ are independent if: . $$ P(X=x, Y=y) = P(X=x)P(Y=y) $$ . ",
    "url": "/docs/statistics/notes/bivariate-dist.html#independence",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#independence"
  },"185": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "With Density Functions?",
    "content": "Even though density functions are not probabilities, if and only if the following holds for continuous random variables: . $$ f_{X,Y}(x,y) = f_X(x)f_Y(y) $$ . then $X$ and $Y$ are independent. Furthermore Furthermore, if we can factorize a joint density function $f_{X,Y}(x,y)$ into, . \\[f_{X,Y}(x,y) = g(x)h(y)\\] where $g(x)$ and $h(y)$ are not necessarily density functions, then $X$ and $Y$ are independent. ",
    "url": "/docs/statistics/notes/bivariate-dist.html#with-density-functions",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html#with-density-functions"
  },"186": {
    "doc": "Bivariate Distribution (Joint Distribution)",
    "title": "Bivariate Distribution (Joint Distribution)",
    "content": " ",
    "url": "/docs/statistics/notes/bivariate-dist.html",
    
    "relUrl": "/docs/statistics/notes/bivariate-dist.html"
  },"187": {
    "doc": "Boosted Trees",
    "title": "Boosted Trees",
    "content": "Another ensemble method that does not rely on bootstrap sampling is boosting. One drawback is that we lose interpretability, even more so than random forests. | Difference from Bagging | Process . | Initial Model and Training Set | Number of Trees $B$ | Number of Splits $d$ | Training Each Tree | Shrinkage Parameter $\\lambda$ | Update the Model | Final Model | . | . ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html"
  },"188": {
    "doc": "Boosted Trees",
    "title": "Difference from Bagging",
    "content": ". | We do not use bootstrap sampling. | We fit each tree with the enitre, but weighted, dataset. | . Fitting the Data Hard When we try to fit a single large data to a model, we say we are fitting the data hard. This often leads to issues like overfitting and high variance. In boosting, we ultimately learn the entire dataset, but we do so in slowly. ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#difference-from-bagging",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#difference-from-bagging"
  },"189": {
    "doc": "Boosted Trees",
    "title": "Process",
    "content": "Following is explained in the context of regression. With classification it is a bit more tricky. But it still is a bottom-up approach fitting to errors from the previous smaller tree. ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#process",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#process"
  },"190": {
    "doc": "Boosted Trees",
    "title": "Initial Model and Training Set",
    "content": "With boosting, we start from an empty tree: . \\[\\hat{f}(x) = 0\\] and sequentially try to fit the next tree using the residuals of the previous tree. The initial residuals are just the response values themselves, since the model just outputs zero: . \\[\\forall i,\\; r_i = y_i\\] So our initial training set is: . $$ \\left\\{ x_i, r_i \\right\\}_{i=1}^{n} $$ . Which is the same as the original dataset. ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#initial-model-and-training-set",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#initial-model-and-training-set"
  },"191": {
    "doc": "Boosted Trees",
    "title": "Number of Trees $B$",
    "content": "We are given a fixed number of trees $B$ to fit. This $B$ has nothing to do with bootstrap sampling. Unlike bagging, high $B$ can lead to overfitting (although not as drastically as we learn slowly), so we use cross-validation to find the optimal $B$. ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#number-of-trees-b",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#number-of-trees-b"
  },"192": {
    "doc": "Boosted Trees",
    "title": "Number of Splits $d$",
    "content": "We select $d$, a small number which represents how many splits each intermediate tree can have ($d$ splits = $d+1$ terminal nodes). This is to ensure that we’re never fitting the data too hard in one go. Choosing $d$ We often choose $d=1$. In this case, each tree is called a stump. Using a stump leads to an additive model: . \\[\\hat{Y} = \\beta_0 + \\sum_{j=1}^p f_j(X_j)\\] ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#number-of-splits-d",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#number-of-splits-d"
  },"193": {
    "doc": "Boosted Trees",
    "title": "Training Each Tree",
    "content": "Each tree is fit to the residuals of the previous tree: . \\[\\hat{f}^b(x)\\] ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#training-each-tree",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#training-each-tree"
  },"194": {
    "doc": "Boosted Trees",
    "title": "Shrinkage Parameter $\\lambda$",
    "content": "We select $\\lambda &gt; 0$, a small shrinkage parameter (such as $0.01$ or $0.001$) that controls the rate of learning. Again, this is to ensure slow learning. Smaller $\\lambda$ requires more trees $B$ to fit the model. ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#shrinkage-parameter-lambda",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#shrinkage-parameter-lambda"
  },"195": {
    "doc": "Boosted Trees",
    "title": "Update the Model",
    "content": "Once we have the $b$-th tree, we update our model: . $$ \\hat{f}(x) \\leftarrow \\hat{f}(x) + \\lambda \\hat{f}^b(x) $$ . We also update each residual: . $$ r_i \\leftarrow r_i - \\lambda \\hat{f}^b(x_i) $$ . We repeat training and updating $B$ times. ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#update-the-model",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#update-the-model"
  },"196": {
    "doc": "Boosted Trees",
    "title": "Final Model",
    "content": "Our final model is the shrunken sum of all the trees: . $$ \\hat{f}(x) = \\sum_{b=1}^{B} \\lambda \\hat{f}^b(x) $$ . ",
    "url": "/docs/data-science/ml-dl/boosted-trees.html#final-model",
    
    "relUrl": "/docs/data-science/ml-dl/boosted-trees.html#final-model"
  },"197": {
    "doc": "Bootstrap",
    "title": "Bootstrap",
    "content": "When we don’t know the distribution of the data, we often use non-parametric inference and try to estimate important statistics with the empirical distribution function. Calculating the measures of uncertainty (e.g. standard error, confidence interval) of these estimated statistics is often difficult. The bootstrap allows us to estimate these measures of uncertainty of estimated statistics using simple resampling techniques and Monte Carlo simulation. | Layers of Approximation | Monte Carlo Simulation | Bootstrap Variance | Bootstrap Percentile Confidence Interval . | Normal Interval | Percentile Interval | Pivot Interval | . | In Practice | . ",
    "url": "/docs/statistics/notes/bootstrap.html",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html"
  },"198": {
    "doc": "Bootstrap",
    "title": "Layers of Approximation",
    "content": "Let’s say we have some samples $X_1, \\dots, X_n$ from an unknown distribution $F$. $T_n = g(X_1, \\dots, X_n)$ is a sample statistic. For example: the sample mean, median, or variance. We want to estimate the uncertainty in the sample distribution of $T_n$, for example $\\Var(T_n)$. But the calculation of $\\Var(T_n)$ is often difficult because we don’t know $F$. Instead, we use the empirical distribution function $\\hat{F}_n$. Draw samples from $\\hat{F}_n$ and calculate the statistic of interest, aggregate the results and calculate the sample variance of these resamples (bootstrap samples). Then we argue that the sample variance of the bootstrap samples is a good estimate variance of the sample distribution $T_n$ (see below). We need to know that there are two layers of approximation happpening in the bootstrap. The first comes from the approximation of the true distribution with the empirical distribution function: . $$ \\Var(T(F)) \\approx \\Var(T(\\hat{F}_n)) $$ . Using a slightly different notation $T(F)$ is a statistical functional of the CDF $F$, and $T(\\hat{F}_n)$ is the plug-in estimator using the eCDF. The second comes from the approximation of the uncertainty in sample distribution using Monte Carlo simulation: . $$ \\Var(T(\\hat{F}_n)) \\approx v_{boot}(T(\\hat{F}_n)) $$ . Increasing the number of simulations will make the second approximation more accurate. ",
    "url": "/docs/statistics/notes/bootstrap.html#layers-of-approximation",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#layers-of-approximation"
  },"199": {
    "doc": "Bootstrap",
    "title": "Monte Carlo Simulation",
    "content": "By law of large numbers, as $B \\to \\infty$, . \\[\\frac{1}{B} \\sum_{b=1}^B g(X_b) \\xrightarrow{P} E[g(X)] = \\int g(x) dF(x)\\] and the sample variance follows: . \\[\\frac{1}{B-1} \\sum_{b=1}^B (g(X_b) - \\overline{g})^2 \\xrightarrow{P} \\Var(g(X)) = \\int g^2(x) dF(x) - \\left(\\int g(x) dF(x)\\right)^2\\] The same applies to multivariate function $g(X_1, \\dots, X_n) = T_n$ as long as the IID assumption holds: . \\[\\frac{1}{B} \\sum_{b=1}^B T_{n, b} \\xrightarrow{P} E[T_n]\\] \\[\\frac{1}{B-1} \\sum_{b=1}^B (T_{n, b} - \\overline{T}_n)^2 \\xrightarrow{P} \\Var(T_n)\\] This is the idea behind the bootstrap. The only thing is that we draw the samples from $\\hat{F}_n$ instead of $F$. ",
    "url": "/docs/statistics/notes/bootstrap.html#monte-carlo-simulation",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#monte-carlo-simulation"
  },"200": {
    "doc": "Bootstrap",
    "title": "Bootstrap Variance",
    "content": "Let $T_n = g(X_1, \\dots, X_n)$ be a statistic of interest where $X_1, \\dots, X_n$ are IID samples from an unknown distribution $F$. We want to estimate $\\Var(T_n) \\approx v_{boot}(T_n)$. | Resampling: Draw $n$ samples with replacement from eCDF $\\hat{F}_n$. \\[X_1^*, \\dots, X_n^* \\sim \\hat{F}_n\\] | Calculation: Calculate the statistic of interest using the resampled data. \\[T_{n, b}^* = g(X_1^*, \\dots, X_n^*)\\] | Repeat: Repeat above two steps $B$ times to obtain $B$ bootstrap samples. \\[T_{n, 1}^*, \\dots, T_{n, B}^*\\] | Estimation: Calculate the sample variance of the bootstrap samples. \\[v_{boot}(T_n) = \\frac{1}{B-1} \\sum_{b=1}^B \\left(T_{n, b}^* - \\frac{1}{B} \\sum_{r=1}^B T_{n, r}^*\\right)^2\\] | . ",
    "url": "/docs/statistics/notes/bootstrap.html#bootstrap-variance",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#bootstrap-variance"
  },"201": {
    "doc": "Bootstrap",
    "title": "Bootstrap Percentile Confidence Interval",
    "content": " ",
    "url": "/docs/statistics/notes/bootstrap.html#bootstrap-percentile-confidence-interval",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#bootstrap-percentile-confidence-interval"
  },"202": {
    "doc": "Bootstrap",
    "title": "Normal Interval",
    "content": "When $T_n$ is approximately normally distributed, the normal interval can be used: . \\[T_n \\pm z_{\\alpha/2} \\sqrt{v_{boot}(T_n)}\\] ",
    "url": "/docs/statistics/notes/bootstrap.html#normal-interval",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#normal-interval"
  },"203": {
    "doc": "Bootstrap",
    "title": "Percentile Interval",
    "content": "Let $T_{n, (1/B)}^* \\leq T_{n, (2/B)}^* \\leq \\dots \\leq T_{n, (1)}^*$ be the ordered bootstrap samples. The percentile interval is: . \\[C_n = (T_{n, (\\alpha/2)}^*, T_{n, (1-\\alpha/2)}^*)\\] ",
    "url": "/docs/statistics/notes/bootstrap.html#percentile-interval",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#percentile-interval"
  },"204": {
    "doc": "Bootstrap",
    "title": "Pivot Interval",
    "content": "Let $\\theta = T(F)$ be the statistic and $\\hat{\\theta}_n = T(\\hat{F}_n)$ be the estimated statistic using the empirical distribution function. Define a pivot: . $$ R_n = \\hat{\\theta}_n - \\theta $$ . If we know the distribution of $R_n$, we could calculate the inverse CDF or the quantiles of $R_n$ and calculate the CI just like we did with standard normal distribution. However, we don’t know the distribution of $R_n$: . \\[H(r) = \\Pr(R_n \\leq r)\\] Instead we bootstrap the pivot: . \\[R_{n, b}^* = \\hat{\\theta}_{n, b}^* - \\hat{\\theta}_n\\] Then the bootstrap estimate of the distribution is: . \\[\\hat{H}_{boot}(r) = \\frac{1}{B} \\sum_{b=1}^B I(R_{n, b}^* \\leq r)\\] Then we’d know the inverse of $\\hat{H}_{boot}(r)$. To get the $1 - \\alpha$ CI, we have to know both the $\\alpha/2$ and $1 - \\alpha/2$ quantiles of $\\hat{H}_{boot}(r)$, because we don’t know if this distribution is symmetric unlike the standard normal distribution. Denote: . \\[\\begin{align*} r_{\\alpha/2}^* &amp;= \\hat{H}_{boot}^{-1}(\\alpha/2) \\\\[0.5em] r_{1 - \\alpha/2}^* &amp;= \\hat{H}_{boot}^{-1}(1 - \\alpha/2) \\end{align*}\\] Since $r_{1 - \\alpha/2}^* &gt; r_{\\alpha/2}^*$ the $1 - \\alpha$ CI is: . \\[\\hat{\\theta}_n - r_{1 - \\alpha/2}^* \\leq \\theta \\leq \\hat{\\theta}_n - r_{\\alpha/2}^*\\] . ",
    "url": "/docs/statistics/notes/bootstrap.html#pivot-interval",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#pivot-interval"
  },"205": {
    "doc": "Bootstrap",
    "title": "In Practice",
    "content": "Same idea, just explained in a different way. Instead of drawing from the empirical distribution function $\\hat{F}_n$, we are given a dataset $Z$. Bootstrap samples are drawn from $Z$ with replacement. The cardinality of the bootstrap sample is the same as the original dataset. Which means that the bootstrap sample can contain the same data point multiple times. ",
    "url": "/docs/statistics/notes/bootstrap.html#in-practice",
    
    "relUrl": "/docs/statistics/notes/bootstrap.html#in-practice"
  },"206": {
    "doc": "Central Limit Theorem / Law of Large Numbers",
    "title": "Central Limit Theorem / Law of Large Numbers",
    "content": ". | The Law of Large Numbers | Central Limit Theorem (CLT) | Central Limit Theorem with SEM | Multivariate CLT | . ",
    "url": "/docs/statistics/notes/central-limit-theorem.html",
    
    "relUrl": "/docs/statistics/notes/central-limit-theorem.html"
  },"207": {
    "doc": "Central Limit Theorem / Law of Large Numbers",
    "title": "The Law of Large Numbers",
    "content": "The weak law of large numbers states that, when $X_1, \\dots, X_n$ are IID, sample mean $\\overline{X}_n$ converges in probability to the population mean $\\mu$ as number of samples $n$ increases. $$ \\overline{X}_n \\xrightarrow{P} \\mu $$ . ",
    "url": "/docs/statistics/notes/central-limit-theorem.html#the-law-of-large-numbers",
    
    "relUrl": "/docs/statistics/notes/central-limit-theorem.html#the-law-of-large-numbers"
  },"208": {
    "doc": "Central Limit Theorem / Law of Large Numbers",
    "title": "Central Limit Theorem (CLT)",
    "content": "The central limit theorem states that, when $X_1, \\dots, X_n$ are IID with mean $\\mu$ and variance $\\sigma^2$, the sample mean $\\overline{X}_n$ converges in distribution to a normal distribution. $$ \\overline{X}_n \\leadsto N\\left(\\mu, \\frac{\\sigma^2}{n}\\right) $$ . Remembering from here that, . \\[\\begin{align*} \\E[\\overline{X}_n] &amp;= \\mu \\\\[0.5em] \\Var(\\overline{X}_n) &amp;= \\frac{\\sigma^2}{n} \\end{align*}\\] Standardizing the Sample Mean Alternative form of the CLT is to standardize the sample mean, . \\[Z_n = \\frac{\\overline{X}_n - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\sqrt{n}(\\overline{X}_n - \\mu)}{\\sigma} \\leadsto N(0, 1)\\] So, $Z_n$ converges to a standard normal distribution. You might think, wouldn’t $\\overline{X}_n - \\mu$ converge to $0$ by the law of large numbers? However, it turns out that $\\sqrt{n}$ is the factor that controls the convergence rate so that the denominator neither shrinks or blows up too fast, but just right to converge to a normal distribution. ",
    "url": "/docs/statistics/notes/central-limit-theorem.html#central-limit-theorem-clt",
    
    "relUrl": "/docs/statistics/notes/central-limit-theorem.html#central-limit-theorem-clt"
  },"209": {
    "doc": "Central Limit Theorem / Law of Large Numbers",
    "title": "Central Limit Theorem with SEM",
    "content": "In practice, we often do not know $\\sigma$. So instead of using standard deviation of the sample mean $\\frac{\\sigma}{\\sqrt{n}}$, we use the estimated standard error of the mean (SEM) $\\frac{S_n}{\\sqrt{n}}$, where $S_n$ is the sample standard deviation. Then, the CLT becomes, . $$ \\frac{\\overline{X}_n - \\mu}{S_n / \\sqrt{n}} \\leadsto N(0, 1) $$ . How? The estimation using SEM is equivalent to: . \\[\\frac{\\overline{X}_n - \\mu}{S_n / \\sqrt{n}} = \\frac{\\overline{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\cdot \\frac{\\sigma}{S_n}\\] We know that $\\frac{\\overline{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\leadsto N(0, 1)$ from the CLT. We know that . \\[S_n \\xrightarrow{P} \\sigma \\quad \\implies \\quad \\frac{\\sigma}{S_n} \\xrightarrow{P} 1 \\quad \\implies \\quad \\frac{\\sigma}{S_n} \\leadsto 1\\] By the property of convergence in distribution, . \\[\\frac{\\overline{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\cdot \\frac{\\sigma}{S_n} \\leadsto N(0, 1) \\cdot 1\\] . ",
    "url": "/docs/statistics/notes/central-limit-theorem.html#central-limit-theorem-with-sem",
    
    "relUrl": "/docs/statistics/notes/central-limit-theorem.html#central-limit-theorem-with-sem"
  },"210": {
    "doc": "Central Limit Theorem / Law of Large Numbers",
    "title": "Multivariate CLT",
    "content": "Now each $\\boldsymbol{X}_i \\in \\mathbb{R}^k$ is a random vector with mean vector $\\boldsymbol{\\mu} \\in \\mathbb{R}^k$ and covariance matrix $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{k \\times k}$. \\[\\boldsymbol{X}_i = \\begin{bmatrix} X_{1i} \\\\ X_{2i} \\\\ \\vdots \\\\ X_{ki} \\end{bmatrix}\\] The sample mean vector $\\boldsymbol{\\overline{X}}_n$ is, . \\[\\boldsymbol{\\overline{X}}_n = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol{X}_i = \\begin{bmatrix} \\overline{X}_{1} \\\\ \\overline{X}_{2} \\\\ \\vdots \\\\ \\overline{X}_{k} \\end{bmatrix}\\] Then, the multivariate CLT states that, . $$ \\sqrt{n}(\\boldsymbol{\\overline{X}}_n - \\boldsymbol{\\mu}) \\leadsto N(\\boldsymbol{0}, \\boldsymbol{\\Sigma}) $$ . ",
    "url": "/docs/statistics/notes/central-limit-theorem.html#multivariate-clt",
    
    "relUrl": "/docs/statistics/notes/central-limit-theorem.html#multivariate-clt"
  },"211": {
    "doc": "SSH Certificates",
    "title": "SSH Certificates",
    "content": ". | SSH authentication methods | SSH certificates | Host certificate . | Configure a host CA | Sign the host key with CA | Save host CA public key on client | . | Client certificate . | Configure a client CA | Sign the client key with CA | Save client CA public key on host | . | Host sshd_config settings | Test connection | Debugging . | From the client side | From the host side . | Linux | macOS | . | To check certificate metadata | . | SSH certificate extensions | . ",
    "url": "/docs/security/ssh/cert.html",
    
    "relUrl": "/docs/security/ssh/cert.html"
  },"212": {
    "doc": "SSH Certificates",
    "title": "SSH authentication methods",
    "content": "There are two popular ways to SSH into a server. | Use a system password | Use SSH key | . Using an SSH key adds more security layers compared to using a system password. However, even with an SSH key, there still exists a problem that once an SSH key is placed on the authorized_keys of the server, it is permanent unless someone actively removes it. This may not matter if you’re the one and only person trying to SSH into a server, but if the number of people that need to be given or revoked access increases, this can become a hassle. Using SSH certificates can alleviate these issues. ",
    "url": "/docs/security/ssh/cert.html#ssh-authentication-methods",
    
    "relUrl": "/docs/security/ssh/cert.html#ssh-authentication-methods"
  },"213": {
    "doc": "SSH Certificates",
    "title": "SSH certificates",
    "content": "SSH certificate authentication goes in both directions. The server/host presents its certificate to the user/client, and vice versa. The whole idea of a certificate is simple: . | Both parties agree on some authority and trust what it signs. | . Such authority is called a Certificate Authority (CA). Technically, our CA is just a pair of cryptographic keys. So instead of trusting each user keys, parties will decide trust the CA that will sign those keys. This eliminates having to accumulate public keys in authorized_keys. In addition, CAs can set a expiration date on their signatures. So if you decide to give someone a server access for only a single day, but don’t want to bother remembering to come back after a day to remove his/her key from your authorized_keys, you can have the CA sign the key to only be valid for a day. In the following example, I will be using Vault to manage these CAs. ",
    "url": "/docs/security/ssh/cert.html#ssh-certificates-1",
    
    "relUrl": "/docs/security/ssh/cert.html#ssh-certificates-1"
  },"214": {
    "doc": "SSH Certificates",
    "title": "Host certificate",
    "content": "Usually people dismiss the need for host certificates. However it is a good security layer to prevent SSHing into a bad machine. When you’re SSHing without a certificate, you’ve probably seen something like this. $ ssh server The authenticity of host 'badsiteindisguise.com' can't be established...cryptographic key fingerprint... Are you sure you want to continue connecting (yes/no/[fingerprint])? . Usually you just end up typing yes, which adds the fingerprint to ~/.ssh/known_hosts and you never see the prompt again. However, just like the prompt says, are you sure that this site can be trusted? Are you sure that there wasn’t a man in the middle that redirected you to one of his bad machines? . By placing a trusted host CA’s public key on the client before the first SSH, this security risk can be avoided. Configure a host CA . Create a key pair for host CA: . ssh-keygen -t ed25519 -C \"hostca\" -f hostca . Which produces hostca and hostca.pub. vault write ssh-host-signer/config/ca generate_signing_key=true currently only generates rsa keys, which is deprecated in newer OpenSSH. To use different crypto algorithms such as ed25519, you have to generate one and upload it to Vault. Mount the SSH secrets engine on Vault: . vault secrets enable -path=ssh-host-signer ssh . The path can be anything you like, just make sure you are logged in to Vault and has the policy to read/write to that path. Upload the CA key pair: . vault write ssh-host-signer/config/ca \\ private_key=@hostca \\ public_key=@hostca.pub . The @ points to the file. Use \"...\" to copy and paste the values. Extend the host key certificate TTL (time-to-live): . vault secrets tune -max-lease-ttl=87600h ssh-host-signer . 87600h is 10 years. Create a role to sign host keys: . vault write ssh-host-signer/roles/hostrole \\ key_type=ca \\ ttl=87600h \\ allow_host_certificates=true \\ allowed_domains=\"example.com,something.com\" \\ allow_bare_domains=true \\ allow_subdomains=true . Vault uses these roles to sign keys. The above configuration basically says it can sign host certificates for domains of example.com, *.example.com, something.com, *.something.com, and the certificate will be valid for 10 years. Sign the host key with CA . Sign and save the resulting certificate on the server: . vault write -field=signed_key ssh-host-signer/sign/hostrole \\ cert_type=host \\ public_key=@/etc/ssh/ssh_host_ed25519_key.pub &gt; /etc/ssh/ssh_host_ed25519_key-cert.pub . Optionally set permission on the certificate: . sudo chmod 0640 /etc/ssh/ssh_host_ed25519_key-cert.pub . If the host key doesn’t exist, create one using ssh-keygen. Update /etc/ssh/sshd_config: . HostKey /etc/ssh/ssh_ed25519_key HostCertificate /etc/ssh/ssh_ed25519_key-cert.pub . Save host CA public key on client . From the client, get the public key of ssh-host-signer CA: . # If using API endpoint curl &lt;vault-api-url&gt;/v1/ssh-host-signer/public-key . # If client has direct access to the Vault server vault read -field=public_key ssh-host-signer/config/ca . Save the result to client’s ~/.ssh/known_hosts: . @cert-authority *.example.com,*.something.com ssh-ed25519 ... If you have already logged in to the server before the host certificate was set up, remove the corresponding fingerprint in known_hosts. Try SSHing to the server with a password or a regular public key. Assuming you have never SSHed to the server before or have removed the previous fingerprint, SSH should not show you the Are you sure you want to continue prompt. If it does, the host certificate is not set up correctly. ",
    "url": "/docs/security/ssh/cert.html#host-certificate",
    
    "relUrl": "/docs/security/ssh/cert.html#host-certificate"
  },"215": {
    "doc": "SSH Certificates",
    "title": "Client certificate",
    "content": "Instead of having the client’s public key saved to host’s authorized_keys, we will have the client use a certificate to authenticate. Some of the process is actually very similar to above. Mostly the only difference is to use client or user instead of host. Configure a client CA . Create a key pair for client CA: . ssh-keygen -t ed25519 -C \"clientca\" -f clientca . Which produces clientca and clientca.pub. You can actually use the same pair of keys you used for host CA. Mount the SSH secrets engine on Vault: . vault secrets enable -path=ssh-client-signer ssh . Upload the CA key pair: . vault write ssh-client-signer/config/ca \\ private_key=@clientca \\ public_key=@clientca.pub . Create a role to sign client keys: . vault write ssh-client-signer/roles/clientrole -&lt;&lt;\"EOH\" { \"allow_user_certificates\": true, \"allowed_users\": \"my-user\", \"allowed_extensions\": \"permit-pty,permit-port-forwarding,permit-x11-forwarding,permit-agent-forwarding,permit-user-rc\", \"default_extensions\": [ { \"permit-pty\": \"\" } ], \"key_type\": \"ca\", \"default_user\": \"my-user\", \"ttl\": \"30m0s\" } EOH . | allowed_users: Comma separated list of allowed username | allowed_extensions: Comma separated list of extensions that client can request in their certificate | default_extensions: Default extensions given when this role signs a certificate | default_user: Username to use when one isn’t specified | ttl: Client certificate expires after ttl. | . Sign the client key with CA . Create an SSH key if one doesn’t already exist: . ssh-keygen -t ed25519 -C \"user@example.com\" -f client_key . Sign and save the resulting certificate on the client: . | To accept default | . vault write -field=signed_key ssh-client-signer/sign/clientrole \\ public_key=@client_key.pub &gt; client_key-cert.pub . | To customize | . vault write ssh-client-signer/sign/my-role -&lt;&lt;\"EOH\" { \"public_key\": \"ssh-ed25519 ...\", \"valid_principals\": \"my-user\", \"extensions\": { \"permit-pty\": \"\", \"permit-port-forwarding\": \"\" } } EOH . Then copy and paste the certificate to client_key-cert.pub. If your certificate ends in the &lt;same_base&gt;-cert.pub suffix, OpenSSH will automatically detect it so you won’t have to pass in your certificate as an identity file in addition to the private key. Save client CA public key on host . From the host, get the public key of ssh-client-signer CA and save it to /etc/ssh/trusted-user-ca-keys.pem: . # If using API endpoint curl -o /etc/ssh/trusted-user-ca-keys.pem http://127.0.0.1:8200/v1/ssh-client-signer/public_key . # If host has direct access to the Vault server vault read -field=public_key ssh-client-signer/config/ca &gt; /etc/ssh/trusted-user-ca-keys.pem . Now modify /etc/ssh/sshd_config on host: . # /etc/ssh/sshd_config TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem . ",
    "url": "/docs/security/ssh/cert.html#client-certificate",
    
    "relUrl": "/docs/security/ssh/cert.html#client-certificate"
  },"216": {
    "doc": "SSH Certificates",
    "title": "Host sshd_config settings",
    "content": "To disable SSH password authentication, . # /etc/ssh/sshd_config PasswordAuthentication no ChallengeResponseAuthentication no . Recap: . HostKey /etc/ssh/ssh_ed25519_key HostCertificate /etc/ssh/ssh_ed25519_key-cert.pub . # /etc/ssh/sshd_config TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem . ",
    "url": "/docs/security/ssh/cert.html#host-sshd_config-settings",
    
    "relUrl": "/docs/security/ssh/cert.html#host-sshd_config-settings"
  },"217": {
    "doc": "SSH Certificates",
    "title": "Test connection",
    "content": "Now the client should be able to authenticate to the server with certificates: . # If the certificate ends in '-cert.pub' with the same base name ssh -i ~/.ssh/client_key my-user@example.com . # If the certificate has a different naming scheme ssh -i ~/.ssh/client-certificate.pub -i ~/.ssh/client_key my-user@example.com . Connection is a success if you don’t see any fingerprint validation prompt and was able to connect without adding client_key.pub to host’s authorized_keys. ",
    "url": "/docs/security/ssh/cert.html#test-connection",
    
    "relUrl": "/docs/security/ssh/cert.html#test-connection"
  },"218": {
    "doc": "SSH Certificates",
    "title": "Debugging",
    "content": "From the client side . Add -vvv to get a verbose log output: . ssh -vvv -i ~/.ssh/client_key my-user@example.com . From the host side . Linux . Set the LogLevel in /etc/ssh/sshd_config to VERBOSE. Then inspect /var/log/auth.log. macOS . log show --process sshd --last &lt;num&gt; --debug --info . See log show help for details. To check certificate metadata . ssh-keygen -Lf ssh_key-cert.pub . ",
    "url": "/docs/security/ssh/cert.html#debugging",
    
    "relUrl": "/docs/security/ssh/cert.html#debugging"
  },"219": {
    "doc": "SSH Certificates",
    "title": "SSH certificate extensions",
    "content": "Some of the basic extensions (names are self explanatory): . | permit-pty: Allow interactive shell | permit-port-forwarding: Allow SSH tunnels | permit-x11-forwarding | permit-agent-forwarding | permit-user-rc | . References: . | Vault: Signed SSH Certificates | . ",
    "url": "/docs/security/ssh/cert.html#ssh-certificate-extensions",
    
    "relUrl": "/docs/security/ssh/cert.html#ssh-certificate-extensions"
  },"220": {
    "doc": "Chalice",
    "title": "Chalice",
    "content": ". | What is Chalice? | Install Chalice | Create a new project | Deploy / Delete | Multifiles | Configuration File . | Environment Variables | . | Deploying with Terraform | . ",
    "url": "/docs/aws/chalice.html",
    
    "relUrl": "/docs/aws/chalice.html"
  },"221": {
    "doc": "Chalice",
    "title": "What is Chalice?",
    "content": "It is a python serverless microframework. What it essentially does is combine AWS API Gateway and associated Lambda functions to help you quickly deploy a microservice. Everything you can do in Chalice you can do in the AWS console, but it is easier to manage via code. The syntax and the concept is very much similar to Flask if you’re familiar with it. ",
    "url": "/docs/aws/chalice.html#what-is-chalice",
    
    "relUrl": "/docs/aws/chalice.html#what-is-chalice"
  },"222": {
    "doc": "Chalice",
    "title": "Install Chalice",
    "content": "pip3 install chalice . As of now (2021-05), chalice best supports Python 3.8. As of now (2022) chalice supports Python 3.9. ",
    "url": "/docs/aws/chalice.html#install-chalice",
    
    "relUrl": "/docs/aws/chalice.html#install-chalice"
  },"223": {
    "doc": "Chalice",
    "title": "Create a new project",
    "content": "To create a new project, . chalice new-project myproj . This will create a myproj directory . myproj ├── .chalice ├── app.py └── requirements.txt . ",
    "url": "/docs/aws/chalice.html#create-a-new-project",
    
    "relUrl": "/docs/aws/chalice.html#create-a-new-project"
  },"224": {
    "doc": "Chalice",
    "title": "Deploy / Delete",
    "content": "The AWS credentials must already be set in ~/.aws/config. To deploy, simply . chalice deploy chalice deploy --stage ${stage} --profile ${profile} . To delete, . chalice delete chalice delete --stage ${stage} --profile ${profile} . ",
    "url": "/docs/aws/chalice.html#deploy--delete",
    
    "relUrl": "/docs/aws/chalice.html#deploy--delete"
  },"225": {
    "doc": "Chalice",
    "title": "Multifiles",
    "content": "If you want to have multiple .py files apart from the app.py(which you will), place all the lib or utils related file in a folder called chalicelib. Anything you add to this directory is recursively added to the deployment. myproj ├── .chalice ├── app.py ├── chalicelib └── requirements.txt . ",
    "url": "/docs/aws/chalice.html#multifiles",
    
    "relUrl": "/docs/aws/chalice.html#multifiles"
  },"226": {
    "doc": "Chalice",
    "title": "Configuration File",
    "content": "In .chalice, there is a file called config.json. This folder contains all the configurations related to this package. You can set app name, deploment stages, environment variables, etc. Environment Variables . For general environment variables, add the following syntax to .chalice/config.json . { \"environment_variables\": { \"ENV_VAR\": \"value\", \"ENV_VAR2\": \"value2\" } } . You can also set stage specific environment variables by, . { \"stages\": { \"dev\": { \"environment_variables\": { \"MY_ENV\": \"value\" } }, \"prod\": { \"environment_variables\": { \"MY_PROD_ENV\": \"value\" } } } } . ",
    "url": "/docs/aws/chalice.html#configuration-file",
    
    "relUrl": "/docs/aws/chalice.html#configuration-file"
  },"227": {
    "doc": "Chalice",
    "title": "Deploying with Terraform",
    "content": "# Will generate deployment.zip and chalice.tf.json chalice package --pkg-format terraform output_dir . chalice package will generate the Lambda deployments and Terraform configuration files. You can then use Terraform CLI to deploy. See here for details. References: . | Chalice: Quickstart | Chalice: Terraform Support | Chalice: Multifile | Chalice: Configuration File | . ",
    "url": "/docs/aws/chalice.html#deploying-with-terraform",
    
    "relUrl": "/docs/aws/chalice.html#deploying-with-terraform"
  },"228": {
    "doc": "Classification",
    "title": "Classification",
    "content": "When response variable is qualitative or categorical, we perform classification. Classification could be simply predicting the class of observations: . \\[f(x) \\in \\{C_1, C_2, \\ldots, C_K\\}\\] But more profoundly, it would about estimating the conditional probability that an observation belongs to a certain class. Classification VS Clustering The difference between classification and clustering is that clustering is essentially unsupervised learning. Unlike classification, there is no predefined notion of classes or labels for the observations during clustering. | Bayes Classifier | Decision Boundary | Why Not Regular Linear Regression? . | Masking Phenomenon | . | Misclassification Rate | Logistic Regression | Discriminant Analysis | Threshold | ROC Curve | . ",
    "url": "/docs/data-science/ml-dl/classification.html",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html"
  },"229": {
    "doc": "Classification",
    "title": "Bayes Classifier",
    "content": "Bayes classifier or Bayes optimal classifier assigns an observation to the class that maximizes the posterior probability: . $$ k^\\ast = \\arg\\max_k P(Y = k \\mid X = x) $$ . Given an observation, what is the probability that it belongs to class $k$? If it’s high, then it must belong to that class $k$. This is a natural and rational way to formulate classification, and we rarely know the true posterior probabilities. Hence the name “optimal”. ",
    "url": "/docs/data-science/ml-dl/classification.html#bayes-classifier",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#bayes-classifier"
  },"230": {
    "doc": "Classification",
    "title": "Decision Boundary",
    "content": "Decision boundary is the surface that separates the classes. Decision boundary between two classes $i$ and $j$ is the set of points $\\boldsymbol{x}$ where the posterior probabilities are equal. For linear classifiers, we would have learned a set of weights/parameters $\\hat{\\beta}_i$ and $\\hat{\\beta}_j$ that determine the probability of $\\boldsymbol{x}$ belonging to class $i$ and $j$. Then our decision boundary would be the set of coordinates $\\boldsymbol{x} \\in \\mathbb{R}^p$ such that: . $$ \\hat{\\beta}_{i0} + \\hat{\\beta}_i^\\top \\boldsymbol{x} = \\hat{\\beta}_{j0} + \\hat{\\beta}_j^\\top \\boldsymbol{x} \\iff \\hat{\\beta}_{i0} - \\hat{\\beta}_{j0} + (\\hat{\\beta}_i - \\hat{\\beta}_j)^\\top \\boldsymbol{x} = 0 $$ . For clarity we denote the intercept term separately from the weights here. Affine Subspace \\[\\overbrace{\\hat{\\beta}_{i0} - \\hat{\\beta}_{j0}}^a + (\\underbrace{\\hat{\\beta}_i - \\hat{\\beta}_j}_\\boldsymbol{b})^\\top \\boldsymbol{x} = 0\\] The decision boundary, . \\[\\{\\boldsymbol{x} \\in \\mathbb{R}^p \\mid a + \\boldsymbol{b}^\\top \\boldsymbol{x} = 0\\}\\] Defines a $(p-1)$-dimensional affine subspace in $\\mathbb{R}^p$. Remeber that a one-dimensional affine subspace is a line, and a two-dimensional affine subspace is a plane. For $K$ classes, there would be a total . \\[{K \\choose 2} = \\frac{K(K-1)}{2}\\] decision boundaries. ",
    "url": "/docs/data-science/ml-dl/classification.html#decision-boundary",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#decision-boundary"
  },"231": {
    "doc": "Classification",
    "title": "Why Not Regular Linear Regression?",
    "content": "In the case of binary classification with label $\\{0, 1\\}$, our regression function . \\[f(x) = \\E[Y \\mid X = x]\\] Conveniently becomes the conditional probability: . \\[P(Y = 1 \\mid X = x)\\] Which is what we want for classification. However, the prediction from linear regression is: . | Hard to interpret as probability: There is no way to bind the prediction to $[0, 1]$. | Hard to define a threshold or cutoff for classification | Doomed for multi-class classification | Mapping qualitative variables to a sequence of numerical labels i.e. $\\{1, 2, 3\\}$ introduces a sense of order and distance between the classes, when there is none. | . ",
    "url": "/docs/data-science/ml-dl/classification.html#why-not-regular-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#why-not-regular-linear-regression"
  },"232": {
    "doc": "Classification",
    "title": "Masking Phenomenon",
    "content": "Take a look at the third bullet point above. One of the reasons why linear regression is doomed for multi-class classification is masking. Masking is a phenomenon where the decision boundary collapses for multi-class classification. The effect is that some classes are “masked” by others, and an observation is never assigned to the masked class. This phenomenon becomes more severe as the number of classes increases. ",
    "url": "/docs/data-science/ml-dl/classification.html#masking-phenomenon",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#masking-phenomenon"
  },"233": {
    "doc": "Classification",
    "title": "Misclassification Rate",
    "content": "Unlike regression, where we use MSE to measure performance, in classification we use misclassification rate or error rate. It is simply the proportion of misclassified observations: . $$ \\text{Error rate} = \\sum_{i=1}^n \\frac{I(y_i \\neq \\hat{y}_i)}{n} $$ . ",
    "url": "/docs/data-science/ml-dl/classification.html#misclassification-rate",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#misclassification-rate"
  },"234": {
    "doc": "Classification",
    "title": "Logistic Regression",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/classification.html#logistic-regression",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#logistic-regression"
  },"235": {
    "doc": "Classification",
    "title": "Discriminant Analysis",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/classification.html#discriminant-analysis",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#discriminant-analysis"
  },"236": {
    "doc": "Classification",
    "title": "Threshold",
    "content": "In the context of binary classification, selecting class $k$ with the highest $p_k(x)$ is equivalent to setting a threshold, say $0.5$, and asking the question: . \\[P(Y = 1 \\mid X = x) &gt; 0.5\\] If yes, then $Y = 1$. Different thresholds would lead to different misclassification rates, which is our measure of performance in classification. So we need to find the optimal threshold as well. ",
    "url": "/docs/data-science/ml-dl/classification.html#threshold",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#threshold"
  },"237": {
    "doc": "Classification",
    "title": "ROC Curve",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/classification.html#roc-curve",
    
    "relUrl": "/docs/data-science/ml-dl/classification.html#roc-curve"
  },"238": {
    "doc": "CLI Setup",
    "title": "IntelliJ CLI Setup",
    "content": ". | Launch IntelliJ from CLI . | Create a launcher script | . | . ",
    "url": "/docs/others/intellij/cli.html#intellij-cli-setup",
    
    "relUrl": "/docs/others/intellij/cli.html#intellij-cli-setup"
  },"239": {
    "doc": "CLI Setup",
    "title": "Launch IntelliJ from CLI",
    "content": "By default, IntelliJ IDEA does not provide a CLI launcher. Create a launcher script . First add the following script to /usr/local/bin (or any other directory in your $PATH). Give the script a name like idea or any other name you prefer. | 1 2 . | #!/bin/zsh open -na \"IntelliJ IDEA.app\" --args \"$@\" . | . Then make the script executable, . chmod 755 /usr/local/bin/idea . Now you can launch IntelliJ IDEA from the command line, . idea . References: . | IDEA CLI Setup | IDEA CLI Open Files | . ",
    "url": "/docs/others/intellij/cli.html#launch-intellij-from-cli",
    
    "relUrl": "/docs/others/intellij/cli.html#launch-intellij-from-cli"
  },"240": {
    "doc": "CLI Setup",
    "title": "CLI Setup",
    "content": " ",
    "url": "/docs/others/intellij/cli.html",
    
    "relUrl": "/docs/others/intellij/cli.html"
  },"241": {
    "doc": "MySQL Client",
    "title": "MySQL Client",
    "content": "If you only need to connect to a MySQL database, you can use the lighter weight MySQL client. | MySQL Client . | Installation . | Adding to PATH | . | Cloning a database . | Export query to recreate empty database | . | . | . ",
    "url": "/docs/db/mysql/client.html",
    
    "relUrl": "/docs/db/mysql/client.html"
  },"242": {
    "doc": "MySQL Client",
    "title": "Installation",
    "content": "Using Homebrew: . brew install mysql-client . Adding to PATH . You will notice that the client is not immediately available in your terminal: . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . | ==&gt; Caveats ==&gt; mysql-client mysql-client is keg-only, which means it was not symlinked into /opt/homebrew, because it conflicts with mysql (which contains client libraries). If you need to have mysql-client first in your PATH, run: echo 'export PATH=\"/opt/homebrew/opt/mysql-client/bin:$PATH\"' &gt;&gt; ~/.zshrc For compilers to find mysql-client you may need to set: export LDFLAGS=\"-L/opt/homebrew/opt/mysql-client/lib\" export CPPFLAGS=\"-I/opt/homebrew/opt/mysql-client/include\" For pkg-config to find mysql-client you may need to set: export PKG_CONFIG_PATH=\"/opt/homebrew/opt/mysql-client/lib/pkgconfig\" . | . You can follow the instruction on line number 7 to add the client binaries to PATH. Doing so will create a conflict with the MySQL server binaries if you happen to install them later on. If you do, you will need to remove the client binaries from PATH. Or you could just create an alias to some of the binaries you may need, for e.g.: . alias mysqldump=\"/opt/homebrew/opt/mysql-client/bin/mysqldump\" . I personally prefer the latter. ",
    "url": "/docs/db/mysql/client.html#installation",
    
    "relUrl": "/docs/db/mysql/client.html#installation"
  },"243": {
    "doc": "MySQL Client",
    "title": "Cloning a database",
    "content": "Once you’ve downloaded the client, you can use mysqldump to selectively clone a database. Refer to mysqldump --help for a comprehensive list. Export query to recreate empty database . To export queries to recreate schemas, views, etc. use the --no-data flag: . mysqldump \\ --host 127.0.0.1 \\ --user root \\ --port 3306 \\ --databases mydb \\ --password --no-data --routines --single-transaction \\ &gt; schema.sql # OR mysqldump \\ -h 127.0.0.1 \\ -u root \\ -P 3306 \\ -B mydb \\ -p -d -R --single-transaction \\ &gt; schema.sql . --single-transaction can be used to avoid locking the database while performing the dump or if you do not have the LOCK TABLES privilege. Use 127.0.0.1 instead of localhost if you want to enforce connection via TCP/IP instead of sockets. MySQL 8.0.32’s mysqldump currently has an issue with AWS RDS when using the --single-transaction flag. See this issue for more details. ",
    "url": "/docs/db/mysql/client.html#cloning-a-database",
    
    "relUrl": "/docs/db/mysql/client.html#cloning-a-database"
  },"244": {
    "doc": "Cognito",
    "title": "AWS Cognito",
    "content": ". | Token: Hosted UI / AWS SDK . | Hosted UI | AWS SDK | . | How to use a custom domain | . ",
    "url": "/docs/aws/cognito.html#aws-cognito",
    
    "relUrl": "/docs/aws/cognito.html#aws-cognito"
  },"245": {
    "doc": "Cognito",
    "title": "Token: Hosted UI / AWS SDK",
    "content": "Hosted UI . Cognito hosts a login portal and an authorization server by default. This UI is hosted on the /login enpoint. After user types in their credentials, a request is automatically made to the /oauth2/authorize endpoint. Upon successful authentication, client is redirected to a URL configured for the user pool client. If you’re using an implicit flow (not recommended), you will be redirected with a token directly. If you’re using an authorization code flow, you will be redirected with a code parameter which you can exchange later to a token at the /oauth2/token endpoint. AWS SDK . Although the hosted UI option is convenient, one downside of it is that customization is limited. ",
    "url": "/docs/aws/cognito.html#token-hosted-ui--aws-sdk",
    
    "relUrl": "/docs/aws/cognito.html#token-hosted-ui--aws-sdk"
  },"246": {
    "doc": "Cognito",
    "title": "How to use a custom domain",
    "content": "To be added . ",
    "url": "/docs/aws/cognito.html#how-to-use-a-custom-domain",
    
    "relUrl": "/docs/aws/cognito.html#how-to-use-a-custom-domain"
  },"247": {
    "doc": "Cognito",
    "title": "Cognito",
    "content": " ",
    "url": "/docs/aws/cognito.html",
    
    "relUrl": "/docs/aws/cognito.html"
  },"248": {
    "doc": "Basic Combinatorics",
    "title": "Basic Combinatorics",
    "content": ". | Permutation . | Permutation without repetition | Permutation with repetition | . | Combination . | Combination without repetition | Combination with repetition | . | . ",
    "url": "/docs/statistics/notes/combinatorics.html",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html"
  },"249": {
    "doc": "Basic Combinatorics",
    "title": "Permutation",
    "content": "A permutation is an arrangement of objects in a specific order. ",
    "url": "/docs/statistics/notes/combinatorics.html#permutation",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html#permutation"
  },"250": {
    "doc": "Basic Combinatorics",
    "title": "Permutation without repetition",
    "content": "If repetition is not allowed, then the number of permutations of $n$ objects taken $r$ at a time is . $$ _nP_r = \\frac{n!}{(n-r)!} $$ . ",
    "url": "/docs/statistics/notes/combinatorics.html#permutation-without-repetition",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html#permutation-without-repetition"
  },"251": {
    "doc": "Basic Combinatorics",
    "title": "Permutation with repetition",
    "content": "If repetition is allowed, then the number of permutations of $n$ objects taken $r$ at a time is $n^r$. ",
    "url": "/docs/statistics/notes/combinatorics.html#permutation-with-repetition",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html#permutation-with-repetition"
  },"252": {
    "doc": "Basic Combinatorics",
    "title": "Combination",
    "content": "A combination is a selection of objects where order does not matter. ",
    "url": "/docs/statistics/notes/combinatorics.html#combination",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html#combination"
  },"253": {
    "doc": "Basic Combinatorics",
    "title": "Combination without repetition",
    "content": "If repetition is not allowed, then the number of combinations of $n$ objects taken $r$ at a time is . $$ _nC_r = \\frac{n!}{r!(n-r)!} $$ . ",
    "url": "/docs/statistics/notes/combinatorics.html#combination-without-repetition",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html#combination-without-repetition"
  },"254": {
    "doc": "Basic Combinatorics",
    "title": "Combination with repetition",
    "content": "If repetition is allowed, then the number of combinations of $n$ objects taken $r$ at a time is . $$ _{r+n-1}C_r = \\frac{(r+n-1)!}{r!(n-1)!} $$ . ",
    "url": "/docs/statistics/notes/combinatorics.html#combination-with-repetition",
    
    "relUrl": "/docs/statistics/notes/combinatorics.html#combination-with-repetition"
  },"255": {
    "doc": "Commonly Used Distributions",
    "title": "Commonly Used Distributions",
    "content": ". | Discrete Random Variables . | Discrete Uniform Distribution | Bernoulli Distribution | Binomial Distribution | Geometric Distribution | Poisson Distribution . | Relation to Binomial Distribution | Sum of Poisson Random Variables | . | . | Continuous Random Variables . | Uniform Distribution | Normal Distribution | Exponential Distribution | $\\chi^2$ Distribution | . | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html"
  },"256": {
    "doc": "Commonly Used Distributions",
    "title": "Discrete Random Variables",
    "content": " ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#discrete-random-variables",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#discrete-random-variables"
  },"257": {
    "doc": "Commonly Used Distributions",
    "title": "Discrete Uniform Distribution",
    "content": "A random variable $X$ is said to have a discrete uniform distribution with parameters $a, b$, defining a range of $[a,b]$ where $n = b-a+1$, if its PMF is given by: . $$ P(X=x) = \\frac{1}{n} \\quad \\text{for} \\quad x \\in [a,b] $$ . We denote this as $X \\sim \\text{DiscreteUniform}(a,b)$. | Mean: $\\frac{a+b}{2}$ | Variance: $\\frac{n^2 - 1}{12}$ | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#discrete-uniform-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#discrete-uniform-distribution"
  },"258": {
    "doc": "Commonly Used Distributions",
    "title": "Bernoulli Distribution",
    "content": "A random variable $X$ is said to have a Bernoulli distribution with parameter $p \\in [0,1]$ if its PMF is given by: . $$ P(X=x) = p^x (1-p)^{1-x} \\quad \\text{for} \\quad x \\in \\{0,1\\} $$ . We denote this as $X \\sim \\text{Bernoulli}(p)$. Intuitively, it is saying what are the odds of getting a $1$ (success) or $0$ (failure) in a single trial, which is $p$ and $1-p$ respectively by design. | Mean: $p$ | Variance: $p(1-p)$ | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#bernoulli-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#bernoulli-distribution"
  },"259": {
    "doc": "Commonly Used Distributions",
    "title": "Binomial Distribution",
    "content": "More here . A random variable $X$ is said to have a binomial distribution with parameters $n \\in \\mathbb{N}$ and $p \\in [0,1]$ if its PMF is given by: . $$ P(X=x) = \\binom{n}{x} p^x (1-p)^{n-x} \\quad \\text{for} \\quad x \\in \\{0,1,\\dots,n\\} $$ . We denote this as $X \\sim \\text{Binomial}(n,p)$. Intuitively, it is saying what are the odds of getting $x$ successes in $n$ Bernoulli trials. | Mean: $np$ | Variance: $np(1-p)$ | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#binomial-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#binomial-distribution"
  },"260": {
    "doc": "Commonly Used Distributions",
    "title": "Geometric Distribution",
    "content": "A random variable $X$ is said to have a geometric distribution with parameter $p \\in [0,1]$ if its PMF is given by: . $$ P(X=x) = p(1-p)^{x-1} \\quad \\text{for} \\quad x \\geq 1 $$ . We denote this as $X \\sim \\text{Geometric}(p)$. Intuitively, it is saying what are the odds of getting $x$ failures before the first success. | Geometric distribution is memoryless. | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#geometric-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#geometric-distribution"
  },"261": {
    "doc": "Commonly Used Distributions",
    "title": "Poisson Distribution",
    "content": "A random variable $X$ is said to have a Poisson distribution with parameter $\\lambda &gt; 0$ if its PMF is given by: . $$ P(X=x) = e^{-\\lambda} \\frac{\\lambda^x}{x!} \\quad \\text{for} \\quad x \\geq 0 $$ . We denote this as $X \\sim \\text{Poisson}(\\lambda)$. Intuitively, it is saying what are the odds of getting $x$ rare events in a given time interval, where $\\lambda$ is the average number of events per interval. | Mean: $\\lambda$ | Variance: $\\lambda$ | . Relation to Binomial Distribution . Poisson distribution is useful when there is no upper bound on the number of data (such as the $n$ in binomial distribution). When $n$ is large and $p$ is small, the binomial distribution can be approximated by the Poisson distribution. To be more specific, a random variable $X \\sim \\text{Binomial}(n,p)$, can be approximated with $X \\sim \\text{Poisson}(\\lambda)$ where $\\lambda = np$. Sum of Poisson Random Variables . If $X_1 \\sim \\text{Poisson}(\\lambda_1)$ and $X_2 \\sim \\text{Poisson}(\\lambda_2)$, then: . $$ X_1 + X_2 \\sim \\text{Poisson}(\\lambda_1 + \\lambda_2) $$ . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#poisson-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#poisson-distribution"
  },"262": {
    "doc": "Commonly Used Distributions",
    "title": "Continuous Random Variables",
    "content": " ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#continuous-random-variables",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#continuous-random-variables"
  },"263": {
    "doc": "Commonly Used Distributions",
    "title": "Uniform Distribution",
    "content": "A random variable $X$ is said to have a uniform distribution with parameters $a, b$, defining a range of $[a,b]$, if its PDF is given by: . $$ f(x) = \\frac{1}{b-a} \\quad \\text{for} \\quad x \\in [a,b] $$ . We denote this as $X \\sim \\text{Uniform}(a,b)$. | Mean: $\\frac{a+b}{2}$ | Variance: $\\frac{(b-a)^2}{12}$ | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#uniform-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#uniform-distribution"
  },"264": {
    "doc": "Commonly Used Distributions",
    "title": "Normal Distribution",
    "content": "See here . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#normal-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#normal-distribution"
  },"265": {
    "doc": "Commonly Used Distributions",
    "title": "Exponential Distribution",
    "content": "A random variable $X$ is said to have an exponential distribution with parameter $\\beta &gt; 0$ if its PDF is given by: . $$ f(x) = \\frac{1}{\\beta} e^{-x/\\beta} \\quad \\text{for} \\quad x &gt; 0 $$ . We denote this as $X \\sim \\text{Exp}(\\beta)$. With Lambda Same idea, but some people use $\\lambda = 1/\\beta$ as the parameter instead: . \\[f(x) = \\lambda e^{-\\lambda x} \\quad \\text{for} \\quad x &gt; 0\\] Intuitively, it is measuring the distance or time between rarer events that occur at a constant average rate $\\beta$. | Exponential distribution is memoryless. | . ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#exponential-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#exponential-distribution"
  },"266": {
    "doc": "Commonly Used Distributions",
    "title": "$\\chi^2$ Distribution",
    "content": "A random variable $X$ is said to have a chi-squared distribution with parameter $k$ degrees of freedom if its PDF is given by: . $$ f(x) = \\frac{1}{2^{k/2} \\Gamma(k/2)} x^{k/2 - 1} e^{-x/2} \\quad \\text{for} \\quad x &gt; 0 $$ . We denote this as $X \\sim \\chi^2_k$. Note You rarely need to know the exact formula. It suffices to know that when $Z_i \\sim \\text{Normal}(0,1)$ where $i = 1,2,\\dots,k$ are independent random variables, . \\[Q = \\sum_{i=1}^k Z_i^2 \\sim \\chi^2_k\\] The sum of squares of $k$ independent standard normal random variables follows a chi-squared distribution with $k$ degrees of freedom. Chi-squared distribution is often used as test statistics in hypothesis testing. ",
    "url": "/docs/statistics/notes/commonly-used-dist.html#chi2-distribution",
    
    "relUrl": "/docs/statistics/notes/commonly-used-dist.html#chi2-distribution"
  },"267": {
    "doc": "Complexity Analysis Examples",
    "title": "Complexity Analysis Examples",
    "content": ". | Substitution method | Single while loop | For loop conditions . | Index square condition | Index increase with multiply | . | Master theorem | Nested for loops with dependence | Solving recurrence with change of variable | . ",
    "url": "/docs/compsci/algo/complexity-example.html",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html"
  },"268": {
    "doc": "Complexity Analysis Examples",
    "title": "Substitution method",
    "content": "Given the recurrence relation, we can find find the complexity by substituting the complexity of the subproblems. \\[T(n) = \\begin{cases} 1 &amp; \\text{if } n = 0 \\\\ 2T(n-1) - 1 &amp; \\text{if } n &gt; 0 \\end{cases}\\] We want to solve . \\[T(n) = 2T(n-1) - 1\\] Usually, when there is negative work (i.e. $-1$), the Master Theorem idea does not work. We know that $T(n-1) = 2T(n-2) - 1$ so we can substitute it in. \\[\\begin{align*} T(n) &amp;= 2(2T(n-2) - 1) - 1 \\\\ &amp;= 2^2T(n-2) - 2^1 - 2^0 \\end{align*}\\] We can continue substituting until we get to $T(0)$, . \\[\\begin{align*} T(n) &amp;= 2^2T(n-2) - 2^1 - 2^0 \\\\ &amp;= 2^3T(n-3) - 2^2 - 2^1 - 2^0 \\\\ ...&amp;= 2^nT(n-n) - 2^{n-1} - 2^{n-2} - ... - 2^1 - 2^0 \\\\ &amp;= 2^n + 2^n - 2^n - 2^{n-1} - 2^{n-2} - ... - 2^1 - 2^0 \\\\ &amp;= 2^{n+1} - (2^0 + 2^1 + ... + 2^n) \\\\ &amp;= 2^{n+1} - \\frac{2^{n+1} - 1}{2 - 1} \\\\ &amp;= 2^{n+1} - 2^{n+1} + 1 \\\\ &amp;= 1 \\end{align*}\\] Therefore, $T(n) = O(1)$. ",
    "url": "/docs/compsci/algo/complexity-example.html#substitution-method",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#substitution-method"
  },"269": {
    "doc": "Complexity Analysis Examples",
    "title": "Single while loop",
    "content": "def f(n): i, x = 1, 1 while x &lt;= n: i += 1 x += i . The loop runs while $x &lt;= n$. What is $x$? It is the sum of the first $i$ integers. Let $k$ be the number of iterations. We want to solve for $k$. \\[\\begin{gather*} 1 + 2 + ... + k \\le n \\\\ \\frac{k(k+1)}{2} \\le n \\tag*{Arithmetic series} \\\\ k \\approx O(\\sqrt{n}) \\end{gather*}\\] . ",
    "url": "/docs/compsci/algo/complexity-example.html#single-while-loop",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#single-while-loop"
  },"270": {
    "doc": "Complexity Analysis Examples",
    "title": "For loop conditions",
    "content": "Assumes that the work of loop is $O(1)$, unless otherwise stated. ",
    "url": "/docs/compsci/algo/complexity-example.html#for-loop-conditions",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#for-loop-conditions"
  },"271": {
    "doc": "Complexity Analysis Examples",
    "title": "Index square condition",
    "content": "... for (i = 1; i*i &lt;= n; i++) ... The loop runs while $i^2 &lt;= n$. Let $k$ be the number of iterations. We want to solve for $k$. \\[k^2 \\le n \\implies k \\approx O(\\sqrt{n})\\] ",
    "url": "/docs/compsci/algo/complexity-example.html#index-square-condition",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#index-square-condition"
  },"272": {
    "doc": "Complexity Analysis Examples",
    "title": "Index increase with multiply",
    "content": "... for (i = 1; i &lt;= n; i *= 2) ... The loop runs while $i &lt;= n$. Let $k$ be the number of iterations. We want to solve for $k$. \\[2^k \\le n \\implies k \\approx O(\\log n)\\] . ",
    "url": "/docs/compsci/algo/complexity-example.html#index-increase-with-multiply",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#index-increase-with-multiply"
  },"273": {
    "doc": "Complexity Analysis Examples",
    "title": "Master theorem",
    "content": ". | Example 1: . \\[T(n) = T(n-2) + O(n^2)\\] Since the branching factor of recursion is $1$, each level of recursion does $O(n^2)$ work. Depth of recursion is $O(n)$ (since $n-2$). Therefore total work is $O(n) \\cdot O(n^2) = O(n^3)$. | . | Example 2: . \\[T(n) = 2T(\\frac{n}{2}) + O(nlog n)\\] Branching factor is $2 = 2^1$, so each level of recursion does $O(nlog n)$ work. Depth of recursion is $O(\\log n)$ (since $\\frac{n}{2}$). Therefore total work is $O(nlog n) \\cdot O(\\log n) = O(nlog^2 n)$. | . | Example 3: . \\[T(n) = T(\\frac{n}{2}) + T(\\frac{n}{4}) + T(\\frac{n}{8}) + O(n)\\] We can tweak the recurrence to . \\[T(n) \\le aT(\\frac{n}{2}) + O(n)\\] We can see that $a &lt; 2^1$, because $\\frac{1}{2} &gt; \\frac{1}{4} + \\frac{1}{8}$. Work is dominated at the root, so $O(n)$. | . | Example 3: . \\[T(n) = T(\\frac{n}{2}) + O(1)\\] Since $1 = 2^0$, work is distributed among the tree. The depth of the tree is $O(\\log n)$ (since $\\frac{n}{2}$). Therefore total work is $O(\\log n) \\cdot O(1) = O(\\log n)$. | Example 4: . \\[T(n) = T(n-1) + T(n-2) + O(1)\\] We can tweak the recurrence to . \\[T(n) \\le 2T(n-1) + O(1)\\] Since $2 &gt; 1$, work is dominated by leaves. The depth of the tree is $O(n)$ (since $n-1$). At depth $n$, there are $2^n$ leaves (since $2T(n-1)$). Therefore total work is $O(1) \\cdot O(2^n) = O(2^n)$. | . ",
    "url": "/docs/compsci/algo/complexity-example.html#master-theorem",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#master-theorem"
  },"274": {
    "doc": "Complexity Analysis Examples",
    "title": "Nested for loops with dependence",
    "content": "Usually with nested loops, we can multiply the complexities. However, if the inner loop depends on the outer loop, we try to find the number of times the inner loop runs in total... for (i = 1; i &lt;= n; i++) for (j = 1; j &lt;= n; j += i) ... As the inner loop condition increases by $i$ each time, we cannot simply multiply the complexities. We want to solve how many times the inner loop runs in total. | When $i = 1$, the inner loop runs $n$ times. | When $i = 2$, the inner loop runs $\\frac{n}{2}$ times. | When $i = 3$, the inner loop runs $\\frac{n}{3}$ times. | When $i = n$, the inner loop runs $\\frac{n}{n} = 1$ time. | . Then, the inner loop runs in total . \\[\\begin{align*} \\sum_{i=1}^n \\frac{n}{i} &amp;= n \\sum_{i=1}^n \\frac{1}{i} \\\\ &amp;\\approx n \\cdot O(\\log n) \\tag{Harmonic series} \\\\ &amp;\\implies O(n \\log n) \\end{align*}\\] . ",
    "url": "/docs/compsci/algo/complexity-example.html#nested-for-loops-with-dependence",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#nested-for-loops-with-dependence"
  },"275": {
    "doc": "Complexity Analysis Examples",
    "title": "Solving recurrence with change of variable",
    "content": "\\[T(n) = 2T(\\sqrt{n}) + O(\\log n)\\] Let $n = 2^m$. Then, . \\[\\begin{align*} T(n) &amp;= T(2^m) \\\\ &amp;= 2T(2^{\\frac{m}{2}}) + O(m) \\end{align*}\\] Define $S(m) = T(2^m)$. Then $S(\\frac{m}{2}) = T(2^{\\frac{m}{2}})$. Therefore, . \\[S(m) = 2S(\\frac{m}{2}) + O(m)\\] Since $2 = 2^1$, work is distributed among the tree. The depth of the tree is $O(\\log m)$ (since $\\frac{m}{2}$). Thus work is $O(m) \\cdot O(\\log m) = O(m \\log m)$. Since $2^m = n \\implies m = \\log n$, it is $O(\\log n \\log \\log n)$. ",
    "url": "/docs/compsci/algo/complexity-example.html#solving-recurrence-with-change-of-variable",
    
    "relUrl": "/docs/compsci/algo/complexity-example.html#solving-recurrence-with-change-of-variable"
  },"276": {
    "doc": "Complexity of Algorithms",
    "title": "Complexity of Algorithms",
    "content": ". | Commonly used complexity classes | Asymptotic notation . | Big-O notation | Big-Omega notation | Big-Theta notation | . | Master theorem . | Divide-and-conquer recurrence relations . | Simple form | Advanced form | . | Decreasing recurrence relations | . | Amortized analysis | Examples | . ",
    "url": "/docs/compsci/algo/complexity.html",
    
    "relUrl": "/docs/compsci/algo/complexity.html"
  },"277": {
    "doc": "Complexity of Algorithms",
    "title": "Commonly used complexity classes",
    "content": ". | $1$: constant | $\\log\\log(n)$ | $\\sqrt{\\log(n)}$ | $log(n)$: logarithmic | $n$: linear | $\\log(n!)$ | $n\\log(n)$: loglinear | $n^c$: polynomial | $c^n$: exponential | $n!$: factorial | . Commonly used definitions in complexity analysis ",
    "url": "/docs/compsci/algo/complexity.html#commonly-used-complexity-classes",
    
    "relUrl": "/docs/compsci/algo/complexity.html#commonly-used-complexity-classes"
  },"278": {
    "doc": "Complexity of Algorithms",
    "title": "Properties of logarithms",
    "content": "\\[\\log(x^y) = y\\log(x)\\] \\[a^{\\log_b(x)} = x^{\\log_b(a)}\\] \\[\\log(xy) = \\log(x) + \\log(y)\\] \\[\\log(\\frac{x}{y}) = \\log(x) - \\log(y)\\] \\[\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}\\] \\[\\sum_{k=1}^n \\log(k) \\approx n\\log(n)\\] ",
    "url": "/docs/compsci/algo/complexity.html#properties-of-logarithms",
    
    "relUrl": "/docs/compsci/algo/complexity.html#properties-of-logarithms"
  },"279": {
    "doc": "Complexity of Algorithms",
    "title": "Arithmetic series",
    "content": "\\[\\sum_{k=1}^n k = 1 + 2 + \\cdots + n = \\frac{n(n+1)}{2}\\] \\[\\sum_{k=a}^b k = (b-a+1)\\frac{b+a}{2}\\] ",
    "url": "/docs/compsci/algo/complexity.html#arithmetic-series",
    
    "relUrl": "/docs/compsci/algo/complexity.html#arithmetic-series"
  },"280": {
    "doc": "Complexity of Algorithms",
    "title": "Geometric series",
    "content": "\\[\\sum_{k=0}^n ar^k = a + ar + ar^2 + \\cdots + ar^n = \\frac{a(1-r^{n+1})}{1-r}\\] ",
    "url": "/docs/compsci/algo/complexity.html#geometric-series",
    
    "relUrl": "/docs/compsci/algo/complexity.html#geometric-series"
  },"281": {
    "doc": "Complexity of Algorithms",
    "title": "Harmonic series",
    "content": "\\[\\sum_{k=1}^n \\frac{1}{k} = 1 + \\frac{1}{2} + \\cdots + \\frac{1}{n} \\approx \\log(n)\\] ",
    "url": "/docs/compsci/algo/complexity.html#harmonic-series",
    
    "relUrl": "/docs/compsci/algo/complexity.html#harmonic-series"
  },"282": {
    "doc": "Complexity of Algorithms",
    "title": "Faulhaber’s formula",
    "content": "Special case of power sum. \\[\\sum_{k=1}^n k^p = 1^p + 2^p + \\cdots + n^p \\approx \\frac{n^{p+1}}{p+1}\\] . ",
    "url": "/docs/compsci/algo/complexity.html#faulhabers-formula",
    
    "relUrl": "/docs/compsci/algo/complexity.html#faulhabers-formula"
  },"283": {
    "doc": "Complexity of Algorithms",
    "title": "Asymptotic notation",
    "content": " ",
    "url": "/docs/compsci/algo/complexity.html#asymptotic-notation",
    
    "relUrl": "/docs/compsci/algo/complexity.html#asymptotic-notation"
  },"284": {
    "doc": "Complexity of Algorithms",
    "title": "Big-O notation",
    "content": "Big-O $O$ is for the upper bound (worst case). Not necessarily tight. For some function $f$ and $g$, . $$ \\exists n_0, c &gt; 0 \\text{ s.t. } \\forall n \\geq n_0,\\; f(n) \\leq c g(n) \\implies f(n) = O(g(n)) $$ . | Transitivity: $f(n) = O(g(n)) \\land g(n) = O(h(n)) \\implies f(n) = O(h(n))$ | Reflexivity: $f(n) = O(f(n))$ | . ",
    "url": "/docs/compsci/algo/complexity.html#big-o-notation",
    
    "relUrl": "/docs/compsci/algo/complexity.html#big-o-notation"
  },"285": {
    "doc": "Complexity of Algorithms",
    "title": "Big-Omega notation",
    "content": "Big-Omega $\\Omega$ is for the lower bound (best case). Not necessarily tight. For some function $f$ and $g$, . $$ \\exists n_0, c &gt; 0 \\text{ s.t. } \\forall n \\geq n_0,\\; f(n) \\geq c g(n) \\implies f(n) = \\Omega(g(n)) $$ . | Transitivity | Reflexivity | Transpose symmetry: $f(n) = \\Omega(g(n)) \\iff g(n) = O(f(n))$ | . ",
    "url": "/docs/compsci/algo/complexity.html#big-omega-notation",
    
    "relUrl": "/docs/compsci/algo/complexity.html#big-omega-notation"
  },"286": {
    "doc": "Complexity of Algorithms",
    "title": "Big-Theta notation",
    "content": "Big-Theta $\\Theta$ is for the tight bound (average case). For some function $f$ and $g$, . $$ \\exists n_0, c_1, c_2 &gt; 0 \\text{ s.t. } \\forall n \\geq n_0,\\; c_1 g(n) \\leq f(n) \\leq c_2 g(n) \\implies f(n) = \\Theta(g(n)) $$ . | Transitivity | Reflexivity | Symmetry: $f(n) = \\Theta(g(n)) \\iff g(n) = \\Theta(f(n))$ | . ",
    "url": "/docs/compsci/algo/complexity.html#big-theta-notation",
    
    "relUrl": "/docs/compsci/algo/complexity.html#big-theta-notation"
  },"287": {
    "doc": "Complexity of Algorithms",
    "title": "Master theorem",
    "content": " ",
    "url": "/docs/compsci/algo/complexity.html#master-theorem",
    
    "relUrl": "/docs/compsci/algo/complexity.html#master-theorem"
  },"288": {
    "doc": "Complexity of Algorithms",
    "title": "Divide-and-conquer recurrence relations",
    "content": "For recursive, divide-and-conquer algorithms, the master theorem can be used to determine the asymptotic complexity. Simple form . If the algorithm has the following recurrence relation, . $$ T(n) = aT(\\frac{n}{b}) + O(n^d) $$ . where $a &gt; 0$, $b &gt; 1$, and $d \\geq 0$, you may use the following rules of Master theorem. | If $a &lt; b^d$ (dominated by the work at root), $$ T(n) = O(n^d) $$ . | If $a = b^d$ (work is evenly distributed in each layer), $$ T(n) = O(n^d \\log(n)) $$ . | If $a &gt; b^d$ (dominated by the work at leaves), $$ T(n) = O(n^{\\log_b(a)}) $$ . | . Advanced form . Advanced form of Master theorem If the algorithm has the following recurrence relation, . $$ T(n) = aT(\\frac{n}{b}) + \\Theta(n^k \\log^p(n)) $$ . where $a \\geq 1$, $b &gt; 1$, $k \\geq 0$, and $p \\in \\mathbb{R}$, you may use the following rules of Master theorem. | If $a &gt; b^k$, $$ T(n) = \\Theta(n^{\\log_b(a)}) $$ . | If $a = b^k$, . | If $p &gt; -1$, $$ T(n) = \\Theta(n^{\\log_b(a)} \\log^{p+1}(n)) $$ . | If $p = -1$, $$ T(n) = \\Theta(n^{\\log_b(a)} \\log\\log(n)) $$ . | If $p &lt; -1$, $$ T(n) = \\Theta(n^{\\log_b(a)}) $$ . | . | If $a &lt; b^k$, . | If $p \\geq 0$, $$ T(n) = \\Theta(n^k \\log^p(n)) $$ . | If $p &lt; 0$, $$ T(n) = O(n^k) $$ . | . | . ",
    "url": "/docs/compsci/algo/complexity.html#divide-and-conquer-recurrence-relations",
    
    "relUrl": "/docs/compsci/algo/complexity.html#divide-and-conquer-recurrence-relations"
  },"289": {
    "doc": "Complexity of Algorithms",
    "title": "Decreasing recurrence relations",
    "content": "If the algorithm has the following recurrence relation, . $$ T(n) = aT(n-b) + O(n^d) $$ . where $a &gt; 0$, $b &gt; 0$, you may use the following rules of Master theorem. | If $a &lt; 1$ (dominated by the work at root), $$ T(n) = O(n^d) $$ . | If $a = 1$ (work is evenly distributed in each layer), $$ T(n) = O(n^{d+1}) $$ . | If $a &gt; 1$ (dominated by the work at leaves), $$ T(n) = O(n^d a^{n/b}) $$ . | . ",
    "url": "/docs/compsci/algo/complexity.html#decreasing-recurrence-relations",
    
    "relUrl": "/docs/compsci/algo/complexity.html#decreasing-recurrence-relations"
  },"290": {
    "doc": "Complexity of Algorithms",
    "title": "Amortized analysis",
    "content": "Amortized analysis is a method for analyzing a sequence of operations. It is often used to show that a sequence of operations is efficient. Even if a single operation is expensive, the amortized cost of each operation can be small if the expensive operation is performed rarely. Amortized analysis is used when the worst-case asymptotic analysis over a sequence of operations is unfairly pessimistic. ",
    "url": "/docs/compsci/algo/complexity.html#amortized-analysis",
    
    "relUrl": "/docs/compsci/algo/complexity.html#amortized-analysis"
  },"291": {
    "doc": "Complexity of Algorithms",
    "title": "Examples",
    "content": "Go to page . ",
    "url": "/docs/compsci/algo/complexity.html#examples",
    
    "relUrl": "/docs/compsci/algo/complexity.html#examples"
  },"292": {
    "doc": "Docker Compose",
    "title": "Docker Compose",
    "content": ". | Why use Docker Compose? | Dockerfile / docker-compose.yml . | Dockerfile | docker-compose.yml | . | Example usage | Useful commands | Itty Bitties . | Build context | Default network | . | . ",
    "url": "/docs/docker/compose.html",
    
    "relUrl": "/docs/docker/compose.html"
  },"293": {
    "doc": "Docker Compose",
    "title": "Why use Docker Compose?",
    "content": "Compose is a tool to help define and run containers/services. It basically packs all those docker bulid ..., docker run ... commands into a single yaml. ",
    "url": "/docs/docker/compose.html#why-use-docker-compose",
    
    "relUrl": "/docs/docker/compose.html#why-use-docker-compose"
  },"294": {
    "doc": "Docker Compose",
    "title": "Dockerfile / docker-compose.yml",
    "content": "Dockerfile . Dockerfile defines the recipe to create an image. docker-compose.yml . docker-compose.yml defines services or containers that run images. ",
    "url": "/docs/docker/compose.html#dockerfile--docker-composeyml",
    
    "relUrl": "/docs/docker/compose.html#dockerfile--docker-composeyml"
  },"295": {
    "doc": "Docker Compose",
    "title": "Example usage",
    "content": "version: '3.9' services: my-service: container_name: my-container build: context: ./src dockerfile: Dockerfile ports: - 1234:1234 volumes: - ./src:/www . For ports and volumes the order of syntax is &lt;host&gt;:&lt;container&gt;. ",
    "url": "/docs/docker/compose.html#example-usage",
    
    "relUrl": "/docs/docker/compose.html#example-usage"
  },"296": {
    "doc": "Docker Compose",
    "title": "Useful commands",
    "content": "# Create and start containers docker-compose up # Build images and start containers docker-compose up --build # Start the containers in detached mode docker-compose up --d # Stop and remove containers and default networks docker-compose down # Lists containers (even the ones that are exited) docker-compose ps . ",
    "url": "/docs/docker/compose.html#useful-commands",
    
    "relUrl": "/docs/docker/compose.html#useful-commands"
  },"297": {
    "doc": "Docker Compose",
    "title": "Itty Bitties",
    "content": "Suppose the project root directory is called proj. proj ├── docker-compose.yml └── src ├── Dockerfile └── ... # docker-compose.yml services: my-service: container_name: my-container build: context: ./src dockerfile: Dockerfile . Build context . With docker build -f ../Dockerfile ., it is possible for the Dockerfile to be outside of the build context. However, it seems that with Compose, the Dockerfile must be within the build context. So in the example case Dockerfile must be under src, otherwise it will produce an error: . failed to solve: rpc error: code = Unknown desc = failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/your-build-context/Dockerfile: no such file or directory . Default network . Compose automatically creates a bridge network of name proj_default, and adds all service containers to it. Check that is is true by, . # Locate the created default network docker network ls # Inspect the containers in it docker inspect proj_default . Then you will see my-container listed under network proj_default. ",
    "url": "/docs/docker/compose.html#itty-bitties",
    
    "relUrl": "/docs/docker/compose.html#itty-bitties"
  },"298": {
    "doc": "Conda",
    "title": "Conda",
    "content": ". | Advantage to other virtual environments | Install Conda (miniforge) | Typical usage | Create environment | Activate / Deactivate | Install packages | Uninstall packages | List and export dependencies | Clone environment | Remove environment | Installing Python 2.7 on Apple Silicon | . ",
    "url": "/docs/python/envs/conda.html",
    
    "relUrl": "/docs/python/envs/conda.html"
  },"299": {
    "doc": "Conda",
    "title": "Advantage to other virtual environments",
    "content": "Unlike some other virtual environments that are dependent on a preinstalled Python, conda is both a Python version manager and a virtual environment manager. conda makes using different Python versions in different environments easier. ",
    "url": "/docs/python/envs/conda.html#advantage-to-other-virtual-environments",
    
    "relUrl": "/docs/python/envs/conda.html#advantage-to-other-virtual-environments"
  },"300": {
    "doc": "Conda",
    "title": "Install Conda (miniforge)",
    "content": "Conda can be installed through homebrew: . brew install miniforge conda init \"$(basename \"${SHELL}\")\" . If you don’t want the base environment activated all the time, . conda config --set auto_activate_base false . ",
    "url": "/docs/python/envs/conda.html#install-conda-miniforge",
    
    "relUrl": "/docs/python/envs/conda.html#install-conda-miniforge"
  },"301": {
    "doc": "Conda",
    "title": "Typical usage",
    "content": "To create an environment for a project: . conda create -n myenv python=3.x conda activate myenv . ",
    "url": "/docs/python/envs/conda.html#typical-usage",
    
    "relUrl": "/docs/python/envs/conda.html#typical-usage"
  },"302": {
    "doc": "Conda",
    "title": "Create environment",
    "content": "Simplest method is: . conda create -n myenv . To use a specific Python version: . conda create --name myenv python=3.8 . Created environments are located in ~/anaconda3/env or ~/miniconda3/env. If you installed conda via GUI installer, the conda folder may be in /opt. Confirm environment creation via . conda env list # OR conda info --envs . ",
    "url": "/docs/python/envs/conda.html#create-environment",
    
    "relUrl": "/docs/python/envs/conda.html#create-environment"
  },"303": {
    "doc": "Conda",
    "title": "Activate / Deactivate",
    "content": "conda activate myenv . conda deactivate . ",
    "url": "/docs/python/envs/conda.html#activate--deactivate",
    
    "relUrl": "/docs/python/envs/conda.html#activate--deactivate"
  },"304": {
    "doc": "Conda",
    "title": "Install packages",
    "content": "To install packages in current active environment, . conda install pkg-name # OR for a specific version conda install pkg-name=1.0.0 . To install packages in another environment, . conda install pkg-name -n myenv . ",
    "url": "/docs/python/envs/conda.html#install-packages",
    
    "relUrl": "/docs/python/envs/conda.html#install-packages"
  },"305": {
    "doc": "Conda",
    "title": "Uninstall packages",
    "content": "conda remove pkg-name . ",
    "url": "/docs/python/envs/conda.html#uninstall-packages",
    
    "relUrl": "/docs/python/envs/conda.html#uninstall-packages"
  },"306": {
    "doc": "Conda",
    "title": "List and export dependencies",
    "content": "conda list . To export dependencies (like pip3 freeze &gt; requirements.txt), . conda list --export &gt; requirements.txt . To create an environment with given requirements (like pip3 install -r requirements.txt), . conda create -n myenv --file requirements.txt . ",
    "url": "/docs/python/envs/conda.html#list-and-export-dependencies",
    
    "relUrl": "/docs/python/envs/conda.html#list-and-export-dependencies"
  },"307": {
    "doc": "Conda",
    "title": "Clone environment",
    "content": "To clone an existing environment, . conda create --name &lt;new-env&gt; --clone &lt;existing-env&gt; . ",
    "url": "/docs/python/envs/conda.html#clone-environment",
    
    "relUrl": "/docs/python/envs/conda.html#clone-environment"
  },"308": {
    "doc": "Conda",
    "title": "Remove environment",
    "content": "Make sure to conda deactivate before removing an environment. conda env list # Check the env name conda env remove -n myenv . ",
    "url": "/docs/python/envs/conda.html#remove-environment",
    
    "relUrl": "/docs/python/envs/conda.html#remove-environment"
  },"309": {
    "doc": "Conda",
    "title": "Installing Python 2.7 on Apple Silicon",
    "content": "In case you need to install Python 2.7 on Apple Silicon, use Rosetta 2: . # Create env with osx-64 subdir CONDA_SUBDIR=osx-64 conda create -n py27 python=2.7 conda activate py27 # Always use osx-64 subdir for packages in this env conda config --env --set subdir osx-64 . References: . | Conda: Managing Environments | Conda: Install Packages | . ",
    "url": "/docs/python/envs/conda.html#installing-python-27-on-apple-silicon",
    
    "relUrl": "/docs/python/envs/conda.html#installing-python-27-on-apple-silicon"
  },"310": {
    "doc": "Conditional Expectation / Variance",
    "title": "Conditional Expectation / Variance",
    "content": "Conditionals random variables come in handy when we construct hierarchical models where one distribution depends on another. Summary statistics like expectation and variance are often of interest in any models. But when we have a hierarchical model, we’d have to go through all the trouble of finding joint distributions, marginalizing them, and then finding the summary statistics. Knowing some properties of conditional expectation and variance can save us a lot of time. | Conditional Expectation . | Condition on a Random Variable . | Multivariate Transformation | . | Conditional Expectation as a Random Variable | . | Law of Total Expectation | Conditional Variance . | Conditional Variance as a Random Variable | . | Law of Total Variance | . ",
    "url": "/docs/statistics/notes/conditional-expectation.html",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html"
  },"311": {
    "doc": "Conditional Expectation / Variance",
    "title": "Conditional Expectation",
    "content": " ",
    "url": "/docs/statistics/notes/conditional-expectation.html#conditional-expectation",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#conditional-expectation"
  },"312": {
    "doc": "Conditional Expectation / Variance",
    "title": "Condition on a Random Variable",
    "content": "The conditional expectation of a random variable $X$ given $Y=y$ is: . $$ \\begin{align*} \\E[X|Y=y] &amp;= \\sum_x x P(X=x|Y=y) \\\\[1em] \\E[X|Y=y] &amp;= \\int x f_{X|Y}(x|y) dx \\end{align*} $$ . Condition on an Event When $A$ is an event of $\\{Y=y\\}$, . \\[\\E[X|A] = \\sum_x x P(X=x|A) = \\E[X|Y=y]\\] Multivariate Transformation . The conditional expectation of $r(X, Y)$ given $Y=y$ is: . $$ \\begin{align*} \\E[r(X, Y)|Y=y] &amp;= \\sum_x r(x, y) P(X=x|Y=y) \\\\[1em] \\E[r(X, Y)|Y=y] &amp;= \\int r(x, y) f_{X|Y}(x|y) dx \\end{align*} $$ . ",
    "url": "/docs/statistics/notes/conditional-expectation.html#condition-on-a-random-variable",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#condition-on-a-random-variable"
  },"313": {
    "doc": "Conditional Expectation / Variance",
    "title": "Conditional Expectation as a Random Variable",
    "content": "Important thing to note is that $\\E[X|Y=y]$ is a function of $\\boldsymbol{y}$. So the exact value is defined only when we have a specific realization of $Y$. Therefore, $\\E[X|Y]$ is a random variable, and not a value. $\\E[X|Y]$ is a random variable of $Y$. ",
    "url": "/docs/statistics/notes/conditional-expectation.html#conditional-expectation-as-a-random-variable",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#conditional-expectation-as-a-random-variable"
  },"314": {
    "doc": "Conditional Expectation / Variance",
    "title": "Law of Total Expectation",
    "content": "Also called rule of iterated expectation. For any two random variables $X$ and $Y$: . $$ \\E[\\E[X|Y]] = \\E[X] \\quad \\text{and} \\quad \\E[\\E[Y|X]] = \\E[Y] $$ . This is a valid expectation because $\\E[X|Y]$ and $\\E[Y|X]$ are both random variables of $Y$ and $X$, respectively. What? Taking $\\E[\\E[X|Y]]$ as an example, first we’d have to take the expectation of $\\E[X|Y]$ over $Y$: . \\[\\E[\\E[X|Y]] = \\int \\E[X|Y=y] f_Y(y) dy\\] Then we’d have to take the expectation of that over $X$: . \\[\\E[\\E[X|Y]] = \\int \\left( \\int x f_{X|Y}(x|y) dx \\right) f_Y(y) dy\\] Since $f_{X|Y}(x|y)f_Y(y) = f_{X, Y}(x, y)$, we can simplify: . \\[\\E[\\E[X|Y]] = \\int \\int x f_{X, Y}(x, y) dx dy = \\E[X]\\] . ",
    "url": "/docs/statistics/notes/conditional-expectation.html#law-of-total-expectation",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#law-of-total-expectation"
  },"315": {
    "doc": "Conditional Expectation / Variance",
    "title": "Conditional Variance",
    "content": "The conditional variance of $Y$ given $X=x$ is: . $$ \\begin{align*} \\Var(Y|X=x) &amp;= \\E[(Y - \\E[Y|X=x])^2|X=x] \\\\[1em] &amp;= \\int (y - \\E[Y|X=x])^2 f_{Y|X}(y|x) dy \\end{align*} $$ . ",
    "url": "/docs/statistics/notes/conditional-expectation.html#conditional-variance",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#conditional-variance"
  },"316": {
    "doc": "Conditional Expectation / Variance",
    "title": "Conditional Variance as a Random Variable",
    "content": "Again, just like expectation, $\\Var(Y|X)$ is a random variable of $X$. ",
    "url": "/docs/statistics/notes/conditional-expectation.html#conditional-variance-as-a-random-variable",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#conditional-variance-as-a-random-variable"
  },"317": {
    "doc": "Conditional Expectation / Variance",
    "title": "Law of Total Variance",
    "content": "For random variables $X$ and $Y$: . $$ \\Var(Y) = \\E[\\Var(Y|X)] + \\Var(\\E[Y|X]) $$ . Remember it as $EV + VE$. ",
    "url": "/docs/statistics/notes/conditional-expectation.html#law-of-total-variance",
    
    "relUrl": "/docs/statistics/notes/conditional-expectation.html#law-of-total-variance"
  },"318": {
    "doc": "Confidence",
    "title": "Confidence",
    "content": ". | Confidence Intervals | Normal Interval | . ",
    "url": "/docs/statistics/notes/confidence.html",
    
    "relUrl": "/docs/statistics/notes/confidence.html"
  },"319": {
    "doc": "Confidence",
    "title": "Confidence Intervals",
    "content": "There is a fixed true parameter $\\theta$ that we want to estimate. A confidence interval $C_n = (a, b)$ is a random interval, and the calculation of $a$ and $b$ is a function of the sample $X_1, \\dots, X_n$. $C_n$ is a random variable. Since $C_n$ is a random variable, there can be many realizations of $C_n$ depending on the data. If the calculation of $C_n$ is repeated many times, and $C_n$ contains $\\theta$ with probability $1 - \\alpha$, then $C_n$ is a $1 - \\alpha$ confidence interval for some significance level $\\alpha$. $$ P(\\theta \\in C_n) \\geq 1 - \\alpha $$ . ",
    "url": "/docs/statistics/notes/confidence.html#confidence-intervals",
    
    "relUrl": "/docs/statistics/notes/confidence.html#confidence-intervals"
  },"320": {
    "doc": "Confidence",
    "title": "Normal Interval",
    "content": "The quantile or the inverse CDF of the standard normal distribution tells us the value of $z$ such that: . \\[P(-z \\leq Z \\leq z) = 1 - \\alpha\\] where $Z \\sim N(0, 1)$. For a sample mean $\\overline{X}$, we know that by CLT: . \\[\\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim N(0, 1)\\] Then, we can use the quantile of the standard normal distribution to say that the following is a $1 - \\alpha$ confidence interval for $\\mu$: . \\[\\overline{X} - z \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\overline{X} + z \\frac{\\sigma}{\\sqrt{n}}\\] ",
    "url": "/docs/statistics/notes/confidence.html#normal-interval",
    
    "relUrl": "/docs/statistics/notes/confidence.html#normal-interval"
  },"321": {
    "doc": "Terraform Configuration",
    "title": "Terraform Configuration",
    "content": "With AWS (As of now) . | Terraform Block | Provider | Resource | Using variables | . ",
    "url": "/docs/terraform/config.html",
    
    "relUrl": "/docs/terraform/config.html"
  },"322": {
    "doc": "Terraform Configuration",
    "title": "Terraform Block",
    "content": "It contains the Terraform settings and has the basic structure of the following . terraform { required_providers { mylocalname = { source = \"source/address\" version = \"~&gt; 1.0\" } } required_version = \"&gt;= 0.14.9\" } . Throughout the module, Terraform refers to providers using a local name. Here I’ve given it a name of mylocalname. Source address takes the form of [Hostname/]Namespace/Type. If Hostname is ommitted, it defaults to registry.terraform.io which is Terraform’s default provider install source. hashicorp/aws is a shorthand for registry.terraform.io/hashicorp/aws. For the version constraint syntax, refer to Version Constraint Syntax. ",
    "url": "/docs/terraform/config.html#terraform-block",
    
    "relUrl": "/docs/terraform/config.html#terraform-block"
  },"323": {
    "doc": "Terraform Configuration",
    "title": "Provider",
    "content": "You can configure each provider using the local name you have provided in the required_providers of the Terraform block. For example, . provider \"mylocalname\" { # ... } . Reference Provider Configuration for details. ",
    "url": "/docs/terraform/config.html#provider",
    
    "relUrl": "/docs/terraform/config.html#provider"
  },"324": {
    "doc": "Terraform Configuration",
    "title": "Resource",
    "content": "Basic syntax is as follows, . resource \"aws_instance\" \"my_server\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" } . The example block above declares a resource type \"aws_instance\" and gives it a local name of \"my_server\". Just like the provider local name, resource local name is used to refer to this resource throughout the module. In addition, the unique ID for the resource becomes aws_instance.my_server. The resource configuration arguments within the block body are specific to each resource type. For an example, refer to documentation here for aws_instance. ",
    "url": "/docs/terraform/config.html#resource",
    
    "relUrl": "/docs/terraform/config.html#resource"
  },"325": {
    "doc": "Terraform Configuration",
    "title": "Using variables",
    "content": "To avoid using hard-coded values in configuration, create a new file variables.tf (name of the file can be anything you want) with the following: . variable \"variable_name\" { description = \"Some description of what this is\" type = string default = \"This is the value of the variable\" } . You can then use the variables in other .tf files as, . var.variable_name . You can also pass in a new variable value for testing by . terraform apply -var 'variable_name=SomeOtherValue' . It will modify the state so that all the variables use the new value. This does not update the original variable declaration. If you run terraform apply again without the -var flag, the state will be modified using the original value. References: . | Terraform: Terraform Settings | Terraform: Providers | Terraform: Resources | Terraform: Version Constraint Syntax | . ",
    "url": "/docs/terraform/config.html#using-variables",
    
    "relUrl": "/docs/terraform/config.html#using-variables"
  },"326": {
    "doc": "SSH Config",
    "title": "SSH Config",
    "content": ". | Useful SSH CLI Flags | SSH (Client) Config | SSHD (SSH Daemon) Config | . ",
    "url": "/docs/security/ssh/config.html",
    
    "relUrl": "/docs/security/ssh/config.html"
  },"327": {
    "doc": "SSH Config",
    "title": "Useful SSH CLI Flags",
    "content": "Man page . -i: Identity file -F: Specify a config file (if omitted, default is ~/.ssh/config) -J [user@]host[:port]: Proxy jump -p: Port -T: Disable pseudo-tty allocation -L local_socket:remote_host:remote_port: Local forwarding . Flags are case sensitive . ",
    "url": "/docs/security/ssh/config.html#useful-ssh-cli-flags",
    
    "relUrl": "/docs/security/ssh/config.html#useful-ssh-cli-flags"
  },"328": {
    "doc": "SSH Config",
    "title": "SSH (Client) Config",
    "content": "Client configuration man page . Host DECLARATION_SCOPE_NAME User USERNAME Hostname HOSTNAME/IP Port SSH_PORT IdentityFile PRIV_KEY LocalForward LOCAL_PORT REMOTE_HOST:REMOTE_PORT ProxyJump JUMP_SERVER_HOST RequestTTY yes/no ForwardX11 yes/no . | Blank lines are ignored. Use # for comments. | To use spaces in a value, surround it with \". | . ",
    "url": "/docs/security/ssh/config.html#ssh-client-config",
    
    "relUrl": "/docs/security/ssh/config.html#ssh-client-config"
  },"329": {
    "doc": "SSH Config",
    "title": "SSHD (SSH Daemon) Config",
    "content": "To be added . Daemon configuration man page . References: . | SSH Academy | . ",
    "url": "/docs/security/ssh/config.html#sshd-ssh-daemon-config",
    
    "relUrl": "/docs/security/ssh/config.html#sshd-ssh-daemon-config"
  },"330": {
    "doc": "Confounding",
    "title": "Confounding",
    "content": "To be added . ",
    "url": "/docs/data-science/ml-dl/confounding.html",
    
    "relUrl": "/docs/data-science/ml-dl/confounding.html"
  },"331": {
    "doc": "Confusion Matrix",
    "title": "Confusion Matrix",
    "content": ". | What is a confusion matrix? | Terminology . | Condition Positive (P) | Condition Negative (N) | True Positive (TP) | True Negative (TN) | False Positive (FP) | False Negative (FN) | . | Types of Errors . | Type I Error | Type II Error | . | Confusion metrics . | True Positive Rate (TPR) | True Negative Rate (TNR) | Positive Predictive Value (PPV) | Accuracy (ACC) | False Negative Rate (FNR) | False Positive Rate (FPR) | . | . ",
    "url": "/docs/statistics/notes/confusion.html#confusion-matrix",
    
    "relUrl": "/docs/statistics/notes/confusion.html#confusion-matrix"
  },"332": {
    "doc": "Confusion Matrix",
    "title": "What is a confusion matrix?",
    "content": "| Actual\\Prediction | Positive | Negative | . | Positive | True Positive | False Negative | . | Negative | False Positive | True Negative | . It is a performance measure for machine learning classification. It is also known as the error matrix. As you can see from the table, because the test result is compared against a condition label, it is usually used for measuring the performance of a supervised learning. ",
    "url": "/docs/statistics/notes/confusion.html#what-is-a-confusion-matrix",
    
    "relUrl": "/docs/statistics/notes/confusion.html#what-is-a-confusion-matrix"
  },"333": {
    "doc": "Confusion Matrix",
    "title": "Terminology",
    "content": "Condition Positive (P) . Actually positive . Condition Negative (N) . Actually negative . True Positive (TP) . Actually positive &amp; Tested positive . True Negative (TN) . Actually negative &amp; Tested negative . False Positive (FP) . Actually negative &amp; Tested positive . False Negative (FN) . Actually positive &amp; Tested negative . For TP, TN, FP, and FN, the last positive/negative indicates the result of the test. The True or False are affirmation or rejection of the test result. Memorize FP as “actually not positive” and FN as “actually not negative”. ",
    "url": "/docs/statistics/notes/confusion.html#terminology",
    
    "relUrl": "/docs/statistics/notes/confusion.html#terminology"
  },"334": {
    "doc": "Confusion Matrix",
    "title": "Types of Errors",
    "content": "The non-errors are True Positive (TP) and True Negative (TN). Type I Error . False Positive (FP) is a Type I error. Type II Error . False Negative (FN) is a Type II error. ",
    "url": "/docs/statistics/notes/confusion.html#types-of-errors",
    
    "relUrl": "/docs/statistics/notes/confusion.html#types-of-errors"
  },"335": {
    "doc": "Confusion Matrix",
    "title": "Confusion metrics",
    "content": "Listing some of the basic ones, . True Positive Rate (TPR) . Also called: sensitivity, recall, hit rate . \\[TPR = \\frac{TP}{P} = \\frac{TP}{TP+FN} = 1 - FNR\\] True Negative Rate (TNR) . Also called: specificity, selectivity . \\[TNR = \\frac{TN}{N} = \\frac{TN}{TN+FP} = 1 - FPR\\] Positive Predictive Value (PPV) . Also called: precision . \\[PPV = \\frac{TP}{TP+FP}\\] Accuracy (ACC) . \\[ACC = \\frac{TP+TN}{P+N} = \\frac{TP+TN}{TP+FN+TN+FP}\\] False Negative Rate (FNR) . Also called: miss rate . \\[FNR = \\frac{FN}{P} = \\frac{FN}{FN+TP} = 1 - TPR\\] False Positive Rate (FPR) . Also called: fall-out . \\[FPR = \\frac{FP}{N} = \\frac{FP}{FP+TN} = 1 - TNR\\] ",
    "url": "/docs/statistics/notes/confusion.html#confusion-metrics",
    
    "relUrl": "/docs/statistics/notes/confusion.html#confusion-metrics"
  },"336": {
    "doc": "Confusion Matrix",
    "title": "Confusion Matrix",
    "content": ". ",
    "url": "/docs/statistics/notes/confusion.html",
    
    "relUrl": "/docs/statistics/notes/confusion.html"
  },"337": {
    "doc": "Docker Container",
    "title": "Docker Container",
    "content": ". | Show running containers | Execute command in container . | Open a container shell | . | Start an existing container in background (detached) | Attach container | . ",
    "url": "/docs/docker/container.html",
    
    "relUrl": "/docs/docker/container.html"
  },"338": {
    "doc": "Docker Container",
    "title": "Show running containers",
    "content": "docker ps . ",
    "url": "/docs/docker/container.html#show-running-containers",
    
    "relUrl": "/docs/docker/container.html#show-running-containers"
  },"339": {
    "doc": "Docker Container",
    "title": "Execute command in container",
    "content": "docker exec -it my-container &lt;command&gt; . Open a container shell . docker exec -it my-container sh . ",
    "url": "/docs/docker/container.html#execute-command-in-container",
    
    "relUrl": "/docs/docker/container.html#execute-command-in-container"
  },"340": {
    "doc": "Docker Container",
    "title": "Start an existing container in background (detached)",
    "content": "The container will run in background and you will not see its stdout/stderr . docker start my-container . ",
    "url": "/docs/docker/container.html#start-an-existing-container-in-background-detached",
    
    "relUrl": "/docs/docker/container.html#start-an-existing-container-in-background-detached"
  },"341": {
    "doc": "Docker Container",
    "title": "Attach container",
    "content": "If you want to see outputs from the container in your terminal (ie. logging), you would want to run the container in attached mode. You can either run it in attached mode to begin with by . docker start my-container --attach # OR docker start my-container -a . Or you can attach a running container later . docker attach my-container . ",
    "url": "/docs/docker/container.html#attach-container",
    
    "relUrl": "/docs/docker/container.html#attach-container"
  },"342": {
    "doc": "Convergence of Random Variables",
    "title": "Convergence of Random Variables",
    "content": "We cannot directly use the calculus definition of convergence when dealing with random vectors. For example, suppose you have $n$ samples $X_1, X_2, \\ldots, X_n$ from the same distribution of a random variable $X$. Even if $n \\to \\infty$, we cannot directly say that $X_n$ converges to $X$, even though they have the same distribution, because they are random variables and $\\Pr(X_n = X) = 0$. So we introduce different types of convergence for random variables. | Convergence in Distribution . | Slutsky’s Theorem | . | Convergence in Probability | Convergence in $r$-th Mean . | Convergence in Quadratic Mean | General $r$-th Mean | . | Chain of Implications . | For Point Mass Distribution | . | . ",
    "url": "/docs/statistics/notes/convergence-of-rv.html",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html"
  },"343": {
    "doc": "Convergence of Random Variables",
    "title": "Convergence in Distribution",
    "content": "$X_n$ converges in distribution to $X$ (or $X_n \\leadsto X$, $X_n \\xrightarrow{d} X$) if: . $$ \\lim_{n \\to \\infty} F_{n}(x) = F(x) $$ . where $F_{n}$ and $F$ are the CDFs of $X_n$ and $X$ respectively. This is also known as weak convergence. | If $X_n \\leadsto X$ and $Y_n \\leadsto c$, then $X_n + Y_n \\leadsto X + c$. | If $X_n \\leadsto X$ and $Y_n \\leadsto c$, then $X_n Y_n \\leadsto Xc$. | If $X_n \\leadsto X$, then $g(X_n) \\leadsto g(X)$ for any continuous function $g$. | . $Y_n \\leadsto c$ means $Y_n$ converges to a point mass distribution Y at $c$. Where $P(Y = c) = 1$. ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-distribution",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-distribution"
  },"344": {
    "doc": "Convergence of Random Variables",
    "title": "Slutsky’s Theorem",
    "content": "The first two bullet points above are part of Slutsky’s Theorem. ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#slutskys-theorem",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#slutskys-theorem"
  },"345": {
    "doc": "Convergence of Random Variables",
    "title": "Convergence in Probability",
    "content": "$X_n$ converges in probability to $X$ (or $X_n \\xrightarrow{P} X$, $\\plim_{n \\to \\infty} X_n = X$) if: . $$ \\lim_{n \\to \\infty} \\Pr(|X_n - X| &gt; \\epsilon) = 0 $$ . for all $\\epsilon &gt; 0$. | If $X_n \\xrightarrow{P} X$ and $Y_n \\xrightarrow{P} Y$, then $X_n + Y_n \\xrightarrow{P} X + Y$. | If $X_n \\xrightarrow{P} X$ and $Y_n \\xrightarrow{P} Y$, then $X_n Y_n \\xrightarrow{P} XY$. | If $X_n \\xrightarrow{P} X$, then $g(X_n) \\xrightarrow{P} g(X)$ for any continuous function $g$. | . ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-probability",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-probability"
  },"346": {
    "doc": "Convergence of Random Variables",
    "title": "Convergence in $r$-th Mean",
    "content": " ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-r-th-mean",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-r-th-mean"
  },"347": {
    "doc": "Convergence of Random Variables",
    "title": "Convergence in Quadratic Mean",
    "content": "$X_n$ converges in quadratic mean to $X$ (or $X_n \\xrightarrow{qm} X$) if: . $$ \\lim_{n \\to \\infty} \\E[(X_n - X)^2] = 0 $$ . Also called convergence in $L^2$ norm or convergence in mean square. | If $X_n \\xrightarrow{qm} X$ and $Y_n \\xrightarrow{qm} Y$, then $X_n + Y_n \\xrightarrow{qm} X + Y$. | . ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-quadratic-mean",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#convergence-in-quadratic-mean"
  },"348": {
    "doc": "Convergence of Random Variables",
    "title": "General $r$-th Mean",
    "content": "$X_n$ converges in $r$-th mean to $X$ if: . $$ \\lim_{n \\to \\infty} \\E[|X_n - X|^r] = 0 $$ . Also called convergence in $L^r$ norm. ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#general-r-th-mean",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#general-r-th-mean"
  },"349": {
    "doc": "Convergence of Random Variables",
    "title": "Chain of Implications",
    "content": "From the strongest to the weakest: . $$ X_n \\xrightarrow{qm} X \\quad \\implies \\quad X_n \\xrightarrow{P} X \\quad \\implies \\quad X_n \\leadsto X $$ . The converse is false. ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#chain-of-implications",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#chain-of-implications"
  },"350": {
    "doc": "Convergence of Random Variables",
    "title": "For Point Mass Distribution",
    "content": "Only when $X$ is a point mass distribution at $c$, i.e.: . \\[\\Pr(X = c) = 1\\] the following holds: . $$ X_n \\leadsto c \\quad \\implies \\quad X_n \\xrightarrow{P} c \\quad $$ . ",
    "url": "/docs/statistics/notes/convergence-of-rv.html#for-point-mass-distribution",
    
    "relUrl": "/docs/statistics/notes/convergence-of-rv.html#for-point-mass-distribution"
  },"351": {
    "doc": "Correlation",
    "title": "Correlation",
    "content": "Correlation is a measure of how two variables are related to each other (i.e. how they trend or move together). It is important to note that correlation does not imply causality. Quite obviously, correlation is high for variables that are interdependent. So you should make sure that variables are independent before you make any conclusions based on correlation. | Pearson’s correlation coefficient $r$ . | Population Pearson’s Correlation Coefficient | Sample Pearson’s Correlation Coefficient | Pearson’s $r$ measures linear relationship | Not a linear regresion | Assumes bivariate normal distribution | Very sensitive to outliers | . | Non-parametric correlation coefficients . | Spearman’s rank correlation coefficient $\\rho$ | Kendall rank correlation coefficient $\\tau$ | . | . ",
    "url": "/docs/statistics/notes/correlation.html",
    
    "relUrl": "/docs/statistics/notes/correlation.html"
  },"352": {
    "doc": "Correlation",
    "title": "Pearson’s correlation coefficient $r$",
    "content": "Pearson’s corrleation corefficient, commonly denoted as $r$, measures the linear relationship between two quantitative variables. It is the most common measure of correlation. ",
    "url": "/docs/statistics/notes/correlation.html#pearsons-correlation-coefficient-r",
    
    "relUrl": "/docs/statistics/notes/correlation.html#pearsons-correlation-coefficient-r"
  },"353": {
    "doc": "Correlation",
    "title": "Population Pearson’s Correlation Coefficient",
    "content": "Population Pearson’s correlation coefficient $r$ is defined as: . $$ r = \\frac{\\Cov[X, Y]}{\\sigma_X \\sigma_Y} $$ . It is basically the covariance divided by the standard deviations of $X$ and $Y$, which just confines the value of $r$ to the range $[-1, 1]$. We say that the correlation is stronger when $\\lvert r\\rvert$ is closer to $1$, and weaker when $\\lvert r\\rvert$ is closer to $0$. ",
    "url": "/docs/statistics/notes/correlation.html#population-pearsons-correlation-coefficient",
    
    "relUrl": "/docs/statistics/notes/correlation.html#population-pearsons-correlation-coefficient"
  },"354": {
    "doc": "Correlation",
    "title": "Sample Pearson’s Correlation Coefficient",
    "content": "$$ r = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})} {\\sqrt{\\sum(x_i - \\bar{x})^2 \\sum(y_i - \\bar{y})^2}} $$ . ",
    "url": "/docs/statistics/notes/correlation.html#sample-pearsons-correlation-coefficient",
    
    "relUrl": "/docs/statistics/notes/correlation.html#sample-pearsons-correlation-coefficient"
  },"355": {
    "doc": "Correlation",
    "title": "Pearson’s $r$ measures linear relationship",
    "content": "As mentioned above, Pearson’s $r$ is a measure of linear relationship. Therefore it is not suitable to measure a non-linear relationship with $r$. You cannot assume a positive linear relationship just because you have some positive $r$ value, because it may not be linear in the first place. You should always use the scatter plot first to check. ",
    "url": "/docs/statistics/notes/correlation.html#pearsons-r-measures-linear-relationship",
    
    "relUrl": "/docs/statistics/notes/correlation.html#pearsons-r-measures-linear-relationship"
  },"356": {
    "doc": "Correlation",
    "title": "Not a linear regresion",
    "content": "Even though Pearson’s $r$ is a measure of linear relationship, it is not the same as the slope of the regression line. Whether the linear regression on the scatter plot of $X$ and $Y$ has a slope of $0$ or $10$ does not affect the value of $r$. ",
    "url": "/docs/statistics/notes/correlation.html#not-a-linear-regresion",
    
    "relUrl": "/docs/statistics/notes/correlation.html#not-a-linear-regresion"
  },"357": {
    "doc": "Correlation",
    "title": "Assumes bivariate normal distribution",
    "content": "Because Pearson’s $r$ is a parametric measure, it assumes that both $X$ and $Y$ have normality. If not, it is not a good measure of correlation. ",
    "url": "/docs/statistics/notes/correlation.html#assumes-bivariate-normal-distribution",
    
    "relUrl": "/docs/statistics/notes/correlation.html#assumes-bivariate-normal-distribution"
  },"358": {
    "doc": "Correlation",
    "title": "Very sensitive to outliers",
    "content": "Pearson’s $r$ will change drastically in the presence of outliers. You should always check for outliers before using $r$. ",
    "url": "/docs/statistics/notes/correlation.html#very-sensitive-to-outliers",
    
    "relUrl": "/docs/statistics/notes/correlation.html#very-sensitive-to-outliers"
  },"359": {
    "doc": "Correlation",
    "title": "Non-parametric correlation coefficients",
    "content": "If any one of $X$ or $Y$ is not normally distributed, then Pearson’s $r$ is not a good measure of correlation. In this case, we can use non-parametric correlation coefficients. ",
    "url": "/docs/statistics/notes/correlation.html#non-parametric-correlation-coefficients",
    
    "relUrl": "/docs/statistics/notes/correlation.html#non-parametric-correlation-coefficients"
  },"360": {
    "doc": "Correlation",
    "title": "Spearman’s rank correlation coefficient $\\rho$",
    "content": "To be added . ",
    "url": "/docs/statistics/notes/correlation.html#spearmans-rank-correlation-coefficient-rho",
    
    "relUrl": "/docs/statistics/notes/correlation.html#spearmans-rank-correlation-coefficient-rho"
  },"361": {
    "doc": "Correlation",
    "title": "Kendall rank correlation coefficient $\\tau$",
    "content": "To be added . ",
    "url": "/docs/statistics/notes/correlation.html#kendall-rank-correlation-coefficient-tau",
    
    "relUrl": "/docs/statistics/notes/correlation.html#kendall-rank-correlation-coefficient-tau"
  },"362": {
    "doc": "Covariance",
    "title": "Covariance",
    "content": ". | Understanding covariance | Sample Covariance | Independence and Covariance | Covariance Matrix | . ",
    "url": "/docs/statistics/notes/covariance.html",
    
    "relUrl": "/docs/statistics/notes/covariance.html"
  },"363": {
    "doc": "Covariance",
    "title": "Understanding covariance",
    "content": "Covariance is a measure of how two variables vary together. It is defined as follows: . $$ \\begin{align*} \\Cov[X, Y] &amp;= \\E[(X - \\E[X])(Y - \\E[Y])] \\\\[1em] &amp;= \\E[XY] - \\E[X]\\E[Y] \\end{align*} $$ . As you can see from first line of the definition, covariance is determined by the product of the deviations of $X$ and $Y$ from their respective means. If they are both above the mean (increasing trend) or both below the mean (decreasing trend), then the product will be positive, resulting in a positive covariance. If they go opposite ways from their means, then the product will be negative, resulting in a negative covariance. ",
    "url": "/docs/statistics/notes/covariance.html#understanding-covariance",
    
    "relUrl": "/docs/statistics/notes/covariance.html#understanding-covariance"
  },"364": {
    "doc": "Covariance",
    "title": "Sample Covariance",
    "content": "$$ \\text{cov}_{x,y} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{n-1} $$ . ",
    "url": "/docs/statistics/notes/covariance.html#sample-covariance",
    
    "relUrl": "/docs/statistics/notes/covariance.html#sample-covariance"
  },"365": {
    "doc": "Covariance",
    "title": "Independence and Covariance",
    "content": "When $X$ and $Y$ are independent, their covariance is zero: . $$ \\Cov[X, Y] = \\E[XY] - \\E[X]\\E[Y] = \\E[X]\\E[Y] - \\E[X]\\E[Y] = 0 $$ . ",
    "url": "/docs/statistics/notes/covariance.html#independence-and-covariance",
    
    "relUrl": "/docs/statistics/notes/covariance.html#independence-and-covariance"
  },"366": {
    "doc": "Covariance",
    "title": "Covariance Matrix",
    "content": "Let $X = (X_1, \\dots, X_n)$ be a random vector. Then the covariance matrix of $X$ is a square matrix $K_{XX}$ with entries: . $$ K_{XX}(i, j) = \\Cov[X_i, X_j] = \\E[(X_i - \\E[X_i])(X_j - \\E[X_j])] $$ . Which turns out to be a matrix of the form: . \\[K_{XX} = \\begin{bmatrix} \\Var[X_1] &amp; \\Cov[X_1, X_2] &amp; \\dots &amp; \\Cov[X_1, X_n] \\\\ \\Cov[X_2, X_1] &amp; \\Var[X_2] &amp; \\dots &amp; \\Cov[X_2, X_n] \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\Cov[X_n, X_1] &amp; \\Cov[X_n, X_2] &amp; \\dots &amp; \\Var[X_n] \\end{bmatrix}\\] ",
    "url": "/docs/statistics/notes/covariance.html#covariance-matrix",
    
    "relUrl": "/docs/statistics/notes/covariance.html#covariance-matrix"
  },"367": {
    "doc": "Cross-Validation",
    "title": "Cross-Validation",
    "content": "Cross-validation is a resampling method. Common practical applications include: . | Test error estimation (model assessment) | Complexity selection (model selection) | . | K-Fold Cross-Validation . | Downside . | Reduced Training Set Size | . | . | Leave-One-Out Cross-Validation (LOOCV) . | Linear Regression with OLS | . | CV as Test Error Estimation and Model Selection | . ",
    "url": "/docs/data-science/notes/cross-validation.html",
    
    "relUrl": "/docs/data-science/notes/cross-validation.html"
  },"368": {
    "doc": "Cross-Validation",
    "title": "K-Fold Cross-Validation",
    "content": "The steps are as follows: . | Shuffle the data. | Divide the data into $\\boldsymbol{K}$ equal-sized (as equal as possible) folds (non-overlapping partitions). | For each fold: . | Leave that fold out as the validation set. | Train the model on the remaining $K-1$ folds. | Evaluate the model on the validation set. | . | Average the validation error across all folds. | . It is important that the folds are non-overlapping. Overlapping folds introduces a lookahead, which leads to underestimation of the test error. Let $n_k$ be the number of samples in the $k$-th fold (ideally $n_k = n/K$, but it may not be the case). Assuming our error metric is MSE (it can be any other metric like misclassification rate for qualitative variables), the cross-validation estimate will be: . $$ \\text{CV}_K = \\sum_{k=1}^K \\frac{n_k}{n} \\text{MSE}_k \\approx \\frac{1}{K} \\sum_{k=1}^K \\text{MSE}_k $$ . The average MSE across all folds weighted by the number of samples in each fold. Remember that above is a single estimate of the test error. To estimate the variance of the test error, you’d have to repeat the process multiple times. ",
    "url": "/docs/data-science/notes/cross-validation.html#k-fold-cross-validation",
    
    "relUrl": "/docs/data-science/notes/cross-validation.html#k-fold-cross-validation"
  },"369": {
    "doc": "Cross-Validation",
    "title": "Downside",
    "content": "Reduced Training Set Size . One fold is always left out for validation, so each training set is . \\[\\frac{K-1}{K}\\] of the original training set. Tends to overestimate the test error. ",
    "url": "/docs/data-science/notes/cross-validation.html#downside",
    
    "relUrl": "/docs/data-science/notes/cross-validation.html#downside"
  },"370": {
    "doc": "Cross-Validation",
    "title": "Leave-One-Out Cross-Validation (LOOCV)",
    "content": "To use as much data as possible for training, we can use Leave-One-Out Cross-Validation (LOOCV). LOOCV is a special case of K-fold cross-validation where: . $$ K = n $$ . In other words, $n_k = 1$. LOOCV does not require pre-shuffle of the data, obviously because each fold is a single observation. PRO: . | Lower bias: Compared to K-fold, each training set is almost the same as the original training set. | Tends not to overestimate the test error. | . | Deterministic result: No randomness in the process. | . CON: . | Higher variance: Because each training set is almost the same, the validation sets are highly correlated, and hence variance is higher. Mean of many correlated quantities has higher variance. | Computationally expensive . | But for linear regression with OLS, it can be computed efficiently. | . | . ",
    "url": "/docs/data-science/notes/cross-validation.html#leave-one-out-cross-validation-loocv",
    
    "relUrl": "/docs/data-science/notes/cross-validation.html#leave-one-out-cross-validation-loocv"
  },"371": {
    "doc": "Cross-Validation",
    "title": "Linear Regression with OLS",
    "content": "It is generally computationally expensive to compute LOOCV. However, for linear regression with OLS, there is a closed-form solution for LOOCV: . $$ \\text{CV}_n = \\frac{1}{n} \\sum_{i=1}^n \\left(\\frac{y_i - \\hat{y}_i}{1 - h_{i}} \\right)^2 $$ . Similar to MSE, but with a correction $1 - h_i$ for each residual term. where: . | $h_i$: the leverage of the $i$-th observation. \\[h_i = \\frac{1}{n} + \\frac{(x_i - \\overline{x})^2}{\\sum_{j=1}^n (x_j - \\overline{x})^2}\\] Reflects how much the $i$-th observation influences the fit. | $\\hat{y}_i$: the predicted value of the $i$-th observation from the model fitted with the entire dataset. | . ",
    "url": "/docs/data-science/notes/cross-validation.html#linear-regression-with-ols",
    
    "relUrl": "/docs/data-science/notes/cross-validation.html#linear-regression-with-ols"
  },"372": {
    "doc": "Cross-Validation",
    "title": "CV as Test Error Estimation and Model Selection",
    "content": "We outlined in the beginning that CV is most commonly used for: . | Model assessment (estimating the test error) | Model selection (how complex the model should be) | . | Blue: True test error (unknown in real life) | Orange: 10-fold CV estimate | Black dashed: LOOCV estimate | . To use the results as a test error estimate, it is quite straightforward: just use the value. To use the results for model selection, we plot the CV estimate against different model complexities and find a minimizing point (represented by $\\times$ in the plot). In the left plot, we see that the model selected by CV estimates are a little bit more complex than the true model. However, this is good enough for practical purposes (and we wouldn’t know the true model complexity anyway). ",
    "url": "/docs/data-science/notes/cross-validation.html#cv-as-test-error-estimation-and-model-selection",
    
    "relUrl": "/docs/data-science/notes/cross-validation.html#cv-as-test-error-estimation-and-model-selection"
  },"373": {
    "doc": "CSR",
    "title": "Certificate Signing Request (CSR)",
    "content": ". | Generate using Java Keytool . | Generate new keystore | Generate CSR | (Optional) Extract PEM file from keystore . | Create p12 file | Create pem file | . | . | . ",
    "url": "/docs/security/ssl/csr.html#certificate-signing-request-csr",
    
    "relUrl": "/docs/security/ssl/csr.html#certificate-signing-request-csr"
  },"374": {
    "doc": "CSR",
    "title": "Generate using Java Keytool",
    "content": "Generate new keystore . keytool -genkey -keyalg rsa -keysize 2048 # To use basic info keytool -genkey -keyalg rsa -keysize 2048 \\ -dname \"cn=${yourdomain}, o=default, c=us\" \\ -keystore ${keystore_name}.keystore . ${yourdomain} must match exactly the domain name written in the SSL. Change keyalg in all commands if you want to use a different algorithm. Generate CSR . keytool -certreq -keyalg rsa -file ${csr_name}.csr -keystore ${keystore_name}.keystore . (Optional) Extract PEM file from keystore . Create p12 file . keytool -importkeystore -srckeystore ${keystore_name}.keystore \\ -destkeystore ${keystore_name}.p12 -deststoretype PKCS12 . Create pem file . openssl pkcs12 -in ${keystore_name}.p12 -nodes -nocerts -out ${keystore_name}.pem . ",
    "url": "/docs/security/ssl/csr.html#generate-using-java-keytool",
    
    "relUrl": "/docs/security/ssl/csr.html#generate-using-java-keytool"
  },"375": {
    "doc": "CSR",
    "title": "CSR",
    "content": " ",
    "url": "/docs/security/ssl/csr.html",
    
    "relUrl": "/docs/security/ssl/csr.html"
  },"376": {
    "doc": "SQL CTE",
    "title": "SQL CTE (Common Table Expressions)",
    "content": ". | WITH | WITH RECURSIVE | . ",
    "url": "/docs/db/sql/cte.html#sql-cte-common-table-expressions",
    
    "relUrl": "/docs/db/sql/cte.html#sql-cte-common-table-expressions"
  },"377": {
    "doc": "SQL CTE",
    "title": "WITH",
    "content": "Let’s you define a temporary result set that you can reference within the main query. WITH cte_name AS [(column1, column2)] ( SELECT column1, column2 FROM tbl ) SELECT * FROM cte_name; . The column alias list (column1, column2) is optional. If you don’t specify it, the column names are taken from CTE query SELECT clause. There should not be a semicolon ; after the CTE query. ",
    "url": "/docs/db/sql/cte.html#with",
    
    "relUrl": "/docs/db/sql/cte.html#with"
  },"378": {
    "doc": "SQL CTE",
    "title": "WITH RECURSIVE",
    "content": "WITH RECURSIVE cte_name AS ( -- Anchor member SELECT column1, column2 FROM tbl WHERE base_condition UNION [ALL] -- Without or with duplicates -- Recursive member SELECT column1, column2 FROM `some joins referencing cte_name` WHERE recursive_condition ) SELECT * FROM cte_name; . Notice how the recursive member in CTE references cte_name itself. ",
    "url": "/docs/db/sql/cte.html#with-recursive",
    
    "relUrl": "/docs/db/sql/cte.html#with-recursive"
  },"379": {
    "doc": "SQL CTE",
    "title": "SQL CTE",
    "content": " ",
    "url": "/docs/db/sql/cte.html",
    
    "relUrl": "/docs/db/sql/cte.html"
  },"380": {
    "doc": "DDL",
    "title": "DDL",
    "content": ". | CREATE TABLE | Column/Table Constraints . | PRIMARY KEY | FOREIGN KEY . | ON DELETE and ON UPDATE | . | CHECK | UNIQUE | NOT NULL | DEFAULT | . | . ",
    "url": "/docs/db/sql/ddl.html",
    
    "relUrl": "/docs/db/sql/ddl.html"
  },"381": {
    "doc": "DDL",
    "title": "CREATE TABLE",
    "content": "CREATE TABLE [IF NOT EXISTS] table_name ( column1 DATA_TYPE(len) column_constraint, column2 DATA_TYPE(len) column_constraint, ... table_constraint ) . ",
    "url": "/docs/db/sql/ddl.html#create-table",
    
    "relUrl": "/docs/db/sql/ddl.html#create-table"
  },"382": {
    "doc": "DDL",
    "title": "Column/Table Constraints",
    "content": "Column constraints come after each column name and data type. Multiple column constraints can be added to a column (e.g. UNIQUE NOT NULL). | PRIMARY KEY | UNIQUE | NOT NULL | . Table constraints come after column definitions, and are usually given constraint names. | PRIMARY KEY | FOREIGN KEY | CHECK | UNIQUE | . ",
    "url": "/docs/db/sql/ddl.html#columntable-constraints",
    
    "relUrl": "/docs/db/sql/ddl.html#columntable-constraints"
  },"383": {
    "doc": "DDL",
    "title": "PRIMARY KEY",
    "content": "For single column primary key: . CREATE TABLE users ( id SERIAL PRIMARY KEY, ) . PostgreSQL’s SERIAL is like INT AUTO_INCREMENT in MySQL. If you want to use composite keys, you need to use table constraints: . CREATE TABLE users ( id INT, username VARCHAR(50), ... [CONSTRAINT pk_users] -- Optional table constraint name PRIMARY KEY (id, username) ) . Adding primary key constraint to existing table: . ALTER TABLE users ADD [CONSTRAINT pk_users] PRIMARY KEY (id); . Or drop: . ALTER TABLE users DROP CONSTRAINT pk_users; . ",
    "url": "/docs/db/sql/ddl.html#primary-key",
    
    "relUrl": "/docs/db/sql/ddl.html#primary-key"
  },"384": {
    "doc": "DDL",
    "title": "FOREIGN KEY",
    "content": "CREATE TABLE users ( id SERIAL PRIMARY KEY, category_id INT, ... [CONSTRAINT fk_users_category_id] FOREIGN KEY (category_id) REFERENCES categories (id) [ON DELETE delete_action] [ON UPDATE update_action] ) . ON DELETE and ON UPDATE . ON DELETE and ON UPDATE refers to situations when the referenced column id is deleted or updated in parent table categories. Available actions are: . | NO ACTION: Actually similar to RESTRICT (more details involved). Raises an error if you try to delete or update in parent table. If no ON DELETE or ON UPDATE is specified, NO ACTION is the default. | SET NULL: Sets foreign key column to NULL if it is nullable. | SET DEFAULT: Sets to default if column has default value. | CASCADE: Removes or updates all rows in this child table accordingly. Most commonly used in practice, as it preserves referential integrity. | RESTRICT: Rejects the delete or update operation for the parent table. | . Again, you can add foreign key constraint to existing table: . ALTER TABLE users ADD CONSTRAINT fk_users_category_id FOREIGN KEY (category_id) REFERENCES categories (id) ON DELETE CASCADE; . ",
    "url": "/docs/db/sql/ddl.html#foreign-key",
    
    "relUrl": "/docs/db/sql/ddl.html#foreign-key"
  },"385": {
    "doc": "DDL",
    "title": "CHECK",
    "content": "General constraint useful when multiple columns are involved: . CREATE TABLE table_name ( column1 DATA_TYPE, column2 DATA_TYPE, ... [CONSTRAINT constraint_name] CHECK (condition expression) ) . But if you only need to check a single column, you can use a column constraint: . CREATE TABLE table_name ( column1 DATA_TYPE CHECK (condition) ) . ",
    "url": "/docs/db/sql/ddl.html#check",
    
    "relUrl": "/docs/db/sql/ddl.html#check"
  },"386": {
    "doc": "DDL",
    "title": "UNIQUE",
    "content": "As a column constraint on single column: . CREATE TABLE users ( username VARCHAR(50) UNIQUE, ) . As a table constraint on multiple columns: . CREATE TABLE users ( username VARCHAR(50), email VARCHAR(50), ... [CONSTRAINT uq_users_username_email] UNIQUE (username, email) ) . ",
    "url": "/docs/db/sql/ddl.html#unique",
    
    "relUrl": "/docs/db/sql/ddl.html#unique"
  },"387": {
    "doc": "DDL",
    "title": "NOT NULL",
    "content": "NOT NULL is a column constraint: . CREATE TABLE users ( username VARCHAR(50) NOT NULL, ) . You can add NOT NULL to existing column: . ALTER TABLE users ALTER COLUMN username SET NOT NULL; . ",
    "url": "/docs/db/sql/ddl.html#not-null",
    
    "relUrl": "/docs/db/sql/ddl.html#not-null"
  },"388": {
    "doc": "DDL",
    "title": "DEFAULT",
    "content": "The default can either be a value or an expression: . CREATE TABLE users ( username VARCHAR(50) DEFAULT 'guest', last_created VARCHAR(50) DEFAULT NOW(), ... ) . ",
    "url": "/docs/db/sql/ddl.html#default",
    
    "relUrl": "/docs/db/sql/ddl.html#default"
  },"389": {
    "doc": "Decision Tree",
    "title": "Decision Tree",
    "content": ". | Overview . | Interpretation of Nodes | Advantages of DT | Disadvantages of DT | . | Internal Node Selection . | Greedy Approach | . | Stopping Criterion | Pruning . | With Cross-Validation | . | Internal Node Selection in Classification . | Gini Index | Entropy | Mutual Information | . | . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html"
  },"390": {
    "doc": "Decision Tree",
    "title": "Overview",
    "content": "Decision tree (DT) is a non-parametric supervised learning method. It can be used for both classification and regression. We start with the root node and do a recursive binary split on some feature condition (internal node) (such as $\\text{feature} &lt; \\text{value}$) until we reach a leaf node, which represents a non-overlapping stratified region of the feature space. Any multi-way split can be represented as a series of binary splits. | In classification, the output is a class label with the majority vote of the instances that fall in to the region of the terminal node (leaf). | In regression, the output is usually the mean of the instances in the terminal node. | . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#overview",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#overview"
  },"391": {
    "doc": "Decision Tree",
    "title": "Interpretation of Nodes",
    "content": ". | The features split at each node represent the most informative feature for the current subset of data | Features partitioned first are considered the most important factor in prediction | . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#interpretation-of-nodes",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#interpretation-of-nodes"
  },"392": {
    "doc": "Decision Tree",
    "title": "Advantages of DT",
    "content": ". | Good interpretability | Does not require much data preprocessing (such as scaling) | Robust to outliers | Able to handle both qualitative and quantitative features and labels | . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#advantages-of-dt",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#advantages-of-dt"
  },"393": {
    "doc": "Decision Tree",
    "title": "Disadvantages of DT",
    "content": ". | Prone to overfitting . | You could literally have a tree that has a leaf for each data point, thus training error of 0 | “Pruning” unnecessary branches can help | . | Feature value partitions can cause bias (see Caveat) | Because tree nodes are decided by probability calculation, you may end up with completely different trees for “inherently” similar data when you slightly change the data . | This unstable nature can be mitigated by using random forests | . | Not competitive in terms of accuracy . | Also mitigated by using random forests | . | . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#disadvantages-of-dt",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#disadvantages-of-dt"
  },"394": {
    "doc": "Decision Tree",
    "title": "Internal Node Selection",
    "content": "While decision trees are very intuitive, question remains: . How do we select which feature and where to split on in each layer of the tree? . In terms of regression, ideally we would like to minimize the residual sum of squares (RSS) across all the leaves: . \\[\\sum_{j=1}^{J} \\sum_{i \\in R_j} (y_i - \\hat{y}_{R_j})^2\\] where: . | $J$ is the number of leaves / regions | $R_j$ is the $j$-th region | $\\hat{y}_{R_j}$ is the mean of the response values in region $R_j$ (prediction) | . However, this is computationally infeasible. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#internal-node-selection",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#internal-node-selection"
  },"395": {
    "doc": "Decision Tree",
    "title": "Greedy Approach",
    "content": "We instead optimize on the binary RSS at each internal node: . $$ \\underset{j, s}{\\arg\\min} \\left[ \\sum_{i: x_i \\in R_1(j, s)} (y_i - \\hat{y}_{R_1})^2 + \\sum_{i: x_i \\in R_2(j, s)} (y_i - \\hat{y}_{R_2})^2 \\right] $$ . At each internal node, we consider all features $j$ and split points $s$: . \\[R_1(j, s) = \\{x_i \\mid x_{ij} &lt; s\\} \\quad \\text{and} \\quad R_2(j, s) = \\{x_i \\mid x_{ij} \\geq s\\}\\] Then select the feature $j$ and split point $s$ that minimizes combined region RSS. The minimizing $(j,s)$ is our internal node, and we repeat the process until a certain stopping criterion is met. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#greedy-approach",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#greedy-approach"
  },"396": {
    "doc": "Decision Tree",
    "title": "Stopping Criterion",
    "content": "Most common early stopping criteria are: . | Maximum depth | Minimum samples per leaf | . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#stopping-criterion",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#stopping-criterion"
  },"397": {
    "doc": "Decision Tree",
    "title": "Pruning",
    "content": "We mentioned above that decision trees are prone to overfitting. Pruning is the process of reducing a large tree after it is fully grown. We do not want to prevent branching while the tree is growing: this leads to an overly short-sighted tree. We denote the original large tree as $T_0$. We want to find a subtree $T \\subset T_0$ that minimize the test error (via cross validation, etc.). However, we cannot possibly test all subtrees. With cost complexity pruning or weakest link pruning we find a sequence of subtrees $T_\\alpha$ indexed by $\\alpha$. In other words, for each tuning parameter $\\alpha \\geq 0$, we can find a subtree $T \\subseteq T_0$ with the minimum penalized RSS: . $$ \\sum_{m=1}^{|T|} \\sum_{i: x_i \\in R_m} (y_i - \\hat{y}_{R_m})^2 + \\alpha |T| $$ . Which works in a similar way to regularization where the penalty is on the number of terminal nodes $|T|$. Unlike the greedy approach used in buliding the original tree, we’re optimizing over the entire subtree. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#pruning",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#pruning"
  },"398": {
    "doc": "Decision Tree",
    "title": "With Cross-Validation",
    "content": "We can use cross-validation to find the best $\\alpha$. First shuffle and split the data into $K$ folds, and select a search range for $\\alpha$. | For each $\\alpha$: . | For each fold k: . | Grow the tree $T_0$ to its maximum size with $K-1$ training folds | Apply above formula to find the best subtree $T_\\alpha$ | Calculate validation error on the $k$-th fold | . | . Average the validation errors across all folds for each $\\alpha$. | . Find the minimizing $\\alpha$ and use the corresponding subtree. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#with-cross-validation",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#with-cross-validation"
  },"399": {
    "doc": "Decision Tree",
    "title": "Internal Node Selection in Classification",
    "content": "In classification we need a different measure of error than RSS. Since the class with the most training observations in a region becomes the predicted class for that region, we could think of using the misclassification rate: . \\[\\text{Error rate} = 1 - \\max_k \\hat{p}_{mk}\\] Where $\\hat{p}_{mk}$ is the proportion of training observations in the $m$-th region that belong to the $k$-th class. However, misclassification rate is not sensitive enough for tree-growing purposes. But during pruning, we use misclassification rate as a measure of error. The following measures are preferred during tree-growing becasue they are more sensitive to node purity than misclassification rate. However, they do not represent actual prediction accuracy. The alternate options are as follows: . ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#internal-node-selection-in-classification",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#internal-node-selection-in-classification"
  },"400": {
    "doc": "Decision Tree",
    "title": "Gini Index",
    "content": "We could try to minimize the Gini index, a measure of impurity in a region: . $$ G = \\sum_{k=1}^{K} \\hat{p}_{mk} (1 - \\hat{p}_{mk}) $$ . Given a region $R_m$, if a single class $k$ dominates the region: . \\[\\hat{p}_{mk} \\approx 1 \\land \\hat{p}_{mk'} \\approx 0 \\implies G \\approx 0\\] Small Gini index means the region is pure. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#gini-index",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#gini-index"
  },"401": {
    "doc": "Decision Tree",
    "title": "Entropy",
    "content": "Another measure of impurity or surprise in a region is entropy: . $$ D = -\\sum_{k=1}^{K} \\hat{p}_{mk} \\log \\hat{p}_{mk} $$ . Small average surprise means the region is pure. Numerically, Gini index and entropy are very similar. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#entropy",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#entropy"
  },"402": {
    "doc": "Decision Tree",
    "title": "Mutual Information",
    "content": "Or we could pick the feature that gives us the most information about the label. For that we need an understanding of entropy and mutual information. In short, entropy is the expected amount of information needed, and mutual information is the amount of information gain on one variable when we are given another, measured in terms of entropy. Let $Y$ be the label and $X_i$ be the $i$-th feature. For each feature $X_i$, we can calculate the mutual information between $X_i$ and $Y$. Higher mutual information means that $X_i$ is more informative about $Y$, which is what we want. \\[\\underset{X_i}{\\arg\\max} \\; I(Y; X_i) = \\underset{X_i}{\\arg\\max} \\; H(Y) - H(Y \\mid X_i)\\] Caveat One caveat is that mutual information is biased towards features with more partition. For two features ID and gender, while there are many distinct values that ID can take on, gender only has so many. So when you split on a feature with many distinct values (quantitative or not), we need to penalize by the number of splits and use a metric called information gain ratio, or just partition on a reasonable range. ",
    "url": "/docs/data-science/ml-dl/decision-tree.html#mutual-information",
    
    "relUrl": "/docs/data-science/ml-dl/decision-tree.html#mutual-information"
  },"403": {
    "doc": "Delta Method",
    "title": "Delta Method",
    "content": ". | Univariate Delta Method | . ",
    "url": "/docs/statistics/notes/delta-method.html",
    
    "relUrl": "/docs/statistics/notes/delta-method.html"
  },"404": {
    "doc": "Delta Method",
    "title": "Univariate Delta Method",
    "content": "Let $X_n$ be a RV that asymptotically follows a normal distribution (see CLT). \\[X_n \\leadsto N(\\mu, \\sigma^2)\\] If $g$ is a differentiable function and $g’(\\mu) \\neq 0$, then the distribution of $g(X_n)$ converges to a normal distribution: . $$ g(X_n) \\leadsto N\\left(g(\\mu),\\, (g'(\\mu))^2\\, \\frac{\\sigma^2}{n}\\right) $$ . Taylor Expansion The first order Taylor expansion approximation of $g(X_n)$ around $\\mu$ is: . \\[g(X_n) \\approx g(\\mu) + g'(\\mu) (X_n - \\mu)\\] Since $g’(\\mu) \\neq 0$, rearranging the terms: . \\[X_n - \\mu \\approx \\frac{g(X_n) - g(\\mu)}{g'(\\mu)}\\] Multiplying both sides by $\\frac{\\sqrt{n}}{\\sigma}$: . \\[\\frac{\\sqrt{n} (X_n - \\mu)}{\\sigma} \\approx \\frac{\\sqrt{n}(g(X_n) - g(\\mu))}{g'(\\mu) \\sigma} \\leadsto N(0, 1)\\] The standardized form makes it easy to see that . \\[g(X_n) \\leadsto N\\left(g(\\mu),\\, (g'(\\mu))^2\\, \\frac{\\sigma^2}{n}\\right)\\] ",
    "url": "/docs/statistics/notes/delta-method.html#univariate-delta-method",
    
    "relUrl": "/docs/statistics/notes/delta-method.html#univariate-delta-method"
  },"405": {
    "doc": "Determinants",
    "title": "Determinants",
    "content": ". | Determinant . | Singular Matrix | Properties of the Determinant | . | Laplace Expansion . | Singleton Matrix Case | General Case . | Expansion Along a Row | Expansion Along a Column | . | 2x2 Matrix Application | . | Rule of Sarrus | Determinant of a Triangular Matrix | Leibniz Formula | Geometrical Interpretation | . ",
    "url": "/docs/linalg/basics/determinant.html",
    
    "relUrl": "/docs/linalg/basics/determinant.html"
  },"406": {
    "doc": "Determinants",
    "title": "Determinant",
    "content": "Determinant of a $n \\times n$ square matrix $\\boldsymbol{A}$ is denoted: . $$ \\det(\\boldsymbol{A}) \\quad \\text{or} \\quad |\\boldsymbol{A}| $$ . Only defined for square matrices. ",
    "url": "/docs/linalg/basics/determinant.html#determinant",
    
    "relUrl": "/docs/linalg/basics/determinant.html#determinant"
  },"407": {
    "doc": "Determinants",
    "title": "Singular Matrix",
    "content": "The following is an important property of the determinant. For a square matrix $\\boldsymbol{A}$, . $$ \\det(\\boldsymbol{A}) = 0 \\quad \\iff \\quad \\boldsymbol{A} \\text{ is singular} \\quad \\iff \\nexists \\boldsymbol{A}^{-1} $$ . Thus a singular matrix is not invertible, and the system of linear equations $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{b}$ has no unique solution. ",
    "url": "/docs/linalg/basics/determinant.html#singular-matrix",
    
    "relUrl": "/docs/linalg/basics/determinant.html#singular-matrix"
  },"408": {
    "doc": "Determinants",
    "title": "Properties of the Determinant",
    "content": "Let $\\boldsymbol{A}$, $\\boldsymbol{B}$, $\\boldsymbol{C}$ be square matrices of same size and $k$ a scalar: . | $\\det(k\\boldsymbol{A}) = k^n \\det(\\boldsymbol{A})$ . | Multiplying a single row or column by $k$ multiplies the determinant by $k$. | Multiplying all rows or columns by $k$ multiplies the determinant by $k^n$. | . | If $\\boldsymbol{A}$, $\\boldsymbol{B}$, $\\boldsymbol{C}$ only differ by a single (same) row or column $i$, and the different row or column of $\\boldsymbol{C}_i = \\boldsymbol{A}_i + \\boldsymbol{B}_i$, then $\\det(\\boldsymbol{C}) = \\det(\\boldsymbol{A}) + \\det(\\boldsymbol{B})$. | If $\\boldsymbol{A}$ is obtained by swapping two rows or columns of $B$, then $\\det(\\boldsymbol{A}) = -\\det(\\boldsymbol{B})$. | If $\\boldsymbol{A}$ has two identical rows or columns, then $\\det(\\boldsymbol{A}) = 0$. | $\\det(\\boldsymbol{A}) \\neq 0$ if and only if $\\boldsymbol{A}$ has full rank. | Adding a multiple of one row or column to another row or column does not change the determinant. | $\\det(\\boldsymbol{A}) = \\det(\\boldsymbol{A}^T)$ | $\\det(I) = 1$ | If any row or column of $\\boldsymbol{A}$ is all zeros, then $\\det(\\boldsymbol{A}) = 0$. | Multiplicativity of determinants: $\\det(\\boldsymbol{A}\\boldsymbol{B}) = \\det(\\boldsymbol{A}) \\det(\\boldsymbol{B})$ | $\\det(\\boldsymbol{A}^{-1}) = \\frac{1}{\\det(\\boldsymbol{A})}$ | $\\det(\\operatorname{adj}(\\boldsymbol{A})) = \\det(\\boldsymbol{A})^{n-1}$ | If $\\boldsymbol{A}$ is an orthogonal matrix, $|\\det(\\boldsymbol{A})| = 1$ | . ",
    "url": "/docs/linalg/basics/determinant.html#properties-of-the-determinant",
    
    "relUrl": "/docs/linalg/basics/determinant.html#properties-of-the-determinant"
  },"409": {
    "doc": "Determinants",
    "title": "Laplace Expansion",
    "content": "You need to understand minor (determinants) and cofactor before continuing. Laplace expansion is a recursive method to calculate the determinant of a matrix. ",
    "url": "/docs/linalg/basics/determinant.html#laplace-expansion",
    
    "relUrl": "/docs/linalg/basics/determinant.html#laplace-expansion"
  },"410": {
    "doc": "Determinants",
    "title": "Singleton Matrix Case",
    "content": "For a $1 \\times 1$ matrix $\\boldsymbol{A} = [a]$, the determinant is defined as simply: . $$ a $$ . ",
    "url": "/docs/linalg/basics/determinant.html#singleton-matrix-case",
    
    "relUrl": "/docs/linalg/basics/determinant.html#singleton-matrix-case"
  },"411": {
    "doc": "Determinants",
    "title": "General Case",
    "content": "With the base case in mind, we can recursively calculate the determinant of a matrix by expanding along a row or a column. Expansion Along a Row . For a $n \\times n$ matrix $\\boldsymbol{A}$, we can fix a row $i$ and expand along that row. Usually, we expand along the first row $i = 1$. The determinant of $\\boldsymbol{A}$ is the sum of the products of the elements on the row $i$ and their cofactors. $$ \\det(\\boldsymbol{A}) = \\sum_{j=1}^n a_{ij} \\cdot (-1)^{i+j} \\boldsymbol{M}_{ij} $$ . Expansion along the row is more common than expansion along the column. Expansion Along a Column . Same idea, we can fix a column $j$ and expand along that column. The determinant of $\\boldsymbol{A}$ is the sum of the products of the elements on the column $j$ and their cofactors. \\[\\det(\\boldsymbol{A}) = \\sum_{i=1}^n a_{ij} \\cdot (-1)^{i+j} M_{ij}\\] ",
    "url": "/docs/linalg/basics/determinant.html#general-case",
    
    "relUrl": "/docs/linalg/basics/determinant.html#general-case"
  },"412": {
    "doc": "Determinants",
    "title": "2x2 Matrix Application",
    "content": "Let’s apply the Laplace expansion to a $2 \\times 2$ matrix $\\boldsymbol{A}$. \\[\\boldsymbol{A} = \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix}\\] Expansion along the first row $i = 1$. \\[\\begin{align*} \\det(\\boldsymbol{A}) &amp;= \\sum_{j=1}^2 a_{1j} \\cdot (-1)^{1+j} M_{1j} \\\\ &amp;= a \\cdot (-1)^{1+1} M_{11} + b \\cdot (-1)^{1+2} M_{12} \\\\ &amp;= a \\cdot M_{11} - b \\cdot M_{12} \\\\ &amp;= a \\cdot d - b \\cdot c \\end{align*}\\] The determinant of a $2 \\times 2$ matrix $\\boldsymbol{A}$ is thus defined as: . $$ \\det(\\boldsymbol{A}) = ad - bc $$ . ",
    "url": "/docs/linalg/basics/determinant.html#2x2-matrix-application",
    
    "relUrl": "/docs/linalg/basics/determinant.html#2x2-matrix-application"
  },"413": {
    "doc": "Determinants",
    "title": "Rule of Sarrus",
    "content": "This is a quick method for the determinant of a $3 \\times 3$ matrix. Let $\\boldsymbol{A}$ be a $3 \\times 3$ matrix: . $$ \\det(\\boldsymbol{A}) = \\begin{vmatrix} a &amp; b &amp; c \\\\ d &amp; e &amp; f \\\\ g &amp; h &amp; i \\end{vmatrix} = a(ei - fh) - b(di - fg) + c(dh - eg) $$ . ",
    "url": "/docs/linalg/basics/determinant.html#rule-of-sarrus",
    
    "relUrl": "/docs/linalg/basics/determinant.html#rule-of-sarrus"
  },"414": {
    "doc": "Determinants",
    "title": "Determinant of a Triangular Matrix",
    "content": "See triangular matrices. For a triangular matrix $\\boldsymbol{T}$, . $$ \\det(\\boldsymbol{T}) = \\prod_{i=1}^n t_{ii} $$ . i.e. the determinant is the product of the diagonal elements. ",
    "url": "/docs/linalg/basics/determinant.html#determinant-of-a-triangular-matrix",
    
    "relUrl": "/docs/linalg/basics/determinant.html#determinant-of-a-triangular-matrix"
  },"415": {
    "doc": "Determinants",
    "title": "Leibniz Formula",
    "content": "Leibniz formula is another way to calculate the determinant of a square matrix. It comes from the observation that the full determinant expansion can be written as a special sum of products of elements. Explanation assumes expansion along row $i$ for simplicity. The key takeaway is that each recursive product in the sum ends up looking like the following: . \\[\\prod_{i=1}^n a_{i\\sigma(i)}\\] That is, while the row $i$ increases from $1$ to $n$ (or is an identity permutation), the column is actually permuted by some $\\sigma$. Like $a_{12} \\cdot a_{23} \\cdot a_{31}$, where the column $j$ is permuted to $2, 3, 1$. In addition, the sign of the recursive product ends up equal to the parity of the permutation $\\sigma$. Therefore the determinant of $\\boldsymbol{A}$ can be written as: . $$ \\det(\\boldsymbol{A}) = \\sum_{\\sigma \\in S_n} \\text{sgn}(\\sigma) \\prod_{i=1}^n a_{i\\sigma(i)} $$ . Or equivalently, . \\[\\det(\\boldsymbol{A}) = \\sum_{\\sigma \\in S_n} \\text{sgn}(\\sigma) \\prod_{i=1}^n a_{\\sigma(i)i}\\] . ",
    "url": "/docs/linalg/basics/determinant.html#leibniz-formula",
    
    "relUrl": "/docs/linalg/basics/determinant.html#leibniz-formula"
  },"416": {
    "doc": "Determinants",
    "title": "Geometrical Interpretation",
    "content": "In 2D, the determinant of a $2 \\times 2$ matrix can be interpreted as the signed area of the parallelogram formed by the two column vectors. In 3D, the determinant of a $3 \\times 3$ matrix can be interpreted as the signed volume of the parallelepiped formed by the three column vectors. A parallelepiped is a 3D generalization of a parallelogram (i.e. a linearly transformed cube). If the columns are linearly dependent, the area or volume becomes zero. ",
    "url": "/docs/linalg/basics/determinant.html#geometrical-interpretation",
    
    "relUrl": "/docs/linalg/basics/determinant.html#geometrical-interpretation"
  },"417": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "content": ". | Principal diagonal | Trace . | Invariant under Cyclic Permutation | . | Diagonal Matrix . | Properties of a Diagonal Matrix | . | Triangular Matrix . | Upper Triangular Matrix | Lower Triangular Matrix | . | Rectangular Diagonal Matrix | . ",
    "url": "/docs/linalg/basics/diagonal.html",
    
    "relUrl": "/docs/linalg/basics/diagonal.html"
  },"418": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Principal diagonal",
    "content": "The principal diagonal of a square matrix is the diagonal from the upper left to the lower right. $$ \\{a_{ij} \\mid i = j\\} $$ . Also called the main diagonal. Each element $a_{ii}$ is called a principal diagonal element. ",
    "url": "/docs/linalg/basics/diagonal.html#principal-diagonal",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#principal-diagonal"
  },"419": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Trace",
    "content": "A trace of a square matrix $\\boldsymbol{A}$ is the sum of its principal diagonal elements: . $$ \\tr(\\boldsymbol{A}) = \\sum_{i=1}^n a_{ii} $$ . For square matrices $\\boldsymbol{A}$ and $\\boldsymbol{B}$: . | $\\tr(\\boldsymbol{A} + \\boldsymbol{B}) = \\tr(\\boldsymbol{A}) + \\tr(\\boldsymbol{B})$ | $\\tr(\\boldsymbol{A} \\boldsymbol{B}) = \\tr(\\boldsymbol{B} \\boldsymbol{A})$ . This property also holds for non-square matrices. | $\\tr(\\lambda \\boldsymbol{A}) = \\lambda \\tr(\\boldsymbol{A})$ | $\\tr(\\boldsymbol{I}_n) = n$ | . ",
    "url": "/docs/linalg/basics/diagonal.html#trace",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#trace"
  },"420": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Invariant under Cyclic Permutation",
    "content": "Coming from the above properties, for matrices $\\boldsymbol{A}, \\boldsymbol{B}, \\boldsymbol{C}$, whose product is defined but are not necessarily square matrices, . $$ \\tr(\\boldsymbol{ABC}) = \\tr(\\boldsymbol{BCA}) = \\tr(\\boldsymbol{CAB}) $$ . ",
    "url": "/docs/linalg/basics/diagonal.html#invariant-under-cyclic-permutation",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#invariant-under-cyclic-permutation"
  },"421": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Diagonal Matrix",
    "content": "A diagonal matrix is a square matrix whose non-principal diagonal elements are all zero. \\[A = \\begin{bmatrix} a_{11} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; a_{22} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nn} \\end{bmatrix}\\] Often denoted by: . $$ A = diag(a_{11}, a_{22}, \\cdots, a_{nn}) $$ . ",
    "url": "/docs/linalg/basics/diagonal.html#diagonal-matrix",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#diagonal-matrix"
  },"422": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Properties of a Diagonal Matrix",
    "content": "For diagonal matrices $A = diag(a_{11}\\cdots, a_{nn})$ and $B = diag(b_{11}\\cdots, b_{nn})$: . | $A + B = diag(a_{11} + b_{11}, \\cdots, a_{nn} + b_{nn})$ | $A B = diag(a_{11} b_{11}, \\cdots, a_{nn} b_{nn})$ | . ",
    "url": "/docs/linalg/basics/diagonal.html#properties-of-a-diagonal-matrix",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#properties-of-a-diagonal-matrix"
  },"423": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Triangular Matrix",
    "content": "For both upper and lower triangular matrices, if the principal diagonal elements are all 1, then the matrix is called a unit (upper/lower) triangular matrix. ",
    "url": "/docs/linalg/basics/diagonal.html#triangular-matrix",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#triangular-matrix"
  },"424": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Upper Triangular Matrix",
    "content": "An upper triangular matrix is a square matrix whose non-principal diagonal elements below the principal diagonal are all zero. Upper triangular matrix, often denoted by $U_n$ is: . $$ U_n = [u_{ij}]_{n \\times n} \\quad \\text{where} \\quad \\forall i &gt; j,\\; u_{ij} = 0 $$ . Example: . \\[\\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 0 &amp; 4 &amp; 5 \\\\ 0 &amp; 0 &amp; 6 \\end{bmatrix}\\] ",
    "url": "/docs/linalg/basics/diagonal.html#upper-triangular-matrix",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#upper-triangular-matrix"
  },"425": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Lower Triangular Matrix",
    "content": "An lower triangular matrix is a square matrix whose non-principal diagonal elements above the principal diagonal are all zero. Lower triangular matrix, often denoted by $L_n$ is: . $$ L_n = [l_{ij}]_{n \\times n} \\quad \\text{where} \\quad \\forall i &lt; j,\\; l_{ij} = 0 $$ . Example: . \\[\\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 3 &amp; 0 \\\\ 4 &amp; 5 &amp; 6 \\end{bmatrix}\\] . ",
    "url": "/docs/linalg/basics/diagonal.html#lower-triangular-matrix",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#lower-triangular-matrix"
  },"426": {
    "doc": "Diagonal of a Matrix / Trace / Triangular Matrix",
    "title": "Rectangular Diagonal Matrix",
    "content": "Sometimes you might see people say rectangular diagonal matrix which refers to a non-square matrix that constains a diagonal matrix as a submatrix, and the rest of the elements are all zero. Suppose $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$. If $m &gt; n$: . \\[\\boldsymbol{A} = \\begin{bmatrix} a_{11} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; a_{22} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nn} \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 \\end{bmatrix}\\] If $m &lt; n$: . \\[\\boldsymbol{A} = \\begin{bmatrix} a_{11} &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; a_{22} &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{mm} &amp; 0 &amp; \\cdots &amp; 0 \\end{bmatrix}\\] You’ll see this in the context of singular value decomposition. $a_{ii}$ can be zero. ",
    "url": "/docs/linalg/basics/diagonal.html#rectangular-diagonal-matrix",
    
    "relUrl": "/docs/linalg/basics/diagonal.html#rectangular-diagonal-matrix"
  },"427": {
    "doc": "Differential Vector Calculus",
    "title": "Differential Vector Calculus (Matrix Calculus)",
    "content": "All derivatives here are expressed in numerator layout or Jacobian formulation. | Gradient of a Function | Chain Rule as Matrix Multiplication | Vector Fields . | Partial Derivative of a Vector Field | . | Jacobian (Gradient of a Vector Field) | Gradient of Matrices . | With Respect to a Vector | With Respect to a Matrix | . | Some Rules of Differentiation | . ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#differential-vector-calculus-matrix-calculus",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#differential-vector-calculus-matrix-calculus"
  },"428": {
    "doc": "Differential Vector Calculus",
    "title": "Gradient of a Function",
    "content": "Let $f: \\mathbb{R}^n \\rightarrow \\mathbb{R},\\, \\boldsymbol{x} \\mapsto f(\\boldsymbol{x})$ be a function. The gradient of $f$ is the row vector of first-order partial derivatives of $f$ with respect to vector $\\boldsymbol{x}$: . $$ \\nabla_\\boldsymbol{x} f = \\mathrm{grad} f = \\frac{d f}{d \\boldsymbol{x}} = \\left[ \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_1} \\dots \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_n} \\right] $$ . ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#gradient-of-a-function",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#gradient-of-a-function"
  },"429": {
    "doc": "Differential Vector Calculus",
    "title": "Chain Rule as Matrix Multiplication",
    "content": "Let $f: \\mathbb{R}^n \\rightarrow \\mathbb{R},\\, \\boldsymbol{x} \\mapsto f(\\boldsymbol{x})$ . Let $x_i(t)$ be a function of $t$. The gradient of $f$ with respect to $t$ can be expressed as: . $$ \\frac{d f}{d t} = \\left[ \\frac{\\partial f}{\\partial x_1} \\dots \\frac{\\partial f}{\\partial x_n} \\right] \\begin{bmatrix} \\frac{\\partial x_1}{\\partial t} \\\\ \\vdots \\\\ \\frac{\\partial x_n}{\\partial t} \\end{bmatrix} $$ . If $x_i$ was a multivariate function of, say $t$ and $s$, then the gradient of $f$ with respect to $t$ and $s$ can be expressed as: . \\[\\frac{d f}{d (t, s)} = \\frac{\\partial f}{\\partial \\boldsymbol{x}} \\frac{\\partial \\boldsymbol{x}}{\\partial (t, s)} = \\left[ \\frac{\\partial f}{\\partial x_1} \\dots \\frac{\\partial f}{\\partial x_n} \\right] \\begin{bmatrix} \\frac{\\partial x_1}{\\partial t} &amp; \\frac{\\partial x_1}{\\partial s} \\\\ \\vdots &amp; \\vdots \\\\ \\frac{\\partial x_n}{\\partial t} &amp; \\frac{\\partial x_n}{\\partial s} \\end{bmatrix}\\] . ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#chain-rule-as-matrix-multiplication",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#chain-rule-as-matrix-multiplication"
  },"430": {
    "doc": "Differential Vector Calculus",
    "title": "Vector Fields",
    "content": "A vector field on $n$-dimensional space is a function that assigns a vector to each point in the space. So vector fields are vector-valued functions of the form: . $$ \\begin{gather*} \\boldsymbol{f}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m,\\, \\boldsymbol{x} \\mapsto \\boldsymbol{f}(\\boldsymbol{x})\\\\[1em] \\boldsymbol{f}(\\boldsymbol{x}) = \\begin{bmatrix} f_1(\\boldsymbol{x}) \\\\ \\vdots \\\\ f_m(\\boldsymbol{x}) \\end{bmatrix} \\end{gather*} $$ . where $n \\geq 1$ and $m &gt; 1$, and each $f_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}$. ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#vector-fields",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#vector-fields"
  },"431": {
    "doc": "Differential Vector Calculus",
    "title": "Partial Derivative of a Vector Field",
    "content": "The partial derivative of a vector field $\\boldsymbol{f}$ is a column vector: . \\[\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}_i} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_i} \\\\ \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_i} \\end{bmatrix}\\] . ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#partial-derivative-of-a-vector-field",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#partial-derivative-of-a-vector-field"
  },"432": {
    "doc": "Differential Vector Calculus",
    "title": "Jacobian (Gradient of a Vector Field)",
    "content": "The Jacobian of a vector field $\\boldsymbol{f}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is the gradient of $\\boldsymbol{f}$, a $m \\times n$ matrix: . $$ \\boldsymbol{J} = \\nabla_\\boldsymbol{x} \\boldsymbol{f} = \\frac{d \\boldsymbol{f}}{d \\boldsymbol{x}} = \\left[ \\frac{\\partial \\boldsymbol{f}}{\\partial x_1} \\dots \\frac{\\partial \\boldsymbol{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} &amp; \\dots &amp; \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} &amp; \\dots &amp; \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} $$ . Let $\\boldsymbol{f}(\\boldsymbol{x}) = \\boldsymbol{A} \\boldsymbol{x}$, where $\\boldsymbol{A}$ is a $m \\times n$ matrix. Then the Jacobian of $\\boldsymbol{f}$ is: . $$ \\frac{d \\boldsymbol{f}}{d \\boldsymbol{x}} = \\boldsymbol{A} $$ . Which is intuitively similar to the derivative of a univariate function. $$ \\frac{d \\boldsymbol{f}}{d \\boldsymbol{x}} \\neq \\frac{d \\boldsymbol{A}}{d \\boldsymbol{x}} $$ . ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#jacobian-gradient-of-a-vector-field",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#jacobian-gradient-of-a-vector-field"
  },"433": {
    "doc": "Differential Vector Calculus",
    "title": "Gradient of Matrices",
    "content": " ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#gradient-of-matrices",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#gradient-of-matrices"
  },"434": {
    "doc": "Differential Vector Calculus",
    "title": "With Respect to a Vector",
    "content": "Say we have a matrix $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$, the gradient of $\\boldsymbol{A}$ with respect to $\\boldsymbol{x} \\in \\mathbb{R}^p$ . \\[\\frac{d \\boldsymbol{A}}{d \\boldsymbol{x}}\\] Has $p$ partial derivatives, each of which is a $m \\times n$ matrix: . \\[\\frac{\\partial \\boldsymbol{A}}{\\partial x_i} \\in \\mathbb{R}^{m \\times n} \\quad \\text{for } i = 1, \\dots, p\\] Therefore, the gradient of $\\boldsymbol{A}$ with respect to $\\boldsymbol{x}$ is a $m \\times n \\boldsymbol{\\times} \\boldsymbol{p}$ tensor. Tensor Flattening This 3D tensor is hard to express as a matrix. However, we can flatten it into e.g. $\\boldsymbol{mp} \\times n$ matrix, which is valid as there is an isomorphism between $\\mathbb{R}^{m \\times n \\times p}$ and $\\mathbb{R}^{mp \\times n}$. ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#with-respect-to-a-vector",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#with-respect-to-a-vector"
  },"435": {
    "doc": "Differential Vector Calculus",
    "title": "With Respect to a Matrix",
    "content": "The idea is similar to the previous section. If we have a matrix $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$ and matrix $\\boldsymbol{B} \\in \\mathbb{R}^{p \\times q}$, the gradient of $\\boldsymbol{A}$ with respect to $\\boldsymbol{B}$ would have the shape . \\[\\frac{d \\boldsymbol{A}}{d \\boldsymbol{B}} \\in \\mathbb{R}^{m \\times n \\times p \\times q}\\] Which can, of course, be reshaped into e.g. $\\boldsymbol{mn} \\times \\boldsymbol{pq}$ matrix. ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#with-respect-to-a-matrix",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#with-respect-to-a-matrix"
  },"436": {
    "doc": "Differential Vector Calculus",
    "title": "Some Rules of Differentiation",
    "content": "Again, all derivatives here are expressed in numerator layout. To get the denominator layout, simply transpose the result. Assuming $\\boldsymbol{A}$ is not a function of $\\boldsymbol{x}$. \\[\\begin{align*} &amp;\\frac{\\partial}{\\partial \\boldsymbol{x}} \\boldsymbol{A} \\boldsymbol{x} = \\boldsymbol{A} \\\\[1em] &amp;\\frac{\\partial}{\\partial \\boldsymbol{x}} \\boldsymbol{x}^\\top \\boldsymbol{A} = \\boldsymbol{A}^\\top \\\\[1em] &amp;\\frac{\\partial}{\\partial \\boldsymbol{x}} \\boldsymbol{x}^\\top \\boldsymbol{x} = 2 \\boldsymbol{x}^\\top \\\\[1em] &amp;\\frac{\\partial}{\\partial \\boldsymbol{x}} \\boldsymbol{x}^\\top \\boldsymbol{A} \\boldsymbol{x} = \\boldsymbol{x}^\\top (\\boldsymbol{A} + \\boldsymbol{A}^\\top) \\end{align*}\\] When $\\boldsymbol{A}$ is symmetric, the last rule simplifies to: . \\[\\frac{\\partial}{\\partial \\boldsymbol{x}} \\boldsymbol{x}^\\top \\boldsymbol{A} \\boldsymbol{x} = 2 \\boldsymbol{x}^\\top \\boldsymbol{A}\\] ",
    "url": "/docs/linalg/basics/differential-vector-calc.html#some-rules-of-differentiation",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html#some-rules-of-differentiation"
  },"437": {
    "doc": "Differential Vector Calculus",
    "title": "Differential Vector Calculus",
    "content": " ",
    "url": "/docs/linalg/basics/differential-vector-calc.html",
    
    "relUrl": "/docs/linalg/basics/differential-vector-calc.html"
  },"438": {
    "doc": "Discriminant Analysis",
    "title": "Discriminant Analysis",
    "content": "One approach to classification was logistic regression. Another approach is discriminant analysis. | Difference from Logistic Regression | Recap: Bayes’ Theorem | Assumptions About the Likelihood . | Single Feature . | Additional Assumptions about the Variance | . | Multivariate . | Again, Additional Assumptions | . | . | Estimating the Prior | Obtaining the Posterior | Linear and Quadratic DA | Linear Discriminant Analysis (LDA) . | Discriminant Function (Discriminant Score) of LDA | Single Feature Discriminant Function | Multivariate Discriminant Function | Discrimant Functions to Probabilities | Discriminant Functions to Decision Boundaries | . | Other Discriminant Analysis Methods | . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html"
  },"439": {
    "doc": "Discriminant Analysis",
    "title": "Difference from Logistic Regression",
    "content": "Logistic regression: . | Does not assume any distribution for the features $X$. | Is unstable when classes are well-separated. | Harder to visualize for multinomial classification. | . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#difference-from-logistic-regression",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#difference-from-logistic-regression"
  },"440": {
    "doc": "Discriminant Analysis",
    "title": "Distribution of Features",
    "content": "While logistic regression does not assume any distribution, discriminant analysis assumes some distribution for the features. Most commonly, normal distribution. ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#distribution-of-features",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#distribution-of-features"
  },"441": {
    "doc": "Discriminant Analysis",
    "title": "Well-Separated Classes",
    "content": "When classes are well-separated, logistic regression does not converge. The general idea is expressed in the following figure: . We see that there is no overlap between the two classes. It is hard to determine which line is the best fit, which makes the model unstable. Discriminant analysis benefits from well-separated classes. In reality, classes are rarely well-separated. So logistic regression is still relevant to most problems. ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#well-separated-classes",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#well-separated-classes"
  },"442": {
    "doc": "Discriminant Analysis",
    "title": "Recap: Bayes’ Theorem",
    "content": "Classification aims to find the posterior: . $$ p_k(x) = P(Y = k \\mid X = x) = \\frac{P(X = x \\mid Y = k) P(Y = k)} {\\sum P(X = x \\mid Y = l) P(Y = l)} $$ . Notice that the marginal $P(X = x)$ is independent of the class $k$. Remembering that optimal classfication is achieved by selecting the $k$ that maximizes the posterior, we can dismiss the denominator during our optimization (you would need it if you wanted the actual probability). The product of the likelihood and prior ultimately determines the class of $X$, which gives us a convenient way to derive the discriminant score. So now we need to find the likelihood and prior in the numerator. ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#recap-bayes-theorem",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#recap-bayes-theorem"
  },"443": {
    "doc": "Discriminant Analysis",
    "title": "Assumptions About the Likelihood",
    "content": "We usually denote the likelihood in each class as $f_k(x)$. Discriminant analysis assumes some distribution for $X$ in a singe class $k$ (likelihood), which is usually a normal distribution (which results in LDA, QDA). ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#assumptions-about-the-likelihood",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#assumptions-about-the-likelihood"
  },"444": {
    "doc": "Discriminant Analysis",
    "title": "Single Feature",
    "content": "With a single feature $x$, the assumption is: . \\[X \\mid Y = k \\sim N(\\mu_k, \\sigma_k^2)\\] Then the likelihood is just the density function of the normal distribution: . $$ f_k(x) = P(X = x \\mid Y = k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left(-\\frac{(x - \\mu_k)^2}{2\\sigma_k^2}\\right) $$ . We can estimate this likelihood from the training data with sample mean and variance of the features in each class: . \\[\\hat{\\mu}_k = \\frac{1}{n_k} \\sum_{i:y_i=k} x_i \\quad\\quad \\hat{\\sigma}^2_k = \\frac{1}{n_k - 1} \\sum_{i:y_i=k} (x_i - \\hat{\\mu}_k)^2\\] Additional Assumptions about the Variance . Another assumption that can be made is that the variance of the features is the same for all classes: . $$ \\sigma_k^2 = \\sigma^2 $$ . If you assume shared variance, we have a linear discriminant analysis (LDA). If you do not, you have a quadratic discriminant analysis (QDA). In LDA, our sample variance $\\hat{\\sigma}^2$ will be the pooled variance: . $$ \\hat{\\sigma}^2 = \\frac{1}{n - K} \\sum_{k=1}^K \\sum_{i:y_i=k} (x_i - \\hat{\\mu}_k)^2 $$ . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#single-feature",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#single-feature"
  },"445": {
    "doc": "Discriminant Analysis",
    "title": "Multivariate",
    "content": "With multiple features $X = (X_1, \\dots, X_p)$, the assumption is that it follows a multivariate normal distribution: . \\[X \\mid Y = k \\sim N(\\mu_k, \\Sigma_k)\\] Then the likelihood is the density function of the multivariate normal distribution: . $$ f_k(x) = \\frac{1}{\\sqrt{(2\\pi)^p \\det(\\Sigma_k)}} \\exp\\left(-\\frac{1}{2} (x - \\mu_k)^\\top \\Sigma_k^{-1} (x - \\mu_k)\\right) $$ . Again, Additional Assumptions . Just like in the single feature case, you can assume that the covariance matrix is the same for all classes: . $$ \\Sigma_k = \\Sigma $$ . Assuming this would result in LDA, while not assuming it would result in QDA. Pooled Covariance For multivariate normal distribution, we would estimate the covariance matrix $\\Sigma$ using the pooled covariance: . \\[\\hat{\\Sigma} = \\frac{1}{n - K} \\sum_{k=1}^K \\sum_{i:y_i=k} (x_i - \\hat{\\mu}_k)(x_i - \\hat{\\mu}_k)^\\top\\] . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#multivariate",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#multivariate"
  },"446": {
    "doc": "Discriminant Analysis",
    "title": "Estimating the Prior",
    "content": "We usually denote the prior of a class as $\\pi_k$. The prior of each class can also be estimated by the proportion of each class in the training data: . \\[\\hat{\\pi}_k = \\frac{n_k}{n} \\approx P(Y = k)\\] . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#estimating-the-prior",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#estimating-the-prior"
  },"447": {
    "doc": "Discriminant Analysis",
    "title": "Obtaining the Posterior",
    "content": "So we obtain the posterior by plugging these estimates into Bayes’ theorem. We usually rewrite the posterior as: . $$ P(Y = k \\mid X = x) = \\frac{\\pi_k f_k(x)} {\\sum_{l=1}^{K} \\pi_l f_l(x)} $$ . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#obtaining-the-posterior",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#obtaining-the-posterior"
  },"448": {
    "doc": "Discriminant Analysis",
    "title": "Linear and Quadratic DA",
    "content": "They both assume normal distribution for the features in each class. Already mentioned above, but to recap: . The main difference between linear and quadratic discriminant analysis lies in the assumption about the variance of features in each class. If we assume that the variance is the same for all classes: . $$ \\sigma_k^2 = \\sigma^2 \\quad\\quad \\Sigma_k = \\Sigma $$ . the discriminant analysis becomes a linear classifier. If we do not make this assumption, the discriminant analysis becomes a quadratic classifier. ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#linear-and-quadratic-da",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#linear-and-quadratic-da"
  },"449": {
    "doc": "Discriminant Analysis",
    "title": "Linear Discriminant Analysis (LDA)",
    "content": "We first start our estimate of the likelihood by assuming data in each class are normally distributed and have the same variance. Plugging in the normal density function into the posterior would result in a super messy equation. ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#linear-discriminant-analysis-lda",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#linear-discriminant-analysis-lda"
  },"450": {
    "doc": "Discriminant Analysis",
    "title": "Discriminant Function (Discriminant Score) of LDA",
    "content": "If you wanted the actual probability of $X$ being in class $k$, you’d have to calculate the denominator. But as we mentioned above, the marginal is independent of the class $k$. If all you want is the class label of $X$ with the highest probability, you can ignore the denominator and try to maximize the numerator: . $$ p_k(x) \\propto \\pi_k f_k(x) $$ . In addition, since log is a monotonic function, you can maximize the log of it instead: . \\[\\log(\\pi_k) + \\log f_k(x)\\] ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#discriminant-function-discriminant-score-of-lda",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#discriminant-function-discriminant-score-of-lda"
  },"451": {
    "doc": "Discriminant Analysis",
    "title": "Single Feature Discriminant Function",
    "content": "Fully expand the $\\log$ and get rid of all the terms that are not dependent on $k$ to get the discriminant function of LDA: . $$ \\delta_k(x) = x \\cdot \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + \\log(\\pi_k) $$ . Notice how the discriminant function is linear in $x$. If you did not assume $\\sigma_k = \\sigma$, you would have a quadratic discriminant function. Then $x$ is assigned to the class $k$ that maximizes the discriminant score: . $$ k^\\ast = \\arg\\max_k \\delta_k(x) $$ . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#single-feature-discriminant-function",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#single-feature-discriminant-function"
  },"452": {
    "doc": "Discriminant Analysis",
    "title": "Multivariate Discriminant Function",
    "content": "\\[p_k(x) \\propto \\log(\\pi_k) -\\frac{1}{2} (x - \\mu_k)^\\top \\Sigma^{-1} (x - \\mu_k)\\] Fully expand the right side and get rid of all the terms that do not depend on $k$ to get the discriminant function of LDA: . $$ \\delta_k(x) = x^\\top \\Sigma^{-1} \\mu_k - \\frac{1}{2} \\mu_k^\\top \\Sigma^{-1} \\mu_k + \\log(\\pi_k) $$ . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#multivariate-discriminant-function",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#multivariate-discriminant-function"
  },"453": {
    "doc": "Discriminant Analysis",
    "title": "Discrimant Functions to Probabilities",
    "content": "Discriminant scores can be converted to probabilities via the softmax function: . $$ P(Y = k \\mid X = x) = \\frac{\\exp(\\delta_k(x))}{\\sum_{l=1}^{K} \\exp(\\delta_l(x))} $$ . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#discrimant-functions-to-probabilities",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#discrimant-functions-to-probabilities"
  },"454": {
    "doc": "Discriminant Analysis",
    "title": "Discriminant Functions to Decision Boundaries",
    "content": "For graphing purposes, we could find the decision boundary between two classes $i$ and $j$. The decision boundary is the set of points $\\boldsymbol{x}$ where the discriminant scores are equal: . $$ \\delta_i(\\boldsymbol{x}) = \\delta_j(\\boldsymbol{x}) $$ . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#discriminant-functions-to-decision-boundaries",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#discriminant-functions-to-decision-boundaries"
  },"455": {
    "doc": "Discriminant Analysis",
    "title": "Other Discriminant Analysis Methods",
    "content": ". | Quadratic Discriminant Analysis (QDA): . | Relax the assumption $\\Sigma_k = \\Sigma$ from LDA. | . | Naive Bayes: . | Assume that features are conditionally independent given the class. | . \\[f_k(x) = \\prod_{j=1}^{p} f_{kj}(x_j)\\] . | Useful when the number of features $p$ is large. | Can be used for mixed feature types (quantitative and qualitative). | . | . ",
    "url": "/docs/data-science/ml-dl/discriminant-analysis.html#other-discriminant-analysis-methods",
    
    "relUrl": "/docs/data-science/ml-dl/discriminant-analysis.html#other-discriminant-analysis-methods"
  },"456": {
    "doc": "Dockerized Jenkins",
    "title": "Dockerized Jenkins",
    "content": ". | Docker Installation . | Disble built-in node executors on initialization | . | Configure Docker node . | TLS credentials for Docker | Configure Docker . | Docker Host URI | Server credentials | Enabled | . | Configure Docker Agent . | Label, Name | Docker Image | Remote File System Root | Usage | Connect method | . | . | Use Docker agent in jobs | . ",
    "url": "/docs/jenkins/docker.html",
    
    "relUrl": "/docs/jenkins/docker.html"
  },"457": {
    "doc": "Dockerized Jenkins",
    "title": "Docker Installation",
    "content": "Consider using docker-compose to manage the containers. It makes your life easier. Official Documentation . The details are well documented in the link above. The above documentation describes the need for two containers, one is a DinD (Docker in Docker) container and the other is the master Jenkins container. The DinD container is used to enable Docker in the Jenkins container. This is accomplished by placing both containers in the same network and exposing the DinD TLS port (2376). It is recommended to map both volumes jenkins-docker-certs and jenkins-data to the host filesystem to persist the data between container restarts. For the Jenkins container, the documentation recommends two ports to be exposed: 8080 for the web UI and 50000 for the slave agent. However, if you are planning to use SSH agents you do not need to expose the 50000 port. Disble built-in node executors on initialization . This is a recommendation described in the Github documentation. Because you generally want to use agents to run your builds, it is advised to set number of executors in the built-in node to zero. You can do so by creating executors.groovy, . // executors.groovy import jenkins.model.* Jenkins.instance.setNumExecutors(0) . And a Dockerfile extending the jenkins/jenkins image, . # Dockerfile FROM jenkins/jenkins:lts-jdk11 COPY --chown=jenkins:jenkins executors.groovy /usr/share/jenkins/ref/init.groovy.d/executors.groovy . This Dockerfile can be further extended to initialize plugins and configure Jenkins. ",
    "url": "/docs/jenkins/docker.html#docker-installation",
    
    "relUrl": "/docs/jenkins/docker.html#docker-installation"
  },"458": {
    "doc": "Dockerized Jenkins",
    "title": "Configure Docker node",
    "content": "TLS credentials for Docker . First navigate to Manage Jenkins &gt; Manage Credentials, . Then create a global-scope credential of type X.509 Certificate. This is the TLS certificate used by the DinD container to authenticate with the Jenkins container. Assuming the name of the DinD container is jenkins-docker, you can get the required values by, . # Client Key docker exec jenkins-docker cat /certs/key.pem | pbcopy # Client Certificate docker exec jenkins-docker cat /certs/cert.pem | pbcopy # Server CA Certificate docker exec jenkins-docker cat /certs/ca.pem | pbcopy . It is useful to set the credential ID to something you can recognize, like docker-tls. Configure Docker . Now navigate to Manage Jenkins &gt; Manage Nodes and Clouds &gt; Configure Clouds, . Then create a new cloud of type Docker, . Docker Host URI . tcp://docker:2376 or leave blank if you’ve already set the DOCKER_HOST environment variable. Server credentials . Select the credential you created above, i.e. docker-tls. Enabled . Make sure it is checked. Configure Docker Agent . Then add an agent with Docker Agent Template, . Label, Name . Set Label to something you can recognize because it will be used in your pipeline, i.e. test-agent . Just give it a matching name. Docker Image . You need to have a Docker image pushed to a remote repository for this option, or prepare local image beforehand. Image can be from a public or private repository, but if you’re using a private one, remeber to generate an access token from Docker Hub and add it to Jenkins via Registry Authentication. The Docker image should be based on the functionalities of either jenkins/agent or jenkins/ssh-agent image. The former uses JNLP for connection to agents, while the latter uses SSH. Enter the image name and tag. Remote File System Root . Set it to /home/jenkins. Usage . I prefer Only build jobs with label expressions matching this node because you can specify types of jobs to run on this agent in the pipeline configuration. Connect method . This depends on the Docker image you configured above. If your image is Jenkins agent executable/JNLP based, select Connect with JNLP. If your image is SSH based, select Connect with SSH. Following example is for SSH agents. ",
    "url": "/docs/jenkins/docker.html#configure-docker-node",
    
    "relUrl": "/docs/jenkins/docker.html#configure-docker-node"
  },"459": {
    "doc": "Dockerized Jenkins",
    "title": "Use Docker agent in jobs",
    "content": "Create a new FreeStyle project for testing purposes. In General, set the following to a label you configured above. References: . | Jenkins Docker GitHub Documentation | . ",
    "url": "/docs/jenkins/docker.html#use-docker-agent-in-jobs",
    
    "relUrl": "/docs/jenkins/docker.html#use-docker-agent-in-jobs"
  },"460": {
    "doc": "DynamoDB",
    "title": "DynamoDB",
    "content": ". | Local Setup | NoSQL Workbench for DynamoDB | Key design / Data model . | Primary Key | Design | . | Itty Bitties | . ",
    "url": "/docs/aws/dynamodb.html",
    
    "relUrl": "/docs/aws/dynamodb.html"
  },"461": {
    "doc": "DynamoDB",
    "title": "Local Setup",
    "content": "Detailed documentation is provided here. Docker option is available as well. ",
    "url": "/docs/aws/dynamodb.html#local-setup",
    
    "relUrl": "/docs/aws/dynamodb.html#local-setup"
  },"462": {
    "doc": "DynamoDB",
    "title": "NoSQL Workbench for DynamoDB",
    "content": "This will be a great lifesaver while designing data models and testing connection. You can download it here. ",
    "url": "/docs/aws/dynamodb.html#nosql-workbench-for-dynamodb",
    
    "relUrl": "/docs/aws/dynamodb.html#nosql-workbench-for-dynamodb"
  },"463": {
    "doc": "DynamoDB",
    "title": "Key design / Data model",
    "content": "If you are used to relational database schemas, it is easy to end up designing your database to use multiple tables, to structure logical joins using foreign key-like attribute and what not, or to use multi-level nested structure. However, in NoSQL, all these familiar patterns are not only inefficient, but also almost impossible to manage. There really is no such thing as a schema design in DynamoDB but a careful design of primary key is useful. Primary Key . There are two types of keys that can consist a primary key in DynamoDB: partition (hash) key and sort (range) key. A primary key could just consist of a partition key or be a compound of partition and sort key. Because each item is identified by a unique primary key, you must use a unique partition key if your primary key only consists of it. However, if you also use the sort key, the partition key may overlap but the sort key must be unique. Partition key and sort key are also called hash and range keys. The naming indicates that the partition key serves as a hashed index to a physical storage internal unit called a partition. The sort key sorts the items within a partition into groups of similar items, effectively providing an efficient way to query for a range. Hence, design of primary key has an impact on the performance of the DB. Design . In relational databases, primary keys are usually a single attribute (like StudentID) of a homogeneous type. However, in DynamoDB it is common to use a multi-purpose (or heterogeneous) key attributes. Typically, every item is given an attribute called PK and SK for partition and sort key. This way the key attributes may contain any information without restriction. ",
    "url": "/docs/aws/dynamodb.html#key-design--data-model",
    
    "relUrl": "/docs/aws/dynamodb.html#key-design--data-model"
  },"464": {
    "doc": "DynamoDB",
    "title": "Itty Bitties",
    "content": ". | Compared to SQL statements, querying in DynamoDB can be a real pain in the ass… | . ",
    "url": "/docs/aws/dynamodb.html#itty-bitties",
    
    "relUrl": "/docs/aws/dynamodb.html#itty-bitties"
  },"465": {
    "doc": "ECR",
    "title": "AWS Elatic Container Registry",
    "content": ". | Pushing image to ECR . | Authenticate Docker | Build or tag image | Push image | . | . ",
    "url": "/docs/aws/ecr.html#aws-elatic-container-registry",
    
    "relUrl": "/docs/aws/ecr.html#aws-elatic-container-registry"
  },"466": {
    "doc": "ECR",
    "title": "Pushing image to ECR",
    "content": "Authenticate Docker . First you must authenticate Docker to push to your ECR registry. You must first configure AWS CLI with your credentials. aws ecr get-login-password --profile ${profile} | docker login --username AWS --password-stdin ${account_id}.dkr.ecr.${region}.amazonaws.com . &lt;account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com is the URI of your ECR registry. Authentication is only valid for 12 hours. Build or tag image . Your image must have a tag that matches the URI of your ECR registry. docker build -t ${account_id}.dkr.ecr.${region}.amazonaws.com/${repo_name}:${tag} . -f Dockerfile # OR docker tag ${image_id} ${account_id}.dkr.ecr.${region}.amazonaws.com/${repo_name}:${tag} . Push image . docker push ${account_id}.dkr.ecr.${region}.amazonaws.com/${repo_name}:${tag} . References: . | AWS ECR: Pushing a Docker image | . ",
    "url": "/docs/aws/ecr.html#pushing-image-to-ecr",
    
    "relUrl": "/docs/aws/ecr.html#pushing-image-to-ecr"
  },"467": {
    "doc": "ECR",
    "title": "ECR",
    "content": " ",
    "url": "/docs/aws/ecr.html",
    
    "relUrl": "/docs/aws/ecr.html"
  },"468": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Eigenvalues / Eigenvectors",
    "content": ". | Characteristic Polynomial . | Roots of the Characteristic Polynomial | . | Eigenvalues and Eigenvector . | Finding Eigenvalues via Characteristic Polynomial . | Eigenvectors and the Kernel | Rank of $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ | Determinant of $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ | Solving the Characteristic Polynomial | . | Eigenvalues of a Transpose | . | Defective Matrix . | Linear Independence of Eigenvectors | . | Diagonalizable Matrix (Non-Defective Matrix) . | Eigen-Decomposition | Determinant of a Matrix Using Eigenvalues | Trace of a Matrix Using Eigenvalues | Spectral Theorem | . | Eigenspace . | Geometric Multiplicity | . | . ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html"
  },"469": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Characteristic Polynomial",
    "content": "For $\\lambda \\in \\mathbb{R}$ and square matrix $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$, . Remeber $\\lambda$ is a variable here. The characteristic polynomial of $\\boldsymbol{A}$ is: . $$ \\begin{align*} \\label{eq:characteristic-polynomial} p_{\\boldsymbol{A}}(\\lambda) &amp;= \\det(\\boldsymbol{A} - \\lambda \\boldsymbol{I}) \\\\[1em] &amp;= (-1)^n \\lambda^n + c_{n-1} \\lambda^{n-1} + \\cdots + c_1 \\lambda + c_0 \\\\[1em] &amp;= (-1)^n \\lambda^n + (-1)^{n-1} \\tr(\\boldsymbol{A}) \\lambda^{n-1} + \\cdots + (-1)^0 \\det(\\boldsymbol{A}) \\end{align*} $$ . where $c_i \\in \\mathbb{R}$. Sometimes it is defined like... \\[p_{\\boldsymbol{A}}(\\lambda) = \\det(\\lambda \\boldsymbol{I} - \\boldsymbol{A})\\] The only difference is that this version guarantees the leading coefficient is positive, or monic: . \\[p_{\\boldsymbol{A}}(\\lambda) = \\lambda^n + c_{n-1} \\lambda^{n-1} + \\cdots + c_1 \\lambda + c_0\\] Unlike the $(-1)^n$ above. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#characteristic-polynomial",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#characteristic-polynomial"
  },"470": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Roots of the Characteristic Polynomial",
    "content": "This is literally the roots $\\lambda$ you get from solving the above polynomial equation: . $$ p_{\\boldsymbol{A}}(\\lambda) = 0 $$ . Also called eigenvalues of $\\boldsymbol{A}$. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#roots-of-the-characteristic-polynomial",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#roots-of-the-characteristic-polynomial"
  },"471": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Eigenvalues and Eigenvector",
    "content": "Let $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$. For the eigenvalue equation: . $$ \\boldsymbol{A} \\boldsymbol{x} = \\lambda \\boldsymbol{x} $$ . The satisfying non-zero vector $\\boldsymbol{x} \\in \\mathbb{R}^n \\setminus \\{\\boldsymbol{0}\\}$ and corresponding scalar $\\lambda \\in \\mathbb{R}$ are called eigenvectors and eigenvalues of $\\boldsymbol{A}$, respectively. Intuition Intuitively, it means that for some linear transformation represented by $\\boldsymbol{A}$, there is a vector that is unchanging in any other way except for the magnitude and maybe reversed direction (if $\\lambda &lt; 0$). In other words, this transformation $\\boldsymbol{A}$ can only scale the eigenvectors by its eigenvalues. Some like to order the eigenvalues in descending order, and call them first, second, etc. eigenvalues. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigenvalues-and-eigenvector",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigenvalues-and-eigenvector"
  },"472": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Finding Eigenvalues via Characteristic Polynomial",
    "content": "Eigenvectors and the Kernel . The above equation can be rewritten as: . $$ (\\boldsymbol{A} - \\lambda \\boldsymbol{I}) \\boldsymbol{x} = \\boldsymbol{0} $$ . or equivalently: . \\[(\\lambda \\boldsymbol{I} - \\boldsymbol{A}) \\boldsymbol{x} = \\boldsymbol{0}\\] With this homogenous system, we see that the non-trivial solution $\\boldsymbol{x}$ (or eigenvectors) are in the kernel of the matrix $(\\boldsymbol{A} - \\lambda \\boldsymbol{I})$: . $$ \\boldsymbol{x} \\in \\ker(\\boldsymbol{A} - \\lambda \\boldsymbol{I}) $$ . Rank of $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ . We saw that the eigenvector is a non-trivial element of the kernel. Which means that the columns of $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ are linearly dependent (they can zero themselves out by a linear combination). Therefore, $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ cannot be full rank: . $$ \\rank(\\boldsymbol{A} - \\lambda \\boldsymbol{I}) &lt; n $$ . Determinant of $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ . From here, we know that the determinant of the matrix is non-zero if and only if the matrix is full rank. Matrix is invertible only when columns are linearly independent, but since it is not, determinant should be zero for the inverse to be undefined. However, we just saw that $\\boldsymbol{A} - \\lambda \\boldsymbol{I}$ cannot be full rank. Hence: . $$ \\det(\\boldsymbol{A} - \\lambda \\boldsymbol{I}) = 0 $$ . Solving the Characteristic Polynomial . Because we know . \\[\\det(\\boldsymbol{A} - \\lambda \\boldsymbol{I}) = 0\\] we can use the characteristic polynomial to find the eigenvalues $\\lambda$. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#finding-eigenvalues-via-characteristic-polynomial",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#finding-eigenvalues-via-characteristic-polynomial"
  },"473": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Eigenvalues of a Transpose",
    "content": "$\\boldsymbol{A}^T$ and $\\boldsymbol{A}$ have the same eigenvalues. However, the eigenvectors are not necessarily the same. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigenvalues-of-a-transpose",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigenvalues-of-a-transpose"
  },"474": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Defective Matrix",
    "content": "A square matrix $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ is defective if it does not have $n$ linearly independent eigenvectors. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#defective-matrix",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#defective-matrix"
  },"475": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Linear Independence of Eigenvectors",
    "content": "Eigenvectors corresponding to distinct eigenvalues are linearly independent. Therefore, eigenvectors with $n$ distinct eigenvalues form a basis of $\\mathbb{R}^n$. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#linear-independence-of-eigenvectors",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#linear-independence-of-eigenvectors"
  },"476": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Diagonalizable Matrix (Non-Defective Matrix)",
    "content": "We say that a matrix $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ is diagonalizable (or non-defective) if it is similar to a diagonal matrix $\\boldsymbol{D}$. It is saying that we can make $\\boldsymbol{A}$ into a diagonal matrix by changing its basis. In other words, there exists an invertible matrix $\\boldsymbol{P}$ such that: . \\[\\boldsymbol{D} = \\boldsymbol{P}^{-1} \\boldsymbol{A} \\boldsymbol{P}\\] This can be rewritten as: . \\[\\boldsymbol{A} = \\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^{-1}\\] ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#diagonalizable-matrix-non-defective-matrix",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#diagonalizable-matrix-non-defective-matrix"
  },"477": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Eigen-Decomposition",
    "content": "Any non-defective matrix $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ can be decomposed into: . $$ \\boldsymbol{A} = \\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^{-1} $$ . where $\\boldsymbol{P}$ is a matrix whose columns are the eigenvectors of $\\boldsymbol{A}$, and $\\boldsymbol{D}$ is a diagonal matrix whose diagonal elements are the eigenvalues of $\\boldsymbol{A}$. What? If you rewrite the above equation as: . \\[\\boldsymbol{A} \\boldsymbol{P} = \\boldsymbol{P} \\boldsymbol{D}\\] Let’s say $\\boldsymbol{P} = [\\boldsymbol{p}_1 \\dots \\boldsymbol{p}_n]$, then: . \\[\\boldsymbol{A} \\boldsymbol{P} = [\\boldsymbol{A} \\boldsymbol{p}_1 \\dots \\boldsymbol{A} \\boldsymbol{p}_n]\\] Keeping in mind that $D$ is a diagonal matrix, let the principal diagonal elements be $c_1, \\dots, c_n$, then: . \\[\\boldsymbol{P} \\boldsymbol{D} = [c_1 \\boldsymbol{p}_1 \\dots c_n \\boldsymbol{p}_n]\\] Since $\\boldsymbol{A} \\boldsymbol{p}_i = c_i \\boldsymbol{p}_i$, . We see that each $\\boldsymbol{p}_i$ is an eigenvector of $\\boldsymbol{A}$, and $c_i$ is the corresponding eigenvalue. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigen-decomposition",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigen-decomposition"
  },"478": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Determinant of a Matrix Using Eigenvalues",
    "content": "What follows is a quick way to calculate the determinant of a matrix usig its eigenvalues. A property of the determinant is that it is invariant under change of basis. So for similar matrices $\\boldsymbol{A}$ and $\\boldsymbol{D}$, their determinants are the same, but it is easy to calculate the determinant of a diagonal matrix $\\boldsymbol{D}$, since it is just the product of its diagonal elements which are the eigenvalues of $\\boldsymbol{A}$. Therefore the determinant of a matrix is the product of its eigenvalues: . $$ \\det(\\boldsymbol{A}) = \\prod_{i=1}^n \\lambda_i $$ . $\\lambda_i$ is not necessarily unique! It can have repeated eigenvalues. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#determinant-of-a-matrix-using-eigenvalues",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#determinant-of-a-matrix-using-eigenvalues"
  },"479": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Trace of a Matrix Using Eigenvalues",
    "content": "Same logic applies to trace as it is also invariant under change of basis. The trace of $\\boldsymbol{D}$ is the sum of its diagonal elements (the eigenvalues of $\\boldsymbol{A}$). Therefore the trace of a matrix is the sum of its eigenvalues: . $$ \\tr(\\boldsymbol{A}) = \\sum_{i=1}^n \\lambda_i $$ . Again, repetition counts. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#trace-of-a-matrix-using-eigenvalues",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#trace-of-a-matrix-using-eigenvalues"
  },"480": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Spectral Theorem",
    "content": "A symmetric matrix $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ is always diagonalizable. Further, the eigenvectors of $\\boldsymbol{A}$ form an orthonormal basis: . \\[\\boldsymbol{P}^\\top \\boldsymbol{P} = \\boldsymbol{I} \\iff \\boldsymbol{P}^\\top = \\boldsymbol{P}^{-1}\\] Therefore the decomposition is: . $$ \\boldsymbol{A} = \\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^\\top $$ . ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#spectral-theorem",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#spectral-theorem"
  },"481": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Eigenspace",
    "content": "Eigenvectors are not unique, that is, any scalar multiple of an eigenvector is also an eigenvector. These eigenvectors that share the same eigenvalue span a subspace of $\\mathbb{R}^n$, called the eigenspace of $\\boldsymbol{A}$ with respect to the eigenvalue $\\lambda$ (denoted with a subscript): . $$ E_{\\lambda} = \\ker(\\boldsymbol{A} - \\lambda \\boldsymbol{I}) $$ . ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigenspace",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#eigenspace"
  },"482": {
    "doc": "Eigenvalues / Eigenvectors",
    "title": "Geometric Multiplicity",
    "content": "Let $\\lambda$ be an eigenvalue of square matrix $\\boldsymbol{A}$. Then the geometric multiplicity of $\\lambda$, is the number of linearly independent eigenvectors corresponding to $\\lambda$, or . $$ \\dim(E_{\\lambda}) $$ . Algebraic multiplicity is the multiplicity of $\\lambda$ as a root of the characteristic polynomial. For example, if a matrix had two repeated eigenvalues, then the algebraic multiplicity of that eigenvalue is 2. ",
    "url": "/docs/linalg/basics/eigenvalue-eigenvector.html#geometric-multiplicity",
    
    "relUrl": "/docs/linalg/basics/eigenvalue-eigenvector.html#geometric-multiplicity"
  },"483": {
    "doc": "Encoding Categorical Variables",
    "title": "Encoding Categorical Variables",
    "content": "Categorical or qualitative variables are often non-numeric and must be encoded to be used in learning. | One-Hot Encoding . | Dummy Variable Trap | . | Dummy Encoding . | Baseline | Interpretation of Dummy Coefficients | Testing for Significance | . | . ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html"
  },"484": {
    "doc": "Encoding Categorical Variables",
    "title": "One-Hot Encoding",
    "content": "For a qualitative variable with $k$ groups, one-hot encoding introduces $k$ new binary variables. For example, consider a variable $X$ with three groups: A, B, and C. ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html#one-hot-encoding",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html#one-hot-encoding"
  },"485": {
    "doc": "Encoding Categorical Variables",
    "title": "Dummy Variable Trap",
    "content": "There is one issue with one-hot encoding: the dummy variable trap. If you look at the encoding, you can see that the third variable is redundant: . Because we could easily infer C by the encoding of A and B alone: 00. This is a problem because now we have multicollinearity between our features. Most one-hot encoding will have a parameter to automatically drop one of the dummy variables. ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html#dummy-variable-trap",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html#dummy-variable-trap"
  },"486": {
    "doc": "Encoding Categorical Variables",
    "title": "Dummy Encoding",
    "content": "Dummy encoding introduces one less binary variable than one-hot encoding, i.e., $k-1$ new binary variables. Each dummy represents . | $A \\lor \\neg A$ | $B \\lor \\neg B$, | . and $\\neg A \\land \\neg B \\implies C$. This avoids the dummy variable trap. ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html#dummy-encoding",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html#dummy-encoding"
  },"487": {
    "doc": "Encoding Categorical Variables",
    "title": "Baseline",
    "content": "With dummy encoding, one group is chosen as the baseline (in our example, C). Say $X_1: A \\lor \\neg A$ and $X_2: B \\lor \\neg B$. In simple linear regression: . \\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon\\] When the categorial variable is $C$ ($X_1 = 0$ and $X_2 = 0$), . \\[Y = \\beta_0 + \\epsilon\\] We are left with the baseline model. ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html#baseline",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html#baseline"
  },"488": {
    "doc": "Encoding Categorical Variables",
    "title": "Interpretation of Dummy Coefficients",
    "content": "In linear regression, the coefficients $\\beta_i$ of quantitative variables are interpreted as such: . The average effect on $Y$ of a one-unit increase in $X_i$. But how do we interpret the coefficients of dummy variables? . The effect is in comparison to the baseline. So in our example above: . \\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon\\] where $X_1$ and $X_2$ are binary dummy variables for A and B, respectively: . | $\\beta_0$ is the expected $Y$ when $X_1 = 0$ and $X_2 = 0$ (C) | $\\beta_1$ is the average effect on $Y$ when $X_1 = 1$ (A) compared to C | $\\beta_2$ is the average effect on $Y$ when $X_2 = 1$ (B) compared to C | . It does not give you comparison between the effects of A and B. ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html#interpretation-of-dummy-coefficients",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html#interpretation-of-dummy-coefficients"
  },"489": {
    "doc": "Encoding Categorical Variables",
    "title": "Testing for Significance",
    "content": "After estimating $\\beta_i$, we want to test whether each group is significantly different from the baseline. Calculate the $t$-statistic for each $\\beta_i$ as such: . $$ t = \\frac{\\hat{\\beta}_i}{\\text{SE}(\\hat{\\beta}_i)} $$ . Remember that we are comparing each group to the baseline (is there a difference between A and C? B and C?). You cannot compare the significance of arbitrary $\\hat{\\beta}_i$ and $\\hat{\\beta}_j$. For this, you must do a pairwise estimation for all groups. ",
    "url": "/docs/data-science/ml-dl/encoding-categories.html#testing-for-significance",
    
    "relUrl": "/docs/data-science/ml-dl/encoding-categories.html#testing-for-significance"
  },"490": {
    "doc": "Ensemble Methods",
    "title": "Ensemble Methods",
    "content": "For $n$ independent samples $X_1, X_2, \\ldots, X_n$, where $\\Var(X_i) = \\sigma^2$, the variance of the sample mean $\\overline{X}$ is $\\sigma^2/n$. By averaging over multiple samples, we can reduce the variance of the estimator. Intuitively We have a very complex ragged line, which obviously has high variance. Averaging has the effect of smoothing out the line. Ensemble methods are learning algorithms that combine several models and then classify new data points by taking a (weighted) vote of their predictions. The idea is that the ensemble model will be more robust and accurate than any individual model. | Bootstrap Aggregation (Bagging) . | Bootstrap Sampling | Aggregating | Out-of-Bag Error | . | Random Subspace Method | Boosting | . ",
    "url": "/docs/data-science/ml-dl/ensemble.html",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html"
  },"491": {
    "doc": "Ensemble Methods",
    "title": "Bootstrap Aggregation (Bagging)",
    "content": "Bootstrap aggregation (or bagging) is a technique that improves stability by training each model on a different subset of the data. As the name suggests, it involves two steps: . ",
    "url": "/docs/data-science/ml-dl/ensemble.html#bootstrap-aggregation-bagging",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html#bootstrap-aggregation-bagging"
  },"492": {
    "doc": "Ensemble Methods",
    "title": "Bootstrap Sampling",
    "content": "See here . We generate $B$ bootstrap samples from the original data set, denoted: . $$ Z^{*b} $$ . ",
    "url": "/docs/data-science/ml-dl/ensemble.html#bootstrap-sampling",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html#bootstrap-sampling"
  },"493": {
    "doc": "Ensemble Methods",
    "title": "Aggregating",
    "content": "We train a model on each of the $B$ bootstrap samples. We denote each model trained from the $b$-th bootstrap sample as: . $$ \\hat{f}^{*b}(x) $$ . Then for an unseen data point $x$, we predict the output by averaging over all the models: . $$ \\hat{f}_{\\text{bag}}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{f}^{*b}(x) $$ . For Classification Problems The above aggregation was in the context of regression. For classification problems, we would first collect all $B$ class predictions from each model then take another majority vote over all the results. Increasing $B$ does not result in overfitting. ",
    "url": "/docs/data-science/ml-dl/ensemble.html#aggregating",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html#aggregating"
  },"494": {
    "doc": "Ensemble Methods",
    "title": "Out-of-Bag Error",
    "content": ". IlIlIIlIIIlIlll, CC BY-SA 4.0, via Wikimedia Commons During the bootstrap sampling process, for each bootstrap sample, we create another data set called the out-of-bag (OOB) set which consists of observations not included in the bootstrap sample. This OOB set becomes our validation set. ",
    "url": "/docs/data-science/ml-dl/ensemble.html#out-of-bag-error",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html#out-of-bag-error"
  },"495": {
    "doc": "Ensemble Methods",
    "title": "Random Subspace Method",
    "content": "Random subspace method is another technique in ensemble learning that reduces correlation between each base model. They are also called attribute bagging or feature bagging. The idea is almost the same as bagging, except that while bagging is a sampling on the training data, random subspace method is a sampling on the predictors. By disallowing each model to see the full set of predictors, we reduce the correlation between them, which lowers the variance of the model. ",
    "url": "/docs/data-science/ml-dl/ensemble.html#random-subspace-method",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html#random-subspace-method"
  },"496": {
    "doc": "Ensemble Methods",
    "title": "Boosting",
    "content": "To be added . See Boosted Trees . ",
    "url": "/docs/data-science/ml-dl/ensemble.html#boosting",
    
    "relUrl": "/docs/data-science/ml-dl/ensemble.html#boosting"
  },"497": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Entropy / KL Divergence / Cross Entropy",
    "content": ". | Informational value (surprise) | Entropy | KL Divergence . | Some properties . | Another way to write KL divergence | KL divergence is not symmetric | . | . | Cross Entropy | Conditional entropy . | Mutual information | . | . ",
    "url": "/docs/statistics/notes/entropy.html",
    
    "relUrl": "/docs/statistics/notes/entropy.html"
  },"498": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Informational value (surprise)",
    "content": "If a variable has a higher “surprise”, we say that it needs more information to describe it due to its uncertainty. A surprising event is one that has a low probability of occurring. Then it is clear that probability $p$ has an inverse relationship with surprise: . \\[\\text{surprise} \\propto \\log\\left(\\frac{1}{p}\\right)\\] Why the log? Intuitively, it makes sense that surprise should be infinitely large when $p = 0$. Infinitely surprised when something impossible happens. On the other hand, surprise should be $0$ when $p = 1$. However with just $\\frac{1}{p}$, we get a value of $1$ when $p = 1$. We put a $\\log$ in front so that: . \\[\\text{surprise} = \\log\\left(\\frac{1}{1}\\right) = 0\\] We can do this because $\\log$ is a monotonic function. Also $\\log$ makes math easier. Define $p_X$ as the probability function of random variable $X$. Therefore we define surprise of $x \\in X$ as: . $$ -\\log(p_X(x)) $$ . ",
    "url": "/docs/statistics/notes/entropy.html#informational-value-surprise",
    
    "relUrl": "/docs/statistics/notes/entropy.html#informational-value-surprise"
  },"499": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Entropy",
    "content": "Entropy is a measure of surprise/uncertainty in a random variable. It is actually the expected value of surprise: . $$ H(X) = E[-\\log(p_X)] = -\\sum_{x \\in X} p_X(x) \\log(p_X(x)) $$ . For continuous random variables, just use the integral. ",
    "url": "/docs/statistics/notes/entropy.html#entropy",
    
    "relUrl": "/docs/statistics/notes/entropy.html#entropy"
  },"500": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "KL Divergence",
    "content": "Kullback-Leibler (KL) divergence is the statistical difference between two distributions. $$ D_{KL}(P\\mathbin{||}Q) = \\sum_{x \\in X} p_P(x) \\log\\left(\\frac{p(x)}{q(x)}\\right) $$ . Also known as relative entropy of $P$ with respect to $Q$, or how much extra surprise we get if we use $Q$ instead of $P$. Most common scenario is to compare the difference between the empirical distribution of the observations and the theoretical model distribution. Let $P$ be the empirical distribution and $Q$ be the theoretical model distribution. Intuitive way to remember this is to calculate the ratio of the probabilities of observing random variable $X$ under $P$ and $Q$: . \\[\\frac{p(x)}{q(x)}\\] Then we take the log of this ratio: . \\[\\log\\left(\\frac{p(x)}{q(x)}\\right)\\] This aligns with our intuition that we want to measure the statistical difference between the two distributions, because it is equal to the logarithmic difference $\\log(p(x)) - \\log(q(x))$. Then KL divergence is the expected value of this logarithmic difference under $P$: . \\[E_p\\left[\\log\\left(\\frac{p(X)}{q(X)}\\right)\\right]\\] ",
    "url": "/docs/statistics/notes/entropy.html#kl-divergence",
    
    "relUrl": "/docs/statistics/notes/entropy.html#kl-divergence"
  },"501": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Some properties",
    "content": "Another way to write KL divergence . By logarithmic properties, . \\[D_{KL}(P\\mathbin{||}Q) = \\sum_{x \\in X} p(x) \\log\\left(\\frac{p(x)}{q(x)}\\right) = - \\sum_{x \\in X} p(x) \\log\\left(\\frac{q(x)}{p(x)}\\right)\\] KL divergence is not symmetric . Algebraically, it is easy to see that $D_{KL}(P\\mathbin{||}Q) \\neq D_{KL}(Q\\mathbin{||}P)$. Intuitive way to remember Remeber that we can think of $P$ as the observed distribution and $Q$ as the theoretical model distribution. We usually want to estimate a model parameter that can minimize the difference with the observed distribution. But a model cannot always perfectly fit the observed distribution, but it will try its best. But two distributions may have different ideas on what counts as “best”. Maybe $P$ has a lot of bumps or outbursts, which may be important because they are caused by relevant events. However, a model distribution might have a tendency to flatten out the bumps and outbursts because it wants to generalize. For $D_{KL}(P\\mathbin{||}Q)$, we are looking at the difference from the empirical distribution perspective. When $P$ looks at $Q$, it may think the difference is big because they did not capture the important information, like the bump. For $D_{KL}(Q\\mathbin{||}P)$, we are looking at the difference from the model perspective. When $Q$ looks at $P$, it may think the difference is small because the mean is similar and the bumps are not important. ",
    "url": "/docs/statistics/notes/entropy.html#some-properties",
    
    "relUrl": "/docs/statistics/notes/entropy.html#some-properties"
  },"502": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Cross Entropy",
    "content": "Cross entropy is a measure of the surprise we have if we use the estimated distribution $Q$ instead of true distribution $P$. Definition of cross entropy using KL divergence is an intuitive way to remember: . $$ H(P, Q) = H(P) + D_{KL}(P\\mathbin{||}Q) $$ . Information we need to describe $P$ when we use $Q$ to explain is equal to information needed for $P$ plus the extra information we need for using $Q$ instead. It is very easy to show that it leads to the following definition: . $$ H(P, Q) = -\\sum_{x \\in X} p(x) \\log(q(x)) $$ . ",
    "url": "/docs/statistics/notes/entropy.html#cross-entropy",
    
    "relUrl": "/docs/statistics/notes/entropy.html#cross-entropy"
  },"503": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Conditional entropy",
    "content": "Conditional entropy of random variable $X$ given $Y$ is the amount of extra information needed to describe $X$ given $Y$. $$ H(X \\mid Y) = -\\sum_{x \\in X} \\sum_{y \\in Y} p_{XY}(x, y) \\log(p_{X \\mid Y}(x \\mid y)) $$ . ",
    "url": "/docs/statistics/notes/entropy.html#conditional-entropy",
    
    "relUrl": "/docs/statistics/notes/entropy.html#conditional-entropy"
  },"504": {
    "doc": "Entropy / KL Divergence / Cross Entropy",
    "title": "Mutual information",
    "content": "Mutual information is the amount of information that random variable $X$ and $Y$ share. $$ I(X; Y) = H(X) - H(X \\mid Y) = H(Y) - H(Y \\mid X) $$ . Also called “information gain of $\\mathbf{X}$” given $Y$. Intuition We need $H(X)$ much information to describe $X$. $H(X \\mid Y)$ is the amount of extra work we have to do from $Y$ in order to describe $X$. So $H(X) - H(X \\mid Y)$ is the amount of free info that $Y$ already gives us about $X$. So $I(X; Y)$ is the amount of information that $X$ and $Y$ already had in common, thus mutual information. It is also the “information gained about $X$” by knowing $Y$. ",
    "url": "/docs/statistics/notes/entropy.html#mutual-information",
    
    "relUrl": "/docs/statistics/notes/entropy.html#mutual-information"
  },"505": {
    "doc": "Error vs Residual",
    "title": "Error vs Residual",
    "content": "In the context of regression, the terms error and residual are often used interchangeably. However, there is a subtle difference between the two. | Recap of Model and Error | Residual Between Data and Estimated Model | . ",
    "url": "/docs/data-science/notes/error-residual.html",
    
    "relUrl": "/docs/data-science/notes/error-residual.html"
  },"506": {
    "doc": "Error vs Residual",
    "title": "Recap of Model and Error",
    "content": "The true model $f$ captures the relationship between the input features $X$ and the output $Y$: . $$ Y = f(X) + \\epsilon $$ . where $\\epsilon$ is the error term. This error is the unavoidable uncertainty that comes from the fact that $X$ may not be the sole relevant variable in predicting $Y$. Every other unobserved factors that affect $Y$ are captured in this error term. So even if we have the true model $f$, we can’t predict the output $Y$ perfectly. ",
    "url": "/docs/data-science/notes/error-residual.html#recap-of-model-and-error",
    
    "relUrl": "/docs/data-science/notes/error-residual.html#recap-of-model-and-error"
  },"507": {
    "doc": "Error vs Residual",
    "title": "Residual Between Data and Estimated Model",
    "content": "The goal of regression is to estimate the true model $f$. For example, we assume a true model: . \\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon\\] Then we estimate this structure using the data we have by learning the coefficients $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$: . \\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\] The residual is the difference between the observed value $y_i$ and the estimated value $\\hat{y}_i$: . $$ y_i - \\hat{y}_i $$ . RSS (Residual Sum of Squares) is the sum of the squared residuals: . \\[\\text{RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\] Difference Between Error and Residual Error is unexplained by the input features and is unobservable. Residual is calculated from the observed data and the estimated model, and thus can be minimized by adjusting the model. Therefore, you could say that the residual is the estimate of the error. That is why the terms are often used interchangeably. ",
    "url": "/docs/data-science/notes/error-residual.html#residual-between-data-and-estimated-model",
    
    "relUrl": "/docs/data-science/notes/error-residual.html#residual-between-data-and-estimated-model"
  },"508": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Estimators / Bias / Consistency",
    "content": ". | Estimators . | Sampling Distribution | Standard Error | . | Bias | Unbiased Estimator | Consistent Estimator | Bias vs Consistency | Mean Squared Error (MSE) of an Estimator | Normal Estimator | . ",
    "url": "/docs/statistics/notes/estimators.html",
    
    "relUrl": "/docs/statistics/notes/estimators.html"
  },"509": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Estimators",
    "content": "Let $X_1, \\dots, X_n$ be IID samples from a population with unknown parameter $\\theta$. An estimator of $\\theta$ is a random variable: . $$ \\hat{\\theta}_n = g(X_1, \\dots, X_n) $$ . where $g$ is a function of the samples. ",
    "url": "/docs/statistics/notes/estimators.html#estimators",
    
    "relUrl": "/docs/statistics/notes/estimators.html#estimators"
  },"510": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Sampling Distribution",
    "content": "Distribution of the estimator $\\hat{\\theta}_n$ is called the sampling distribution. ",
    "url": "/docs/statistics/notes/estimators.html#sampling-distribution",
    
    "relUrl": "/docs/statistics/notes/estimators.html#sampling-distribution"
  },"511": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Standard Error",
    "content": "The standard deviation of the sampling distribution is called the standard error. $$ \\text{SE}(\\hat{\\theta}_n) = \\sqrt{\\Var(\\hat{\\theta}_n)} $$ . ",
    "url": "/docs/statistics/notes/estimators.html#standard-error",
    
    "relUrl": "/docs/statistics/notes/estimators.html#standard-error"
  },"512": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Bias",
    "content": "Let $\\hat{\\theta}$ be an estimator of $\\theta$. The bias of an estimator is defined as: . $$ \\text{bias}(\\hat{\\theta}_n) = \\text{E}_\\theta[\\hat{\\theta}_n] - \\theta $$ . The above $\\text{E}_\\theta$ is expectation respect to the distribution $f(x_1, \\dots, x_n; \\theta)$, not the distribution for $\\theta$. ",
    "url": "/docs/statistics/notes/estimators.html#bias",
    
    "relUrl": "/docs/statistics/notes/estimators.html#bias"
  },"513": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Unbiased Estimator",
    "content": "We say that an estimator $\\hat{\\theta}_n$ is unbiased if: . $$ \\text{bias}(\\hat{\\theta}_n) = 0 \\iff \\text{E}_\\theta[\\hat{\\theta}_n] = \\theta $$ . The expected value of an unbiased estimator is equal to the true parameter value. ",
    "url": "/docs/statistics/notes/estimators.html#unbiased-estimator",
    
    "relUrl": "/docs/statistics/notes/estimators.html#unbiased-estimator"
  },"514": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Consistent Estimator",
    "content": "We say that an estimator $\\hat{\\theta}_n$ is consistent if: . $$ \\hat{\\theta}_n \\xrightarrow{P} \\theta \\iff \\plim_{n \\to \\infty} \\hat{\\theta}_n = \\theta $$ . The estimator converges in probability to the true parameter value. ",
    "url": "/docs/statistics/notes/estimators.html#consistent-estimator",
    
    "relUrl": "/docs/statistics/notes/estimators.html#consistent-estimator"
  },"515": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Bias vs Consistency",
    "content": "Being an unbiased estimator does not imply consistency. However, if the unbiased estimator converges to a point, then it is consistent: . $$ \\text{bias} \\rightarrow 0 \\wedge \\text{se} \\rightarrow 0 \\implies \\hat{\\theta}_n \\xrightarrow{P} \\theta $$ . On the other hand, a biased estimator can be consistent. The uncorrected biased sample variance . \\[S_n^2 = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X}_n)^2\\] is one example of a biased estimator that is consistent. ",
    "url": "/docs/statistics/notes/estimators.html#bias-vs-consistency",
    
    "relUrl": "/docs/statistics/notes/estimators.html#bias-vs-consistency"
  },"516": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Mean Squared Error (MSE) of an Estimator",
    "content": "When we build a model $\\hat{\\theta}_n$, we can optimize the model to minimize the mean of squared difference from the true parameter $\\theta$. This mean squared error (MSE) is the measure of the performance of an estimator. MSE of an estimator $\\hat{\\theta}_n$ is defined as: . $$ \\begin{align} \\text{MSE}(\\hat{\\theta}_n) &amp;= \\text{E}_\\theta[(\\hat{\\theta}_n - \\theta)^2] \\\\[1em] &amp;= \\text{bias}^2(\\hat{\\theta}_n) + \\Var(\\hat{\\theta}_n) \\end{align} $$ . See proof from $(1)$ to $(2)$, the bias-variance decomposition of MSE, here. ",
    "url": "/docs/statistics/notes/estimators.html#mean-squared-error-mse-of-an-estimator",
    
    "relUrl": "/docs/statistics/notes/estimators.html#mean-squared-error-mse-of-an-estimator"
  },"517": {
    "doc": "Estimators / Bias / Consistency",
    "title": "Normal Estimator",
    "content": "An estimator $\\hat{\\theta}_n$ is asymptotically normal if: . $$ \\frac{\\hat{\\theta}_n - \\theta}{\\text{SE}(\\hat{\\theta}_n)} \\leadsto N(0,1) $$ . ",
    "url": "/docs/statistics/notes/estimators.html#normal-estimator",
    
    "relUrl": "/docs/statistics/notes/estimators.html#normal-estimator"
  },"518": {
    "doc": "F-Score",
    "title": "F-Score",
    "content": ". | Confusion matrix | Precision and Recall . | Precision | Recall | . | F1-score | . ",
    "url": "/docs/statistics/notes/f1-score.html#f-score",
    
    "relUrl": "/docs/statistics/notes/f1-score.html#f-score"
  },"519": {
    "doc": "F-Score",
    "title": "Confusion matrix",
    "content": "| Actual\\Prediction | Positive | Negative | . | Positive | True Positive | False Negative | . | Negative | False Positive | True Negative | . ",
    "url": "/docs/statistics/notes/f1-score.html#confusion-matrix",
    
    "relUrl": "/docs/statistics/notes/f1-score.html#confusion-matrix"
  },"520": {
    "doc": "F-Score",
    "title": "Precision and Recall",
    "content": ". Walber, CC BY-SA 4.0, via Wikimedia Commons Precision . Also called the positive predict value (PPV), . \\[precision = \\frac{TP}{TP + FP}\\] Recall . Also called the sensitivity, . \\[recall = \\frac{TP}{TP + FN}\\] . ",
    "url": "/docs/statistics/notes/f1-score.html#precision-and-recall",
    
    "relUrl": "/docs/statistics/notes/f1-score.html#precision-and-recall"
  },"521": {
    "doc": "F-Score",
    "title": "F1-score",
    "content": "An F-score is a measure of a binary classification’s accuracy. There exists a general F-score of $F_\\beta$, where the $\\beta$ acts as a weight of importance for recall. However, the balanced F-score (or $F_1$ score), where precision and recall are considered equally, is the harmonic mean of precision and recall: . \\[F_1 = \\frac{2}{recall^{-1} + precision^{-1}} = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall} = \\frac{TP}{TP + \\frac{1}{2}(FP + FN)}\\] Where $0 \\le F_1 \\le 1$. $F_1$ of $1.0$ means perfect precision and recall, while $0$ means either one of them was $0$. Always remeber that F1 score (and the whole TP, TN …) is dependent on which threshold was selected (by examining ROC, etc.). Low F1 score does not represent the performance of the entire model, but the performance at a certain classification threshold. ",
    "url": "/docs/statistics/notes/f1-score.html#f1-score",
    
    "relUrl": "/docs/statistics/notes/f1-score.html#f1-score"
  },"522": {
    "doc": "F-Score",
    "title": "F-Score",
    "content": ". ",
    "url": "/docs/statistics/notes/f1-score.html",
    
    "relUrl": "/docs/statistics/notes/f1-score.html"
  },"523": {
    "doc": "Feature Selection",
    "title": "Feature Selection",
    "content": ". | Downside of Having Too Many Features | Overall Significance Test of Regression . | F-Test for Linear Regression Analysis | . | Feature Selection Methods . | Best Subset Selection | Stepwise Regression . | Backward elimination | Forward selection | Bidirectional elimination | . | . | . ",
    "url": "/docs/data-science/notes/feature-selection.html",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html"
  },"524": {
    "doc": "Feature Selection",
    "title": "Downside of Having Too Many Features",
    "content": ". | It is not easy or possible to visualize the resulting model due to the high dimensionality of the feature space. But to be fair, this is unavoidable. | Model interpretability is decreased as more features are added to the model. | Sometimes, not all features are relevant to the dependent variable and including them in the model can only result in high variance and overfitting. Which is the most concerning point. | . So, it would be better to select only the relevant features for the model. Modern ML libraries with regression models usually automatically perform feature selection for you. ",
    "url": "/docs/data-science/notes/feature-selection.html#downside-of-having-too-many-features",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html#downside-of-having-too-many-features"
  },"525": {
    "doc": "Feature Selection",
    "title": "Overall Significance Test of Regression",
    "content": "One important question to ask before feature selection is: . Were any of the features useful in predicting the response at all? . If none of the features used in the model are relevant, then there is no point in using this model at all, let alone selecting features. In the case of linear regression, suppose we have three estimators $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, and $\\hat{\\beta}_3$, each a weight for a feature. The null hypothesis we want to test then would be: . $$ H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0 $$ . Which says, none of the features are useful in predicting the response, so it is not any better than the intercept-only model (also called the mean model, baseline model, etc.) . ",
    "url": "/docs/data-science/notes/feature-selection.html#overall-significance-test-of-regression",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html#overall-significance-test-of-regression"
  },"526": {
    "doc": "Feature Selection",
    "title": "F-Test for Linear Regression Analysis",
    "content": "This can be done by F-test for linear regression. F-statistic for linear regression analysis compares the RSS of two different models: . $$ F = \\frac{(RSS_1 - RSS_2)/(p_2-p_1)}{RSS_2/(n-p_2-1)} $$ . where $p_1$ and $p_2$ are the number of parameters in the two models respectively. Assuming that the null hypothesis is true, $RSS_1$ becomes $TSS$ (total sum of squares) and $p_1$ becomes 0. Hence, the F-statistic becomes: . $$ F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)} \\sim F_{p, n-p-1} $$ . When the null hypothesis is true, the $F$ statistic takes a value close to 1. If not, the value gets bigger than 1. We want this F-statistic to be large, in order to confirm that at least one of the features is useful. How large? This depends on $n$, $p$, and the significance level $\\alpha$. Generally, if $n$ is small, we need a larger F-statistic to reject the null hypothesis. Some intuition Recall from $R^2$ that $TSS - RSS$ is the explained variance by the model. If the model explains the variance well, then $TSS - RSS$ is large, and the F-statistic is large as well. ",
    "url": "/docs/data-science/notes/feature-selection.html#f-test-for-linear-regression-analysis",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html#f-test-for-linear-regression-analysis"
  },"527": {
    "doc": "Feature Selection",
    "title": "Feature Selection Methods",
    "content": "First, the obvious ones: . | Just use all the features . | Might be reasonable if you already have some prior domain knowledge about the problem (e.g. via laws of physics) and you’re sure that all the features are relevant and beneficial to the model. | . | . ",
    "url": "/docs/data-science/notes/feature-selection.html#feature-selection-methods",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html#feature-selection-methods"
  },"528": {
    "doc": "Feature Selection",
    "title": "Best Subset Selection",
    "content": "Brute-force all the possible combinations of features. Decide on a metric to evaluate the model. Choose the combination of features that maximizes good fit. This is not feasible in most cases ($2^p - 1$ combinations for $p$ features). But if you have a small number of features, this might be okay. The search for the best subset may lead to overfitting/high variance. ",
    "url": "/docs/data-science/notes/feature-selection.html#best-subset-selection",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html#best-subset-selection"
  },"529": {
    "doc": "Feature Selection",
    "title": "Stepwise Regression",
    "content": "The more sophisticated stepwise regression methods that selects features step-by-step based on the results of hypothesis testing. They do not guarantee the best subset of features, but they are computationally more efficient. Backward elimination . Backward elimination cannot be used if the number of features is greater than the number of observations. Start with all the features and remove the least significant feature . | Pick a significance level $\\alpha$ (e.g. 0.05). | Fit all possible models with all the features except one. | Find the model with the highest $p$-value. | If $p &gt; \\alpha$, remove that feature. Otherwise, stop. | Fit the models again with the remaining features and repeat until stop. | . Forward selection . Forward selection can always be used, but tends to be too greedy. Start with no feature and cumulatively add the most significant feature . | Pick a significance level $\\alpha$ (e.g. 0.05). | For each feature $X_i$, fit a simple regression model and select $X_i$ with the lowest $p$-value. | If the lowest $p &lt; \\alpha$, add that feature to the model. Otherwise, stop. | For each feature $X_j$ that is previously not considered, fit a regression model together with all the previously selected features. Then select $X_j$ with the lowest $p$-value. | Repeat until stop. | . Bidirectional elimination . Combination of backward elimination and forward selection . | Pick two significance levels $\\alpha_{enter}$ and $\\alpha_{stay}$. | Perform one step of forward selection (selecting if $p &lt; \\alpha_{enter}$). | Perform the entire backward elimination (removing in each step if $p &gt; \\alpha_{stay}$) In other words, features \"stay\" if $p &lt; \\alpha_{stay}$. | If no feature was added or removed in the previous two steps, stop. Otherwise, repeat. | . ",
    "url": "/docs/data-science/notes/feature-selection.html#stepwise-regression",
    
    "relUrl": "/docs/data-science/notes/feature-selection.html#stepwise-regression"
  },"530": {
    "doc": "filter-repo",
    "title": "git filter-repo",
    "content": ". | Installation | Set subdirectory as root of its own repo . | Clone a fresh copy of the repo | Set the contents of subdirectory as the content of new repo | Create a new remote and push | . | Move multiple subdirectories to a new repo | Delete files from all commit history | . ",
    "url": "/docs/git-hub/git/filter-repo.html#git-filter-repo",
    
    "relUrl": "/docs/git-hub/git/filter-repo.html#git-filter-repo"
  },"531": {
    "doc": "filter-repo",
    "title": "Installation",
    "content": "Install via Homebrew: . brew install git-filter-repo . ",
    "url": "/docs/git-hub/git/filter-repo.html#installation",
    
    "relUrl": "/docs/git-hub/git/filter-repo.html#installation"
  },"532": {
    "doc": "filter-repo",
    "title": "Set subdirectory as root of its own repo",
    "content": "You could technically just copy over the directory and create a new repo. However, if you’d like to carry over commits that are relevant to the subdirectory to the new reoo, you can use git filter-repo to do so. Suppose you have a repo named test-repo with the following structure: . ├── dir1 ├── dir2 └── dir3 . And you want to move the contents of dir1 into a new repo named dir1-repo. Clone a fresh copy of the repo . Cloning a fresh copy before running git filter-repo is a recommended practice. git clone ${https_or_ssh_to_test_repo} dir1-repo . Set the contents of subdirectory as the content of new repo . cd dir1-repo git filter-repo --subdirectory-filter dir1 . Relevant commits should have been cherry picked as well. Create a new remote and push . Create a new repo on GitHub. Suppose its name is dir1-repo. First check if you still have the remote pointing to the original test-repo: . git remote -v . If you do, modify it: . Assuming origin is the name of the main upstream remote. git remote set-url origin ${https_or_ssh_to_dir1_repo} # OR if the remote settings were already purged git add remote origin ${https_or_ssh_to_dir1_repo} . Verify that a new remote origin has been set and push: . git push -u origin ${branch} . ",
    "url": "/docs/git-hub/git/filter-repo.html#set-subdirectory-as-root-of-its-own-repo",
    
    "relUrl": "/docs/git-hub/git/filter-repo.html#set-subdirectory-as-root-of-its-own-repo"
  },"533": {
    "doc": "filter-repo",
    "title": "Move multiple subdirectories to a new repo",
    "content": "Suppose you have a repo named test-repo with the following structure: . ├── dir1 ├── dir2 ├── dir3 └── dir4 . And you want to move dir1 and dir2 to a new repo named new-repo: . ├── dir1 └── dir2 . Steps are similar to above, except for the git filter-repo command: . git filter-repo --path dir1 --path dir2 . ",
    "url": "/docs/git-hub/git/filter-repo.html#move-multiple-subdirectories-to-a-new-repo",
    
    "relUrl": "/docs/git-hub/git/filter-repo.html#move-multiple-subdirectories-to-a-new-repo"
  },"534": {
    "doc": "filter-repo",
    "title": "Delete files from all commit history",
    "content": "To remove certain files from all commit history, use the following command: . git filter-repo --invert-paths --path &lt;file1&gt; --path &lt;file2&gt; . References . | git-filter-repo | GitHub: Splitting a subfolder out into a new repository | . ",
    "url": "/docs/git-hub/git/filter-repo.html#delete-files-from-all-commit-history",
    
    "relUrl": "/docs/git-hub/git/filter-repo.html#delete-files-from-all-commit-history"
  },"535": {
    "doc": "filter-repo",
    "title": "filter-repo",
    "content": " ",
    "url": "/docs/git-hub/git/filter-repo.html",
    
    "relUrl": "/docs/git-hub/git/filter-repo.html"
  },"536": {
    "doc": "Floating Point Representation",
    "title": "Floating Point Representation",
    "content": ". | Floating Point Structure | Single Precision . | Single Precision Example | . | . ",
    "url": "/docs/compsci/computing/floating-point.html",
    
    "relUrl": "/docs/compsci/computing/floating-point.html"
  },"537": {
    "doc": "Floating Point Representation",
    "title": "Floating Point Structure",
    "content": ". ",
    "url": "/docs/compsci/computing/floating-point.html#floating-point-structure",
    
    "relUrl": "/docs/compsci/computing/floating-point.html#floating-point-structure"
  },"538": {
    "doc": "Floating Point Representation",
    "title": "Single Precision",
    "content": "A decimal number $x$ is broken down in single precision as: . $$ x = (-1)^\\boldsymbol{S} \\times (1.0 + \\boldsymbol{F}) \\times 2^{\\boldsymbol{E} - 127} $$ . | $\\boldsymbol{S}$ is the sign: $0$ for positive, $1$ for negative | $\\boldsymbol{E}$ is the exponent: $1 \\leq \\boldsymbol{E} \\leq 254$ | $\\boldsymbol{F}$ is the fraction: $0 \\leq \\boldsymbol{F} &lt; 1$ | . The values of $\\boldsymbol{S}$, $\\boldsymbol{E}$, and $\\boldsymbol{F}$ need to be converted to binaries of 1, 8, and 23 bits respectively, and concatenated to form a 32-bit binary number. \\[\\begin{gather*} \\boldsymbol{S} := \\texttt{s} \\\\[1em] \\boldsymbol{E} := \\texttt{e}_7 \\dots \\texttt{e}_0 \\\\[1em] \\boldsymbol{F} := \\texttt{f}_1 \\dots \\texttt{f}_{23} \\end{gather*}\\] Fractions Remeber that $\\boldsymbol{F}$ is a fraction, and its binary representation is obtained by finding $\\texttt{f}_i \\in \\{0, 1\\}$ such that: . \\[\\boldsymbol{F} = \\sum_{i=1}^{23} \\frac{\\texttt{f}_i}{2^i}\\] where $\\texttt{f}_1$ is the leftmost bit of $\\boldsymbol{F}$. Which is the reverse direction of $\\boldsymbol{E}$: . \\[\\boldsymbol{E} = \\sum_{i=0}^{7} \\texttt{e}_i 2^i\\] Note how the indexings differ. ",
    "url": "/docs/compsci/computing/floating-point.html#single-precision",
    
    "relUrl": "/docs/compsci/computing/floating-point.html#single-precision"
  },"539": {
    "doc": "Floating Point Representation",
    "title": "Single Precision Example",
    "content": "To find the single precision representation of $x = 3.125$: . $\\texttt{s = 0}$ because $x$ is positive. Now convert each side of the decimal point ($3$ and $0.125$) to binary: . \\[\\begin{gather*} (3.125)_{10} = (11.001)_2 \\\\[0.5em] \\Downarrow \\\\[0.5em] 1.1001 \\times 2^1 \\\\[0.5em] \\Downarrow \\\\[0.5em] 1.1001 \\times 2^{128 - 127} \\end{gather*}\\] Hence $\\boldsymbol{E} = 128 = \\texttt{10000000}$ and $\\boldsymbol{F} = \\texttt{10010000000000000000000}$. The single precision representation of $x$ is: . \\[\\texttt{01000000010010000000000000000000}\\] ",
    "url": "/docs/compsci/computing/floating-point.html#single-precision-example",
    
    "relUrl": "/docs/compsci/computing/floating-point.html#single-precision-example"
  },"540": {
    "doc": "Frontend Web",
    "title": "Frontend Web",
    "content": ". | SPA vs SSR vs Static Site . | Single-Page Application (SPA) | Server-Side Rendering | Static Site | . | . ",
    "url": "/docs/learned/frontend-web.html",
    
    "relUrl": "/docs/learned/frontend-web.html"
  },"541": {
    "doc": "Frontend Web",
    "title": "SPA vs SSR vs Static Site",
    "content": "Here is an attempt to understand the exact differences between the three. Single-Page Application (SPA) . An SPA uses CSR (client-side rendering). Just by that I can already see the glaring difference to SSR (server-side rendering). In CSR, as the name suggests the client (browser) dynamically renders the web app. All the HTML, CSS, and Javascript are loaded in the beginning of the app’s lifecycle. Script makes AJAX calls to the API when it needs new data and dynamically integrates it. So technically, there really is only one page that is being presented to the user, it’s just that the contents within the page change to meet your needs. One advantage of SPA is that it provides better UX, because there is little to no lag time during navigation within the app. This comes from the fact that SPA does not require duplicate resources again and again after each click unlike MPA (Multiple-Page Application)/SSR. Things that always stay static on a website, like the general frame or style can stay as is and only new data are fetched from server. One disadvantage is that it is generally considered to have poor SEO (Search-Engine Optimization) compared to server-side apps. This is because without JS rendering, the HTML of an SPA is pretty much empty. If you check the source code of an SPA (not from the console), you will see that it does not contain much other than all the scripts that are sitting and waiting to execute upon interaction. In addition, SPAs might not have unique URLs for each content delivered. In many cases the URL stays the same throughout the entire site. Therefore crawling and indexing becomes slow and difficult. Server-Side Rendering . With all that being said about SPA, SSR is easier to understand. When navigation happens (e.g via click), the server builds the page and hands it over to the browser. Within a browser, you will only see the resources that consist the current page that you are on. You can already see why this could be slow, since it’s like asking the chef to dip your nachos every single bite when you could’ve just had the chips and cheese in front of you and dip it yourself. Due to this nature of SSR, you will see the page flicker upon navigation unlike the smooth UX of SPA. However, the benefit of SSR compared to SPA is that it is more secure, less heavy on the browser (and no memory leaks), and better SEO. Static Site . Static sites do not have dynamic content and consist of only the static files (HTML, CSS, JS). You could think of this as if the SSR had already rendered every single page that the client might request and had it prepared for you. There is no backend component to static sites and no rendering is involved. ",
    "url": "/docs/learned/frontend-web.html#spa-vs-ssr-vs-static-site",
    
    "relUrl": "/docs/learned/frontend-web.html#spa-vs-ssr-vs-static-site"
  },"542": {
    "doc": "GitHub Integration",
    "title": "Github Integration",
    "content": ". | Setup | Deployment key for Github repo . | Generate a key pair in Jenkins container | Add private key to Jenkins credentials | Add public key to Github repo | . | GitHub webhook for Jenkins | Create a Jenkins item . | No ECDSA error | . | . ",
    "url": "/docs/jenkins/github.html#github-integration",
    
    "relUrl": "/docs/jenkins/github.html#github-integration"
  },"543": {
    "doc": "GitHub Integration",
    "title": "Setup",
    "content": "One way to install and experiment with Jenkins locally is to use Docker. Necessary steps are well documented and thoroughly explained in the official documentation. It is easier to manage the containers if you transcribe the commands in the docs to a docker-compose file. ",
    "url": "/docs/jenkins/github.html#setup",
    
    "relUrl": "/docs/jenkins/github.html#setup"
  },"544": {
    "doc": "GitHub Integration",
    "title": "Deployment key for Github repo",
    "content": "Generate a key pair in Jenkins container . Suppose you have a Jenkins container named jenkins running locally, . exec a shell in the container and generate a key pair in /var/jenkins_home/.ssh: . docker exec -it jenkins bash mkdir -p /var/jenkins_home/.ssh ssh-keygen -t ed25519 -f /var/jenkins_home/.ssh/jenkins_github . You will now have a key pair named jenkins_github in /var/jenkins_home/.ssh. Add private key to Jenkins credentials . Now log in to Jenkins Dashboard and navigate to Manage Jenkins &gt; Manage Credentials. Click on Add Credentials and select SSH Username with private key from the dropdown. Copy the contents of jenkins_github and paste it in the Private Key field. Add public key to Github repo . Go to your Github repo and navigate to Settings &gt; Deploy keys. Copy the contents of jenkins_github.pub and paste it in the Key field. ",
    "url": "/docs/jenkins/github.html#deployment-key-for-github-repo",
    
    "relUrl": "/docs/jenkins/github.html#deployment-key-for-github-repo"
  },"545": {
    "doc": "GitHub Integration",
    "title": "GitHub webhook for Jenkins",
    "content": "If you have not chosen to Install suggested plugins during the Jenkins setup, you may need to install Git plugin and GitHub plugin manually. To create a GitHub webhook, you need a working public URL. If you do not have one, you can use ngrok, etc. to create a forwarding URL for your Jenkins exposed port. Go to your Github repo and navigate to Settings &gt; Webhooks &gt; Add webhook. | Payload URL: Must be appended with /github-webhook/ to work with the GitHub plugin. | Content type: Must be set to application/json. | . ",
    "url": "/docs/jenkins/github.html#github-webhook-for-jenkins",
    
    "relUrl": "/docs/jenkins/github.html#github-webhook-for-jenkins"
  },"546": {
    "doc": "GitHub Integration",
    "title": "Create a Jenkins item",
    "content": "TBA . No ECDSA error . If you encounter the following error while configuring the URL for the repo, . No ECDSA host key is known for github.com and you have requested strict checking. Navigate to Manage Jenkins &gt; Configure Global Security, . Find Git Host Key Verification Configuration and set Host Key Verification Strategy to Accept first connection. ",
    "url": "/docs/jenkins/github.html#create-a-jenkins-item",
    
    "relUrl": "/docs/jenkins/github.html#create-a-jenkins-item"
  },"547": {
    "doc": "GitHub Integration",
    "title": "GitHub Integration",
    "content": " ",
    "url": "/docs/jenkins/github.html",
    
    "relUrl": "/docs/jenkins/github.html"
  },"548": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Goals and Target of Data Analysis",
    "content": ". | Goals of Data Analysis . | Describe the Data . | Causality | Correlation | . | . | Purpose of Statistics in Data Analysis | Types of Statistics . | Descriptive Statistics | Inferential Statistics . | Statistical Inference | Statistical Testing | . | . | Target of Analysis . | Population . | Finite population | Infinite population | . | Finding the characteristics of the population . | Complete enumeration | Sample survey . | Sample size | . | . | . | . ",
    "url": "/docs/statistics/basics/goals-target-analysis.html",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html"
  },"549": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Goals of Data Analysis",
    "content": "Three main goals of data analysis: . | Summarize the data: e.g. calculate the mean | Describe the data | Predict the data | . ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#goals-of-data-analysis",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#goals-of-data-analysis"
  },"550": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Describe the Data",
    "content": "This is more like understanding the characteristics of the data and the relationships between variables. Questions like “Was this effective?” or “Is there a relationship between ~” fit here. In data analysis, there are two main types of relationships: causality and correlation. Causality . | Relationship of cause and effect: if-then | If you know the cause, you can not only predict the effect, but also control the outcome by intervening the cause. | e.g. If you take this treatment, you will get better. | . | . Correlation . | Relationship of tendency: when one is of a certain state, then the other tends to be of a certain state. | Different from causality in that changing one variable does not necessarily change the other. | e.g. People with higher income tend to be happier, but giving people more money does not necessarily make them happier since other factors come into play. | . | . ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#describe-the-data",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#describe-the-data"
  },"551": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Purpose of Statistics in Data Analysis",
    "content": "Dispersion is the degree of spread of the data. Higher the dispersion, the more difficult it is to really understand the data, because it brings uncertainty to the relationship between variables (observations that abide the laws of physics are relatively deterministic, hence have low dispersion). This uncertainty is the reason we need statistics, and probability is the language of uncertainty. ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#purpose-of-statistics-in-data-analysis",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#purpose-of-statistics-in-data-analysis"
  },"552": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Types of Statistics",
    "content": " ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#types-of-statistics",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#types-of-statistics"
  },"553": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Descriptive Statistics",
    "content": "The main focus is on understanding and explaining the data itself. | Summarize the data | Describe the data | . ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#descriptive-statistics",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#descriptive-statistics"
  },"554": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Inferential Statistics",
    "content": "Aims to infer the characteristics of the source from which the data was collected. To predict the data, we need to understand the source. One way to do this is to come up with a probability model of the source. There are two main types of inferential statistics: . | Statistical inference | Statistical testing | . Statistical Inference . e.g. Throw a coin 100 times and count the number of heads. Then we can infer the probability of getting heads. Statistical Testing . e.g. Hypothesize that the coin is fair. Then we can test the hypothesis by throwing the coin 100 times and see if the number of heads is close to 50. ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#inferential-statistics",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#inferential-statistics"
  },"555": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Target of Analysis",
    "content": "Before you start analyzing any data, clearly define: . | The goal of analysis | The target of analysis | . As described above, the goal may be to understand the data or to predict the data. Once the goal is set, you need to define the target of analysis, aka the population. e.g. If the goal is to confirm the effect of a certain treatment, then the target of analysis would be the entire population of people who have the related disease. ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#target-of-analysis",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#target-of-analysis"
  },"556": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Population",
    "content": "The target of the analysis is called the population. The number of elements in the population is called the population size. There are two types of population depending on the size: . Finite population . No matter how large the population is, if the cardinality of the population can be fully enumerated, then it is a finite population. Infinite population . If the cardinality of the population is infinite, then it is an infinite population. Population that changes over time is also considered an infinite population. ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#population",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#population"
  },"557": {
    "doc": "Goals and Target of Data Analysis",
    "title": "Finding the characteristics of the population",
    "content": "If we know the characteristics of the population, then it becomes easier for us to predict the data. Then how would we know the characteristics of the population? . Complete enumeration . | Possible only for finite populations | Descriptive statistics can do the job | Unrealistic for large populations | . Sample survey . | Sampling is the process of selecting a subset of the population | Inferential statistics will be used to infer the characteristics of the population from the sample | . Sample size . The number of elements in the sample is called the sample size. The sample size is usually denoted by: . $$ n $$ . It is important to differentiate number of samples from sample size. Number of samples is the number of times you perform the sampling process, while sample size is the number of elements in the sample. ",
    "url": "/docs/statistics/basics/goals-target-analysis.html#finding-the-characteristics-of-the-population",
    
    "relUrl": "/docs/statistics/basics/goals-target-analysis.html#finding-the-characteristics-of-the-population"
  },"558": {
    "doc": "SQL Grouping",
    "title": "SQL Grouping",
    "content": "See basics here: . | GROUP BY | HAVING | . | GROUPING SETS . | GROUPING | . | CUBE | ROLLUP | . ",
    "url": "/docs/db/sql/grouping.html",
    
    "relUrl": "/docs/db/sql/grouping.html"
  },"559": {
    "doc": "SQL Grouping",
    "title": "GROUPING SETS",
    "content": "Given two columns column1 and column2, the total combinations of grouping sets that can be formed are: . | (column1, column2) Full set | (column1) Singletons | (column2) | () Empty set | . The keyword GROUPING SETS is a way to specify multiple grouping sets in a single GROUP BY clause. It is actually a shorthand for UNION ALL of multiple GROUP BY clauses. SELECT column1, column2, COUNT(*) as count FROM tbl GROUP BY GROUPING SETS ( (column1), (column2) ); . Which would have been: . SELECT column1, NULL as column2, COUNT(*) as count FROM tbl GROUP BY column1 UNION ALL SELECT NULL as column1, column2, COUNT(*) as count FROM tbl GROUP BY column2; . A union of queries with grouping set (column1) and (column2). This can become very annoying, very quickly. With GROUPING SETS you don’t even have to worry about making the queries union-compatible. ",
    "url": "/docs/db/sql/grouping.html#grouping-sets",
    
    "relUrl": "/docs/db/sql/grouping.html#grouping-sets"
  },"560": {
    "doc": "SQL Grouping",
    "title": "GROUPING",
    "content": "GROUPING(column) is a function that outputs . | 0 if the column is a member of the grouping set (i.e. it is being grouped by this column) | 1 if the column is not a member of the grouping set | . I personally thought the booleans were counter-intuitive. But think of it as, is this column a grouping, as in, were they smashed together under a certain group? Try to differentiate being a group by criterion and being a grouping. This function is about the latter. Basically creates boolean columns indicating whether this column was used as a grouping criterion to generate this row. Let’s take a look at a crazy example: . SELECT f.film_id, fa.actor_id, GROUPING(f.film_id) AS film_id_grouping, GROUPING(fa.actor_id) AS actor_id_grouping, COUNT(*) AS cnt FROM film f JOIN film_actor fa ON f.film_id = fa.film_id GROUP BY GROUPING SETS ( (f.film_id), (fa.actor_id), (f.film_id, fa.actor_id) ) HAVING GROUPING(f.film_id) = 0 AND GROUPING(fa.actor_id) = 0; . What is HAVING doing there? Without the HAVING above, the resulting top rows will have GROUPING values of 0 for film_id and 1 for actor_id, because the first grouping set is (f.film_id). What the HAVING does is allows us to select subsets of the GROUPING SETS (in this case, the last one (f.film_id, fa.actor_id)). So technically, it’d be like not using the GROUPING SETS from the beginning and sticking to our usual GROUP BY f.film_id, fa.actor_id. ",
    "url": "/docs/db/sql/grouping.html#grouping",
    
    "relUrl": "/docs/db/sql/grouping.html#grouping"
  },"561": {
    "doc": "SQL Grouping",
    "title": "CUBE",
    "content": "Remember how we said given two columns column1 and column2, the total combinations of grouping sets that can be formed are: . | (column1, column2) Full set | (column1) Singletons | (column2) | () Empty set | . CUBE generates this power set (2^n) for us without having to write them all out. GROUP BY CUBE (column1, column2) -- is equivalent to GROUP BY GROUPING SETS ( (column1, column2) (column1), (column2), (), ) . Again, you can use HAVING to select subsets of the power set: . HAVING GROUPING(column1) = 0 AND GROUPING(column2) = 0 -- would select the full set HAVING GROUPING(column1) = 0 AND GROUPING(column2) = 1 -- would select column1 singleton set -- and so on... ",
    "url": "/docs/db/sql/grouping.html#cube",
    
    "relUrl": "/docs/db/sql/grouping.html#cube"
  },"562": {
    "doc": "SQL Grouping",
    "title": "ROLLUP",
    "content": "Unlike CUBE, which generates the entire power set, ROLLUP generates the hierarchical subsets. GROUP BY ROLLUP (c1, c2, c3) -- is equivalent to GROUP BY GROUPING SETS ( (c1, c2, c3), (c1, c2), (c1), () ) . It is called hierarchical because it imposes hierarchy in the given order of the columns. If you compare it to a markdown header, c1 is the # header, c2 is the ## header, and c3 is the ### header. Because (c1, c2, c3) comes first and the empty set comes last, our results will return bottom-up aggregation (individualized to general). ROLLUP is very useful for generating subtotals. Take a look at this example: . SELECT rating, CASE WHEN length &gt;= 120 THEN 'long' WHEN length &lt; 120 THEN 'short' ELSE 'unknown' END AS length_category, AVG(rental_rate) FROM film GROUP BY ROLLUP (rating, 2); . The generated result is: . | rating | length_category | avg | . | null | null | 2.98 | . | R | short | 3.0094174757281553 | . | PG-13 | long | 3.1375409836065574 | . | NC-17 | long | 3.0518556701030928 | . | PG-13 | short | 2.9107920792079208 | . | NC-17 | short | 2.9015044247787611 | . | G | short | 2.8185714285714286 | . | PG | long | 3.1363414634146341 | . | R | long | 2.8595652173913043 | . | G | long | 2.99 | . | PG | short | 2.99 | . | R | null | 2.9387179487179487 | . | PG | null | 3.0518556701030928 | . | G | null | 2.888876404494382 | . | PG-13 | null | 3.0348430493273543 | . | NC-17 | null | 2.970952380952381 | . ",
    "url": "/docs/db/sql/grouping.html#rollup",
    
    "relUrl": "/docs/db/sql/grouping.html#rollup"
  },"563": {
    "doc": "Groups",
    "title": "Groups",
    "content": ". | Definition . | Closure | Associativity | Existence of a Neutral Element | Existence of an Inverse Element | . | Abelian Group . | Commutativity | . | . ",
    "url": "/docs/compsci/math/groups.html",
    
    "relUrl": "/docs/compsci/math/groups.html"
  },"564": {
    "doc": "Groups",
    "title": "Definition",
    "content": "Let $\\mathcal{G}$ be a set and $\\otimes: \\mathcal{G} \\times \\mathcal{G} \\to \\mathcal{G}$ an inner operation on $\\mathcal{G}$. Then $G = (\\mathcal{G}, \\otimes)$ is a group if it satisfies the following conditions: . ",
    "url": "/docs/compsci/math/groups.html#definition",
    
    "relUrl": "/docs/compsci/math/groups.html#definition"
  },"565": {
    "doc": "Groups",
    "title": "Closure",
    "content": "Closure of $\\mathcal{G}$ under $\\otimes$: . $$ \\forall x,y \\in \\mathcal{G},\\, x \\otimes y \\in \\mathcal{G} $$ . ",
    "url": "/docs/compsci/math/groups.html#closure",
    
    "relUrl": "/docs/compsci/math/groups.html#closure"
  },"566": {
    "doc": "Groups",
    "title": "Associativity",
    "content": "$$ \\forall x,y,z \\in \\mathcal{G},\\, (x \\otimes y) \\otimes z = x \\otimes (y \\otimes z) $$ . ",
    "url": "/docs/compsci/math/groups.html#associativity",
    
    "relUrl": "/docs/compsci/math/groups.html#associativity"
  },"567": {
    "doc": "Groups",
    "title": "Existence of a Neutral Element",
    "content": "$$ \\exists e \\in \\mathcal{G} \\mathbin{s.t.} \\forall x \\in \\mathcal{G},\\, x \\otimes e = x \\wedge e \\otimes x = x $$ . ",
    "url": "/docs/compsci/math/groups.html#existence-of-a-neutral-element",
    
    "relUrl": "/docs/compsci/math/groups.html#existence-of-a-neutral-element"
  },"568": {
    "doc": "Groups",
    "title": "Existence of an Inverse Element",
    "content": "$$ \\forall x \\in \\mathcal{G},\\, \\exists y \\in \\mathcal{G} \\mathbin{s.t.} x \\otimes y = e \\wedge y \\otimes x = e $$ . ",
    "url": "/docs/compsci/math/groups.html#existence-of-an-inverse-element",
    
    "relUrl": "/docs/compsci/math/groups.html#existence-of-an-inverse-element"
  },"569": {
    "doc": "Groups",
    "title": "Abelian Group",
    "content": "If a group additionally satisfies the following property, it is called an Abelian group: . ",
    "url": "/docs/compsci/math/groups.html#abelian-group",
    
    "relUrl": "/docs/compsci/math/groups.html#abelian-group"
  },"570": {
    "doc": "Groups",
    "title": "Commutativity",
    "content": "$$ \\forall x,y \\in \\mathcal{G},\\, x \\otimes y = y \\otimes x $$ . ",
    "url": "/docs/compsci/math/groups.html#commutativity",
    
    "relUrl": "/docs/compsci/math/groups.html#commutativity"
  },"571": {
    "doc": "Hierarchical Query",
    "title": "Hierarchical Query",
    "content": "What is a hierarchical query? . In a company, employees are organized in a hierarchical structure. Each employee has a manager, except maybe the CEO. Suppose we have an employee table with employee_id and manager_id columns which reflects this hierarchy of the company. Querying the names of all employees and their managers is a common hierarchical query. Our first intuition would be to use self-join: . SELECT e1.first_name emp, e1.job_id emp_job, 'Reports to' what, e2.first_name mgr, e2.job_id mgr_job FROM hr.employees e1 LEFT JOIN hr.employees e2 ON e1.manager_id = e2.employee_id ORDER BY e1.employee_id; . | EMP | EMP_JOB | WHAT | MGR | MGR_JOB | . | Steven | AD_PRES | Reports to | - | - | . | Neena | AD_VP | Reports to | Steven | AD_PRES | . | Lex | AD_VP | Reports to | Steven | AD_PRES | . | Alexander | IT_PROG | Reports to | Lex | AD_VP | . | Bruce | IT_PROG | Reports to | Alexander | IT_PROG | . | David | IT_PROG | Reports to | Alexander | IT_PROG | . | Valli | IT_PROG | Reports to | Alexander | IT_PROG | . | Diana | IT_PROG | Reports to | Alexander | IT_PROG | . But self-join is not very query efficient, and we’d like to use a more optimized method. | Oracle CONNECT BY . | Starting Point | Top-Down vs Bottom-Up | Pruning Branches in Top-Down | . | PostgreSQL WITH RECURSIVE | . ",
    "url": "/docs/db/sql/hierarchical-query.html",
    
    "relUrl": "/docs/db/sql/hierarchical-query.html"
  },"572": {
    "doc": "Hierarchical Query",
    "title": "Oracle CONNECT BY",
    "content": "Oracle provides the CONNECT BY clause to query hierarchical data. SELECT first_name emp_name, job_id emp_job, PRIOR first_name mgr_name, PRIOR job_id mgr_job FROM hr.employees START WITH manager_id IS NULL -- Start with the President CONNECT BY PRIOR employee_id = manager_id; . ",
    "url": "/docs/db/sql/hierarchical-query.html#oracle-connect-by",
    
    "relUrl": "/docs/db/sql/hierarchical-query.html#oracle-connect-by"
  },"573": {
    "doc": "Hierarchical Query",
    "title": "Starting Point",
    "content": "START WITH is used to specify the root of the hierarchy. In our example, that would be the President, who has no manager, hence manager_id IS NULL. ",
    "url": "/docs/db/sql/hierarchical-query.html#starting-point",
    
    "relUrl": "/docs/db/sql/hierarchical-query.html#starting-point"
  },"574": {
    "doc": "Hierarchical Query",
    "title": "Top-Down vs Bottom-Up",
    "content": "Depending on whether the connection was top-down or bottom-up in the hierarchy tree, the PRIOR keyword refers to either the parent or child. In our example above, our prior is the manager (parent) of the current employee, which was imposed by: . START WITH manager_id IS NULL -- Root was the President CONNECT BY PRIOR employee_id = manager_id -- From the root, connect to child . It is equivalent to saying use the parent’s employee_id to connect to the child’s manager_id. This is a top-down approach. A bottom-up approach would be to start with some employee and find all the managers up to the President. START WITH employee_id = 206 -- Start with some employee CONNECT BY PRIOR manager_id = employee_id; -- His manager_id will be used to connect to parent . Full Query SELECT prior first_name emp_name, prior job_id emp_job, first_name mgr_name, job_id mgr_job, LEVEL FROM hr.employees START WITH employee_id = 206 CONNECT BY PRIOR manager_id = employee_id; . LEVEL is a special keyword that returns the level of the hierarchy, with starting node as level 1. ",
    "url": "/docs/db/sql/hierarchical-query.html#top-down-vs-bottom-up",
    
    "relUrl": "/docs/db/sql/hierarchical-query.html#top-down-vs-bottom-up"
  },"575": {
    "doc": "Hierarchical Query",
    "title": "Pruning Branches in Top-Down",
    "content": "To prune branches in a top-down hierarchy, place additional conditions in the CONNECT BY clause: . SELECT first_name emp_name, job_id emp_job, PRIOR first_name mgr_name, PRIOR job_id mgr_job FROM hr.employees START WITH manager_id IS NULL -- Start with the President CONNECT BY PRIOR employee_id = manager_id AND job_id != 'IT_PROG'; -- Exclude all child branches with IT_PROG job . Putting the condition in WHERE does not have the effect of pruning branches, it merely filters the nodes after the hierarchy is built. ",
    "url": "/docs/db/sql/hierarchical-query.html#pruning-branches-in-top-down",
    
    "relUrl": "/docs/db/sql/hierarchical-query.html#pruning-branches-in-top-down"
  },"576": {
    "doc": "Hierarchical Query",
    "title": "PostgreSQL WITH RECURSIVE",
    "content": "To be added . CONNECT BY is Oracle-specific, but a similar hierarchical query can be achieved in PostgreSQL using WITH RECURSIVE. ",
    "url": "/docs/db/sql/hierarchical-query.html#postgresql-with-recursive",
    
    "relUrl": "/docs/db/sql/hierarchical-query.html#postgresql-with-recursive"
  },"577": {
    "doc": "Hyperparameters",
    "title": "Hyperparameters",
    "content": ". | Grid search | . ",
    "url": "/docs/data-science/notes/hyperparameters.html",
    
    "relUrl": "/docs/data-science/notes/hyperparameters.html"
  },"578": {
    "doc": "Hyperparameters",
    "title": "Grid search",
    "content": "To be added . ",
    "url": "/docs/data-science/notes/hyperparameters.html#grid-search",
    
    "relUrl": "/docs/data-science/notes/hyperparameters.html#grid-search"
  },"579": {
    "doc": "Type I and Type II Errors",
    "title": "Type I and Type II Errors",
    "content": ". | Truth Table | Type I Error | Type II Error . | Power of Test | Power Function | . | Effect Size | Relationship between $\\alpha$ and $\\beta$ | Sample Size Planning | . ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html"
  },"580": {
    "doc": "Type I and Type II Errors",
    "title": "Truth Table",
    "content": "In hypothesis testing, we have two truths: . | Null hypothesis ($H_0$) is true | Alternative hypothesis ($H_a$) is true | . Based on the results of the test, we make two decisions: . | Reject the null hypothesis | Fail to reject the null hypothesis | . Then we have a truth table of the following: . ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#truth-table",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#truth-table"
  },"581": {
    "doc": "Type I and Type II Errors",
    "title": "Type I Error",
    "content": "Type I error is when we reject the null hypothesis when it is actually true. Type I error is also called false positive. Why is Type I error called false positive? Remember that alternatitve hypothesis is what we want to prove. Try to see things from the perspective of the alternative hypothesis. By rejecting the null hypothesis, we’re basically saying yes (positive) to our alternative hypothesis that is actually false. Because we do not actually know the true state of the world, it is techinally impossible to know whether we have made a Type I error. However, we can control the probability of making a Type I error. Remember that we reject the null hypothesis when: . $$ p &lt; \\alpha $$ . Therefore, if we fix the value of $\\alpha$, we can control the probability of making a Type I error. So when we say $\\alpha = 0.05$, it means that we are willing to accept a 5% chance of making a Type I error. ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#type-i-error",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#type-i-error"
  },"582": {
    "doc": "Type I and Type II Errors",
    "title": "Type II Error",
    "content": "Type II error is when we fail to reject the null hypothesis when it is actually false. Type II error is also called false negative. Why is Type II error called false negative? Our alternative hypothesis was actually true, but we fail to confirm it / end up saying “no” (negative). The probability of making a Type II error is denoted by $\\beta$. ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#type-ii-error",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#type-ii-error"
  },"583": {
    "doc": "Type I and Type II Errors",
    "title": "Power of Test",
    "content": "The power of test is the probability of rejecting the null hypothesis when it is actually false. It is denoted by: . $$ 1 - \\beta $$ . The power of test is the probability of not making a Type II error. The most common power of test is $80\\%$. However, unlike $\\alpha$, we cannot control the value of $\\beta$ directly. There are a few factors that affect the power of test: . | Sample size: larger sample size $\\rightarrow$ higher power . | Higher sample size reduces variance, which in turn reduces overlap | . | Effect size: larger effect size $\\rightarrow$ higher power | . Keeping these factors in mind, we instead try to design our experiment so that we have a desired $1 - \\beta$. ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#power-of-test",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#power-of-test"
  },"584": {
    "doc": "Type I and Type II Errors",
    "title": "Power Function",
    "content": "The power of a test is the probability of rejecting the null hypothesis when the alternative hypothesis is true. When do we reject the null hypothesis? When the test statistic is in the rejection region: . \\[\\Pr(X \\in R)\\] However, this probability is dependent on the true parameter $\\theta$, because $\\theta$ determines the position and shape of the distributions, and thus the overlap. Example For example, if we have a normal distribution with mean $\\mu$, the power of test becomes the form of: . \\[1 - \\Phi(z)\\] where $\\Phi$ is the CDF of the standard normal distribution. The $z$-score is a function of the true mean $\\mu$, therefore the power of test for a normal distribution is a function of $\\mu$. Therefore, to emphasize the dependence on $\\theta$, we can express the power of test as a function of $\\theta$: . $$ B(\\theta) = \\Pr(X \\in R; \\theta) $$ . ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#power-function",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#power-function"
  },"585": {
    "doc": "Type I and Type II Errors",
    "title": "Effect Size",
    "content": "Effect size measures the relationship between two variables. Calculating the effect size depends on the type of test we are performing. For a t-test on the difference between two means, the effect size becomes the standardized difference between the two means or the Cohen’s d: . $$ d = \\frac{\\mu_A - \\mu_B}{\\sigma} $$ . For other tests, we can use other measures of effect size. It is important to pre-determine a relevant effect size (i.e. the blood pressure must decrease by a certain amount) before starting an experiment. Otherwise, depending on how we design our experiment, we might end up with a positive result even though the effect is not significant (i.e. miniscule reduction in blood pressure). ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#effect-size",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#effect-size"
  },"586": {
    "doc": "Type I and Type II Errors",
    "title": "Relationship between $\\alpha$ and $\\beta$",
    "content": "Ideally, we’d want to have both $\\alpha$ and $\\beta$ to be small. However, there is a trade-off between the two. If we try to reduce our false positive rate $\\alpha$, we will end up increasing our false negative rate $\\beta$. ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#relationship-between-alpha-and-beta",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#relationship-between-alpha-and-beta"
  },"587": {
    "doc": "Type I and Type II Errors",
    "title": "Sample Size Planning",
    "content": "$\\alpha$, $\\beta$, sample size $n$, and effect size are all related. There is a property that, if we fix any three of the four, the last one is pre-determined. When we plan an experiment, we usually have a desired $\\alpha$, $\\beta$, and effect size in mind. Then we can calculate the required sample size $n$. ",
    "url": "/docs/statistics/basics/hypothesis-testing-errors.html#sample-size-planning",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-errors.html#sample-size-planning"
  },"588": {
    "doc": "Hypothesis Testing Methods",
    "title": "Hypothesis Testing Methods",
    "content": ". | Selecting the Right Method . | What happens when you choose an inappropriate test? . | Using a t-Test for Non-Normal Data | . | . | Combination of Data Types . | Qualitative vs. Quantitative | Qualitative vs. Qualitative . | Contingency Table | . | Quantitative vs. Quantitative | . | Distribution of Quantitative Variable . | Parametric Test . | Normality | . | Nonparametric Test | Assumption of Homogeneity of Variance | . | Number of Samples . | Multiple Comparison Problem | How to Avoid the MCP | . | Hypothesis Testing for Qualitative Variable | . ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html"
  },"589": {
    "doc": "Hypothesis Testing Methods",
    "title": "Selecting the Right Method",
    "content": "As seen in the previous section, during hypothesis testing, we: . | Set up a null hypothesis and assume it true | Calculate a test statistic from the real data to test against the null hypothesis | . How one would set up the null hypothesis and what test statistic one would use depends on the type of data, number of samples, and the teting method. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#selecting-the-right-method",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#selecting-the-right-method"
  },"590": {
    "doc": "Hypothesis Testing Methods",
    "title": "What happens when you choose an inappropriate test?",
    "content": "Using a t-Test for Non-Normal Data . Suppose we use a t-test on a population without normality (and a small sample size). What happens is, even if we set the significance level to 0.05, the probability of making a Type I error does not match the significance level. If the tails are much skinnier than the t-distribution, then the probability of making a Type I error is much lower than 0.05. This in turn has the effect of increasing the probability of making a Type II error. This case is sometimes called conservative testing, because you are much more reluctant to accept the alternative hypothesis. Some may prefer this idea, but it still poses a problem. If the tails are much fatter than the t-distribution, then the probability of making a Type I error is much higher than 0.05. This is a big problem because it means that we are more prone to claiming something insignificant to be significant. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#what-happens-when-you-choose-an-inappropriate-test",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#what-happens-when-you-choose-an-inappropriate-test"
  },"591": {
    "doc": "Hypothesis Testing Methods",
    "title": "Combination of Data Types",
    "content": "There are two different types of data: . | Quantitative | Qualitative | . Suppose we are comparing two different variables. Depending on the combination of data types, the way we interpret our null hypothesis and test statistic will change. So it is important to first determine the data that we’re working with before selecting a hypothesis testing method. The difference in characteristic can be best illustrated with some figures. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#combination-of-data-types",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#combination-of-data-types"
  },"592": {
    "doc": "Hypothesis Testing Methods",
    "title": "Qualitative vs. Quantitative",
    "content": "For instance, suppose we were testing the effectiveness of a new drug by comparing some measurement (i.e. blood pressure) of people who take the drug and people who take a placebo. Then, we’d have a bar plot like the following: . In this case, we have a qualitative variable (i.e. drug vs. placebo), and a quantitative variable (i.e. body fat). ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#qualitative-vs-quantitative",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#qualitative-vs-quantitative"
  },"593": {
    "doc": "Hypothesis Testing Methods",
    "title": "Qualitative vs. Qualitative",
    "content": "Contingency Table . When we have two qualitative variables, we can use a contingency table to visualize the data. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#qualitative-vs-qualitative",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#qualitative-vs-qualitative"
  },"594": {
    "doc": "Hypothesis Testing Methods",
    "title": "Quantitative vs. Quantitative",
    "content": "When we have two quantitative variables, we can use a scatter plot to visualize the data. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#quantitative-vs-quantitative",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#quantitative-vs-quantitative"
  },"595": {
    "doc": "Hypothesis Testing Methods",
    "title": "Distribution of Quantitative Variable",
    "content": "When we have a quantitative variable, it is important to understand the distribution of the variable before selecting a hypothesis testing method. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#distribution-of-quantitative-variable",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#distribution-of-quantitative-variable"
  },"596": {
    "doc": "Hypothesis Testing Methods",
    "title": "Parametric Test",
    "content": "Hypothesis testing that assumes a specific distribution for the population (mathematically defined by parameters) is called a parametric test. For instance, the t-distribution assumes that the population distribution is normal. Hence, any t-test that we perform will be based on the assumption that the population distribution is normal. | One-Sample t-Test | Paired t-Test | Two-Sample t-Test | Welch’s t-Test | . Normality . If a set of data has normality, then it means that it was sampled from a population that is normally distributed. The majority of parametric tests assume that the population distribution is normal. There are a few ways to check for normality: . | Quantile-Quantile (Q-Q) Plot: a graphical/visual method | Shapiro-Wilk Test: a statistical method using hypothesis testing | Kolmogorov-Smirnov (K-S) Test: a statistical method using hypothesis testing | . When using hypothesis testing to check for normality, we set the null hypothesis to be that the data is normally distributed. There is also the issue of test multiplicity, which is the problem of performing multiple hypothesis tests on the same data set, because we perform the normality test before performing the actual test. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#parametric-test",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#parametric-test"
  },"597": {
    "doc": "Hypothesis Testing Methods",
    "title": "Nonparametric Test",
    "content": "Not all data follow a certain mathematical distribution. For data with asymmetry or outliers, statistics such as the mean and standard deviation are not reliable. In such cases, parametric tests are not appropriate. Hypothesis testing that does not depend on parameters, such as mean and standard deviation, is called a nonparametric test. When the distributions in comparison are similar/identical: . | Wilcoxon Rank Sum Test | Mann-Whitney U Test | . When the distributions in comparison are different: . | Fligner-Policello Test | Brunner-Munzel Test | . Still not recommended for tests with extremely different distributions. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#nonparametric-test",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#nonparametric-test"
  },"598": {
    "doc": "Hypothesis Testing Methods",
    "title": "Assumption of Homogeneity of Variance",
    "content": "When we compare the means of groups of data, we often assume that all comparison populations have the same variance. If the variance of all populations are the same, then we say that the they have homogeneity of variance. Some of the hypothesis tests to test for homogeneity of variance are: . | Bartlett’s Test | Levene’s Test | . The null hypothesis would be that the populations have homogeneity of variance. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#assumption-of-homogeneity-of-variance",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#assumption-of-homogeneity-of-variance"
  },"599": {
    "doc": "Hypothesis Testing Methods",
    "title": "Number of Samples",
    "content": "Number of samples refers to the number of groups of data that we have. Do not confuse this with the sample size $n$, which refers to the number of observations in a single group. If we had a quantitative, single variable that approximates a normal distribution, then we would use a one-sample t-test. If we had two quantitative variables that approximates a normal distribution, then we would use a two-sample t-test. The most common case is when we have two groups of data, but there are cases where we have to make a comparison between more than two groups. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#number-of-samples",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#number-of-samples"
  },"600": {
    "doc": "Hypothesis Testing Methods",
    "title": "Multiple Comparison Problem",
    "content": "Why not just perform multiple pairwise t-tests? . Suppose we have $m$ pairs of groups. For each pair, the Type I error rate is $\\alpha$. When we perform $m$ two-sample t-tests, the probability of making at least one Type I error is equal to 1 minus the probability of never making a Type I error in any of the tests: . $$ 1 - (1 - \\alpha)^m $$ . This type of error rate is actually called the family-wise error rate (FWER). For example, if we have 3 pairs of groups, and we set $\\alpha = 0.05$, then the probability of making at least one Type I error is: . $$ 1 - (1 - 0.05)^3 = 0.1426 &gt; 0.05 $$ . Which is dangerously higher than the desired Type I error rate of $\\alpha$. This is called the multiple comparison problem (MCP). ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#multiple-comparison-problem",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#multiple-comparison-problem"
  },"601": {
    "doc": "Hypothesis Testing Methods",
    "title": "How to Avoid the MCP",
    "content": "When there are more than two groups of data, we generally perform an omnibus test to test for significant difference between at least one pair of groups. If the result of the omnibus test turns out to be significant, (as necessary to the purpose of your research) we perform a post-hoc test that either tries to correct our results from the previous test or performs an additional test to see exactly which pairs of groups are different. Even though the name suggest otherwise, not all post-hoc tests pre-requisite a test like ANOVA. Some post-hoc tests like Bonferroni, Tukey, Dunnet, Williams, etc. can be used without ANOVA. Post-hoc tests are sometimes just called multiple comparison analysis as well. In addition, even though the omnibus test turns out to be insignificant, a post-hoc test may report significance. This may occur if the statistics and distributions used for the pre and post tests are different. So it is worth performing a standalone multiple comparison analysis. ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#how-to-avoid-the-mcp",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#how-to-avoid-the-mcp"
  },"602": {
    "doc": "Hypothesis Testing Methods",
    "title": "Tests for Multiple Comparison",
    "content": "Omnibus Test: . | ANOVA: parametric test | Kruskal-Wallis Test: nonparametric test | . Multiple Comparison Analysis / Post-Hoc Test: . | Bonferroni Correction | Tukey’s HSD Test: when comparing all groups to each other | Steel-Dwass Test: nonparametric version of Tukey’s HSD Test | Dunnett’s Test: when comparing all groups to a control group | Steel Test: nonparametric version of Dunnett’s Test | Williams Test: when you can rank/sort the groups into a specific order | Scheffe’s Test | Newman-Keuls Test | . ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#tests-for-multiple-comparison",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#tests-for-multiple-comparison"
  },"603": {
    "doc": "Hypothesis Testing Methods",
    "title": "Hypothesis Testing for Qualitative Variable",
    "content": "When the population is quantitative, we often set up a hypothesis test about the population mean. When the population is qualitative, we often set up a hypothesis test about: . $$ P: \\text{probability of an event occurring in the population} $$ . | Binomial test | Chi-square test of goodness of fit | Chi-square test of independence | . ",
    "url": "/docs/statistics/basics/hypothesis-testing-methods.html#hypothesis-testing-for-qualitative-variable",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing-methods.html#hypothesis-testing-for-qualitative-variable"
  },"604": {
    "doc": "Hypothesis Testing",
    "title": "Statistical Hypothesis Testing",
    "content": ". | Different Types of Data Analysis . | Confirmatory Data Analysis | Exploratory Data Analysis | . | Setting Up a Hypothesis . | Null Hypothesis | Alternative Hypothesis | Proof by Contradiction | . | p-Value | Significance Level $\\alpha$ . | Rejection Region . | One-Tailed Test / One-Sided Test | Two-Tailed Test / Two-Sided Test | . | Statistically Significant | . | Different Methods for Hypothesis Testing | Hypothesis Testing and Confidence Interval | Plotting Graphs in Hypothesis Testing . | Error Bars | Indicating Statistical Significance | . | Errors in Hypothesis Testing | . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#statistical-hypothesis-testing",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#statistical-hypothesis-testing"
  },"605": {
    "doc": "Hypothesis Testing",
    "title": "Different Types of Data Analysis",
    "content": " ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#different-types-of-data-analysis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#different-types-of-data-analysis"
  },"606": {
    "doc": "Hypothesis Testing",
    "title": "Confirmatory Data Analysis",
    "content": "Confirmatory data analysis is when the researcher already has a clear hypothesis and tries to test whether the data confirms or rejects it. For example, a researcher may hypothesize that a new drug is more effective than a placebo. Then, the researcher would collect data and perform statistical tests to compare the two groups. This page focuses on confirmatory data analysis. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#confirmatory-data-analysis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#confirmatory-data-analysis"
  },"607": {
    "doc": "Hypothesis Testing",
    "title": "Exploratory Data Analysis",
    "content": "Exploratory data analysis is when the researcher does not have a clear hypothesis and tries to find patterns or trends in the data. May be used to generate hypotheses for confirmatory data analysis. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#exploratory-data-analysis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#exploratory-data-analysis"
  },"608": {
    "doc": "Hypothesis Testing",
    "title": "Setting Up a Hypothesis",
    "content": "Say we want to test the effectiveness of a new drug. Let $A$ be population of blood pressure of people who take the new drug, and $B$ be the population of blood pressure of people who take a placebo. For the drug to be effective, we want $\\mu_A \\ne \\mu_B$, where $\\mu_A$ and $\\mu_B$ are the population means of $A$ and $B$. Notice that the hypothesis is about the population, not the sample. In hypothesis testing, we set up two hypotheses: . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#setting-up-a-hypothesis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#setting-up-a-hypothesis"
  },"609": {
    "doc": "Hypothesis Testing",
    "title": "Null Hypothesis",
    "content": "The null hypothesis is the negation of the hypothesis we want to confirm. With our example, the null hypothesis is: . $$ \\begin{equation} \\label{eq:null-h} \\tag{Null Hypothesis} \\mu_A = \\mu_B \\end{equation} $$ . This would mean that the drug is not effective. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#null-hypothesis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#null-hypothesis"
  },"610": {
    "doc": "Hypothesis Testing",
    "title": "Alternative Hypothesis",
    "content": "The alternative hypothesis is the hypothesis we want to confirm. With our example, the alternative hypothesis is: . $$ \\begin{equation} \\label{eq:alt-h} \\tag{Alternative Hypothesis} \\mu_A \\ne \\mu_B \\end{equation} $$ . This would mean that the drug is effective. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#alternative-hypothesis",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#alternative-hypothesis"
  },"611": {
    "doc": "Hypothesis Testing",
    "title": "Proof by Contradiction",
    "content": "Hypothesis testing takes the following approach: . | Set up the null hypothesis and alternative hypothesis | Assume a distribution where the null hypothesis is true | Calculate a test statistic from the real sample data | Test how this statistic fits into this assumed distribution | If the real data statistic is unlikely when the null hypothesis is true, then we reject the null hypothesis | By rejecting the null hypothesis, we accept the alternative hypothesis | Otherwise, we fail to reject the null hypothesis | . Notice the wording: fail to reject the null hypothesis. Failing to reject does not equal accepting the null hypothesis or rejecting the alternative hypothesis. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#proof-by-contradiction",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#proof-by-contradiction"
  },"612": {
    "doc": "Hypothesis Testing",
    "title": "p-Value",
    "content": "The $p$-value is: . The probability of observing the data in a distribution that assumes the null hypothesis is true. So if the p-value of a real data is low, then the data is unlikely to occur when the null hypothesis is true. Which in turn means that the null hypothesis is unlikely to be true. So the next question is: . | What is considered a low $p$-value? | . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#p-value",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#p-value"
  },"613": {
    "doc": "Hypothesis Testing",
    "title": "Significance Level $\\alpha$",
    "content": "Whether we reject the null hypothesis or not depends on the significance level, commonly denoted by $\\alpha$. Most commonly used significance level is $\\alpha = 0.05$. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#significance-level-alpha",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#significance-level-alpha"
  },"614": {
    "doc": "Hypothesis Testing",
    "title": "Rejection Region",
    "content": "The rejection region $R$ refers to the area on the left and right tails of the distribution that we would reject the null hypothesis. More formally \\[R = \\{ x \\mid T(x) &lt; -c \\lor T(x) &gt; c \\}\\] Where $T(x)$ is the test statistic and $c$ is the critical value. For $\\alpha = 0.05$, the rejection region would be on each side of the distribution, 2.5% each. One-Tailed Test / One-Sided Test . One-tailed test is when we reject the null hypothesis by considering only one tail of the distribution, and thus $\\alpha / 2$. Two-Tailed Test / Two-Sided Test . Two-tailed test is when we reject the null hypothesis by considering both tails of the distribution, and thus the whole $\\alpha$. Unless there is a reason to use one-tailed test, it is much more common to use two-tailed test. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#rejection-region",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#rejection-region"
  },"615": {
    "doc": "Hypothesis Testing",
    "title": "Statistically Significant",
    "content": "If the $p$-value is less than $\\alpha$, then the data is statistically significant. $$ p &lt; \\alpha $$ . Then we reject the null hypothesis and accept the alternative hypothesis. Otherwise, we have no grounds to reject the null hypothesis. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#statistically-significant",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#statistically-significant"
  },"616": {
    "doc": "Hypothesis Testing",
    "title": "Different Methods for Hypothesis Testing",
    "content": "Go to page . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#different-methods-for-hypothesis-testing",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#different-methods-for-hypothesis-testing"
  },"617": {
    "doc": "Hypothesis Testing",
    "title": "Hypothesis Testing and Confidence Interval",
    "content": "The relationship between confidence interval and hypothesis testing is like a mirror image. $$ \\text{Significance Level}\\; \\alpha = 1 - \\text{Confidence Level} $$ . With a 95 CI, we infer a likely (with 95% chance) range of the population statistic based on the sample statistic computed from real data. Then we test if our null hypothesis fits into this range. For instance, with our example null hypothesis, we can calculate a 95 CI for $\\mu_A - \\mu_B$, and see if it contains 0. If not, then we reject the null hypothesis. On the other hand, with hypothesis testing, we first assume that the null hypothesis is true, and then calculate a sample statistic from the real data. Then we test how this sample statistic fits into this assumed null hypothesis. For instance, with our example null hypothesis, we obtain a distribution of $\\mu_A - \\mu_B$ of which the mean is 0. Then we calculate the probability $p$ of observing the real data, and see if it is less than $\\alpha = 0.05$. If so, then we reject the null hypothesis. ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#hypothesis-testing-and-confidence-interval",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#hypothesis-testing-and-confidence-interval"
  },"618": {
    "doc": "Hypothesis Testing",
    "title": "Plotting Graphs in Hypothesis Testing",
    "content": " ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#plotting-graphs-in-hypothesis-testing",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#plotting-graphs-in-hypothesis-testing"
  },"619": {
    "doc": "Hypothesis Testing",
    "title": "Error Bars",
    "content": "With bar plots and scatter plots, you’ll often see error bars. It is important to describe in the legends which metric is used for the error bars, because it can mean different things. Suppose we have a bar plot with sample mean as the variable, . | Standard deviation . | The error bars represent the dispersion of the sample | Does not represent a probability | . | Standard error of the mean . | The error bars represent the probability of the sample mean | . | Confidence interval | . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#error-bars",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#error-bars"
  },"620": {
    "doc": "Hypothesis Testing",
    "title": "Indicating Statistical Significance",
    "content": "In figures and charts, we commonly use asterisks ($*$) to indicate statistical significance. Although the figure below does not, make sure to indicate what the asterisks mean in the legends. Commonly used symbols are: . | $p &lt; 0.05$: $*$ | $p &lt; 0.01$: $**$ | $p &lt; 0.001$: $***$ | Non-significant: $\\text{N.S.}$ | . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#indicating-statistical-significance",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#indicating-statistical-significance"
  },"621": {
    "doc": "Hypothesis Testing",
    "title": "Errors in Hypothesis Testing",
    "content": "Go to page . ",
    "url": "/docs/statistics/basics/hypothesis-testing.html#errors-in-hypothesis-testing",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html#errors-in-hypothesis-testing"
  },"622": {
    "doc": "Hypothesis Testing",
    "title": "Hypothesis Testing",
    "content": " ",
    "url": "/docs/statistics/basics/hypothesis-testing.html",
    
    "relUrl": "/docs/statistics/basics/hypothesis-testing.html"
  },"623": {
    "doc": "As IDE Extensions",
    "title": "As IDE Extensions",
    "content": "To be added . | Extensions | GitHub Copilot | . ",
    "url": "/docs/others/vim/ide.html",
    
    "relUrl": "/docs/others/vim/ide.html"
  },"624": {
    "doc": "As IDE Extensions",
    "title": "Extensions",
    "content": ". | VSCode: vscodevim.vim | IntelliJ: IdeaVim | . ",
    "url": "/docs/others/vim/ide.html#extensions",
    
    "relUrl": "/docs/others/vim/ide.html#extensions"
  },"625": {
    "doc": "As IDE Extensions",
    "title": "GitHub Copilot",
    "content": "If you’re using GitHub Copilot, the default key mapping for Dismiss an inline suggestion is Esc. However, since Esc is used to switch to normal mode in Vim, you’d probably want to map it to something else. | VSCode: editor.action.inlineSuggest.hide | IntelliJ: Copilot: Hide Completions in Editor | . References: . | Configure GitHub Copilot: Visual Studio Code | Configure GitHub Copilot: JetBrains | . ",
    "url": "/docs/others/vim/ide.html#github-copilot",
    
    "relUrl": "/docs/others/vim/ide.html#github-copilot"
  },"626": {
    "doc": "Independent and Identically Distributed (IID)",
    "title": "Independent and Identically Distributed (IID)",
    "content": "IID (aka iid, i.i.d.) is a commonly used assumption in statistical modeling, which simplifies the underlying mathematics of a complex system. When we have a set or sequence of i.i.d. random variables, it means: . | Independent: Each random variable is independent of each other | Identically Distributed: Each random variable has the same probability distribution . Do not mistake identical for uniform distribution. | . If we have IID random variables $X_1,\\dots, X_n$, each with the same CDF $F$, we denote: . $$ X_1,\\dots, X_n \\sim F $$ . Additionally, the random variables $X_1, \\dots, X_n$ are called random sample of size $n$ from $F$. ",
    "url": "/docs/statistics/notes/iid.html",
    
    "relUrl": "/docs/statistics/notes/iid.html"
  },"627": {
    "doc": "Image and Kernel",
    "title": "Image and Kernel",
    "content": ". | Domain and Codomain | Image / Range . | Column Space | . | Kernel / Nullspace . | Homogeneous System | . | Rank-Nullity Theorem | . ",
    "url": "/docs/linalg/basics/image-kernel.html",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html"
  },"628": {
    "doc": "Image and Kernel",
    "title": "Domain and Codomain",
    "content": "For $\\Phi: V \\rightarrow W$, $V$ is the domain and $W$ is the codomain of $\\Phi$. ",
    "url": "/docs/linalg/basics/image-kernel.html#domain-and-codomain",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html#domain-and-codomain"
  },"629": {
    "doc": "Image and Kernel",
    "title": "Image / Range",
    "content": "For $\\Phi: V \\rightarrow W$, the image or range of $\\Phi$ is the set of all vectors in $W$ that are mapped from $V$. $$ \\mathrm{Im}(\\Phi) = \\{\\Phi(\\mathbf{x}) \\in W \\mid \\mathbf{x} \\in V\\} $$ . Also denoted as $\\Phi(V)$. ",
    "url": "/docs/linalg/basics/image-kernel.html#image--range",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html#image--range"
  },"630": {
    "doc": "Image and Kernel",
    "title": "Column Space",
    "content": "Let $A$ be the linear transformation matrix of $\\Phi$. Then the columns of $A$ span $\\mathrm{Im}(\\Phi)$: . \\[\\mathrm{Im}(\\Phi) = \\mathrm{span}[\\mathbf{a}_1, \\dots, \\mathbf{a}_n]\\] Therefore $\\mathrm{Im}(\\Phi)$ is also called the column space of $A$. | $\\mathrm{rank}(A) = \\mathrm{dim}(\\mathrm{Im}(\\Phi))$. | . ",
    "url": "/docs/linalg/basics/image-kernel.html#column-space",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html#column-space"
  },"631": {
    "doc": "Image and Kernel",
    "title": "Kernel / Nullspace",
    "content": "For $\\Phi: V \\rightarrow W$, the kernel or nullspace of $\\Phi$ is the set of all vectors in $V$ that are mapped to the zero vector in $W$. $$ \\mathrm{ker}(\\Phi) = \\{\\mathbf{x} \\in V \\mid \\Phi(\\mathbf{x}) = \\mathbf{0}\\} $$ . Also denoted as $\\Phi^{-1}(\\mathbf{0})$. | Since $\\Phi(\\mathbf{0}) = \\mathbf{0}$, kernel is never empty. | If kernel is a singleton set of ${\\mathbf{0}}$, then $\\Phi$ is injective (one-to-one). | Also means the linear transformation matrix corresponding to $\\Phi$ has linearly independent columns. | . | . ",
    "url": "/docs/linalg/basics/image-kernel.html#kernel--nullspace",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html#kernel--nullspace"
  },"632": {
    "doc": "Image and Kernel",
    "title": "Homogeneous System",
    "content": "Let $A$ be the linear transformation matrix of $\\Phi$. Then $\\mathrm{ker}(\\Phi)$ is the solution set of the homogeneous system $A\\mathbf{x} = \\mathbf{0}$. ",
    "url": "/docs/linalg/basics/image-kernel.html#homogeneous-system",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html#homogeneous-system"
  },"633": {
    "doc": "Image and Kernel",
    "title": "Rank-Nullity Theorem",
    "content": ". ARAKI Satoru, CC BY-SA 4.0, via Wikimedia Commons Let $A$ be an $m \\times \\boldsymbol{n}$ linear transformation matrix of $\\Phi: V \\rightarrow W$. So $V \\in \\mathbb{R}^n$ and $W \\in \\mathbb{R}^m$. Then the rank-nullity theorem states that: . $$ \\begin{gather*} \\boldsymbol{n} = \\rank(A) + \\text{nullity}(A) \\\\[0.5em] \\Updownarrow \\\\[0.5em] \\dim(V) = \\dim(\\mathrm{Im}(\\Phi)) + \\dim(\\ker(\\Phi)) \\end{gather*} $$ . ",
    "url": "/docs/linalg/basics/image-kernel.html#rank-nullity-theorem",
    
    "relUrl": "/docs/linalg/basics/image-kernel.html#rank-nullity-theorem"
  },"634": {
    "doc": "Docker Images",
    "title": "Docker Images",
    "content": ". | Docker Image / Images . | Image | Images | . | Dangling images . | Remove dangling images | . | . ",
    "url": "/docs/docker/images.html",
    
    "relUrl": "/docs/docker/images.html"
  },"635": {
    "doc": "Docker Images",
    "title": "Docker Image / Images",
    "content": "You may have noticed that there are two Docker CLI commands that seem similar . | docker image | docker images | . There is a bit of a difference between the two. Image . Actually builds, pulls, and removes images. This command is used to physically manage the images. You can of course list images as well. docker image ls . Images . This has to do with displaying in a high-level fashion what kind of images exist. Primary purpose is to display image metadata. docker images . ",
    "url": "/docs/docker/images.html#docker-image--images",
    
    "relUrl": "/docs/docker/images.html#docker-image--images"
  },"636": {
    "doc": "Docker Images",
    "title": "Dangling images",
    "content": "When you do . docker images -a | grep '&lt;none&gt;' # OR docker image ls -a | grep '&lt;none&gt;' . Or check the Images tab in Docker Desktop, you may see a bunch of images with the name and tag of &lt;none&gt;. This is a residue / intermediate image created from previous image builds. It seems they exist as a cached layer for subsequent builds. But it is safe to delete them. Remove dangling images . You can remove these dangling images by . docker image prune . docker image prune -a not only removes dangling images but also any unused images. This can come in handy, but if you’re keeping any pulled Docker registry images (unused in containers at the moment) in your local storage for some reason, this is not what you want. ",
    "url": "/docs/docker/images.html#dangling-images",
    
    "relUrl": "/docs/docker/images.html#dangling-images"
  },"637": {
    "doc": "Demo",
    "title": "Demo",
    "content": " ",
    "url": "/docs/demo/",
    
    "relUrl": "/docs/demo/"
  },"638": {
    "doc": "MySQL/MariaDB",
    "title": "MySQL/MariaDB",
    "content": " ",
    "url": "/docs/db/mysql/",
    
    "relUrl": "/docs/db/mysql/"
  },"639": {
    "doc": "Algorithms",
    "title": "Algorithm Quick Notes",
    "content": "Random notes on algorithm. ",
    "url": "/docs/compsci/algo/#algorithm-quick-notes",
    
    "relUrl": "/docs/compsci/algo/#algorithm-quick-notes"
  },"640": {
    "doc": "Algorithms",
    "title": "Algorithms",
    "content": " ",
    "url": "/docs/compsci/algo/",
    
    "relUrl": "/docs/compsci/algo/"
  },"641": {
    "doc": "Computing",
    "title": "Computing",
    "content": "Random notes on computing. ",
    "url": "/docs/compsci/computing/",
    
    "relUrl": "/docs/compsci/computing/"
  },"642": {
    "doc": "SQL",
    "title": "SQL",
    "content": "Many of the example queries in this page refer to: . | Pagila Database | . Pagila Schema . Image Source ",
    "url": "/docs/db/sql/",
    
    "relUrl": "/docs/db/sql/"
  },"643": {
    "doc": "Computer Science",
    "title": "Computer Science",
    "content": "Random notes on computer science. ",
    "url": "/docs/compsci/",
    
    "relUrl": "/docs/compsci/"
  },"644": {
    "doc": "ngrok",
    "title": "ngrok",
    "content": "Official Guide . | Installation | Setup | Forward a local port to a public URL | . ",
    "url": "/docs/others/ngrok/",
    
    "relUrl": "/docs/others/ngrok/"
  },"645": {
    "doc": "ngrok",
    "title": "Installation",
    "content": "brew install ngrok/ngrok/ngrok # OR brew install --cask ngrok . Check installation via: . ngrok -h . ",
    "url": "/docs/others/ngrok/#installation",
    
    "relUrl": "/docs/others/ngrok/#installation"
  },"646": {
    "doc": "ngrok",
    "title": "Setup",
    "content": "To use ngrok you must be signed up for an account. You can do this via the official website. Once you login, you will be given an authtoken to authenticate ngrok. Copy the value and authenticate in terminal: . ngrok config add-authtoken $AUTH_TOKEN . ",
    "url": "/docs/others/ngrok/#setup",
    
    "relUrl": "/docs/others/ngrok/#setup"
  },"647": {
    "doc": "ngrok",
    "title": "Forward a local port to a public URL",
    "content": "Run the following command: . ngrok http $PORT . The public URL will be displayed in the terminal: ... Forwarding https://some.url.given.ngrok.io -&gt; http://localhost:$PORT ... For free plans, the URL changes every time you restart ngrok. ",
    "url": "/docs/others/ngrok/#forward-a-local-port-to-a-public-url",
    
    "relUrl": "/docs/others/ngrok/#forward-a-local-port-to-a-public-url"
  },"648": {
    "doc": "Vim",
    "title": "Vim",
    "content": "To be added . | Window | Key mapping | NerdTree | . ",
    "url": "/docs/others/vim/",
    
    "relUrl": "/docs/others/vim/"
  },"649": {
    "doc": "Vim",
    "title": "Window",
    "content": "To split, . :sp # Split window horizontally :vsp # Split window vertically . To navigate between windows, . &lt;Ctrl&gt; + w + w # Navigate between viewports &lt;Ctrl&gt; + w + h/j/k/l # Navigate to respective direction . ",
    "url": "/docs/others/vim/#window",
    
    "relUrl": "/docs/others/vim/#window"
  },"650": {
    "doc": "Vim",
    "title": "Key mapping",
    "content": "There are 6 types of mapping commands: . :map # Recursive / Works in normal, visual, select and operator modes :noremap # Non-recursive version :nmap # Recursive / Works in normal mode :nnoremap :vmap # Recursive / Works in visual mode :vnoremap . Type one of the above to list the current key mappings. To set new mappings, add them to ~/.vim/vimrc: . \"Example nnoremap &lt;C-n&gt; :&lt;NERDTreeToggle&lt;CR&gt; . ",
    "url": "/docs/others/vim/#key-mapping",
    
    "relUrl": "/docs/others/vim/#key-mapping"
  },"651": {
    "doc": "Vim",
    "title": "NerdTree",
    "content": "Set shortcut to toggle NerdTree: . nnoremap nerd :&lt;NERDTreeToggle&lt;CR&gt; . In NerdTree, type ? to toggle help. References: . | Key Mapping | . ",
    "url": "/docs/others/vim/#nerdtree",
    
    "relUrl": "/docs/others/vim/#nerdtree"
  },"652": {
    "doc": "Vue",
    "title": "Vue",
    "content": " ",
    "url": "/docs/vue/",
    
    "relUrl": "/docs/vue/"
  },"653": {
    "doc": "Jenkins",
    "title": "Jenkins",
    "content": " ",
    "url": "/docs/jenkins/",
    
    "relUrl": "/docs/jenkins/"
  },"654": {
    "doc": "Git/GitHub",
    "title": "Git/GitHub",
    "content": " ",
    "url": "/docs/git-hub/",
    
    "relUrl": "/docs/git-hub/"
  },"655": {
    "doc": "Git/GitHub",
    "title": "You probably already know what this is",
    "content": "Version control system; awesome stuff. ",
    "url": "/docs/git-hub/#you-probably-already-know-what-this-is",
    
    "relUrl": "/docs/git-hub/#you-probably-already-know-what-this-is"
  },"656": {
    "doc": "Kubernetes",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/kubernetes/",
    
    "relUrl": "/docs/kubernetes/"
  },"657": {
    "doc": "Stats/ML Quick Notes",
    "title": "Statistics / Machine Learning Quick Notes",
    "content": "To be added . Fragments of things I learned. They may be moved to a separate category later. ",
    "url": "/docs/statistics/notes/#statistics--machine-learning-quick-notes",
    
    "relUrl": "/docs/statistics/notes/#statistics--machine-learning-quick-notes"
  },"658": {
    "doc": "Stats/ML Quick Notes",
    "title": "Stats/ML Quick Notes",
    "content": " ",
    "url": "/docs/statistics/notes/",
    
    "relUrl": "/docs/statistics/notes/"
  },"659": {
    "doc": "Git",
    "title": "Git",
    "content": " ",
    "url": "/docs/git-hub/git/",
    
    "relUrl": "/docs/git-hub/git/"
  },"660": {
    "doc": "ML/DL",
    "title": "Machine Learning and Deep Learning",
    "content": " ",
    "url": "/docs/data-science/ml-dl/#machine-learning-and-deep-learning",
    
    "relUrl": "/docs/data-science/ml-dl/#machine-learning-and-deep-learning"
  },"661": {
    "doc": "ML/DL",
    "title": "Referenced Books",
    "content": ". | An Introduction to Statistical Learning | . ",
    "url": "/docs/data-science/ml-dl/#referenced-books",
    
    "relUrl": "/docs/data-science/ml-dl/#referenced-books"
  },"662": {
    "doc": "ML/DL",
    "title": "ML/DL",
    "content": " ",
    "url": "/docs/data-science/ml-dl/",
    
    "relUrl": "/docs/data-science/ml-dl/"
  },"663": {
    "doc": "GitHub",
    "title": "GitHub",
    "content": " ",
    "url": "/docs/git-hub/github/",
    
    "relUrl": "/docs/git-hub/github/"
  },"664": {
    "doc": "Security",
    "title": "Security",
    "content": " ",
    "url": "/docs/security/",
    
    "relUrl": "/docs/security/"
  },"665": {
    "doc": "Vault",
    "title": "Vault",
    "content": ". | Installation . | With Homebrew | With Docker | . | Server configuration file . | storage | listener | log level | ttl (Time-To-Live) | ui | . | . ",
    "url": "/docs/security/vault/",
    
    "relUrl": "/docs/security/vault/"
  },"666": {
    "doc": "Vault",
    "title": "Installation",
    "content": "With Homebrew . brew tap hashicorp/tap . brew install hashicorp/tap/vault . With Docker . Official docker image is vault. Three volumes can be mounted. | /vault/logs to persist logs | /vault/file to persist data when file is the storage backnd for Vault | /vault/config for Vault server configuration file | . By default, Vault will run in container as a development server (vault server -dev). Vault entrypoint checks for a command and uses it as a subcommand to vault. If you do not wish to run in development mode, set command to server. To prevent memory leaking information to disk through swaps, container must be run with cap-add set to IPC_LOCK. To disable memory locking due to setcap issues, set SKIP_SETCAP environment variable to a non-empty value. In non-development environment, you must add disable_mlock: true to the configuration file to disable this functionality. Place a configuration file (either using .hcl or .json) for the Vault server in /vault/config. Vault will automatically read it. ",
    "url": "/docs/security/vault/#installation",
    
    "relUrl": "/docs/security/vault/#installation"
  },"667": {
    "doc": "Vault",
    "title": "Server configuration file",
    "content": "You can use either HCL or JSON, but I will use HCL because I prefer its syntax. The entire set of configuration can be found here. The following are some of the most basic configurations to run a Vault server. storage . The list of all storage backends can be found here. The simplest storage backend is the filesystem. Example: . storage \"file\" { path = \"/vault/file\" } . listener . listener configures where Vault should listen for requests. There is only one configuration right now which is TCP. listener \"tcp\" { # If you're using docker, and you want to access the web UI # Use address = \"0.0.0.0:8200\" address = \"127.0.0.1:8200\" # You must explicitly disable tls if you're not using it tls_disable = \"false\" | \"true\" (string) # Else tls_cert_file = \"...\" tls_key_file = \"...\" } . Make sure to secure your connection with tls (Let’s Encrypt or so) if you expect your Vault server to have non-local http requests, which usually is the case when being used for production. log level . Specifies log level. log_level = \"trace\" | \"debug\" | \"error\" | \"warn\" | \"info\" . ttl (Time-To-Live) . max_lease_ttl = \"768h\" (string) default_least_ttl = \"700h\" (string) . These set the lease expiration time for non-root tokens and secrets. default_least_ttl cannot be greater than max_lease_ttl. max_lease_ttl can be overriden later for different token lease methods. ui . ui = false | true (boolean) . Set to true to enable web UI. ",
    "url": "/docs/security/vault/#server-configuration-file",
    
    "relUrl": "/docs/security/vault/#server-configuration-file"
  },"668": {
    "doc": "PGP Key",
    "title": "PGP Key",
    "content": ". | OpenPGP | GnuPG . | Basic usage | Editing a key | Encrypt and decrypt | Error | . | Key ID . | Fingerprint | Long key ID | Short key ID | . | . ",
    "url": "/docs/security/pgp/",
    
    "relUrl": "/docs/security/pgp/"
  },"669": {
    "doc": "PGP Key",
    "title": "OpenPGP",
    "content": "To be added . ",
    "url": "/docs/security/pgp/#openpgp",
    
    "relUrl": "/docs/security/pgp/#openpgp"
  },"670": {
    "doc": "PGP Key",
    "title": "GnuPG",
    "content": "Basic usage . # Follow prompt to create keys gpg --full-generate-key # List public keys gpg --list-keys # List secret keys gpg --list-secret-keys . Editing a key . gpg --edit-key &lt;key-id&gt; . To fix the expiration setting, for example, do: . gpg&gt; expire ...prompt... Then save the settings by: . gpg&gt; save . Related files will be stored in ~/.gnupg. Encrypt and decrypt . To be added . The last % of decrypted output is unused. Error . In case you get any error of the following: . $ gpg: public key decryption failed: Inappropriate ioctl for device $ gpg: decryption failed: Inappropriate ioctl for device . or . $ gpg: public key decryption failed: No such file or directory $ gpg: decryption failed: No such file or directory . Try: . echo $GPG_TTY . If it shows a not a tty error, set: . export GPG_TTY=$(tty) . You can place them in your shell configuration file. ",
    "url": "/docs/security/pgp/#gnupg",
    
    "relUrl": "/docs/security/pgp/#gnupg"
  },"671": {
    "doc": "PGP Key",
    "title": "Key ID",
    "content": "The key ID is calculated from your public key and the creation timestamp. Fingerprint . The long hex printed with gpg --list-keys is the fingerprint of the key. Long key ID . The last 16 hex of the fingerprint. Short key ID . The last 8 hex of the fingerprint. You can provide either one of the three for a key ID. ",
    "url": "/docs/security/pgp/#key-id",
    
    "relUrl": "/docs/security/pgp/#key-id"
  },"672": {
    "doc": "DS Quick Notes",
    "title": "Data Science Quick Notes",
    "content": "To be added . Fragments of things I learned. They may be moved to a separate category later. ",
    "url": "/docs/data-science/notes/#data-science-quick-notes",
    
    "relUrl": "/docs/data-science/notes/#data-science-quick-notes"
  },"673": {
    "doc": "DS Quick Notes",
    "title": "DS Quick Notes",
    "content": " ",
    "url": "/docs/data-science/notes/",
    
    "relUrl": "/docs/data-science/notes/"
  },"674": {
    "doc": "SSH",
    "title": "SSH",
    "content": " ",
    "url": "/docs/security/ssh/",
    
    "relUrl": "/docs/security/ssh/"
  },"675": {
    "doc": "Basic Stats for Data",
    "title": "Basic Statistics for Data Analysis",
    "content": "Summary of a book on basic statistics for data analysis. With my own interpretation and explanations… . Related Pages . | Hypothesis Testing . | Hypothesis Testing Methods | Type I and Type II Errors | Comparing Means in Parametric Tests | Welch’s t-Test | Comparing with Nonparametric Tests | ANOVA | Post-Hoc Test | Binomial Test | . | . ",
    "url": "/docs/statistics/basics/#basic-statistics-for-data-analysis",
    
    "relUrl": "/docs/statistics/basics/#basic-statistics-for-data-analysis"
  },"676": {
    "doc": "Basic Stats for Data",
    "title": "Basic Stats for Data",
    "content": " ",
    "url": "/docs/statistics/basics/",
    
    "relUrl": "/docs/statistics/basics/"
  },"677": {
    "doc": "Home",
    "title": "Online Long-Term Memory",
    "content": "Personal documentation of itty bitties and all the hacky decisions I’ve made throughout my learning. ",
    "url": "/#online-long-term-memory",
    
    "relUrl": "/#online-long-term-memory"
  },"678": {
    "doc": "Home",
    "title": "Disclaimer",
    "content": "The information contained in this document is not necessarily correct or comprehensive. It will be biased in many ways and may contain naive and pitiful approaches made by a novice. Its sole purpose is to document my footsteps to reference in the future. ",
    "url": "/#disclaimer",
    
    "relUrl": "/#disclaimer"
  },"679": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/",
    
    "relUrl": "/"
  },"680": {
    "doc": "Data Science",
    "title": "Data Science",
    "content": " ",
    "url": "/docs/data-science/#data-science",
    
    "relUrl": "/docs/data-science/#data-science"
  },"681": {
    "doc": "Data Science",
    "title": "Data Science",
    "content": ". ",
    "url": "/docs/data-science/",
    
    "relUrl": "/docs/data-science/"
  },"682": {
    "doc": "Math",
    "title": "Math Quick Notes",
    "content": "Random quick notes on mathematical concepts. ",
    "url": "/docs/compsci/math/#math-quick-notes",
    
    "relUrl": "/docs/compsci/math/#math-quick-notes"
  },"683": {
    "doc": "Math",
    "title": "Math",
    "content": " ",
    "url": "/docs/compsci/math/",
    
    "relUrl": "/docs/compsci/math/"
  },"684": {
    "doc": "Database",
    "title": "Database",
    "content": " ",
    "url": "/docs/db/",
    
    "relUrl": "/docs/db/"
  },"685": {
    "doc": "DB Quick Notes",
    "title": "DB Quick Notes",
    "content": " ",
    "url": "/docs/db/notes/",
    
    "relUrl": "/docs/db/notes/"
  },"686": {
    "doc": "Linux",
    "title": "Linux",
    "content": " ",
    "url": "/docs/linux/",
    
    "relUrl": "/docs/linux/"
  },"687": {
    "doc": "LeetCode",
    "title": "LeetCode",
    "content": "LeetCode problems and solutions. ",
    "url": "/docs/compsci/leetcode/",
    
    "relUrl": "/docs/compsci/leetcode/"
  },"688": {
    "doc": "Flutter",
    "title": "Flutter",
    "content": " ",
    "url": "/docs/flutter/",
    
    "relUrl": "/docs/flutter/"
  },"689": {
    "doc": "AWS",
    "title": "AWS",
    "content": " ",
    "url": "/docs/aws/",
    
    "relUrl": "/docs/aws/"
  },"690": {
    "doc": "Docker",
    "title": "Docker",
    "content": " ",
    "url": "/docs/docker/",
    
    "relUrl": "/docs/docker/"
  },"691": {
    "doc": "Docker",
    "title": "Explained in a really dumb way",
    "content": "You build an image that contains all the resources that compose a project. This packaging makes porting really easy because all the resources that made your project run at one time is now completely captured in it. You could think of this as a snapshot of your project. This image can be run in a docker container. A container is basically a process isolated from your computer. Think of it as a mini sandbox that mimics your system. Inside a container resources will be downloaded, installed, and copied just as you would normally, but whatever that happened during a container execution will not meddle with your actual computer (unless you specifically configure it to). ",
    "url": "/docs/docker/#explained-in-a-really-dumb-way",
    
    "relUrl": "/docs/docker/#explained-in-a-really-dumb-way"
  },"692": {
    "doc": "Linear Algebra Basics",
    "title": "Linear Algebra Basics",
    "content": " ",
    "url": "/docs/linalg/basics/",
    
    "relUrl": "/docs/linalg/basics/"
  },"693": {
    "doc": "Java",
    "title": "Java",
    "content": " ",
    "url": "/docs/java/",
    
    "relUrl": "/docs/java/"
  },"694": {
    "doc": "SSL",
    "title": "SSL",
    "content": " ",
    "url": "/docs/security/ssl/",
    
    "relUrl": "/docs/security/ssl/"
  },"695": {
    "doc": "Others",
    "title": "List of All Documentations",
    "content": " ",
    "url": "/docs/others/#list-of-all-documentations",
    
    "relUrl": "/docs/others/#list-of-all-documentations"
  },"696": {
    "doc": "Others",
    "title": "Others",
    "content": " ",
    "url": "/docs/others/",
    
    "relUrl": "/docs/others/"
  },"697": {
    "doc": "Things I Learned",
    "title": "Things I Learned",
    "content": "List of itty bitty things that I want to keep a note of, but couldn’t quite find a category to place yet. Contents listed here may be moved or grouped with other pages if more related contents are produced. ",
    "url": "/docs/learned/",
    
    "relUrl": "/docs/learned/"
  },"698": {
    "doc": "IntelliJ",
    "title": "IntelliJ",
    "content": " ",
    "url": "/docs/others/intellij/",
    
    "relUrl": "/docs/others/intellij/"
  },"699": {
    "doc": "Linear Algebra Quick Notes",
    "title": "Linear Algebra Quick Notes",
    "content": "To be added . Fragments of things I learned and recaps. ",
    "url": "/docs/linalg/notes/",
    
    "relUrl": "/docs/linalg/notes/"
  },"700": {
    "doc": "Database",
    "title": "Database",
    "content": ". | ACID / BASE . | ACID | BASE | . | CAP Theory | ORM | . ",
    "url": "/docs/learned/db/",
    
    "relUrl": "/docs/learned/db/"
  },"701": {
    "doc": "Database",
    "title": "ACID / BASE",
    "content": "ACID . | Atomicity: All operations in a transaction are atomic, meaning they either all succeed or none happen (single failure rolls back the entire transaction). | Consistency: A transaction does not break any invariants set by DB. A DB must be in a valid state before and after a transaction. | Isolation: The end result of a DB after concurrent transactions and sequential transactions must be the same. All transactions must operate as if they were operating on an isolated DB. | Durability: Once a transaction is committed, the commit is retained even after a system failure. | . ACID transaction has been the norm for relational databases. It is more conservative in a sense and more suitable in domains where data safety is critical (financial institutes). However, it is generally considered to be slower due to heavy locking. BASE . | Basic Availiability: Reading and writing is available whenever possible. | Soft-state: State of the system do not ensure write consistency, and replica nodes are not guranteed to be consistent with each other. | Eventually consistent: Given time, system will eventually converge to a known state. | . Where throughput is deemed higher importance than immediate consistency, ACID may be too restrictive. BASE transaction is more optimistic in locking compared to ACID. Many NoSQL databases adhere to BASE when data safety is less of a risk. ",
    "url": "/docs/learned/db/#acid--base",
    
    "relUrl": "/docs/learned/db/#acid--base"
  },"702": {
    "doc": "Database",
    "title": "CAP Theory",
    "content": "TBA . ",
    "url": "/docs/learned/db/#cap-theory",
    
    "relUrl": "/docs/learned/db/#cap-theory"
  },"703": {
    "doc": "Database",
    "title": "ORM",
    "content": "TBA . References: . | Data Consistency Models | . ",
    "url": "/docs/learned/db/#orm",
    
    "relUrl": "/docs/learned/db/#orm"
  },"704": {
    "doc": "Linear Algebra",
    "title": "Linear Algebra",
    "content": " ",
    "url": "/docs/linalg/",
    
    "relUrl": "/docs/linalg/"
  },"705": {
    "doc": "OAuth 2.0",
    "title": "OAuth 2.0",
    "content": ". | What is an OAuth 2.0 protocol? . | OpenID | . | Client types . | Client secret | Public clients | Confidential clients | . | Authorization flow . | Implicit flow | Authorization code flow | Authorization code flow with PKCE | . | Authorization server API . | Authorize | Token | . | PKCE Code Challenge . | Code verifier | Code challenge | . | . ",
    "url": "/docs/learned/oauth2/",
    
    "relUrl": "/docs/learned/oauth2/"
  },"706": {
    "doc": "OAuth 2.0",
    "title": "What is an OAuth 2.0 protocol?",
    "content": "According to Google, it is an ‘open standard for access delegation’. While it sounds intimidating, it is essentially made to ‘let this application access my Google photos’, ‘let this site use my Facebook contacts’, etc. So it was developed as method for authorization to a 3rd party resource. Some terms: . | Resource owner: that’s the user (you) wanting to grant access | Resource server: the API you want to access | Client: application requesting access | User Agent: the thing user is using to talk to client (browser, mobile app) | Authorization server: authorizes and grants access tokens to client | . OpenID . One thing to note is the word authorization, and you shoud not to confuse it with authentication. When I first read about OAuth, I thought, “Well isn’t this the ‘Sign in with Google/Facebook’ button that I see quite a lot on websites these days?”. It sort of is, because the protocol behind that button is OpenID which is built on top of OAuth 2.0. So the way they operate are very similar, but it is good to know the difference that OAuth is for authorization and OpenID builds a layer on top of OAuth for authentication. ",
    "url": "/docs/learned/oauth2/#what-is-an-oauth-20-protocol",
    
    "relUrl": "/docs/learned/oauth2/#what-is-an-oauth-20-protocol"
  },"707": {
    "doc": "OAuth 2.0",
    "title": "Client types",
    "content": "There are two different types of clients in OAuth. One is a public client and the other is a confidential client. To understand the difference, you need to know the term client secret. Client secret . A client secret is nothing more than a random string generated. It is usually created by generating a secure random string of 256-bit (32 bytes) and then converting it to hex. This value should never be revealed to the outside except for the authorizing server and the client app. Hence the name ‘client secret’. Inside your code, client secret will be used to successfully authorize users. But the issue that arises is where should the client store this secret. Public clients . If the client cannot keep the client secret a secret, it is called a public client. For example, single-page apps that expose everything on the browser with no backend or mobile apps that can have their HTTPS request intercepted and revealed are considered public clients. In case of an SPA, everything is exposed on the browser. Chrome inspect will reveal the source code, local storage, session, and cookies. So storing client secret is infeasible. For a mobile app, apparently it is possible to provide a fake HTTPS certificate that goes to your own API. So you can catch an HTTPS leaving the phone, route it to a different API, have that API make a request to the initial intended API, and return the response to phone as if it would normally, while the proxy API in the middle can inspect all the requests (which may contain the client secret at some point). Confidential clients . This is typically a traditional web server or anything backed by a server where nobody can take a peek at the source code or have the requests intercepted. ",
    "url": "/docs/learned/oauth2/#client-types",
    
    "relUrl": "/docs/learned/oauth2/#client-types"
  },"708": {
    "doc": "OAuth 2.0",
    "title": "Authorization flow",
    "content": "There are a few different flows, but I will only document three of them: implicit flow, authorization code flow, authorization code flow with PKCE. The general process is as below: . | Client sends request to autorization server | Client gets an authorization code back | Client sends request to a token endpoint | Client gets an access token | Client places this token in a header when sending a request to resource server | . Implicit flow . Implicit flow is much more simplified. After step 1, implicit flow skips right to step 4. Because the access token is revealed on the browser url, this is considered an insecure lecay method. Authorization code flow . Client gets an authorization code back as a request parameter embedded in the url. The client then uses this code to exchange it for an access token. Usually secure random strings such as state and client secret are used to validate the process. Authorization code flow with PKCE . For public clients that cannot keep any secret strings, PKCE (Proof Key for Code Exchange) is implemented. This step includes an additional code challenge and verifying step. ",
    "url": "/docs/learned/oauth2/#authorization-flow",
    
    "relUrl": "/docs/learned/oauth2/#authorization-flow"
  },"709": {
    "doc": "OAuth 2.0",
    "title": "Authorization server API",
    "content": "Typically there are two endpoints during the process. Authorize . Typical request is an HTTPS GET to a path that often looks like oauth/authorize. Parameters . | response_type: code for authorization code flow and token for implicit flow | client_id: client app id | redirect_uri: absolute uri to be redirected after authorization | state: a random value that will be returned back in redirect. This is a protection against CSRF. | scope: the scope of resources you want to protect | code_challenge_method (PKCE only): the encryption used in code challenge; typically S256 for SHA256 | code_challenge (PKCE only): the generated challenge from code_verifier | . Token . After extracting the authorization code from the redirect url, you make an HTTPS POST request to oauth/token. Header: . | Authorization: Basic Base64_url_encode('client_id:client_secret') | Content-Type: application/x-www-form-urlencoded | . Body: . | grant_type: authorization_code, refresh_token, client_credentials | client_id | redirect_uri: should be the same as the one used for authorization request | scope | code: extracted from url | code_verifier: proof key for the code_challenge | . Response: . { \"id_token\": \"~\", \"access_token\": \"~\", \"refresh_token\": \"~\", \"token_type\": \"Bearer\", \"expires_in\": 10000 } . ",
    "url": "/docs/learned/oauth2/#authorization-server-api",
    
    "relUrl": "/docs/learned/oauth2/#authorization-server-api"
  },"710": {
    "doc": "OAuth 2.0",
    "title": "PKCE Code Challenge",
    "content": "Code verifier . According to here it is a ‘cryptographically random string using the characters A-Z, a-z, 0-9, and the punctuation characters -._~ (hyphen, period, underscore, and tilde), between 43 and 128 characters long’. Code challenge . Code challenge is created by hashing the code_verifier with SHA256 and then encoding as a BASE6-URL string. References: . | OAuth: PKCE | AWS Cognito: AUTHORIZE | AWS Cognito: TOKEN | Auth0: PKCE | . ",
    "url": "/docs/learned/oauth2/#pkce-code-challenge",
    
    "relUrl": "/docs/learned/oauth2/#pkce-code-challenge"
  },"711": {
    "doc": "zsh",
    "title": "zsh &amp; Shell setup",
    "content": ". | Install zsh . | OS X | Ubuntu | . | Change to zsh | Install oh-my-zsh | Change Theme | Recommended plugins . | zsh-syntax-highlighting | zsh-autosuggestions | fzf | z | fasd | . | Preferred Iterm2/Gnome Terminal color schemes | . ",
    "url": "/docs/others/zsh/#zsh--shell-setup",
    
    "relUrl": "/docs/others/zsh/#zsh--shell-setup"
  },"712": {
    "doc": "zsh",
    "title": "Install zsh",
    "content": "OS X . brew install zsh . Ubuntu . sudo apt install zsh . ",
    "url": "/docs/others/zsh/#install-zsh",
    
    "relUrl": "/docs/others/zsh/#install-zsh"
  },"713": {
    "doc": "zsh",
    "title": "Change to zsh",
    "content": "Make zsh the default shell . chsh -s $(which zsh) . Confirm shell has changed . echo $SHELL . In Ubuntu, if echo $SHELL or echo $0 still shows bash, try logging out and log back in. Hopefully, shell would have been changed and zsh-newuser-install will pop up. ",
    "url": "/docs/others/zsh/#change-to-zsh",
    
    "relUrl": "/docs/others/zsh/#change-to-zsh"
  },"714": {
    "doc": "zsh",
    "title": "Install oh-my-zsh",
    "content": "Assuming you have curl installed, . sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" . In case of a change refer to here for a new link. ",
    "url": "/docs/others/zsh/#install-oh-my-zsh",
    
    "relUrl": "/docs/others/zsh/#install-oh-my-zsh"
  },"715": {
    "doc": "zsh",
    "title": "Change Theme",
    "content": "My preferred theme is Powerlevel10k. To install it as an Oh My Zsh theme, . git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k . Then in ~/.zshrc, set ZSH_THEME . ZSH_THEME=\"powerlevel10k/powerlevel10k\" . When using Iterm2, the recommended fonts are automatically installed. Otherwise, install the fonts from here. ",
    "url": "/docs/others/zsh/#change-theme",
    
    "relUrl": "/docs/others/zsh/#change-theme"
  },"716": {
    "doc": "zsh",
    "title": "Recommended plugins",
    "content": "zsh-syntax-highlighting . See here for details. git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting . To activate the plugin, go to .zshrc and add zsh-syntax-highlighting to plugins. zsh-autosuggestions . See here for details. git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions . To activate the plugin, go to .zshrc and add zsh-autosuggestions to plugins. fzf . See here for details. # OS X brew install fzf # Ubuntu sudo apt install fzf . Then activate the plugin in .zshrc. z . Feature that was included in fasd. Simply add z to oh-my-zsh plugins in .zshrc. fasd . DEPRECATED . See here for details. # OS X brew install fasd # Ubuntu sudo apt install fasd . Then activate the plugin in .zshrc. ",
    "url": "/docs/others/zsh/#recommended-plugins",
    
    "relUrl": "/docs/others/zsh/#recommended-plugins"
  },"717": {
    "doc": "zsh",
    "title": "Preferred Iterm2/Gnome Terminal color schemes",
    "content": "Look for the following themes in Iterm2 / Gough: . | Snazzy | Tomorrow Night | . ",
    "url": "/docs/others/zsh/#preferred-iterm2gnome-terminal-color-schemes",
    
    "relUrl": "/docs/others/zsh/#preferred-iterm2gnome-terminal-color-schemes"
  },"718": {
    "doc": "zsh",
    "title": "zsh",
    "content": " ",
    "url": "/docs/others/zsh/",
    
    "relUrl": "/docs/others/zsh/"
  },"719": {
    "doc": "Python Environments",
    "title": "Python Environments",
    "content": ". | Why do you need them? | Python version manager vs Virtual environments . | Typical use case | . | Notes / sanity check | . ",
    "url": "/docs/python/envs/",
    
    "relUrl": "/docs/python/envs/"
  },"720": {
    "doc": "Python Environments",
    "title": "Why do you need them?",
    "content": "Every Python project comes with different requirements. For example: . |   | Python | Library1 | Library2 | Library3 | . | Project A | 3.6 | x | 1.1.2 | 2.3.0 | . | Project B | 3.10 | x | 2.3.1 | 3.0.1 | . | Project C | 2.7 | 1.4.0 | 1.1.2 | x | . As the number of projects grow, managing different versions of Python and their packages are going to be increasingly difficult. Switching between them and resolving conflicts is one hassle, but removing them after use is also a pain. Environments, however, remembers the context of a project, and keeps them independent of other project’s context. Hence, project collaboration and management becomes much easier with environments. ",
    "url": "/docs/python/envs/#why-do-you-need-them",
    
    "relUrl": "/docs/python/envs/#why-do-you-need-them"
  },"721": {
    "doc": "Python Environments",
    "title": "Python version manager vs Virtual environments",
    "content": "It can be confusing because they all go by the name environment. Long story short, . | Version manager: manages Python versions | Virtual environment: manages libraries | . You’ll probably end up needing both. Typical use case . You install and select a Python version to use with a version manager. Then create a virtual environment for a project using that Python version. For example (not comprehensive): . | pyenv: version manager | Conda: version manager + virtual environment | venv: virtual environment | Pipenv: virtual environment | Poetry: virtual environment | . ",
    "url": "/docs/python/envs/#python-version-manager-vs-virtual-environments",
    
    "relUrl": "/docs/python/envs/#python-version-manager-vs-virtual-environments"
  },"722": {
    "doc": "Python Environments",
    "title": "Notes / sanity check",
    "content": ". | which python / which python3 will point to the python binary | which pip / which pip3 will point the pip binary | pip -V / pip3 -V will point to the site-packages | conda run which python / conda run python -V does the expected for the base conda env or the active env | pipenv run which python / pipenv run python -V does the expected for the current root directory env | However, pipenv run pip -V will create an env for the cwd and add pip to the Pipfile for cwd | . ",
    "url": "/docs/python/envs/#notes--sanity-check",
    
    "relUrl": "/docs/python/envs/#notes--sanity-check"
  },"723": {
    "doc": "MongoDB",
    "title": "MongoDB",
    "content": "On-prem community edition . | Install MongoDB (locally) | Run and stop MongoDB (locally) | . ",
    "url": "/docs/others/mongodb/",
    
    "relUrl": "/docs/others/mongodb/"
  },"724": {
    "doc": "MongoDB",
    "title": "Install MongoDB (locally)",
    "content": "brew tap mongodb/brew brew install mongodb-community@4.4 . This installs . | mongod server | mongos sharded cluster query router | mongo shell | . And also . | /usr/local/etc/mongod.conf configuration file | /usr/local/var/log/mongodb log directory | /usr/local/var/mongodb data directory | . And finally MongoDB Database Tools . Location varies by system. Check with brew --prefix. ",
    "url": "/docs/others/mongodb/#install-mongodb-locally",
    
    "relUrl": "/docs/others/mongodb/#install-mongodb-locally"
  },"725": {
    "doc": "MongoDB",
    "title": "Run and stop MongoDB (locally)",
    "content": "Run MongoDB as a macOS service (recommended) . brew services start mongodb-community@4.4 # Verify it is running (should be in started status) brew service list | grep mongodb-community . You can then use the mongo shell via . mongo . Stop MongoDB . brew services stop mongodb-community@4.4 . References: . | MongoDB: Install | . ",
    "url": "/docs/others/mongodb/#run-and-stop-mongodb-locally",
    
    "relUrl": "/docs/others/mongodb/#run-and-stop-mongodb-locally"
  },"726": {
    "doc": "Network",
    "title": "Network Basics",
    "content": ". | IP Address . | Private IP Address . | IPv4: RFC1918 | . | . | . ",
    "url": "/docs/learned/network/#network-basics",
    
    "relUrl": "/docs/learned/network/#network-basics"
  },"727": {
    "doc": "Network",
    "title": "IP Address",
    "content": "IP (Internet Protocol) address is a unique address that identifies a device on a network using an Internet Protocol. Private IP Address . Reserved range for private networks . IPv4: RFC1918 . | [24-bit block] CIDR: 10.0.0.0/8, Subnet mask: 255.0.0.0 | [20-bit block] CIDR: 172.16.0.0/12, Subnet mask: 255.240.0.0 | [16-bit block] CIDR: 192.168.0.0/16, Subnet mask: 255.255.0.0 | . ",
    "url": "/docs/learned/network/#ip-address",
    
    "relUrl": "/docs/learned/network/#ip-address"
  },"728": {
    "doc": "Network",
    "title": "Network",
    "content": " ",
    "url": "/docs/learned/network/",
    
    "relUrl": "/docs/learned/network/"
  },"729": {
    "doc": "Scrapy",
    "title": "Scrapy",
    "content": "To be added . Python web scraper . Official Documentation . | Installation | Start a project | Create a spider . | Show available spider templates | Generate spider | Check generated spiders | . | . ",
    "url": "/docs/others/scrapy/",
    
    "relUrl": "/docs/others/scrapy/"
  },"730": {
    "doc": "Scrapy",
    "title": "Installation",
    "content": "pip install Scrapy # or poetry add Scrapy . ",
    "url": "/docs/others/scrapy/#installation",
    
    "relUrl": "/docs/others/scrapy/#installation"
  },"731": {
    "doc": "Scrapy",
    "title": "Start a project",
    "content": "cd &lt;proj-root&gt; scrapy startproject &lt;proj-name&gt; . ",
    "url": "/docs/others/scrapy/#start-a-project",
    
    "relUrl": "/docs/others/scrapy/#start-a-project"
  },"732": {
    "doc": "Scrapy",
    "title": "Create a spider",
    "content": "First navigate to a specific Scrapy project: . cd &lt;proj-name&gt; . Check that you are indeed in the right project by: . $ scrapy Scrapy x.x.x - project: &lt;proj-name&gt; . Show available spider templates . $ scrapy genspider -l basic crawl csvfeed xmlfeed . Generate spider . scrapy genspider -t crawl &lt;spider-name&gt; &lt;allowed-domain&gt; . Check generated spiders . scrapy list . ",
    "url": "/docs/others/scrapy/#create-a-spider",
    
    "relUrl": "/docs/others/scrapy/#create-a-spider"
  },"733": {
    "doc": "Python",
    "title": "Python",
    "content": " ",
    "url": "/docs/python/",
    
    "relUrl": "/docs/python/"
  },"734": {
    "doc": "Volta",
    "title": "Volta",
    "content": "Javascript command-line tool manager . Official Guide . | Why Volta? | Installation . | Using Homebrew | Using installation script | . | Usage example . | Install | . | curl SSL certificate problem . | Workaround (Not Recommended) | Fix | . | . ",
    "url": "/docs/others/volta/",
    
    "relUrl": "/docs/others/volta/"
  },"735": {
    "doc": "Volta",
    "title": "Why Volta?",
    "content": "If you’ve ever tried uninstalling Node or installing a newer version of Node for a project, you may have found that it can get quite ugly. Volta keeps all of the binaries in your home directory, and makes it easy to install and uninstall different versions. You can also use Volta to pin a specified Node version for each project, much like the Python virtual environments. ",
    "url": "/docs/others/volta/#why-volta",
    
    "relUrl": "/docs/others/volta/#why-volta"
  },"736": {
    "doc": "Volta",
    "title": "Installation",
    "content": "Using Homebrew . brew install volta . Add to ~/.zshrc: . export VOLTA_HOME=\"$HOME/.volta\" export PATH=\"$VOLTA_HOME/bin:$PATH\" . Using installation script . curl https://get.volta.sh | bash . Necessary PATH will be added to .zshrc. If you get a curl: (60) SSL certificate problem: certificate has expired error, you may be using an old version of OpenSSL or LibreSSL. Workaround/Fix . ",
    "url": "/docs/others/volta/#installation",
    
    "relUrl": "/docs/others/volta/#installation"
  },"737": {
    "doc": "Volta",
    "title": "Usage example",
    "content": "Install . volta install node volta install yarn . ",
    "url": "/docs/others/volta/#usage-example",
    
    "relUrl": "/docs/others/volta/#usage-example"
  },"738": {
    "doc": "Volta",
    "title": "curl SSL certificate problem",
    "content": "This is a known issue (as of Sep. 2021). The issue is not due to Volta but is related to an older version of OpenSSL/LibreSSL. See here for details, but long story short: . | Update to OpenSSL 1.1 for secure connection using LetsEncrypt certificates. | . Workaround (Not Recommended) . As suggested by this comment, one hacky workaround is to just use an insecure (-k) curl: . curl -k https://get.volta.sh &gt; volta.sh . Then change line 10 of volta.sh to use an insecure curl as well: . 9| get_latest_release() { 10| curl -k --silent \"https://volta.sh/latest-version\" 11| } . Then run: . bash volta.sh . It works, but defeats the whole purpose of certificates. Fix . Better approach is to install the brew packaged curl, as it uses OpenSSL 1.1 while the shipped curl uses an older version of LibreSSL. ",
    "url": "/docs/others/volta/#curl-ssl-certificate-problem",
    
    "relUrl": "/docs/others/volta/#curl-ssl-certificate-problem"
  },"739": {
    "doc": "Homebrew",
    "title": "Homebrew",
    "content": "Package manager for macOS . Official Page . | Installation . | Opt-out of Homebrew analytics | . | Useful commands . | brew search | brew install | brew uninstall | brew list | brew deps | brew info | brew update | brew upgrade | brew doctor | brew autoremove | . | Installing other versions of Casks | Notes . | keg-only | . | . ",
    "url": "/docs/others/homebrew/",
    
    "relUrl": "/docs/others/homebrew/"
  },"740": {
    "doc": "Homebrew",
    "title": "Installation",
    "content": "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" . Then follow the instructions. In my case, I had to add /opt/homebrew/bin to PATH. echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' &gt;&gt; ~/.zprofile eval \"$(/opt/hombrew/bin/brew shellenv)\" # Or just open a new tab . Opt-out of Homebrew analytics . brew analytics off . ",
    "url": "/docs/others/homebrew/#installation",
    
    "relUrl": "/docs/others/homebrew/#installation"
  },"741": {
    "doc": "Homebrew",
    "title": "Useful commands",
    "content": "brew search . brew search ${package} . brew install . brew install ${package} brew install --cask ${package} . cask is an extension to Hombrew formulae, mainly for GUI applications . brew uninstall . brew uninstall ${package} . brew uninstall won’t let you remove a package if it is a dependency of another package. You could force uninstall, but you generally don’t wanna do this. brew list . brew list brew list --versions . brew deps . brew deps ${package} brew deps --installed brew deps --installed --tree . Shows dependencies. brew info . brew info ${package} . Shows a summary of information of a formula/cask. Summary includes dependencies, current stable version, install status, etc. brew update . brew update . Updates brew itself. brew upgrade . brew upgrade # Upgrade all brew upgrade ${package} . Upgrades installed packages that are outdated. brew doctor . brew doctor . Diagnoses problems or errors regarding, but not limited to, brew. Possible warnings or errors may include, interruption during brew install, failure to symlink binary, deprecated Xcode, etc. brew autoremove . brew autoremove . This removes dangling dependencies that were not removed with the parent package. ",
    "url": "/docs/others/homebrew/#useful-commands",
    
    "relUrl": "/docs/others/homebrew/#useful-commands"
  },"742": {
    "doc": "Homebrew",
    "title": "Installing other versions of Casks",
    "content": "If you want to install an older version of a cask, . brew tap homebrew/cask-versions . Then search for the version you want. brew search ${package} . ",
    "url": "/docs/others/homebrew/#installing-other-versions-of-casks",
    
    "relUrl": "/docs/others/homebrew/#installing-other-versions-of-casks"
  },"743": {
    "doc": "Homebrew",
    "title": "Notes",
    "content": "keg-only . By default, brew installed binaries are symlinked to /usr/local/bin, but keg-only formulae are not. This is usually due to the preexistence of an older OS shipped default version, typically in /usr/bin. Although not symlinked in /usr/local/bin, keg-only or not, every brew formula is kept in /usr/local/Cellar and every formula is symlinked in /usr/local/opt. Which means you can add /usr/local/opt/&lt;formula&gt;/bin to PATH (just making sure it goes in the front of /usr/bin so that it is found first). All of the information here can be found during install or brew info Caveats. ",
    "url": "/docs/others/homebrew/#notes",
    
    "relUrl": "/docs/others/homebrew/#notes"
  },"744": {
    "doc": "Terraform",
    "title": "Terraform",
    "content": " ",
    "url": "/docs/terraform/",
    
    "relUrl": "/docs/terraform/"
  },"745": {
    "doc": "Terraform",
    "title": "What is Terraform?",
    "content": "Infrastructure as Code (IaC): Terraform is a software tool that codes the infrastructure with a declarative configuration language. Your entire infrastructure is managed through a set of declarations. The benefit of IaC is that everything is collected within a single tool. This gets rid of the pain of having to jump to different tools every time you want to configure your resources. ",
    "url": "/docs/terraform/#what-is-terraform",
    
    "relUrl": "/docs/terraform/#what-is-terraform"
  },"746": {
    "doc": "Time Series Analysis",
    "title": "Time Series Analysis",
    "content": "Includes summary of multiple books and online resources on time series analysis. With my own interpretation and explanations… . References: . | Practical Time Series Analysis: Prediction with Statistics and Machine Learning by Aileen Nielsen | . ",
    "url": "/docs/data-science/time-series/",
    
    "relUrl": "/docs/data-science/time-series/"
  },"747": {
    "doc": "Chrome Extensions",
    "title": "Chrome Extensions",
    "content": "To be added . Official Documentation . | Manifest V3 / V2 | To view the contents of extension storage | . ",
    "url": "/docs/others/chrome-ext/",
    
    "relUrl": "/docs/others/chrome-ext/"
  },"748": {
    "doc": "Chrome Extensions",
    "title": "Manifest V3 / V2",
    "content": "To be added . ",
    "url": "/docs/others/chrome-ext/#manifest-v3--v2",
    
    "relUrl": "/docs/others/chrome-ext/#manifest-v3--v2"
  },"749": {
    "doc": "Chrome Extensions",
    "title": "To view the contents of extension storage",
    "content": "Open the background in inspect view mode. Then type the following: . chrome.storage.local.get(console.log) . ",
    "url": "/docs/others/chrome-ext/#to-view-the-contents-of-extension-storage",
    
    "relUrl": "/docs/others/chrome-ext/#to-view-the-contents-of-extension-storage"
  },"750": {
    "doc": "R",
    "title": "R",
    "content": " ",
    "url": "/docs/data-science/r/",
    
    "relUrl": "/docs/data-science/r/"
  },"751": {
    "doc": "DBeaver",
    "title": "DBeaver",
    "content": ". | Installation | Export settings and connections | Download Vim plugin | SSH Troubleshooting | . ",
    "url": "/docs/others/dbeaver/",
    
    "relUrl": "/docs/others/dbeaver/"
  },"752": {
    "doc": "DBeaver",
    "title": "Installation",
    "content": "brew install --cask dbeaver-community . ",
    "url": "/docs/others/dbeaver/#installation",
    
    "relUrl": "/docs/others/dbeaver/#installation"
  },"753": {
    "doc": "DBeaver",
    "title": "Export settings and connections",
    "content": "On MacOS, workspace configurations are stored in ~/Library/DBeaverData. Refer to link for different OS. To export the settings and connections, copy ~/Library/DBeaverData/workspace6/General/.dbeaver from source to target. ",
    "url": "/docs/others/dbeaver/#export-settings-and-connections",
    
    "relUrl": "/docs/others/dbeaver/#export-settings-and-connections"
  },"754": {
    "doc": "DBeaver",
    "title": "Download Vim plugin",
    "content": "On the top nagivation bar, click Help &gt; Install New Software.... Then type the following URL in the Work with field and click Add. http://vrapper.sourceforge.net/update-site/stable . Enter Vrapper for the Name field and click OK. Then select Vrapper and any other optional Vim plugins to install. Click Next to install the plugin. I personally find optional Surround.vim plugin to be very useful. After installation, restart DBeaver. ",
    "url": "/docs/others/dbeaver/#download-vim-plugin",
    
    "relUrl": "/docs/others/dbeaver/#download-vim-plugin"
  },"755": {
    "doc": "DBeaver",
    "title": "SSH Troubleshooting",
    "content": "While SSHing into a remote server, if you get the following error: . invalid privatekey: [B@540..... You are probably using a key algorithm incompatible for JSch implementation. To solve this navigate to Connection settings -&gt; SSH. Open Advanced settings, and change Implementation to SSHJ. ",
    "url": "/docs/others/dbeaver/#ssh-troubleshooting",
    
    "relUrl": "/docs/others/dbeaver/#ssh-troubleshooting"
  },"756": {
    "doc": "Flask",
    "title": "Flask",
    "content": " ",
    "url": "/docs/flask/",
    
    "relUrl": "/docs/flask/"
  },"757": {
    "doc": "Statistics",
    "title": "Statistics / Machine Learning",
    "content": "Statistics with most of the focus on how they apply to machine learning. ",
    "url": "/docs/statistics/#statistics--machine-learning",
    
    "relUrl": "/docs/statistics/#statistics--machine-learning"
  },"758": {
    "doc": "Statistics",
    "title": "Statistics",
    "content": " ",
    "url": "/docs/statistics/",
    
    "relUrl": "/docs/statistics/"
  },"759": {
    "doc": "Jekyll",
    "title": "Jekyll",
    "content": ". | Ruby installation with rbenv | Install Jekyll | Create a Jekyll blog | Bundler / Gemfile . | Install gems listed in Gemfile | Adding gems to project | Removing gems | Execute a command in the context of the bundle | . | . ",
    "url": "/docs/others/jekyll/",
    
    "relUrl": "/docs/others/jekyll/"
  },"760": {
    "doc": "Jekyll",
    "title": "Ruby installation with rbenv",
    "content": "I’ve decided to use rbenv only because I didn’t want to mess with the system ruby that comes with macOS (I am currently using Catalina). Assuming you have Homebrew installed. # Install rbenv and ruby-build brew install rbenv # Set up rbenv integration with your shell rbenv init # Then follow the instruction that appears on screen . # rbenv init will ask you to add the following to .zshrc eval \"$(rbenv init - zsh)\" . Now that you have installed rbenv, create a folder that will contain your Jekyll site. I will refer to the folder as blog. Once created, move into blog. cd blog # List latest stable versions rbenv install -l # I chose 3.0.2 rbenv install 3.0.2 rbenv rehash # Following creates .ruby-version in cwd rbenv local 3.0.2 # Confirm ruby version in folder ruby -v . All the ruby versions are installed in ~/.rbenv. ",
    "url": "/docs/others/jekyll/#ruby-installation-with-rbenv",
    
    "relUrl": "/docs/others/jekyll/#ruby-installation-with-rbenv"
  },"761": {
    "doc": "Jekyll",
    "title": "Install Jekyll",
    "content": "Before installing the gems, check where they are being installed via . # Refer to INSTALLATION DIRECTORY / GEM PATHS gem env # OR gem env home . Rest of the stuff are just my preferences/me being a clean freak. Now, the Jekyll documentation tells you to do a local install with the --user-install flag. If you’re not using rbenv this is indeed more desirable as it installs your gems to your home directory (like ~/.gem). However, for my purpose and with rbenv it was unnecessary. As you’ll notice by inspecting the gem env outputs, the global install directory (INSTALLATION DIRECTORY) is already in your home directory (~/.rbenv/versions/...). On the other hand, the user install directory (USER INSTALLATION DIRECTORY) is set to some local folder (~/.local/share/gem/ruby/...). I personally prefer having all the packages contained in ~/.rbenv, so I simply chose to omit --user-install and do: . End of me being a freak. gem install jekyll bundler . ",
    "url": "/docs/others/jekyll/#install-jekyll",
    
    "relUrl": "/docs/others/jekyll/#install-jekyll"
  },"762": {
    "doc": "Jekyll",
    "title": "Create a Jekyll blog",
    "content": "First create a new Jekyll project by . # Assuming you're still in the blog folder jekyll new . It will create a default website you can test locally. # Will generate a static html site in _site bundle exec jekyll serve # With live-reloading bundle exec jekyll serve --livereload . If you get any errors regarding webrick: cannot load such file -- webrick (LoadError), add webrick by bundle add webrick. This is due to ruby 3 excluding webrick as a default bundled gem. ",
    "url": "/docs/others/jekyll/#create-a-jekyll-blog",
    
    "relUrl": "/docs/others/jekyll/#create-a-jekyll-blog"
  },"763": {
    "doc": "Jekyll",
    "title": "Bundler / Gemfile",
    "content": "Think of the bundler as the npm/yarn of Ruby and Gemfile as the package.json of Node projects. When you create a new Jekyll project with jekyll new, a Gemfile is automatically created. This Gemfile will list the basic gem dependencies to create a basic Jekyll site. Install gems listed in Gemfile . If there already exists a Gemfile, you can download all the necessary gems for this project by: . bundle install . These gems are usually installed in the same place they would be when you call gem install. Exact location can be confirmed by bundle show &lt;gem-name&gt;. Adding gems to project . When you need to add another gem for your project, you can either: . | Type it out yourself in Gemfile | . # Gemfile gem \"just-the-docs\" . Then, . bundle install . OR . | Use bundle add | . bundle add just-the-docs . If the gems already exist in system, it’ll just use that. If they don’t already, it will download the gem for you. Removing gems . When you no longer need a gem for the project, . bundle remove just-the-docs . This doesn’t remove the gem from the system. Only removes it from your project’s Gemfile. Execute a command in the context of the bundle . Every bundled gem will be made available in the context of the command you wish to execute even if these gems are not in the executable path. bundle exec jekyll build . References: . | Markdown Supported Languages | . ",
    "url": "/docs/others/jekyll/#bundler--gemfile",
    
    "relUrl": "/docs/others/jekyll/#bundler--gemfile"
  },"764": {
    "doc": "Inferential Statistics",
    "title": "Inferential Statistics",
    "content": ". | Recap: Why Inferential Statistics? . | Overview of the idea | Modeling | . | Random Sampling . | Simple Random Sampling | Stratified Sampling | Other Sampling Methods | . | Sampling Distribution . | Sample Statistic as a Random Variable | . | Sampling Distribution of the Sample Mean . | Law of Large Numbers | Central Limit Theorem | . | Estimators . | Consistent Estimator | Unbiased Estimator | . | Sampling Error . | Standard Error of the Mean | . | Confidence Interval . | Confidence Interval for the Mean | . | t-Distribution . | t-Score | t-Distribution vs Standard Normal Distribution | Degrees of Freedom | Confidence Interval Using t-Distribution . | Narrowing the Confidence Interval | . | . | . ",
    "url": "/docs/statistics/basics/inferencial-stats.html",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html"
  },"765": {
    "doc": "Inferential Statistics",
    "title": "Recap: Why Inferential Statistics?",
    "content": "Our goal is to understand the population. We have two main options: . | Complete enumeration | Sample survey | . Because complete enumeration is unrealistic, we need to figure out how to use samples to understand the population. Inferential statistics is used to analyze samples and infer the population. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#recap-why-inferential-statistics",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#recap-why-inferential-statistics"
  },"766": {
    "doc": "Inferential Statistics",
    "title": "Overview of the idea",
    "content": ". | Assume population is represented by a probability distribution, namely the population distribution. | The parameters define the shape of population distribution. | The samples are values drawn from the population distribution. | From the samples, we infer the parameters of the population distribution. | . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#overview-of-the-idea",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#overview-of-the-idea"
  },"767": {
    "doc": "Inferential Statistics",
    "title": "Modeling",
    "content": "In a realistic sense, the population distribution cannot exactly match a certain mathematical probability distribution. Instead, we are merely modeling the population distribution with a certain probability distribution. Sounds obvious, but it is an important concept to keep in mind. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#modeling",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#modeling"
  },"768": {
    "doc": "Inferential Statistics",
    "title": "Random Sampling",
    "content": "Random sampling is essential if we want an unbiased inference. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#random-sampling",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#random-sampling"
  },"769": {
    "doc": "Inferential Statistics",
    "title": "Simple Random Sampling",
    "content": "This is equivalent to drawing papers from a jar. Results are ideal, but not realistic as it can be time-consuming and costly. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#simple-random-sampling",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#simple-random-sampling"
  },"770": {
    "doc": "Inferential Statistics",
    "title": "Stratified Sampling",
    "content": "This is equivalent to drawing papers from jars of different colors. We divide the population into strata, and draw random samples from each stratum. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#stratified-sampling",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#stratified-sampling"
  },"771": {
    "doc": "Inferential Statistics",
    "title": "Other Sampling Methods",
    "content": "To be added . | Systematic sampling | Cluster sampling | . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#other-sampling-methods",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#other-sampling-methods"
  },"772": {
    "doc": "Inferential Statistics",
    "title": "Sampling Distribution",
    "content": "Sampling distribution is the probability distribution of a statistic obtained from a random sample of size $n$. It is the probability distribution you observe when you repeatedly draw samples of size $n$ from the population and calculate each sample’s statistic. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#sampling-distribution",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#sampling-distribution"
  },"773": {
    "doc": "Inferential Statistics",
    "title": "Sample Statistic as a Random Variable",
    "content": "Take the example of the sample mean $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$. Each $x_i$ is also a random variable since it is randomly drawn from the population. Then $\\bar{x}$ is also a random variable since it is a function of $x_i$. We generally use lower case letters to denote the realization of a random variable, and use upper case letters to denote the random variable itself. To make it more clear, let’s use capital letters to denote the random variables. $$ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i $$ . Then we know that $\\bar{X}$ must have an associated probability distribution. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#sample-statistic-as-a-random-variable",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#sample-statistic-as-a-random-variable"
  },"774": {
    "doc": "Inferential Statistics",
    "title": "Sampling Distribution of the Sample Mean",
    "content": "Below are some of the useful concepts when inferencing the population mean from the sample mean. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#sampling-distribution-of-the-sample-mean",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#sampling-distribution-of-the-sample-mean"
  },"775": {
    "doc": "Inferential Statistics",
    "title": "Law of Large Numbers",
    "content": "The law of large numbers states that the sample mean $\\bar{x}$ converges to the population mean $\\mu$ as the sample size $n$ increases. $$ \\bar{x} \\to \\mu \\text{ as } n \\to \\infty $$ . This only holds for the mean, not for other statistics. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#law-of-large-numbers",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#law-of-large-numbers"
  },"776": {
    "doc": "Inferential Statistics",
    "title": "Central Limit Theorem",
    "content": "The central limit theorem (CLT) states that, regardless of whether the population distribution is normal or not, when the sample size $n$ is large enough, the sampling distribution of $\\bar{X}$ is approximately normal with parameters $\\mu$ and $\\frac{\\sigma^2}{n}$. Important assumption of CLT is that $X_i$ are i.i.d. $$ \\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n}) \\text{ as } n \\to \\infty $$ . So as $n$ increases, the sampling distribution of $\\bar{X}$ becomes a normal distribution where most of the values are close to $\\mu$ with a standard deviation of $\\frac{\\sigma}{\\sqrt{n}}$. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#central-limit-theorem",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#central-limit-theorem"
  },"777": {
    "doc": "Inferential Statistics",
    "title": "Estimators",
    "content": "An estimator is a statistic used to estimate a population parameter. Because it is a function of random variables, it is also a random variable. Realization of estimators are estimates of the parameter. Let’s say we have a population parameter $\\theta$ that we want to estimate. Let $X_i$ be the random variable and we have a statistic calculated from $X_i$. We will denote the statistic as $T_n$, where $n$ is the sample size. Then $T_n$ is an estimator of $\\theta$. $$ T_n = u(X_1, X_2, \\dots, X_n) $$ . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#estimators",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#estimators"
  },"778": {
    "doc": "Inferential Statistics",
    "title": "Consistent Estimator",
    "content": "An estimator $T_n$ is consistent if $T_n$ converges in probability to $\\theta$ as $n \\to \\infty$. $$ \\plim_{n \\to \\infty} T_n = \\theta $$ . Convergence in probability $$ \\forall \\epsilon &gt; 0,\\; \\lim_{n \\to \\infty} Pr[|T_n - \\theta| &gt; \\epsilon] = 0 $$ . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#consistent-estimator",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#consistent-estimator"
  },"779": {
    "doc": "Inferential Statistics",
    "title": "Unbiased Estimator",
    "content": "An estimator $T_n$ is unbiased if the expected value of $T_n$ is equal to $\\theta$. $$ E[T_n] = \\theta $$ . Therefore the sampling distribution of $T_n$ is centered at $\\theta$. This means that the estimator is not systematically over- or under-estimating. If the expected value of $T_n$ is not equal to $\\theta$, then the estimator is considered biased. One example of an unbiased estimator is the sample mean $\\bar{X}$. Proof that sample mean is an unbiased estimator of population mean $$ \\begin{align*} E[\\bar{X}] &amp;= E[\\frac{1}{n} \\sum_{i=1}^n X_i] \\\\ &amp;= \\frac{1}{n} \\sum_{i=1}^n E[X_i] \\tag{linearity of expectation} \\\\ &amp;= \\frac{1}{n} \\sum_{i=1}^n \\mu \\tag{by definition} \\\\ &amp;= \\frac{1}{n} \\cdot n \\cdot \\mu \\\\ &amp;= \\mu \\end{align*} $$ . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#unbiased-estimator",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#unbiased-estimator"
  },"780": {
    "doc": "Inferential Statistics",
    "title": "Sampling Error",
    "content": "Sampling error is the difference between the sample statistic and the population statistic. An example of sampling error would be $\\bar{X} - \\mu$. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#sampling-error",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#sampling-error"
  },"781": {
    "doc": "Inferential Statistics",
    "title": "Sampling Error as a Random Variable",
    "content": "Let’s take the example of $\\bar{X} - \\mu$. $\\bar{X} - \\mu$ is also a random variable since $\\mu$ is a constant. This means that $\\bar{X} - \\mu$ has an associated probability distribution. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#sampling-error-as-a-random-variable",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#sampling-error-as-a-random-variable"
  },"782": {
    "doc": "Inferential Statistics",
    "title": "Sampling Distribution",
    "content": "By the Central Limit Theorem, we know that the sampling distribution of $\\bar{X}$ is approximately normal with parameters $\\mu$ and $\\frac{\\sigma^2}{n}$. Since we’re merely shifting the distribution horizontally by $\\mu$, we know that the distribution of $\\bar{X} - \\mu$ is also approximately normal with parameters $0$ and $\\frac{\\sigma^2}{n}$: . $$ \\begin{equation*} \\label{eq:sa} \\end{equation*} \\bar{X} - \\mu \\sim N(0, \\frac{\\sigma^2}{n}) \\text{ as } n \\to \\infty $$ . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#sampling-distribution-1",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#sampling-distribution-1"
  },"783": {
    "doc": "Inferential Statistics",
    "title": "Standard Error of the Mean",
    "content": "The standard error of the mean (SEM) is the standard deviation of the sampling distribution of the sampling mean $\\bar{X}$. $$ \\text{SEM} = \\frac{\\sigma}{\\sqrt{n}} $$ . However, we usually don’t know the population standard deviation $\\sigma$. So we use the sample standard deviation $s$ (or the unbiased estimator of the population standard deviation) instead: . $$ \\text{SEM} \\approx \\frac{s}{\\sqrt{n}} $$ . ",
    "url": "/docs/statistics/basics/inferencial-stats.html#standard-error-of-the-mean",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#standard-error-of-the-mean"
  },"784": {
    "doc": "Inferential Statistics",
    "title": "Confidence Interval",
    "content": "A confidence interval is a range of values that we are fairly confident contains the population parameter. So basically how confident can we be that the estimate obtained from the sample is close to the true population parameter. The smaller the confidence interval, the more precise the estimate is. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#confidence-interval",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#confidence-interval"
  },"785": {
    "doc": "Inferential Statistics",
    "title": "Confidence Interval for the Mean",
    "content": "Let’s say we want to estimate the population mean $\\mu$. We know that the sampling distribution of $\\bar{X} - \\mu$ is approximately . $$ \\bar{X} - \\mu \\sim N(0, \\frac{\\sigma^2}{n}) \\text{ as } n \\to \\infty $$ . Because the sampling distribution is normal, we know that approx. 95% of the values fall within approx. $2 \\cdot \\text{SEM}$ . Technically, 95% of the values fall within $1.96 \\cdot \\frac{s}{\\sqrt{n}}$. This 1.96 is the z-score that marks $0.025$ area (2.5%) on the right tail of the standard normal distribution. $$ \\begin{gather*} 0 - 1.96 \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq 0 + 1.96 \\cdot \\frac{s}{\\sqrt{n}} \\\\ \\downarrow \\\\ \\bar{X} - 1.96 \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + 1.96 \\cdot \\frac{s}{\\sqrt{n}} \\end{gather*} $$ . Then we can say that we are 95% confident that the population mean $\\mu$ falls within the interval . $$ \\bar{X} \\pm 1.96 \\cdot \\frac{s}{\\sqrt{n}} $$ . Basically, when we perform the interval calculation for 100 samples, we expect the true population mean to fall within the interval 95 times out of the 100 times. This is the confidence interval at the 95% confidence level. 95% is the most common confidence level. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#confidence-interval-for-the-mean",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#confidence-interval-for-the-mean"
  },"786": {
    "doc": "Inferential Statistics",
    "title": "t-Distribution",
    "content": "The Central Limit Theorem only applies when the sample size $n$ is large enough. In reality, we don’t always have a large sample size during data analysis. Also, since we don’t know the population standard deviation $\\sigma$, we use the sample standard deviation $s$ as an estimator of $\\sigma$ instead. t-distribution is a probability distribution that is used when the sample size is small and the population standard deviation is unknown. The t-distribution assumes that the population from which the sample is drawn follows a normal distribution. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#t-distribution",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#t-distribution"
  },"787": {
    "doc": "Inferential Statistics",
    "title": "t-Score",
    "content": "The t-score is calculated by the following formula: . $$ T = \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} $$ . Just like the z-score, we are standardizing the sampling distribution of the sample mean $\\bar{X}$: . | Shifting the mean to 0 and standardizing variance to 1. | . The only difference is that we don’t know the population standard deviation $\\sigma$, so we estimate it with the sample standard deviation $s$. Because of this estimation, the t-score is not exactly a standard normal distribution. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#t-score",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#t-score"
  },"788": {
    "doc": "Inferential Statistics",
    "title": "t-Distribution vs Standard Normal Distribution",
    "content": "The t-distribution is similar to the normal distribution, but with heavier tails. The tails of a distribution are the regions that fall outside of 2 standard deviations from the mean. As the sample size $n$ increases, the t-distribution approaches $N(0, 1)$. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#t-distribution-vs-standard-normal-distribution",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#t-distribution-vs-standard-normal-distribution"
  },"789": {
    "doc": "Inferential Statistics",
    "title": "Degrees of Freedom",
    "content": "The degrees of freedom (typically denoted by $\\nu$ or d.f.) is the number of independent observations in a sample that are used to calculate an estimate of a population parameter. Typically, the degrees of freedom equals the number of sample size $n$ minus the number of parameters to estimate. When we’re estimating the mean, $\\nu = n - 1$. Degrees of freedom $\\nu$ is a parameter that determines the shape of the t-distribution. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#degrees-of-freedom",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#degrees-of-freedom"
  },"790": {
    "doc": "Inferential Statistics",
    "title": "Confidence Interval Using t-Distribution",
    "content": "The 95% confidence interval above assumes that $n$ is large enough and hence the sampling distribution of $\\bar{X}$ is approximately normal. When $n$ is small, realistically, we use the t-distribution instead. So the realistic confidence interval is calculated by the following formula: . $$ \\begin{equation} \\label{eq:ci-t} \\bar{X} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\end{equation} $$ . where $t_{\\alpha/2, \\nu}$ is the t-score such that . $$ Pr[-t_{\\alpha/2, \\nu} \\leq t \\leq t_{\\alpha/2, \\nu}] = 1 - \\alpha $$ . Setting $\\alpha = 0.05$ gives us the 95% confidence interval. We will discuss $\\alpha$ in more detail in the following sections. Narrowing the Confidence Interval . If we wanted to make our estimate more precise, we want to narrow down the confidence interval. If we take a look at equation $\\eqref{eq:ci-t}$, we notice that we can either: . | Increase the sample size $n$ | Decrease the sample standard deviation $s$ | . Increasing the sample size $n$ is not always realistic. Since it is $\\sqrt{n}$ in the denominator, in order to narrow down the confidence unit by $1/k$, we need to increase the sample size by $k^2$. Decreasing the sample standard deviation $s$ is also not always possible, because of the nature of the population. However, we can try to decrease the sample standard deviation $s$ by collecting our samples with a more precise measure. ",
    "url": "/docs/statistics/basics/inferencial-stats.html#confidence-interval-using-t-distribution",
    
    "relUrl": "/docs/statistics/basics/inferencial-stats.html#confidence-interval-using-t-distribution"
  },"791": {
    "doc": "Vue Project Setup",
    "title": "Vue Project Setup",
    "content": ". | Start project directory | Install Tailwind CSS . | Remove unused styles in production builds | Include Tailwind CSS | WindiCSS (optional) | . | Add path alias | Desktop App with Electron (Optional) | Install ESLint and Prettier (Optional) | . ",
    "url": "/docs/vue/init.html",
    
    "relUrl": "/docs/vue/init.html"
  },"792": {
    "doc": "Vue Project Setup",
    "title": "Start project directory",
    "content": "Details are listed here. yarn create vite &lt;app-name&gt; --template vue-ts # Init project cd &lt;app-name&gt; yarn # Install packages yarn dev # Check build . ",
    "url": "/docs/vue/init.html#start-project-directory",
    
    "relUrl": "/docs/vue/init.html#start-project-directory"
  },"793": {
    "doc": "Vue Project Setup",
    "title": "Install Tailwind CSS",
    "content": "Details are listed here. But for the brief summary: . yarn add tailwindcss@latest postcss@latest autoprefixer@latest --dev npx tailwindcss init -p . npx tailwind init -p generates two files tailwind.config.js and postcss.config.js. Remove unused styles in production builds . In tailwind.config.js, replace the purge to following line, . purge: ['./index.html', './src/**/*.{vue,js,ts,jsx,tsx}'] . Include Tailwind CSS . Create a file src/index.css. Then add the following to the file, . @tailwind base; @tailwind components; @tailwind utilities; . Then in src/main.js, import src/index.css. import { createApp } from 'vue' import App from './App.vue' import './index.css' createApp(App).mount('#app') . WindiCSS (optional) . Possible replacement for TailwindCSS. See installation here. ",
    "url": "/docs/vue/init.html#install-tailwind-css",
    
    "relUrl": "/docs/vue/init.html#install-tailwind-css"
  },"794": {
    "doc": "Vue Project Setup",
    "title": "Add path alias",
    "content": "Unlike webpack, Vite does not automatically provide the @ path alias to src. To enable this alias go to vite.config.ts and import path from 'path'. If import path from 'path' shows a type warning: yarn add @types/node --dev. Then add the following to defineConfig in vite.config.ts: . // vite.config.ts import path from 'path' export default defineConfig({ ..., resolve:{ alias: [ { find: '@', replacement: path.resolve(__dirname, './src') } ] } }) . ",
    "url": "/docs/vue/init.html#add-path-alias",
    
    "relUrl": "/docs/vue/init.html#add-path-alias"
  },"795": {
    "doc": "Vue Project Setup",
    "title": "Desktop App with Electron (Optional)",
    "content": "Really nice detail in this blog. Don’t forget to yarn add concurrently cross-end wait-on electron-buider --dev. They are needed to run the package.json scripts. ",
    "url": "/docs/vue/init.html#desktop-app-with-electron-optional",
    
    "relUrl": "/docs/vue/init.html#desktop-app-with-electron-optional"
  },"796": {
    "doc": "Vue Project Setup",
    "title": "Install ESLint and Prettier (Optional)",
    "content": "yarn add eslint prettier eslint-plugin-vue eslint-config-prettier --dev . Then create two files .eslintrc.js and .prettierrc.js in the project root directory, . // .eslintrc.js module.exports = { extends: [ 'plugin:vue/vue3-essential', 'prettier', ], rules: { // override/add rules settings here, such as: 'vue/no-unused-vars': 'error', }, } . // .prettierrc.js module.exports = { semi: false, tabWidth: 2, useTabs: false, printWidth: 80, endOfLine: 'auto', singleQuote: true, trailingComma: 'es5', bracketSpacing: true, arrowParens: 'always', } . ",
    "url": "/docs/vue/init.html#install-eslint-and-prettier-optional",
    
    "relUrl": "/docs/vue/init.html#install-eslint-and-prettier-optional"
  },"797": {
    "doc": "Basic Linux Setup",
    "title": "Basic Linux Setup",
    "content": "A note for myself. | Update packages | Install packages | Change to zsh | Color schemes | Little bit of customization . | GNOME Shell Integration | Dash to Panel | . | . ",
    "url": "/docs/linux/init.html",
    
    "relUrl": "/docs/linux/init.html"
  },"798": {
    "doc": "Basic Linux Setup",
    "title": "Update packages",
    "content": "sudo apt update &amp;&amp; sudo apt upgrade . ",
    "url": "/docs/linux/init.html#update-packages",
    
    "relUrl": "/docs/linux/init.html#update-packages"
  },"799": {
    "doc": "Basic Linux Setup",
    "title": "Install packages",
    "content": "List of packages I frequently use. To be added . sudo apt install &lt;package-name&gt; . | vim | net-tools | git | gnome-tweaks | htop | neofetch | nautilus | curl | tree | tmux | fasd | fzf | bat | fd | exa | . ",
    "url": "/docs/linux/init.html#install-packages",
    
    "relUrl": "/docs/linux/init.html#install-packages"
  },"800": {
    "doc": "Basic Linux Setup",
    "title": "Change to zsh",
    "content": "See here. ",
    "url": "/docs/linux/init.html#change-to-zsh",
    
    "relUrl": "/docs/linux/init.html#change-to-zsh"
  },"801": {
    "doc": "Basic Linux Setup",
    "title": "Color schemes",
    "content": "See here for details. First install the following, . sudo apt-get install dconf-cli uuid-runtime . Then, . bash -c \"$(curl -sLo- https://git.io/vQgMr)\" . Recommended color schemes are: . | Snazzy (174) | Tomorrow Night (204) | . ",
    "url": "/docs/linux/init.html#color-schemes",
    
    "relUrl": "/docs/linux/init.html#color-schemes"
  },"802": {
    "doc": "Basic Linux Setup",
    "title": "Little bit of customization",
    "content": "GNOME Shell Integration . Download the following extension from chrome. https://chrome.google.com/webstore/detail/gnome-shell-integration/gphhapmejobijbbhgpjhcjognlahblep . Dash to Panel . Download the following extension form chrome. https://extensions.gnome.org/extension/1160/dash-to-panel/ . ",
    "url": "/docs/linux/init.html#little-bit-of-customization",
    
    "relUrl": "/docs/linux/init.html#little-bit-of-customization"
  },"803": {
    "doc": "Inner Products and Norms",
    "title": "Inner Products and Norms",
    "content": ". | Geometric Vectors | Inner Product . | Dot Product | General Inner Product | Inner Product Space | Existence of Symmetric, Positive Definite Matrix | . | Norm . | Manhattan Norm | Euclidean Norm | . | Inner Product Induced Norm . | Cauchy-Schwarz Inequality | Commonly Used Inner Product Induced Norms . | Length of a Vector | Distance Between Two Vectors | . | . | . ",
    "url": "/docs/linalg/basics/inner-products-norms.html",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html"
  },"804": {
    "doc": "Inner Products and Norms",
    "title": "Geometric Vectors",
    "content": ". | Geometrical interpretation of vectors. | Intuitively, a line segment with a direction that start at the origin. | This interpretation is useful in understanding norms and inner products. | . ",
    "url": "/docs/linalg/basics/inner-products-norms.html#geometric-vectors",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#geometric-vectors"
  },"805": {
    "doc": "Inner Products and Norms",
    "title": "Inner Product",
    "content": " ",
    "url": "/docs/linalg/basics/inner-products-norms.html#inner-product",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#inner-product"
  },"806": {
    "doc": "Inner Products and Norms",
    "title": "Dot Product",
    "content": "$$ \\mathbf{x} \\cdot \\mathbf{y} = \\mathbf{x}^T \\mathbf{y} = \\sum_{i=1}^n x_i y_i $$ . This special type of inner product is also called the scalar product. ",
    "url": "/docs/linalg/basics/inner-products-norms.html#dot-product",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#dot-product"
  },"807": {
    "doc": "Inner Products and Norms",
    "title": "General Inner Product",
    "content": "Review the concepts of bi-linear mapping, symmetric, and positive definite. Let $\\Omega: V \\times V \\rightarrow \\mathbb{R}$ be a bi-linear mapping, or just use a binary operator $\\langle \\cdot, \\cdot \\rangle$ . $\\langle \\cdot, \\cdot \\rangle$ is an inner product if $\\Omega$ is symmetric and positive definite. ",
    "url": "/docs/linalg/basics/inner-products-norms.html#general-inner-product",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#general-inner-product"
  },"808": {
    "doc": "Inner Products and Norms",
    "title": "Inner Product Space",
    "content": "An inner product space is the tuple . $$ (V, \\langle \\cdot, \\cdot \\rangle) $$ . where $V$ is a vector space and $\\langle \\cdot, \\cdot \\rangle$ is a general inner product. When $\\langle \\cdot, \\cdot \\rangle$, is a regular dot product, this space is called the Euclidean vector space. ",
    "url": "/docs/linalg/basics/inner-products-norms.html#inner-product-space",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#inner-product-space"
  },"809": {
    "doc": "Inner Products and Norms",
    "title": "Existence of Symmetric, Positive Definite Matrix",
    "content": "$\\langle \\cdot, \\cdot \\rangle$ is an inner product if and only if there is a symmetric, positive definite matrix $A$ such that . $$ \\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\mathbf{x}^T A \\mathbf{y} $$ . See details here. ",
    "url": "/docs/linalg/basics/inner-products-norms.html#existence-of-symmetric-positive-definite-matrix",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#existence-of-symmetric-positive-definite-matrix"
  },"810": {
    "doc": "Inner Products and Norms",
    "title": "Norm",
    "content": "A norm on a vector space $V$ is a function that assigns each vector $\\mathbf{x} \\in V$ its length $\\lVert\\mathbf{x}\\rVert \\in \\mathbb{R}$: . $$ \\|\\cdot\\|: V \\rightarrow \\mathbb{R},\\, \\mathbf{x} \\mapsto \\|\\mathbf{x}\\| $$ . For a function to be a norm, it must satisfy the following properties $\\forall \\mathbf{x}, \\mathbf{y} \\in V$ and $\\forall \\lambda \\in \\mathbb{R}$: . | Absolutely homogeneous: $\\lVert\\lambda \\mathbf{x}\\rVert = |\\lambda| \\lVert\\mathbf{x}\\rVert$ | Triangle inequality: $\\lVert\\mathbf{x} + \\mathbf{y}\\rVert \\leq \\lVert\\mathbf{x}\\rVert + \\lVert\\mathbf{y}\\rVert$ | Positive definite: $\\lVert\\mathbf{x}\\rVert \\geq 0$ and $\\lVert\\mathbf{x}\\rVert = 0 \\iff \\mathbf{x} = \\mathbf{0}$ . It is always non-negative and zero only when the vector is the zero vector. | . ",
    "url": "/docs/linalg/basics/inner-products-norms.html#norm",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#norm"
  },"811": {
    "doc": "Inner Products and Norms",
    "title": "Manhattan Norm",
    "content": "Also known as the $\\boldsymbol{L_1}$ norm. $\\forall \\mathbf{x} \\in \\mathbb{R}^n$: . $$ \\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n |x_i| $$ . ",
    "url": "/docs/linalg/basics/inner-products-norms.html#manhattan-norm",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#manhattan-norm"
  },"812": {
    "doc": "Inner Products and Norms",
    "title": "Euclidean Norm",
    "content": "Also known as the $\\boldsymbol{L_2}$ norm. $$ \\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2} = \\sqrt{\\mathbf{x}^T \\mathbf{x}} $$ . ",
    "url": "/docs/linalg/basics/inner-products-norms.html#euclidean-norm",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#euclidean-norm"
  },"813": {
    "doc": "Inner Products and Norms",
    "title": "Inner Product Induced Norm",
    "content": "Some norms can be induced by inner products, meaning: . $$ \\|\\mathbf{x}\\| = \\sqrt{\\langle\\mathbf{x},\\mathbf{x}\\rangle} $$ . Not every norm is induced by an inner product. Manhattan norm is not induced by any inner product, but Euclidean norm is. ",
    "url": "/docs/linalg/basics/inner-products-norms.html#inner-product-induced-norm",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#inner-product-induced-norm"
  },"814": {
    "doc": "Inner Products and Norms",
    "title": "Cauchy-Schwarz Inequality",
    "content": "For any inner product space $(V, \\langle \\cdot, \\cdot \\rangle)$, induced norm satisfies the following inequality: . $$ |\\langle\\mathbf{x},\\mathbf{y}\\rangle| \\leq \\|\\mathbf{x}\\| \\|\\mathbf{y}\\| $$ . ",
    "url": "/docs/linalg/basics/inner-products-norms.html#cauchy-schwarz-inequality",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#cauchy-schwarz-inequality"
  },"815": {
    "doc": "Inner Products and Norms",
    "title": "Commonly Used Inner Product Induced Norms",
    "content": "Length of a Vector . Euclidean norm gives us the length of a vector. It is induced by the dot product. $$ \\|\\mathbf{x}\\|_2 = \\sqrt{\\langle\\mathbf{x},\\mathbf{x}\\rangle} $$ . Distance Between Two Vectors . Distance between two vectors (Euclidean distance) is also induced by the dot product. $$ d(\\mathbf{x}, \\mathbf{y}) = \\|\\mathbf{x} - \\mathbf{y}\\|_2 = \\sqrt{\\langle\\mathbf{x} - \\mathbf{y}, \\mathbf{x} - \\mathbf{y}\\rangle} $$ . Mapping $d: V \\times V \\rightarrow \\mathbb{R}$, $(\\mathbf{x}, \\mathbf{y}) \\mapsto d(\\mathbf{x}, \\mathbf{y})$ is called a metric. ",
    "url": "/docs/linalg/basics/inner-products-norms.html#commonly-used-inner-product-induced-norms",
    
    "relUrl": "/docs/linalg/basics/inner-products-norms.html#commonly-used-inner-product-induced-norms"
  },"816": {
    "doc": "What is Time Series Analysis?",
    "title": "What is Time Series Analysis?",
    "content": ". | Time Series Analysis | Early Time Series Analysis | . ",
    "url": "/docs/data-science/time-series/intro-to-time-series.html",
    
    "relUrl": "/docs/data-science/time-series/intro-to-time-series.html"
  },"817": {
    "doc": "What is Time Series Analysis?",
    "title": "Time Series Analysis",
    "content": "Time series analysis can be defined as the following: . Extracting meaningful summary and statistic from points arranged in chronological order . Analysis goes both ways . | Diagnose past events | Predict future events | . Analysis of time series rose from various disciplines and applications: . | Medicine | Weather | Economics | Astronomy | . ECG and EEG are most common time series data in medicine. In the past, these fields faced challenges due to the scarcity of recordings and bias of data towards those with symptoms. However, with the advancement of wearable technology, it is now possible to collect routine measurements. Time series analysis have developed tremendously with the advancement of computing power. ",
    "url": "/docs/data-science/time-series/intro-to-time-series.html#time-series-analysis",
    
    "relUrl": "/docs/data-science/time-series/intro-to-time-series.html#time-series-analysis"
  },"818": {
    "doc": "What is Time Series Analysis?",
    "title": "Early Time Series Analysis",
    "content": "Traditional analysis models often presupposed its own outcome. For example, a cyclical model presupposes cyclical data. Which results in a lot of shortcomings. With the emergence of autoregressive models, time series analysis became more flexible. Unlike some other fields that are driven by theory, time series analysis was driven by practical applications. | Businesses led the field because they had more data than academics | Practical results were more important than underlying theory | . ",
    "url": "/docs/data-science/time-series/intro-to-time-series.html#early-time-series-analysis",
    
    "relUrl": "/docs/data-science/time-series/intro-to-time-series.html#early-time-series-analysis"
  },"819": {
    "doc": "Invertible Matrix",
    "title": "Invertible Matrix",
    "content": ". | Inverse Matrix . | Matrix of a System of Linear Equations . | Homogeneous System of Linear Equations | . | Singular matrix is not invertible | Properties of inverse matrix | . | How to find the inverse matrix . | Using determinant and adjugate matrix | Using elementary row operations | Gaussian Elimination on Augmented Matrix | Using LU decomposition | . | . ",
    "url": "/docs/linalg/basics/invertible.html",
    
    "relUrl": "/docs/linalg/basics/invertible.html"
  },"820": {
    "doc": "Invertible Matrix",
    "title": "Inverse Matrix",
    "content": "Inverse matrix of a $n \\times n$ square matrix $A$ is denoted by $A^{-1}$ and defined as the matrix that satisfies the following equation: . $$ AA^{-1} = A^{-1}A = I_n $$ . If a matrix has an inverse matrix, it is called invertible, regular, or non-singular. ",
    "url": "/docs/linalg/basics/invertible.html#inverse-matrix",
    
    "relUrl": "/docs/linalg/basics/invertible.html#inverse-matrix"
  },"821": {
    "doc": "Invertible Matrix",
    "title": "Matrix of a System of Linear Equations",
    "content": "If a matrix $A$ is invertible, then the system of linear equations $Ax = b$ has a unique solution $x = A^{-1}b$. If a matrix is singular, then the system of linear equations $Ax = b$ has either no solution or infinitely many solutions. Homogeneous System of Linear Equations . For a homogeneous system of linear equations $Ax = 0$, if $A$ is invertible, then the only solution is $x = 0$. $x = 0$ in a homogeneous system of linear equations is called the trivial solution. ",
    "url": "/docs/linalg/basics/invertible.html#matrix-of-a-system-of-linear-equations",
    
    "relUrl": "/docs/linalg/basics/invertible.html#matrix-of-a-system-of-linear-equations"
  },"822": {
    "doc": "Invertible Matrix",
    "title": "Singular matrix is not invertible",
    "content": "A matrix is singular if and only if its determinant is zero. If the determinant is zero, then the matrix is not invertible. See down below. You’ll see that the inverse matrix is undefined when the determinant is zero. ",
    "url": "/docs/linalg/basics/invertible.html#singular-matrix-is-not-invertible",
    
    "relUrl": "/docs/linalg/basics/invertible.html#singular-matrix-is-not-invertible"
  },"823": {
    "doc": "Invertible Matrix",
    "title": "Properties of inverse matrix",
    "content": "For any invertible matrix $A$ and $B$ of the same size and scalar $c \\neq 0$, . | $(A^{-1})^{-1} = A$ | $AB$ is invertible and $(AB)^{-1} = B^{-1}A^{-1}$ | $(cA)^{-1} = \\frac{1}{c}A^{-1}$ | $A^k$ is invertible and $(A^k)^{-1} = (A^{-1})^k$ for $k &gt; 0 \\wedge k \\in \\mathbb{Z}$ | . Invertible Matrix Theorem For a square matrix $A \\in \\mathbb{R}^{n \\times n}$, the following statements are all equivalent: . | $A$ is invertible. | $A$ is non-singular. | $A$ is row equivalent to $I_n$. | $A$ in a row echelon form has $n$ pivots. | The system of linear equations $Ax = b$ has a unique solution for every $b \\in \\mathbb{R}^n$. | The homogeneous system of linear equations $Ax = 0$ has only the trivial solution. | The columns of $A$ are linearly independent $\\Leftrightarrow \\rank(A) = n$ | The columns of $A$ span $\\mathbb{R}^n$ $\\Leftrightarrow \\dim(\\text{Im}(A)) = n$ | $A^T$ is invertible. | . ",
    "url": "/docs/linalg/basics/invertible.html#properties-of-inverse-matrix",
    
    "relUrl": "/docs/linalg/basics/invertible.html#properties-of-inverse-matrix"
  },"824": {
    "doc": "Invertible Matrix",
    "title": "How to find the inverse matrix",
    "content": " ",
    "url": "/docs/linalg/basics/invertible.html#how-to-find-the-inverse-matrix",
    
    "relUrl": "/docs/linalg/basics/invertible.html#how-to-find-the-inverse-matrix"
  },"825": {
    "doc": "Invertible Matrix",
    "title": "Using determinant and adjugate matrix",
    "content": "If a square matrix $A$ is invertible, then the inverse matrix $A^{-1}$ can be found by . $$ A^{-1} = \\frac{1}{\\det(A)} \\operatorname{adj}(A) $$ . where $\\det(A)$ is the determinant of $A$ and $\\operatorname{adj}(A)$ is the adjugate matrix of $A$. ",
    "url": "/docs/linalg/basics/invertible.html#using-determinant-and-adjugate-matrix",
    
    "relUrl": "/docs/linalg/basics/invertible.html#using-determinant-and-adjugate-matrix"
  },"826": {
    "doc": "Invertible Matrix",
    "title": "Using elementary row operations",
    "content": "If we can transform a matrix $A$ into an identity matrix $I_n$ using a sequence of elementary row operations, then the matrix multiplication of the corresponding elementary matrices is the inverse matrix $A^{-1}$: . $$ E_k \\cdots E_2 E_1 A = I_n \\Rightarrow A^{-1} = E_k \\cdots E_2 E_1 $$ . ",
    "url": "/docs/linalg/basics/invertible.html#using-elementary-row-operations",
    
    "relUrl": "/docs/linalg/basics/invertible.html#using-elementary-row-operations"
  },"827": {
    "doc": "Invertible Matrix",
    "title": "Gaussian Elimination on Augmented Matrix",
    "content": "Pretty much the same idea as above. We want to find matrix $X$ s.t. $AX = I$. So we augment $A$ with $I_n$ and perform Gaussian elimination on it: . \\[[A \\mid I_n] \\xrightarrow{\\text{Gaussian elimination}} [I_n \\mid X]\\] Then $X = A^{-1}$. ",
    "url": "/docs/linalg/basics/invertible.html#gaussian-elimination-on-augmented-matrix",
    
    "relUrl": "/docs/linalg/basics/invertible.html#gaussian-elimination-on-augmented-matrix"
  },"828": {
    "doc": "Invertible Matrix",
    "title": "Using LU decomposition",
    "content": "To be added . ",
    "url": "/docs/linalg/basics/invertible.html#using-lu-decomposition",
    
    "relUrl": "/docs/linalg/basics/invertible.html#using-lu-decomposition"
  },"829": {
    "doc": "jenv",
    "title": "jenv",
    "content": ". | Installation | Typical usage | Basic commands . | Add JDK | List all added JDKs | Set global JDK | Set JDK for current working directory | . | . ",
    "url": "/docs/java/jenv.html",
    
    "relUrl": "/docs/java/jenv.html"
  },"830": {
    "doc": "jenv",
    "title": "Installation",
    "content": "brew install jenv echo 'export PATH=\"$HOME/.jenv/bin:$PATH\"' &gt;&gt; ~/.zshrc echo 'eval \"$(jenv init -)\"' &gt;&gt; ~/.zshrc exec $SHELL -l jenv enable-plugin export exec $SHELL -l . ",
    "url": "/docs/java/jenv.html#installation",
    
    "relUrl": "/docs/java/jenv.html#installation"
  },"831": {
    "doc": "jenv",
    "title": "Typical usage",
    "content": "First install the JDK you want to use, . brew install --cask corretto11 . Then add it to jenv, . jenv rehash jenv add \"$(/usr/libexec/java_home)\" # Or if the following does not work jenv add /Library/Java/JavaVirtualMachines/amazon-corretto-11.jdk/Contents/Home . Check that JDK has been added by, . $ jenv versions * system 11.0 11.0.16.1 corretto64-11.0.16.1 . To set a JDK for current working directory, . jenv local 11.0 # OR 11.0.16.1 OR corretto64-11.0.16.1 . Confirm that JAVA_HOME has been set, . echo ${JAVA_HOME} . ",
    "url": "/docs/java/jenv.html#typical-usage",
    
    "relUrl": "/docs/java/jenv.html#typical-usage"
  },"832": {
    "doc": "jenv",
    "title": "Basic commands",
    "content": "jenv -h or jenv help &lt;command&gt; for more details. Add JDK . jenv add ${PATH_TO_JVM_HOME} . List all added JDKs . jenv versions . Set global JDK . jenv global ${version_name_from_jenv_versions} . Set JDK for current working directory . jenv local ${version_name_from_jenv_versions} . ",
    "url": "/docs/java/jenv.html#basic-commands",
    
    "relUrl": "/docs/java/jenv.html#basic-commands"
  },"833": {
    "doc": "Java Memory",
    "title": "Java Memory",
    "content": ". | Runtime Data Area | jmap . | Example usage | Errors | . | . ",
    "url": "/docs/java/jmap.html",
    
    "relUrl": "/docs/java/jmap.html"
  },"834": {
    "doc": "Java Memory",
    "title": "Runtime Data Area",
    "content": "To be added . ",
    "url": "/docs/java/jmap.html#runtime-data-area",
    
    "relUrl": "/docs/java/jmap.html#runtime-data-area"
  },"835": {
    "doc": "Java Memory",
    "title": "jmap",
    "content": "jmap is a CLI tool used to get memory-related information of a JVM. Example usage . jmap -heap $PID . Errors . If you get the following error, . Can't attach to the process: ptrace(PTRACE_ATTACH, ..) failed for $PID: Operation not permitted . Try the following, . echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope . If you get the following error, . cannot open binary file . Make sure you are running the command as the same user that started the JVM. ",
    "url": "/docs/java/jmap.html#jmap",
    
    "relUrl": "/docs/java/jmap.html#jmap"
  },"836": {
    "doc": "SQL Joins",
    "title": "SQL Joins",
    "content": ". | CROSS JOIN | Inner vs Outer Joins | Join Conditions . | ON . | Equi-Join | . | USING | . | JOIN / INNER JOIN | Outer Joins . | Exclusive Outer Joins | . | NATURAL Joins | SELF JOIN | . ",
    "url": "/docs/db/sql/joins.html",
    
    "relUrl": "/docs/db/sql/joins.html"
  },"837": {
    "doc": "SQL Joins",
    "title": "CROSS JOIN",
    "content": "A CROSS JOIN returns the Cartesian product of two tables, creating n * m rows where n and m are the number of rows in each table. SELECT * FROM a CROSS JOIN b; . Or you could just use a comma ,: . SELECT * FROM a, b; . ",
    "url": "/docs/db/sql/joins.html#cross-join",
    
    "relUrl": "/docs/db/sql/joins.html#cross-join"
  },"838": {
    "doc": "SQL Joins",
    "title": "Inner vs Outer Joins",
    "content": "Theoretically, you could think of all joins starting from the Cartesian product. Not exactly what the query optimizer does, but it helps to understand the concept. After obtaining the Cartesian product, we filter out rows based on some conditions: . | Inner Join: Returns only the rows that fulfill the condition. | Outer Join: Returns the rows that fulfill the condition and . | Left Outer Join: Also the rows with values from the left table | Right Outer Join: Also the rows with values from the right table | Full Outer Join: Also the rows with values from both tables | . | . For example, left outer join has the following logic: . | We have a Cartesian product of two tables. | The rows that fulfill the condition are kept. | In addition, find all rows from the left table (not the Cartesian product) that did not make it to the final result. | For each of those rows, fill in NULL values for the right table columns, and include them in the final result. | . ",
    "url": "/docs/db/sql/joins.html#inner-vs-outer-joins",
    
    "relUrl": "/docs/db/sql/joins.html#inner-vs-outer-joins"
  },"839": {
    "doc": "SQL Joins",
    "title": "Join Conditions",
    "content": " ",
    "url": "/docs/db/sql/joins.html#join-conditions",
    
    "relUrl": "/docs/db/sql/joins.html#join-conditions"
  },"840": {
    "doc": "SQL Joins",
    "title": "ON",
    "content": "With ON, you can use any comparison operators to join tables =, &gt;, &lt;, &gt;=, &lt;=, &lt;&gt;, !=, etc. Equi-Join . Equi-join is the most common type of join. It is when a join condition uses the = operator. SELECT s.store_id, a.address, district FROM store s JOIN address a ON s.address_id = a.address_id; . Range variable s and a are technically optional, but they are highly recommended and can become necessary to resolve ambiguity when referencing column names that exist in both tables. You can equi-join on multiple columns as well with AND: . SELECT * FROM a JOIN b ON a.key1 = b.key1 AND a.key2 = b.key2; . ",
    "url": "/docs/db/sql/joins.html#on",
    
    "relUrl": "/docs/db/sql/joins.html#on"
  },"841": {
    "doc": "SQL Joins",
    "title": "USING",
    "content": "When you want to equi-join on columns with the same name, you can use the shorthand USING keyword: . SELECT s.store_id, a.address, district FROM store s JOIN address a USING (address_id); . Do not forget the parentheses () around the key name. ",
    "url": "/docs/db/sql/joins.html#using",
    
    "relUrl": "/docs/db/sql/joins.html#using"
  },"842": {
    "doc": "SQL Joins",
    "title": "JOIN / INNER JOIN",
    "content": "In PostgreSQL, when you use JOIN, it is equivalent to INNER JOIN. Only returns rows that fulfill the condition. SELECT * FROM a [INNER] JOIN b ON condition; . ",
    "url": "/docs/db/sql/joins.html#join--inner-join",
    
    "relUrl": "/docs/db/sql/joins.html#join--inner-join"
  },"843": {
    "doc": "SQL Joins",
    "title": "Outer Joins",
    "content": "In keywords, the word OUTER is omitted: . | LEFT JOIN | RIGHT JOIN | FULL JOIN | . Remember, for dangling left or right rows, NULL values are filled in for the columns from the other table. ",
    "url": "/docs/db/sql/joins.html#outer-joins",
    
    "relUrl": "/docs/db/sql/joins.html#outer-joins"
  },"844": {
    "doc": "SQL Joins",
    "title": "Exclusive Outer Joins",
    "content": "To filter out rows that have matching values, you can add a NULL check in the WHERE clause. For exclusive left join: . SELECT * FROM a LEFT JOIN b USING (key) WHERE b.key IS NULL; . For exclusive right join: . SELECT * FROM a RIGHT JOIN b USING (key) WHERE a.key IS NULL; . For exclusive full join: . SELECT * FROM a FULL JOIN b USING (key) WHERE a.key IS NULL OR b.key IS NULL; . ",
    "url": "/docs/db/sql/joins.html#exclusive-outer-joins",
    
    "relUrl": "/docs/db/sql/joins.html#exclusive-outer-joins"
  },"845": {
    "doc": "SQL Joins",
    "title": "NATURAL Joins",
    "content": "Natural join is an equi-join on columns with the same name. NATURAL is a keyword that can come before INNER, LEFT, or RIGHT, or simply JOIN. SELECT * FROM a NATURAL [INNER | LEFT | RIGHT] JOIN b; . For NATURAL JOIN, the columns with the same name are automatically matched. Joins with USING can be simplified with NATURAL JOIN. The problem is, if there are multiple columns with the same name, natural join will try to find a match across all those columns. In other words, SELECT * FROM a NATURAL JOIN b with two matching column names key1 and key2 is equivalent to: . SELECT * FROM a JOIN b ON a.key1 = b.key1 AND a.key2 = b.key2; . Commonly used column names such as created_time or last_updated can easily mess up natural join and lead to empty results. It is not recommended to use NATURAL JOIN because it can lead to ambiguity. ",
    "url": "/docs/db/sql/joins.html#natural-joins",
    
    "relUrl": "/docs/db/sql/joins.html#natural-joins"
  },"846": {
    "doc": "SQL Joins",
    "title": "SELF JOIN",
    "content": "Self join is simply joining a table with itself. The only caveat is that aliasing becomes mandatory. SELECT * FROM tbl t1 JOIN tbl t2 ON t1.key = t2.key; . ",
    "url": "/docs/db/sql/joins.html#self-join",
    
    "relUrl": "/docs/db/sql/joins.html#self-join"
  },"847": {
    "doc": "JS/TS Cheatsheet",
    "title": "Javascript/Typescript Cheatsheet",
    "content": ". | Installation | Typescript compiler | Basic typing . | Primitive types | Array and tuple types | Union and enum types | Object types and type alias | Function types | Literal types | . | Type assertions | Interface . | Object interface | Function interface | . | Undefined values . | Non-null assertions (!) | . | Index signature | Generics | Classes | Readonly arrays and tuples | Symbol type | Computed property names | Template strings | . ",
    "url": "/docs/vue/jsts.html#javascripttypescript-cheatsheet",
    
    "relUrl": "/docs/vue/jsts.html#javascripttypescript-cheatsheet"
  },"848": {
    "doc": "JS/TS Cheatsheet",
    "title": "Installation",
    "content": "I personally prefer to install typescript compiler per project directory. npm i typescript --save-dev # or -D # OR yarn add typescript --dev . ",
    "url": "/docs/vue/jsts.html#installation",
    
    "relUrl": "/docs/vue/jsts.html#installation"
  },"849": {
    "doc": "JS/TS Cheatsheet",
    "title": "Typescript compiler",
    "content": "Basic usage: . tsc &lt;filename&gt; # One-time compile tsc --watch &lt;filename&gt; # Livereloading . When specifiying the filename for tsc you may include or leave out the .ts extension. tsc --init . init creates the tsconfig.json file. With a tsconfig.json file, you can leave out the filename when runnig tsc. ",
    "url": "/docs/vue/jsts.html#typescript-compiler",
    
    "relUrl": "/docs/vue/jsts.html#typescript-compiler"
  },"850": {
    "doc": "JS/TS Cheatsheet",
    "title": "Basic typing",
    "content": "Primitive types . Primitives are all lowercase. let a: number = 1; let b: string = \"a\"; let c: boolean = true; // Lowercase let d: any = { x: 0 }; . Unless declared without initialization, these are usually inferred. Array and tuple types . Simply add brackets: . let a: number[] = [1, 2, 3, 4]; // You can also use Array&lt;number&gt; let b: [number, string] = [1, \"a\"]; let c: [number, string][] = [[1, \"a\"], [2, \"b\"]]; . Union and enum types . Union: . let id: string | number; . Enum: . enum MyEnum { Up = 1, // Default is 0 Down, Left, Right } . The first constant in an enum always has the value of 0. If you set it to 1, the rest will have an ascending value of 2, 3, and 4. You can also give string values to enums. Object types and type alias . Object typing without the type alias can be messy: . const obj: { a: number, b?: string, readonly c: boolean, } = { a: 1, c: true } . Using type: . type MyObj = { a: number, b?: string, readonly c: boolean }; const obj: MyObj = { a: 1, c: true } . The ? means it is an optional property or an optional parameter if used in functions. Function types . function f(x: number, y: string): void { ... } . Literal types . You can use this like a constant or quicky enum: . function f(x: number, y: \"a\" | \"b\"): -1 | 0 | 1 { ... } . To change an object to a literal type use as const: . const x = { a: \"hello\", b: \"world\" } as const . ",
    "url": "/docs/vue/jsts.html#basic-typing",
    
    "relUrl": "/docs/vue/jsts.html#basic-typing"
  },"851": {
    "doc": "JS/TS Cheatsheet",
    "title": "Type assertions",
    "content": "To give any variables explicit types: . let a: any = 1; let b = a as number // OR let c = &lt;number&gt;a . ",
    "url": "/docs/vue/jsts.html#type-assertions",
    
    "relUrl": "/docs/vue/jsts.html#type-assertions"
  },"852": {
    "doc": "JS/TS Cheatsheet",
    "title": "Interface",
    "content": "Object interface . interface MyInterface { a: number, b?: string } . Function interface . interface FuncInterface { (x: number, y: string): void } . While it is similar to type aliasing, there are some differences: . | You cannot use union types with an interface. | . type MyType = string | number; // OK // interface MyType2 = string | number; // NO . | You can add new fields to existing interfaces but not in type aliasing. | . interface MyInterface{ a: number } interface MyInterface{ b: string } . ",
    "url": "/docs/vue/jsts.html#interface",
    
    "relUrl": "/docs/vue/jsts.html#interface"
  },"853": {
    "doc": "JS/TS Cheatsheet",
    "title": "Undefined values",
    "content": "Use null or undefined. function f(x: number | null): void{ ... } . Non-null assertions (!) . someObj!.runFunction(); . ",
    "url": "/docs/vue/jsts.html#undefined-values",
    
    "relUrl": "/docs/vue/jsts.html#undefined-values"
  },"854": {
    "doc": "JS/TS Cheatsheet",
    "title": "Index signature",
    "content": "To be added . ",
    "url": "/docs/vue/jsts.html#index-signature",
    
    "relUrl": "/docs/vue/jsts.html#index-signature"
  },"855": {
    "doc": "JS/TS Cheatsheet",
    "title": "Generics",
    "content": "To be added . ",
    "url": "/docs/vue/jsts.html#generics",
    
    "relUrl": "/docs/vue/jsts.html#generics"
  },"856": {
    "doc": "JS/TS Cheatsheet",
    "title": "Classes",
    "content": "To be added . ",
    "url": "/docs/vue/jsts.html#classes",
    
    "relUrl": "/docs/vue/jsts.html#classes"
  },"857": {
    "doc": "JS/TS Cheatsheet",
    "title": "Readonly arrays and tuples",
    "content": "To be added . ",
    "url": "/docs/vue/jsts.html#readonly-arrays-and-tuples",
    
    "relUrl": "/docs/vue/jsts.html#readonly-arrays-and-tuples"
  },"858": {
    "doc": "JS/TS Cheatsheet",
    "title": "Symbol type",
    "content": "To be added . ",
    "url": "/docs/vue/jsts.html#symbol-type",
    
    "relUrl": "/docs/vue/jsts.html#symbol-type"
  },"859": {
    "doc": "JS/TS Cheatsheet",
    "title": "Computed property names",
    "content": "To be added . ",
    "url": "/docs/vue/jsts.html#computed-property-names",
    
    "relUrl": "/docs/vue/jsts.html#computed-property-names"
  },"860": {
    "doc": "JS/TS Cheatsheet",
    "title": "Template strings",
    "content": "let a = `Put ${variableName} here.` . ",
    "url": "/docs/vue/jsts.html#template-strings",
    
    "relUrl": "/docs/vue/jsts.html#template-strings"
  },"861": {
    "doc": "JS/TS Cheatsheet",
    "title": "JS/TS Cheatsheet",
    "content": " ",
    "url": "/docs/vue/jsts.html",
    
    "relUrl": "/docs/vue/jsts.html"
  },"862": {
    "doc": "Moment / Expectation / Variance",
    "title": "Moment / Expectation / Variance",
    "content": ". | First Moment (Expectation) . | Linearity of Expectation | Linearity of Expectation in Matrix Form | Product of Independent Random Variables | . | K-th Moment | Moment Generating Function . | MGF under Random Variable Transformation | . | Second Central Moment (Variance) . | Standard Deviation | Linear Combination of Variance | Linear Combination of Variance in Matrix Form | Sum of Independent Random Variables | . | K-th Central Moment | . ",
    "url": "/docs/statistics/notes/kth-moment.html",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html"
  },"863": {
    "doc": "Moment / Expectation / Variance",
    "title": "First Moment (Expectation)",
    "content": "Also known as mean or expectation. $$ \\E[X] = \\int x dF(x) $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#first-moment-expectation",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#first-moment-expectation"
  },"864": {
    "doc": "Moment / Expectation / Variance",
    "title": "Linearity of Expectation",
    "content": "For random variables $X_i$ and constants $a_i$: . $$ \\E\\left[\\sum_{i=1}^n a_i X_i\\right] = \\sum_{i=1}^n a_i \\E[X_i] $$ . Expectation of Binomial with Bernoulli The expected value of a binomial random variable $X \\sim \\text{Binomial}(n, p)$ can be derived from the expected value of a Bernoulli random variable $X_i \\sim \\text{Bernoulli}(p)$: . \\[\\E[X] = \\E\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n \\E[X_i] = \\sum_{i=1}^n p = np\\] ",
    "url": "/docs/statistics/notes/kth-moment.html#linearity-of-expectation",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#linearity-of-expectation"
  },"865": {
    "doc": "Moment / Expectation / Variance",
    "title": "Linearity of Expectation in Matrix Form",
    "content": "Let $X$ be a random vector of $n$ random variables with mean vector $\\mu$ and variance $\\Sigma$. Let $a$ be a constant vector of $n$ constants. Then: . $$ \\E[a^T X] = a^T \\mu $$ . If $A$ is a constant matrix: . $$ \\E[AX] = A\\mu $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#linearity-of-expectation-in-matrix-form",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#linearity-of-expectation-in-matrix-form"
  },"866": {
    "doc": "Moment / Expectation / Variance",
    "title": "Product of Independent Random Variables",
    "content": "When $X_i$ are independent: . $$ \\E\\left[\\prod_{i=1}^n X_i\\right] = \\prod_{i=1}^n \\E[X_i] $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#product-of-independent-random-variables",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#product-of-independent-random-variables"
  },"867": {
    "doc": "Moment / Expectation / Variance",
    "title": "K-th Moment",
    "content": "The $k$-th moment of a random variable $X$ is: . $$ \\E[X^k] = \\int x^k dF(x) $$ . as long as $\\E[{|X|}^k] &lt; \\infty$. ",
    "url": "/docs/statistics/notes/kth-moment.html#k-th-moment",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#k-th-moment"
  },"868": {
    "doc": "Moment / Expectation / Variance",
    "title": "Moment Generating Function",
    "content": "Moment generating function (MGF) is a function that specifies a probability distribution (just like PDF, CDF, etc.). The MGF of a random variable $X$ is: . $$ \\psi_X(t) = \\E[e^{tX}] = \\int e^{tx} f_X(x) dx $$ . Laplace Transform Applying LOTUS, gives us: . \\[\\E(e^{tX}) = \\int e^{tx} f_X(x) dx\\] The following is called the two-sided Laplace transform of $f_X(x)$: . \\[\\mathcal{L}\\{f_X\\}(s) = \\int e^{-sx} f_X(x) dx\\] Since $\\E[e^{tX}] = \\mathcal{L}{f_X}(-t)$ the MGF is sometimes called the Laplace transform of $f_X(x)$. It is called moment generating function because the $k$-th derivative of $\\psi_X(t)$ at $t=0$ gives the $k$-th moment of $X$: . $$ \\E[X^k] = \\psi_X^{(k)}(0) $$ . First Moment from MGF The first moment (expectation) of $X$ can be derived from the MGF: . \\[\\psi_X'(0) = \\left[ \\frac{d}{dt} \\E[e^{tX}] \\right]_{t=0} = \\E\\left[ \\frac{d}{dt} e^{tX} \\right]_{t=0} = \\E[X e^{tX}]_{t=0} = \\E[X]\\] ",
    "url": "/docs/statistics/notes/kth-moment.html#moment-generating-function",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#moment-generating-function"
  },"869": {
    "doc": "Moment / Expectation / Variance",
    "title": "MGF under Random Variable Transformation",
    "content": ". | When $\\psi_X(t)$ is the MFG of $X$ and $Y = aX + b$: | . $$ \\psi_Y(t) = \\E[e^{tY}] = \\E[e^{t(aX + b)}] = e^{tb} \\E[e^{taX}] = e^{tb} \\psi_X(at) $$ . | When $\\psi_i(t)$ is the MFG of independent $X_i$ and $Y = \\sum_{i=1}^n X_i$: | . $$ \\psi_Y(t) = \\E[e^{tY}] = \\E[e^{t\\sum_{i=1}^n X_i}] = \\prod_{i=1}^n \\E[e^{tX_i}] = \\prod_{i=1}^n \\psi_i(t) $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#mgf-under-random-variable-transformation",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#mgf-under-random-variable-transformation"
  },"870": {
    "doc": "Moment / Expectation / Variance",
    "title": "Second Central Moment (Variance)",
    "content": "Also known as variance. $$ \\Var(X) = \\E[(X - \\mu)^2] = \\E[X^2] - \\E[X]^2 $$ . Expand \\[\\begin{align*} \\Var(X) &amp;= \\E[(X - \\E[X])^2] \\tag{$\\E[X] = \\mu$} \\\\[0.5em] &amp;= \\E[X^2 - 2X\\E[X] + \\E[X]^2] \\\\[0.5em] &amp;= \\E[X^2] - 2\\E[X]\\E[X] + \\E[X]^2 \\tag{linearity of expectation} \\\\[0.5em] &amp;= \\E[X^2] - \\E[X]^2 \\end{align*}\\] Rearranging the terms a little bit gives us: $$ \\E[X^2] = \\Var(X) + \\E[X]^2 $$ This is useful to know when you have $\\E[X]$ and $\\Var(X)$. ",
    "url": "/docs/statistics/notes/kth-moment.html#second-central-moment-variance",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#second-central-moment-variance"
  },"871": {
    "doc": "Moment / Expectation / Variance",
    "title": "Standard Deviation",
    "content": "Standard deviation is the square root of variance: . $$ \\sigma = \\sqrt{\\Var(X)} $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#standard-deviation",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#standard-deviation"
  },"872": {
    "doc": "Moment / Expectation / Variance",
    "title": "Linear Combination of Variance",
    "content": "If $a$ and $b$ are constants: . $$ \\begin{equation} \\label{eq:linear-combination-of-variance} \\Var(aX + b) = a^2 \\Var(X) \\end{equation} $$ . Furthermore, for $X$ and $Y$: . $$ \\Var(aX + bY) = a^2 \\Var(X) + b^2 \\Var(Y) + 2ab \\Cov(X, Y) $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#linear-combination-of-variance",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#linear-combination-of-variance"
  },"873": {
    "doc": "Moment / Expectation / Variance",
    "title": "Linear Combination of Variance in Matrix Form",
    "content": "Let $X$ be a random vector of $n$ random variables with mean vector $\\mu$ and variance $\\Sigma$. Let $a$ be a constant vector of $n$ constants. Then: . $$ \\Var(a^T X) = a^T \\Sigma a $$ . If $A$ is a constant matrix: . $$ \\Var(AX) = A\\Sigma A^T $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#linear-combination-of-variance-in-matrix-form",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#linear-combination-of-variance-in-matrix-form"
  },"874": {
    "doc": "Moment / Expectation / Variance",
    "title": "Sum of Independent Random Variables",
    "content": "When $X_i$ are independent and $X = \\sum_{i=1}^n X_i$: . $$ \\Var(X) = \\sum_{i=1}^n \\Var(X_i) $$ . Variance of Binomial with Bernoulli The variance of a binomial random variable $X \\sim \\text{Binomial}(n, p)$ can be derived from the variance of a Bernoulli random variable $X_i \\sim \\text{Bernoulli}(p)$: . \\[\\Var(X) = \\sum_{i=1}^n \\Var(X_i) = \\sum_{i=1}^n p(1-p) = np(1-p)\\] Together with linear combination of variance above, if $X = \\sum_{i=1}^n a_i X_i$: . $$ \\Var(X) = \\sum_{i=1}^n a_i^2 \\Var(X_i) $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#sum-of-independent-random-variables",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#sum-of-independent-random-variables"
  },"875": {
    "doc": "Moment / Expectation / Variance",
    "title": "K-th Central Moment",
    "content": "The $k$-th central moment of a random variable $X$ is: . $$ \\E[(X - \\mu)^k] = \\int (x - \\mu)^k dF(x) $$ . ",
    "url": "/docs/statistics/notes/kth-moment.html#k-th-central-moment",
    
    "relUrl": "/docs/statistics/notes/kth-moment.html#k-th-central-moment"
  },"876": {
    "doc": "Lagrange Multipliers",
    "title": "Method of Lagrange Multipliers",
    "content": "Popular method to solve constrained optimization problems. | Lagrange Multipliers . | Multiple constraints | . | Lagrangian | Lagrangian dual function | . ",
    "url": "/docs/statistics/notes/lagrangian.html#method-of-lagrange-multipliers",
    
    "relUrl": "/docs/statistics/notes/lagrangian.html#method-of-lagrange-multipliers"
  },"877": {
    "doc": "Lagrange Multipliers",
    "title": "Lagrange Multipliers",
    "content": "Optimization problem with constraints is often defined as follows: . | Objective function to be maximized or minimized | Constraint(s) that must be satisfied | . In the case of the figure above, the objective function is $f(x,y)$ and the constraint is $g(x,y) = c$. Very rough idea is as follows: . Out of the many level curves $f(x,y) = d$ can take, we want to pick the one with maximum or minimum $d$. Since we have a constraint, we can only expand or shrink the curve until it touches the constraint $g(x,y) = c$. There should be a point where both curves become tangent to each other. At this tangent, $f(x,y)$ is at a local extreme while satisfying the constraint. The gradient vector $\\nabla f(x,y)$ is orthogal to its tangent vector, and so is the gradient vector $\\nabla g(x,y)$ to its tangent vector. Although they may be in opposite directions and/or different magnitudes, both gradient vectors are aligned. In the figure above, they are the blue dotted line vector and the red line vector at the tangent point facing opposite directions. If we scale the gradient vector $\\nabla g(x,y)$ by a constant $\\lambda$, we can make it equal to the gradient vector $\\nabla f(x,y)$. $$ \\nabla f(x,y) = \\lambda \\nabla g(x,y) \\quad \\Rightarrow\\quad \\nabla f(x,y) - \\lambda \\nabla g(x,y) = 0 $$ . This constant $\\lambda$ is called the Lagrange multiplier, and $(x,y)$ that satisfies the above equation is the optimal solution. ",
    "url": "/docs/statistics/notes/lagrangian.html",
    
    "relUrl": "/docs/statistics/notes/lagrangian.html"
  },"878": {
    "doc": "Lagrange Multipliers",
    "title": "Multiple constraints",
    "content": "When there are multiple constraints, i.e. $g_i(x,y) = c_i$, we can extend the above equation as follows: . $$ \\nabla f(x,y) = \\sum_{i=1}^{m} \\lambda_i \\nabla g_i(x,y) \\quad \\Rightarrow\\quad \\nabla f(x,y) - \\sum_{i=1}^{m} \\lambda_i \\nabla g_i(x,y) = 0 $$ . where $m$ is the number of constraints. $\\lambda_i$ are the set of Lagrange multipliers. ",
    "url": "/docs/statistics/notes/lagrangian.html#multiple-constraints",
    
    "relUrl": "/docs/statistics/notes/lagrangian.html#multiple-constraints"
  },"879": {
    "doc": "Lagrange Multipliers",
    "title": "Lagrangian",
    "content": "You may be wondering where the actual constraint constant of each $g_i(x,y) = c_i$ went. Because that information is not captured in the equation above. In fact, the above system of equations does not provide enough information to solve for the optimal solution, because now we have added $m$ more unknowns $\\lambda_i$, while the gradient vectors $\\nabla f(x,y)$ and $\\nabla g_i(x,y)$ only provide enough for $x$ and $y$. We want to package the information of the constraints into the system of equations. The Lagrangian is the function that accomplishes this. $$ \\mathcal{L}(x,y,\\lambda) = f(x,y) - \\sum_{i=1}^{m} \\lambda_i (g_i(x,y) - c_i) $$ . To solve for the optimal solution, now you just need to solve: . $$ \\nabla \\mathcal{L}(x,y,\\lambda) = 0 $$ . \\[\\nabla \\mathcal{L}(x,y,\\lambda) = \\begin{bmatrix} \\frac{\\partial \\mathcal{L}}{\\partial x} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial y} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda_1} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda_m} \\end{bmatrix} = \\vec{0}\\] . ",
    "url": "/docs/statistics/notes/lagrangian.html#lagrangian",
    
    "relUrl": "/docs/statistics/notes/lagrangian.html#lagrangian"
  },"880": {
    "doc": "Lagrange Multipliers",
    "title": "Lagrangian dual function",
    "content": "To be added . The above Lagrangian is the primal form of the optimization problem. There is actually a dual form of the optimization problem. Say our goal was to minimize the Lagrangian above: . The primal approach above is to minimize the first part by minimizing over the primal variables $x$ and $y$ while adhering to the second part. Or we could try to maximize the second part by maximizing over the dual variable $\\lambda$ while adhering to some constraints which are derived from the primal variables. Why would we want to do this? . Turns out, sometimes the dual form is easier to solve than the primal form. ",
    "url": "/docs/statistics/notes/lagrangian.html#lagrangian-dual-function",
    
    "relUrl": "/docs/statistics/notes/lagrangian.html#lagrangian-dual-function"
  },"881": {
    "doc": "Linear Independence",
    "title": "Linear Independence",
    "content": ". | Linear Combination . | Linear Combination for Zero Vector | . | Linearly Independent | . ",
    "url": "/docs/linalg/basics/linear-independence.html",
    
    "relUrl": "/docs/linalg/basics/linear-independence.html"
  },"882": {
    "doc": "Linear Independence",
    "title": "Linear Combination",
    "content": "Let $V$ be a vector space and finite number of vectors $\\boldsymbol{x}_i \\in V$ where $i \\in \\{1, \\dots, k\\}$. $\\forall \\boldsymbol{v} \\in V$ where $\\exists \\lambda_i \\in \\mathbb{R}$ such that: . \\[\\boldsymbol{v} = \\sum_{i=1}^k \\lambda_i \\boldsymbol{x}_i\\] Then $\\boldsymbol{v}$ is a linear combination of $\\boldsymbol{x}_i$. ",
    "url": "/docs/linalg/basics/linear-independence.html#linear-combination",
    
    "relUrl": "/docs/linalg/basics/linear-independence.html#linear-combination"
  },"883": {
    "doc": "Linear Independence",
    "title": "Linear Combination for Zero Vector",
    "content": "The trivial linear combination for $\\sum_{i=1}^k \\lambda_i \\boldsymbol{x}_i = \\mathbf{0}$ is when $\\forall \\lambda_i = 0$. If $\\exists \\lambda_i \\neq 0$, then the linear combination is non-trivial. ",
    "url": "/docs/linalg/basics/linear-independence.html#linear-combination-for-zero-vector",
    
    "relUrl": "/docs/linalg/basics/linear-independence.html#linear-combination-for-zero-vector"
  },"884": {
    "doc": "Linear Independence",
    "title": "Linearly Independent",
    "content": "Let $V$ be a vector space and $\\boldsymbol{x}_i \\in V$ where $i \\in \\{1, \\dots, k\\}$. If there exists a non-trivial linear combination of $\\boldsymbol{x}_i$ that equals $\\mathbf{0}$, then $\\boldsymbol{x}_i$ is linearly dependent. Otherwise, if only a trivial combination exists, $\\boldsymbol{x}_i$ is linearly independent. If the only way to zero out the combination was to zero each and every one out, it means they have no relation to each other (no redundancy in information). Interesting observations: . | If $\\exists \\boldsymbol{x}_i = \\mathbf{0}$, then set of $\\boldsymbol{x}_i$ is linearly dependent. | Because setting all the others to zero and giving $\\boldsymbol{x}_i$ a non-zero value is a non-trivial combination that equals $\\mathbf{0}$. | . | If any $\\boldsymbol{x}_i$ is formed by a linear combination of the others, then set of $\\boldsymbol{x}_i$ is linearly dependent. | Because you can subtract the linear combination from $\\boldsymbol{x}_i$, and the result is a non-trivial combination that equals $\\mathbf{0}$. | . | Gaussian elimination (just to row echelon) can be used to determine linear independence of the column vectors. | Pivot columns are linearly independent to the columns to the left of them. | Set of column vectors are linearly independent if all columns are pivot columns. | . | . ",
    "url": "/docs/linalg/basics/linear-independence.html#linearly-independent",
    
    "relUrl": "/docs/linalg/basics/linear-independence.html#linearly-independent"
  },"885": {
    "doc": "Linear Mappings",
    "title": "Linear Mappings",
    "content": ". | Linear Transformation . | Composite Linear Transformation | Transformation Matrix | . | Types of Linear Mappings . | Homomorphism | Isomorphism . | When are two vector spaces isomorphic? | Inverse Mapping of an Isomorphism | . | Endomorphism | Automorphism . | Identity Mapping | . | . | Change of Basis of Linear Transformation . | Matrix Equivalence | Matrix Similarity | Invariance Under Basis Change | . | Bi-Linear Mapping . | Symmetric Bi-Linear Mapping | Positive Definite Bi-Linear Mapping | . | . ",
    "url": "/docs/linalg/basics/linear-mapping.html",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html"
  },"886": {
    "doc": "Linear Mappings",
    "title": "Linear Transformation",
    "content": "Linear transformation or linear mapping or vector space homomorphism is a mapping between two vector spaces that preserves the operations of vector addition and scalar multiplication and closure. This can be summarized as: . For vector spaces $V$, $W$, a mapping $\\Phi: V \\rightarrow W$ is a linear transformation if $\\forall \\mathbf{x}, \\mathbf{y} \\in V$ and $\\forall \\lambda, \\psi \\in \\mathbb{R}$: . $$ \\Phi(\\lambda \\mathbf{x} + \\psi \\mathbf{y}) = \\lambda \\Phi(\\mathbf{x}) + \\psi \\Phi(\\mathbf{y}) $$ . ",
    "url": "/docs/linalg/basics/linear-mapping.html#linear-transformation",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#linear-transformation"
  },"887": {
    "doc": "Linear Mappings",
    "title": "Composite Linear Transformation",
    "content": "Composite linear transformation is also a linear transformation. If $\\Phi: V \\rightarrow W$ and $\\Psi: W \\rightarrow X$ are linear transformations, then $\\Psi \\circ \\Phi$ is also a linear transformation. ",
    "url": "/docs/linalg/basics/linear-mapping.html#composite-linear-transformation",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#composite-linear-transformation"
  },"888": {
    "doc": "Linear Mappings",
    "title": "Transformation Matrix",
    "content": "With respect to ordered bases. Linear transformations can be represented by matrices. Let $V$ and $W$ be vector spaces with ordered bases $B = (\\mathbf{b}_1, \\dots, \\mathbf{b}_n)$ and $C = (\\mathbf{c}_1, \\dots, \\mathbf{c}_m)$ respectively. A linear mapping $\\Phi: V \\rightarrow W$ of . \\[\\Phi(\\mathbf{b}_j) = \\sum_{i=1}^m a_{ij} \\mathbf{c}_i\\] is represented by the matrix . \\[A_{\\Phi} = \\begin{bmatrix} a_{11} &amp; \\dots &amp; a_{1n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; \\dots &amp; a_{mn} \\end{bmatrix}\\] or for short . \\[A_{\\Phi}(i, j) = a_{ij}\\] $A_{\\Phi}$ is called the transformation matrix of $\\Phi$ with respect to the ordered bases. ",
    "url": "/docs/linalg/basics/linear-mapping.html#transformation-matrix",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#transformation-matrix"
  },"889": {
    "doc": "Linear Mappings",
    "title": "Types of Linear Mappings",
    "content": "Review the general concepts of injective, surjective, bijective mappings. ",
    "url": "/docs/linalg/basics/linear-mapping.html#types-of-linear-mappings",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#types-of-linear-mappings"
  },"890": {
    "doc": "Linear Mappings",
    "title": "Homomorphism",
    "content": "Let $\\Phi: V \\rightarrow W$ be a linear transformation. $\\Phi$ is a homomorphism. ",
    "url": "/docs/linalg/basics/linear-mapping.html#homomorphism",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#homomorphism"
  },"891": {
    "doc": "Linear Mappings",
    "title": "Isomorphism",
    "content": "Let $\\Phi: V \\rightarrow W$ be a linear transformation. $\\Phi$ is an isomorphism if it is bijective. When are two vector spaces isomorphic? . Finite-dimensional vector spaces $V$ and $W$ are isomorphic if and only if they have the same dimension. $$ V \\cong W \\iff \\dim(V) = \\dim(W) $$ . More details There exists a bijection $\\Phi: V \\rightarrow W$ when $\\dim(V) = \\dim(W)$. This means vector spaces of the same dimension are essentially the same thing, only represented differently. Inverse Mapping of an Isomorphism . The inverse mapping of an isomorphism $\\Phi^{-1}: W \\rightarrow V$ is also an isomorphism, by the bijectivity of the mapping. ",
    "url": "/docs/linalg/basics/linear-mapping.html#isomorphism",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#isomorphism"
  },"892": {
    "doc": "Linear Mappings",
    "title": "Endomorphism",
    "content": "Let $\\Phi: V \\rightarrow V$ be a linear transformation. $\\Phi$ is an endomorphism. ",
    "url": "/docs/linalg/basics/linear-mapping.html#endomorphism",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#endomorphism"
  },"893": {
    "doc": "Linear Mappings",
    "title": "Automorphism",
    "content": "Let $\\Phi: V \\rightarrow V$ be a linear transformation. $\\Phi$ is an automorphism if it is bijective. Identity Mapping . An identity mapping $\\mathrm{id}_V: V \\rightarrow V,\\, x \\mapsto x$ is an automorphism in $V$. ",
    "url": "/docs/linalg/basics/linear-mapping.html#automorphism",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#automorphism"
  },"894": {
    "doc": "Linear Mappings",
    "title": "Change of Basis of Linear Transformation",
    "content": "Let $\\Phi: V \\rightarrow W$ be a linear transformation. Let $B = (\\boldsymbol{b}_1, \\dots, \\boldsymbol{b}_n)$ and $\\tilde{B} = (\\tilde{\\boldsymbol{b}}_1, \\dots, \\tilde{\\boldsymbol{b}}_n)$ be ordered bases of $V$. Let $\\boldsymbol{S}$ be the transformation matrix of $\\mathrm{id}_V$ which maps coordinates of $\\tilde{B}$ to $B$. Let $C = (\\boldsymbol{c}_1, \\dots, \\boldsymbol{c}_m)$ and $\\tilde{C} = (\\tilde{\\boldsymbol{c}}_1, \\dots, \\tilde{\\boldsymbol{c}}_m)$ be ordered bases of $W$. Let $\\boldsymbol{T}$ be the transformation matrix of $\\mathrm{id}_W$ which maps coordinates of $\\tilde{C}$ to $C$. Change of basis matrices $\\boldsymbol{S}$ and $\\boldsymbol{T}$ are invertible because they are automorphisms. If $A_{\\Phi}$ is the transformation matrix of $\\Phi$ with respect to $B$ and $C$, and $\\tilde{A}_{\\Phi}$ is the transformation matrix of $\\Phi$ with respect to $\\tilde{B}$ and $\\tilde{C}$, then . $$ \\tilde{A}_{\\Phi} = T^{-1} A_{\\Phi} S $$ . ",
    "url": "/docs/linalg/basics/linear-mapping.html#change-of-basis-of-linear-transformation",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#change-of-basis-of-linear-transformation"
  },"895": {
    "doc": "Linear Mappings",
    "title": "Matrix Equivalence",
    "content": "We say that $A$ and $\\tilde{A}$ are equivalent if there exist invertible matrices $S$ and $T$ such that . \\[\\tilde{A} = T^{-1} A S\\] ",
    "url": "/docs/linalg/basics/linear-mapping.html#matrix-equivalence",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#matrix-equivalence"
  },"896": {
    "doc": "Linear Mappings",
    "title": "Matrix Similarity",
    "content": "If $A$ and $\\tilde{A}$ are square matrices and there exists an invertible matrix $S$ such that . \\[\\tilde{A} = S^{-1} A S\\] then we say that $A$ and $\\tilde{A}$ are similar. Similar, in that transformation $A$ and $\\tilde{A}$ are essentially the same, except for the change of basis represented by $S$. ",
    "url": "/docs/linalg/basics/linear-mapping.html#matrix-similarity",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#matrix-similarity"
  },"897": {
    "doc": "Linear Mappings",
    "title": "Invariance Under Basis Change",
    "content": "Some characteristic values of a linear transformation (or matrix) do not change under basis change. Some of these are: . | Eigenvalues | Determinants | Trace | . ",
    "url": "/docs/linalg/basics/linear-mapping.html#invariance-under-basis-change",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#invariance-under-basis-change"
  },"898": {
    "doc": "Linear Mappings",
    "title": "Bi-Linear Mapping",
    "content": "As seen above, linear mapping means it is a mapping closed under vector addition and scalar multiplication. Bi-linear mapping is similar, just that this mapping takes two arguments instead of one. For vector spaces $V$, $W$, $X$, a mapping $\\Omega: V \\times W \\rightarrow X$ is a bi-linear mapping if $\\forall \\mathbf{x} \\in V, \\forall \\mathbf{y} \\in W, \\forall \\mathbf{z} \\in W$ and $\\forall \\lambda, \\psi \\in \\mathbb{R}$: . $$ \\begin{gather*} \\Omega(\\lambda \\mathbf{x} + \\psi \\mathbf{y}, \\mathbf{z}) = \\lambda \\Omega(\\mathbf{x}, \\mathbf{z}) + \\psi \\Omega(\\mathbf{y}, \\mathbf{z}) \\\\[1em] \\Omega(\\mathbf{x}, \\lambda \\mathbf{y} + \\psi \\mathbf{z}) = \\lambda \\Omega(\\mathbf{x}, \\mathbf{y}) + \\psi \\Omega(\\mathbf{x}, \\mathbf{z}) \\end{gather*} $$ . More generally \\[\\begin{align*} \\Omega\\left(\\sum_{i=1}^n \\lambda_i \\mathbf{x}_i, \\sum_{j=1}^m \\psi_j \\mathbf{y}_j\\right) &amp;= \\lambda_1 \\psi_1 \\Omega(\\mathbf{x}_1, \\mathbf{y}_1) + \\dots + \\lambda_2 \\psi_1 \\Omega(\\mathbf{x}_2, \\mathbf{y}_1) + \\dots + \\lambda_n \\psi_m \\Omega(\\mathbf{x}_n, \\mathbf{y}_m) \\\\[1em] &amp;= \\sum_{i=1}^n \\sum_{j=1}^m \\lambda_i \\psi_j \\Omega(\\mathbf{x}_i, \\mathbf{y}_j) \\end{align*}\\] ",
    "url": "/docs/linalg/basics/linear-mapping.html#bi-linear-mapping",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#bi-linear-mapping"
  },"899": {
    "doc": "Linear Mappings",
    "title": "Symmetric Bi-Linear Mapping",
    "content": "$\\Omega$ is symmetric if $V = W$ and $\\forall \\mathbf{x}, \\mathbf{y} \\in V$: . $$ \\Omega(\\mathbf{x}, \\mathbf{y}) = \\Omega(\\mathbf{y}, \\mathbf{x}) $$ . ",
    "url": "/docs/linalg/basics/linear-mapping.html#symmetric-bi-linear-mapping",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#symmetric-bi-linear-mapping"
  },"900": {
    "doc": "Linear Mappings",
    "title": "Positive Definite Bi-Linear Mapping",
    "content": "$\\Omega$ is positive definite if $V = W$ and $\\forall \\mathbf{x} \\in V$: . | When $\\mathbf{x} \\neq \\mathbf{0}$, $\\Omega(\\mathbf{x}, \\mathbf{x}) &gt; 0$. | When $\\mathbf{x} = \\mathbf{0}$, $\\Omega(\\mathbf{x}, \\mathbf{x}) = 0$. | . ",
    "url": "/docs/linalg/basics/linear-mapping.html#positive-definite-bi-linear-mapping",
    
    "relUrl": "/docs/linalg/basics/linear-mapping.html#positive-definite-bi-linear-mapping"
  },"901": {
    "doc": "Linear Regression",
    "title": "Linear Regression",
    "content": ". | What is Linear Regression? | Simple Linear Regression | Multiple Linear Regression . | Feature Selection | . | Polynomial Regression . | Interaction Terms . | Comparing the Effect to the Simpler Model | Hierarchical Principle | . | Non-Linear Terms | Polynomial Feature Matrix . | Single Feature | Two Features | . | . | When is it adequate to use linear regression? . | Linearity | No multicollinearity | Zero conditional mean of the error | Homoscedasticity of the error | No autocorrelation of the residuals | Normality of the error | No outliers | . | . ",
    "url": "/docs/data-science/ml-dl/linear-regression.html",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html"
  },"902": {
    "doc": "Linear Regression",
    "title": "What is Linear Regression?",
    "content": "In statistical estimation, linear regression models the relationship between a dependent variable $y$ and one or more independent variables $x_i$ as a linear transformation of the independent variables plus some error/noise $\\varepsilon$. In general it models the relationship with the following equation: . | $y \\in \\mathbb{R}^{n \\times 1}$ is the dependent variable | $X \\in \\mathbb{R}^{n \\times p}$ is the matrix of independent variables consisting of $n$ observations and $p$ features | $\\beta \\in \\mathbb{R}^{p \\times 1}$ is the vector of coefficients | $\\varepsilon \\in \\mathbb{R}^{n \\times 1}$ is the error term | . To be more precise... During actual estimation: . | $X$ is a matrix of dimension $(n, p+1)$ with the first column consisting of 1s (for the intercept term) | . \\[X = \\begin{bmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1p} \\\\ 1 &amp; x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{np} \\end{bmatrix}\\] . | $\\beta$ is a vector of dimension $(p+1, 1)$ with the first element being the intercept term $\\beta_0$ | . \\[\\beta = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\\] Just so that the matrix multiplication $X \\beta$ produces: . $$ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} + \\varepsilon_i $$ . $$ y = X \\beta + \\varepsilon $$ . For a linear regression model, $\\beta$ is the model parameter that we try to estimate. Therefore, the prediction of the model is: . $$ \\hat{y} = X \\hat{\\beta} $$ . The model fitting process consists of estimating the parameter matrix $\\beta$ such that the residual (difference between observed $y$ and predicted $\\hat{y}$ value) is minimized. The most common minimization method is the ordinary least squares (OLS) method. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#what-is-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#what-is-linear-regression"
  },"903": {
    "doc": "Linear Regression",
    "title": "Simple Linear Regression",
    "content": "Simple linear regression is a linear regression model with a single independent variable. In other words, the number of features $p$ is equal to 1, so the feature matrix $X$ is a just a column vector. Assuming each observation is independent of each other, . $$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i $$ . where the error term has zero mean and constant variance: . \\[\\E(\\varepsilon_i | X) = 0 \\quad \\land \\quad \\Var(\\varepsilon_i | X) = \\sigma^2\\] Normality of the error term $\\varepsilon | X \\sim \\mathcal{N}(0, \\sigma^2)$ is not a requirement, but beneficial. Entire process is equivalent to finding a best-fit line in a 2D graph. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#simple-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#simple-linear-regression"
  },"904": {
    "doc": "Linear Regression",
    "title": "Multiple Linear Regression",
    "content": "Multiple linear regression is a linear regression model with multiple independent variables. $$ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} + \\varepsilon_i $$ . Do not confuse this with multivariate linear regression, which is a linear regression model with multiple dependent variables. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#multiple-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#multiple-linear-regression"
  },"905": {
    "doc": "Linear Regression",
    "title": "Feature Selection",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#feature-selection",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#feature-selection"
  },"906": {
    "doc": "Linear Regression",
    "title": "Polynomial Regression",
    "content": "Polynomial regression is actually just a special case of multiple linear regression. It’s just that we transform the feature matrix to include polynomial terms. Why is this linear? What matters is the coefficients of the model, because they are the actual unknowns that we try to estimate while the features are collections of known values. Although the features are in polynomial forms, the model itself is still a linear combination of the coefficients. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#polynomial-regression",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#polynomial-regression"
  },"907": {
    "doc": "Linear Regression",
    "title": "Interaction Terms",
    "content": "If some features are believed to be highly correlated, adding interaction terms to the 1-degree multiple linear model, which assumes independence of the features, can increase the model’s accuracy. For example: . $$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 \\boldsymbol{X_1 X_2} + \\epsilon $$ . In this case, . | Positive $\\hat{\\beta}_3$: $X_1$ and $X_2$ amplify each other’s effect on $Y$ . | Also called synergy | . | Negative $\\hat{\\beta}_3$: $X_1$ and $X_2$ dampen each other’s effect on $Y$ | . Comparing the Effect to the Simpler Model . To see if the interaction term is needed, . | Compare the $R^2$ (explained variance) of models with and without the interaction term . | $R^2$ should be higher with interaction | . | t-Test the significance of the interaction parameter | . Hierarchical Principle . There is one caveat when using interaction terms: . If you include an interaction term in the model, you should also include the main effects. Even if the main effects are tested to be insignificant, the interaction term can still be significant. In such a case, the main effects should still be included in the model for the interaction term to be interpretable. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#interaction-terms",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#interaction-terms"
  },"908": {
    "doc": "Linear Regression",
    "title": "Non-Linear Terms",
    "content": "Maybe the relationship between the response and the feature is not linear. In this case we can use transformed predictors to model the non-linear relationship, for example: . $$ Y = \\beta_0 + \\beta_1 X + \\beta_2 \\boldsymbol{X^2} + \\epsilon $$ . Adding this feature is valid because there is no linear dependency between $X$ and $X^2$. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#non-linear-terms",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#non-linear-terms"
  },"909": {
    "doc": "Linear Regression",
    "title": "Polynomial Feature Matrix",
    "content": "Amalgamating the above two concepts: . Single Feature . For a single feature $x$ and a polynomial degree of $d$, . $$ y_i = \\beta_0 + \\beta_1 x_{i} + \\beta_2 x_{i}^2 + \\cdots + \\beta_d x_{i}^d + \\varepsilon_i $$ . Is still just our regular . \\[y = X \\beta + \\varepsilon\\] when we define the feature matrix $X$ as: . \\[X = \\begin{bmatrix} 1 &amp; x_{1} &amp; x_{1}^2 &amp; \\cdots &amp; x_{1}^d \\\\ 1 &amp; x_{2} &amp; x_{2}^2 &amp; \\cdots &amp; x_{2}^d \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n} &amp; x_{n}^2 &amp; \\cdots &amp; x_{n}^d \\end{bmatrix}\\] This matrix is also called the Vandermonde matrix. Two Features . For two features $x_1$ and $x_2$ and a polynomial degree of $2$, . $$ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i1}^2 + \\beta_4 x_{i2}^2 + \\beta_5 x_{i1} x_{i2} + \\varepsilon_i $$ . so the feature matrix $X$ is: . \\[X = \\begin{bmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; x_{11}^2 &amp; x_{12}^2 &amp; x_{11} x_{12} \\\\ 1 &amp; x_{21} &amp; x_{22} &amp; x_{21}^2 &amp; x_{22}^2 &amp; x_{21} x_{22} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n1}^2 &amp; x_{n2}^2 &amp; x_{n1} x_{n2} \\end{bmatrix}\\] Only difference is that now joint polynomial terms are now included to model the interaction between the two features. When we have $p$ features and a polynomial degree of $d$, the number of features becomes a combination of $p+1$ variables (including the intercept) selected $d$ at a time with repetition allowed. If you increase the complexity of the model too much, estimation becomes computationally expensive. Also complex polynomial models are prone to overfitting. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#polynomial-feature-matrix",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#polynomial-feature-matrix"
  },"910": {
    "doc": "Linear Regression",
    "title": "When is it adequate to use linear regression?",
    "content": "For the linear model to be useful, typically the following checks should hold: . While some of the following conditions are intuitive, some of the not-so-obvious reasons come from the fact that they are required for parameter estimation to have a closed form solution, making estimation feasible or efficient (e.g. inverse of a matrix exists). ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#when-is-it-adequate-to-use-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#when-is-it-adequate-to-use-linear-regression"
  },"911": {
    "doc": "Linear Regression",
    "title": "Linearity",
    "content": "The relationship between the feature and response variables, or the structure of the true model, should be linear. Quite obvious: you don’t want to fit an arch to a line: . ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#linearity",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#linearity"
  },"912": {
    "doc": "Linear Regression",
    "title": "No multicollinearity",
    "content": "The independent variables should not be correlated with each other. If the value of one predictor is predetermined by the values of the other predictors, you have multicollinearity. In other words, if you have an $n \\times p$ feature matrix $X$, assuming $n &gt; p$, the feature matrix should have full rank of $p$. Otherwise, you have multicollinearity between the features. Multicollinearity can cause the following problems: . | Computationally expensive . | Increases unnecessary coefficients to be estimated | The feature matrix becomes singular . | To be specific $X^\\top X$ becomes singular | Rank deficient matrices are not invertible, which is required for OLS to have a closed form solution | . | . | Introduces confusion . | Harder to explain the effects of each predictor because they affect one another | . | . Near-perfect collinearity Maybe all features are linearly independent, in other words, they are not perfectly correlated. Then the closed-form solution for OLS exists. However, even if the features are not perfectly correlated, high correlation makes the estimator unstable or high in variance, which could be an indication that the model is not suitable. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#no-multicollinearity",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#no-multicollinearity"
  },"913": {
    "doc": "Linear Regression",
    "title": "Zero conditional mean of the error",
    "content": "Linear regression is suitable if the unknown error term has zero conditional mean: . $$ \\E(\\varepsilon | X) = 0 $$ . If you think about it, this assumption is essentially saying that the unknown error is negligible in determining the response. This makes sense because if the error is so high that it dominates the response, there is no point in trying to model the relationship. Check the residuals Upon fitting the model, you should check the residuals to see if they are centered around zero. Also, note the subtle difference between the error term and the residual. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#zero-conditional-mean-of-the-error",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#zero-conditional-mean-of-the-error"
  },"914": {
    "doc": "Linear Regression",
    "title": "Homoscedasticity of the error",
    "content": "Linear regression is suitable if the unknown error term has constant conditional variance: . $$ \\Var(\\varepsilon | X) = \\sigma^2 $$ . If you think about it, you want the data points to be within a certain boundary around the regression line for the model to be useful. It’s not a bad model, but it can be an indication that a linear model may not be the most suitable structure. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#homoscedasticity-of-the-error",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#homoscedasticity-of-the-error"
  },"915": {
    "doc": "Linear Regression",
    "title": "No autocorrelation of the residuals",
    "content": "Autocorrelation is the correlation with the lagged version of itself. For linear regression to be suitable, there should be no autocorrelation. In the figure below, there is a clear correlation between certain lagged periods: . ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#no-autocorrelation-of-the-residuals",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#no-autocorrelation-of-the-residuals"
  },"916": {
    "doc": "Linear Regression",
    "title": "Normality of the error",
    "content": "If the linear regression model captures the relationship well enough, the residuals should be normally distributed. For example, the following figure suggests maybe it wasn’t the best idea to use a single line to explain the samples: . Also having this condition brings additional benefits especially when using the OLS method for parameter estimation. And most of the time, the OLS method is used for parameter estimation. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#normality-of-the-error",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#normality-of-the-error"
  },"917": {
    "doc": "Linear Regression",
    "title": "No outliers",
    "content": "Outliers are data points that are significantly different from the rest of the data. If you know that these odd data points are truly outliers (in other words, they are not representative of the population, but only noise), then you can just remove them. However, if these points are, although rare, representative of the population maybe due to some special features, then you should consider using a different model, because a linear regression model is not robust to outliers. Modern ML libraries with linear regression models usually provide robust estimation methods that deweight outliers. ",
    "url": "/docs/data-science/ml-dl/linear-regression.html#no-outliers",
    
    "relUrl": "/docs/data-science/ml-dl/linear-regression.html#no-outliers"
  },"918": {
    "doc": "Logistic Function",
    "title": "Logistic Function",
    "content": ". | Definition | Standard Logistic Function (Sigmoid) . | In Logistic Regression | Horizontal Reflection of Sigmoid | Derivative of Sigmoid | . | Logit Function | . ",
    "url": "/docs/data-science/notes/logistic-function.html",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html"
  },"919": {
    "doc": "Logistic Function",
    "title": "Definition",
    "content": "A logistic function is a sigmoid curve that maps any real-valued number to the range $[0, L]$: . $$ f(x) = \\frac{L}{1 + e^{-k(x - x_0)}} $$ . Where: . | $L$: Maximum value of the curve | $k$: Steepness of the curve | $x_0$: The $x$ value of the function’s center | . ",
    "url": "/docs/data-science/notes/logistic-function.html#definition",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html#definition"
  },"920": {
    "doc": "Logistic Function",
    "title": "Standard Logistic Function (Sigmoid)",
    "content": "Standard logistic function, often just called the sigmoid function, has $L = 1$, $k = 1$, and $x_0 = 0$. It is often denoted $\\sigma(x)$: . $$ \\sigma(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{1 + e^x} $$ . Varying Parameters You will see how the curve changes from the standard sigmoid as we vary the parameters. ",
    "url": "/docs/data-science/notes/logistic-function.html#standard-logistic-function-sigmoid",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html#standard-logistic-function-sigmoid"
  },"921": {
    "doc": "Logistic Function",
    "title": "In Logistic Regression",
    "content": "In the context of logistic regression, the sigmoid function is used to model the probability that a given input belongs to a certain class, because it maps any real-valued number to the range $[0, 1]$. It is often denoted $p(X)$ in such context to emphasize that it models the probability: . $$ p(X) = \\frac{e^{X\\beta}}{1 + e^{X\\beta}} $$ . ",
    "url": "/docs/data-science/notes/logistic-function.html#in-logistic-regression",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html#in-logistic-regression"
  },"922": {
    "doc": "Logistic Function",
    "title": "Horizontal Reflection of Sigmoid",
    "content": "The horizontal reflection of the sigmoid function is: . $$ \\sigma(-x) = 1 - \\sigma(x) $$ . Derivation \\[\\begin{align*} \\sigma(x) &amp;= \\frac{1}{1 + e^{-x}} = \\frac{1}{1 + e^{-x}} \\cdot \\frac{e^x}{e^x} = \\frac{e^x}{1+ e^x} \\\\[0.5em] &amp; = 1 - \\sigma(-x) \\end{align*} \\iff \\sigma(-x) = 1 - \\sigma(x)\\] ",
    "url": "/docs/data-science/notes/logistic-function.html#horizontal-reflection-of-sigmoid",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html#horizontal-reflection-of-sigmoid"
  },"923": {
    "doc": "Logistic Function",
    "title": "Derivative of Sigmoid",
    "content": "The derivative of the sigmoid function is: . $$ \\sigma'(x) = \\sigma(x)(1 - \\sigma(x)) $$ . Derivation First we start from the modified form of the sigmoid function: . \\[\\sigma(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{1 + e^x}\\] Then we take the derivative: . \\[\\begin{align*} \\frac{d}{dx} \\sigma(x) &amp;= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} = \\frac{e^x}{(1 + e^x)^2} = \\frac{e^x}{1 + e^x} \\cdot \\frac{1}{1 + e^x} \\\\[0.5em] &amp;= \\sigma(x)(1 - \\sigma(x)) \\end{align*}\\] This simple derivative form is very useful in the context of machine learning. ",
    "url": "/docs/data-science/notes/logistic-function.html#derivative-of-sigmoid",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html#derivative-of-sigmoid"
  },"924": {
    "doc": "Logistic Function",
    "title": "Logit Function",
    "content": "The logit function is the inverse of the standard logistic function. Let $p(X)$ be the probability modeled by the sigmoid function: . \\[p(X) = \\frac{e^{f(X)}}{1 + e^{f(X)}}\\] Then we rearrange the equation to solve for $f(X)$: . $$ f(X) = \\log\\left(\\frac{p(X)}{1 - p(X)}\\right) $$ . Derivation \\[\\begin{gather*} p(X) + p(X)e^{f(X)} = e^{f(X)} \\\\[0.5em] e^{f(X)} = \\frac{p(X)}{1 - p(X)} \\\\[0.5em] f(X) = \\log\\left(\\frac{p(X)}{1 - p(X)}\\right) \\end{gather*}\\] The $f(X)$ is called the log-odds or logit of the probability $p(X)$. So we define the logit as a function of the probability: . $$ \\text{logit}(p) = \\log\\left(\\frac{p}{1 - p}\\right) $$ . What is odds? Odds is the ratio of the probability of success to the probability of failure. Let $p$ be the probability of success, then odds of success versus failure is defined as: . \\[\\text{odds} = \\frac{p}{1 - p}\\] We take the log of the odds to get the log-odds or logit. Also, . \\[p = \\frac{\\text{odds}}{1 + \\text{odds}}\\] ",
    "url": "/docs/data-science/notes/logistic-function.html#logit-function",
    
    "relUrl": "/docs/data-science/notes/logistic-function.html#logit-function"
  },"925": {
    "doc": "Logistic Regression",
    "title": "Logistic Regression",
    "content": ". | Quick Recap of Logistic Function and Logit | Binary Logistic Regression . | Interpretation of the Coefficients | . | MLE for Logistic Regression . | Testing for Estimator Significance | . | Multinomial Logistic Regression | Softmax Coding | . ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html"
  },"926": {
    "doc": "Logistic Regression",
    "title": "Quick Recap of Logistic Function and Logit",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#quick-recap-of-logistic-function-and-logit",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#quick-recap-of-logistic-function-and-logit"
  },"927": {
    "doc": "Logistic Regression",
    "title": "Binary Logistic Regression",
    "content": "Let $Y$ a binary response variable. We want to know $p(X)$ be the probability that $Y = 1$ given $X$: . $$ p(X) = P(Y = 1 \\mid X) $$ . In this case, our baseline class is $Y = 0$. In logistic regression, we model $p(X)$ using the logistic function: . $$ p(X; \\beta) = \\frac{e^{f(X;\\, \\beta)}}{1 + e^{f(X;\\, \\beta)}} $$ . Where $f(X; \\beta)$ is a linear function of $X$ (also the logit or log-odds of sigmoid $p(X)$): . $$ f(X; \\beta) = \\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p $$ . So logistic regression is still a linear model. ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#binary-logistic-regression",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#binary-logistic-regression"
  },"928": {
    "doc": "Logistic Regression",
    "title": "Interpretation of the Coefficients",
    "content": ". | A positive $\\hat{\\beta}_j$ means that $X_j$ is associated with higher probability of $Y = 1$. | One unit increase in $X_j$ increases the log-odds of $Y = 1$ versus $Y = 0$ by $\\hat{\\beta}_j$. | Because $f(X; \\beta)$ is the the logit (log-odds) of $p$ (probability of $Y=1$). | . | . ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#interpretation-of-the-coefficients",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#interpretation-of-the-coefficients"
  },"929": {
    "doc": "Logistic Regression",
    "title": "MLE for Logistic Regression",
    "content": "To estimate $\\beta$ we use maximum likelihood estimation (MLE). The likelihood function is: . $$ \\mathcal{L}(\\beta) = \\prod_{i=1}^n p(x_i; \\beta)^{y_i} (1 - p(x_i; \\beta))^{1 - y_i} $$ . The parameter $\\beta$ should maximize $p$ when $y = 1$, maximize $1 - p$ when $y = 0$, and thus maximize the likelihood. The log-likelihood function is: . \\[\\begin{align*} \\ell(\\beta) &amp;= \\sum_{i=1}^n \\left[ y_i \\log p(x_i; \\beta) + (1 - y_i) \\log (1 - p(x_i; \\beta)) \\right] \\\\[0.5em] &amp;= \\sum_{i=1}^n \\left[ y_i f(x_i; \\beta) - \\log(1 + e^{f(x_i; \\beta)}) \\right] \\end{align*}\\] Derivation Remember that logit is: . \\[f(x_i; \\beta) = \\log\\left(\\frac{p(x_i; \\beta)}{1 - p(x_i; \\beta)}\\right) = \\log(p(x_i; \\beta)) - \\log(1 - p(x_i; \\beta))\\] And . \\[\\log(1 - p(x_i; \\beta)) = \\log\\left(\\frac{1}{1 + e^{f(x_i; \\beta)}}\\right) = -\\log(1 + e^{f(x_i; \\beta)})\\] Then: . \\[\\begin{align*} &amp;y_i \\log p(x_i; \\beta) + (1 - y_i) \\log (1 - p(x_i; \\beta)) \\\\[0.5em] =\\; &amp;y_i \\log p(x_i; \\beta) - y_i \\log(1 - p(x_i; \\beta)) + \\log(1 - p(x_i; \\beta)) \\\\[0.5em] =\\; &amp;y_i f(x_i; \\beta) - \\log(1 + e^{f(x_i; \\beta)}) \\end{align*}\\] We take the derivative of $\\ell(\\beta)$ with respect to $\\beta$ and solve for $\\beta$: . \\[\\frac{\\partial \\ell(\\beta)}{\\partial \\beta} = 0\\] Then we use iterative methods to get $\\hat{\\beta}$. There is no closed-form solution for $\\hat{\\beta}$. ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#mle-for-logistic-regression",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#mle-for-logistic-regression"
  },"930": {
    "doc": "Logistic Regression",
    "title": "Testing for Estimator Significance",
    "content": "Remember that MLE estimators are asymptotically normal. Therefore, you can test for the significance of the estimators using the z-statistic: . $$ z = \\frac{\\hat{\\beta}_j}{\\text{SE}(\\hat{\\beta}_j)} $$ . ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#testing-for-estimator-significance",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#testing-for-estimator-significance"
  },"931": {
    "doc": "Logistic Regression",
    "title": "Multinomial Logistic Regression",
    "content": "When the response variable has more than two classes, let’s say $K$ classes, we use multinomial logistic regression. The probability model is: . $$ P(Y = k \\mid X; \\beta) = \\frac{e^{\\beta_{k0} + \\beta_k^T X}} {1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_l^T X}} $$ . You will see that we actually have $K-1$ equations, because we usually set the class $K$ as the baseline where $\\beta_{K0} = 0$ and $\\beta_{K} = \\mathbf{0}$. ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#multinomial-logistic-regression",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#multinomial-logistic-regression"
  },"932": {
    "doc": "Logistic Regression",
    "title": "Softmax Coding",
    "content": "In multinomial logistic regression, we usually set the last class $K$ as the baseline, where all $\\beta_{K0} = 0$ and $\\beta_K = \\mathbf{0}$. But with softmax coding, we do not set any class as the baseline. In softmax coding, our log-odds (or logit function) of class $k$ versus any class $k’$ is: . $$ f(x; \\beta) = (\\beta_{k0}-\\beta_{k'0}) + (\\beta_{k1} - \\beta_{k'1})x_1 + \\ldots (\\beta_{kp} - \\beta_{k'p})x_p $$ . While in multinomial logistic regression, our log-odds (or logit function) was always the class $k$ in question versus the baseline class $K$ where all the coefficients are zero: . $$ f(x; \\beta) = \\beta_{k0} + \\beta_{k1}x_1 + \\ldots + \\beta_{kp}x_p $$ . ",
    "url": "/docs/data-science/ml-dl/logistic-regression.html#softmax-coding",
    
    "relUrl": "/docs/data-science/ml-dl/logistic-regression.html#softmax-coding"
  },"933": {
    "doc": "5 - Longest Palindromic Substring - Medium",
    "title": "Longest Palindromic Substring",
    "content": ". | Problem | Explanation | Solution | . ",
    "url": "/docs/compsci/leetcode/longest-palindromic-substring.html#longest-palindromic-substring",
    
    "relUrl": "/docs/compsci/leetcode/longest-palindromic-substring.html#longest-palindromic-substring"
  },"934": {
    "doc": "5 - Longest Palindromic Substring - Medium",
    "title": "Problem",
    "content": "Given a string s, return the longest palindromic substring in s. ",
    "url": "/docs/compsci/leetcode/longest-palindromic-substring.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/longest-palindromic-substring.html#problem"
  },"935": {
    "doc": "5 - Longest Palindromic Substring - Medium",
    "title": "Explanation",
    "content": "The solution uses dynamic programming, with the memoization matrix $M[i,j]$ defined as follows: . \\[M[i,j] = \\begin{cases} \\text{true} &amp; \\text{if } s[i, j] \\text{ is a palindrome} \\\\[0.5em] \\text{false} &amp; \\text{otherwise} \\end{cases}\\] where $s[i, j]$ is the substring of $s$ from index $i$ to index $j$ (inclusive). One thing to note is that a substring of length $1$ is always a palindrome. This will be our base case: . \\[M[i,i] = \\text{true} \\quad \\forall i \\in [0, n)\\] If we want to know if substring $s[i, j]$ is a palindrome, . | For substrings of length $2$, it suffices to check $s[i] = s[j]$. | For substrings of length $l \\geq 3$, in addition to checking $s[i] = s[j]$, we also need to check if $s[i+1, j-1]$ is a palindrome ($M[i+1, j-1] = \\text{true}$) . Checking $s[i+1, j-1]$ is a palindrome is equivalent to checking the value of the cell at the one left-bottom diagonal of $M[i,j]$ (the orange arrow). | . To ensure that $M[i+1, j-1]$ is already computed before computing $M[i,j]$, we need to make sure that we are computing the cells in the matrix in the right order. The computation order must be in a diagonal fashion, starting from $M[0,1]$ and going to the right bottom. We can do this by fixing the length of the substring $l$, and then iterate through the string $s$ from left to right. ",
    "url": "/docs/compsci/leetcode/longest-palindromic-substring.html#explanation",
    
    "relUrl": "/docs/compsci/leetcode/longest-palindromic-substring.html#explanation"
  },"936": {
    "doc": "5 - Longest Palindromic Substring - Medium",
    "title": "Solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 . | public String longestPalindrome(String s) { int n = s.length(); boolean[][] M = new boolean[n][n]; for (int i = 0; i &lt; n; i++) { M[i][i] = true; // Set base case } int max = 1; int start = 0; for (int l = 2; l &lt;= n; l++) { for (int i = 0; i &lt; n - l + 1; i++) { int j = i + l - 1; boolean isPalindrome = s.charAt(i) == s.charAt(j); isPalindrome = isPalindrome &amp;&amp; (l == 2 || M[i + 1][j - 1]); if (isPalindrome) { max = l; start = i; } M[i][j] = isPalindrome; } } return s.substring(start, start + max); } . | . The complexity of the solution is $O(n^2)$. ",
    "url": "/docs/compsci/leetcode/longest-palindromic-substring.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/longest-palindromic-substring.html#solution"
  },"937": {
    "doc": "5 - Longest Palindromic Substring - Medium",
    "title": "5 - Longest Palindromic Substring - Medium",
    "content": " ",
    "url": "/docs/compsci/leetcode/longest-palindromic-substring.html",
    
    "relUrl": "/docs/compsci/leetcode/longest-palindromic-substring.html"
  },"938": {
    "doc": "3 - Longest Substring Without Repeating Characters - Medium",
    "title": "Longest Substring Without Repeating Characters",
    "content": ". | Problem | Solution | . ",
    "url": "/docs/compsci/leetcode/longest-substring-no-repeat.html#longest-substring-without-repeating-characters",
    
    "relUrl": "/docs/compsci/leetcode/longest-substring-no-repeat.html#longest-substring-without-repeating-characters"
  },"939": {
    "doc": "3 - Longest Substring Without Repeating Characters - Medium",
    "title": "Problem",
    "content": "Given a string s, find the length of the longest substring without repeating characters. Input: s = \"abcabcbb\" Output: 3 Explanation: The answer is \"abc\", with the length of 3. ",
    "url": "/docs/compsci/leetcode/longest-substring-no-repeat.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/longest-substring-no-repeat.html#problem"
  },"940": {
    "doc": "3 - Longest Substring Without Repeating Characters - Medium",
    "title": "Solution",
    "content": "The main idea is to use an imaginary sliding window. Until we see a repeated character, we just can keep expanding the window. However, once we see a repeated character, the starting point of the window needs to be moved to the right until the last occurrence of the repeated character is no longer in the window. \\[\\fbox{abcde} \\mbox{fd} \\implies \\fbox{abcdef} \\mbox{d} \\implies \\mbox{abcd} \\fbox{efd}\\] So, we should to keep track of the last occurrence of each character. I will be using a HashMap&lt;Character, Integer&gt; to do this, where each character is mapped to its index of last occurrence. HashMap&lt;Character, Integer&gt; seen = new HashMap&lt;&gt;(); int maxLen = 0; // Max found so far int curLen = 0; // Size of current window for (int j = 0; j &lt; s.length(); j++) { Character c = s.charAt(j); if (seen.containsKey(c)) { // Found a repeated character int i = seen.get(c); // Retrieve index of last occurrence if (j - curLen &gt; i) { // If last occurrence is not within window curLen++; } else { curLen = j - (i + 1) + 1; // Calculate new window size } seen.replace(c, j); // Update last occurrence } else { curLen++; // Expand window seen.put(c, j); // Record last occurrence } maxLen = Math.max(maxLen, curLen); } return maxLen; . Everything is straightforward except for: . if (j - curLen &gt; i) { // If last occurrence is not within window curLen++; } else { curLen = j - (i + 1) + 1; // Calculate new window size } . What is the if statement doing? . Take the example of abbcda. When we see the last a at index 5, the window looks like . \\[\\mbox{ab} \\fbox{bcd} \\mbox{a}\\] The window should now ignore everything before the second b, but the HashMap still has a -&gt; 0 in it. Calculating j - (i + 1) + 1 will give us the wrong window of . \\[\\fbox{abbcda}\\] so we have to make the window ignore everything outside of current window. ",
    "url": "/docs/compsci/leetcode/longest-substring-no-repeat.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/longest-substring-no-repeat.html#solution"
  },"941": {
    "doc": "3 - Longest Substring Without Repeating Characters - Medium",
    "title": "3 - Longest Substring Without Repeating Characters - Medium",
    "content": " ",
    "url": "/docs/compsci/leetcode/longest-substring-no-repeat.html",
    
    "relUrl": "/docs/compsci/leetcode/longest-substring-no-repeat.html"
  },"942": {
    "doc": "M1 TensorFlow",
    "title": "M1 Tensorflow",
    "content": "GPU accelerated TensorFlow on M1 . See here for the official documentation. | Install Miniforge | Install TensorFlow dependencies | Install base TensorFlow and tensorflow-metal | To upgrade to a new TensorFlow version | . ",
    "url": "/docs/data-science/m1-tf.html#m1-tensorflow",
    
    "relUrl": "/docs/data-science/m1-tf.html#m1-tensorflow"
  },"943": {
    "doc": "M1 TensorFlow",
    "title": "Install Miniforge",
    "content": "Download and install Miniforge3 conda: . curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh chmod +x Miniforge3-MacOSX-arm64.sh sh Miniforge3-MacOSX-arm64.sh # Optional conda config --set auto_activate_base false . For information on conda see here. Installing Miniconda3 macOS Apple M1 64-bit bash (Py38 conda 4.10.1 2021-11-08) did not work. Miniforge’s arm64 was the only thing that worked. ",
    "url": "/docs/data-science/m1-tf.html#install-miniforge",
    
    "relUrl": "/docs/data-science/m1-tf.html#install-miniforge"
  },"944": {
    "doc": "M1 TensorFlow",
    "title": "Install TensorFlow dependencies",
    "content": "Create a new environment: . conda create -n tf-m1 python=3.9 . You can use either Python 3.8 or 3.9. Install tensorflow-deps: . conda install -c apple tensorflow-deps . ",
    "url": "/docs/data-science/m1-tf.html#install-tensorflow-dependencies",
    
    "relUrl": "/docs/data-science/m1-tf.html#install-tensorflow-dependencies"
  },"945": {
    "doc": "M1 TensorFlow",
    "title": "Install base TensorFlow and tensorflow-metal",
    "content": "Making sure the environment is activated: . Check environment is indeed activated by which pip. Especially if you’re doing it in a VSCode terminal. pip install tensorflow-macos . pip install tensorflow-metal . ",
    "url": "/docs/data-science/m1-tf.html#install-base-tensorflow-and-tensorflow-metal",
    
    "relUrl": "/docs/data-science/m1-tf.html#install-base-tensorflow-and-tensorflow-metal"
  },"946": {
    "doc": "M1 TensorFlow",
    "title": "To upgrade to a new TensorFlow version",
    "content": "From the official doc, the recommended way is: . # uninstall existing tensorflow-macos and tensorflow-metal python -m pip uninstall tensorflow-macos python -m pip uninstall tensorflow-metal # Upgrade tensorflow-deps conda install -c apple tensorflow-deps --force-reinstall # or point to specific conda environment conda install -c apple tensorflow-deps --force-reinstall -n my_env . ",
    "url": "/docs/data-science/m1-tf.html#to-upgrade-to-a-new-tensorflow-version",
    
    "relUrl": "/docs/data-science/m1-tf.html#to-upgrade-to-a-new-tensorflow-version"
  },"947": {
    "doc": "M1 TensorFlow",
    "title": "M1 TensorFlow",
    "content": " ",
    "url": "/docs/data-science/m1-tf.html",
    
    "relUrl": "/docs/data-science/m1-tf.html"
  },"948": {
    "doc": "Mallows's Cp",
    "title": "Mallows’s $C_p$",
    "content": "Mallows’s $C_p$ is used to assess model selection in regression analysis using ordinary least squares (OLS). $$ C_p = \\frac{1}{n} \\left( \\text{RSS} + 2p\\hat{\\sigma}^2 \\right) $$ . where: . | $\\text{RSS}$: Residual Sum of Squares | $p$: number of parameters used in the model | $\\hat{\\sigma}^2$: estimated variance of the error term | . Lower values of $C_p$ indicate better models. ",
    "url": "/docs/data-science/notes/mallows-c.html#mallowss-c_p",
    
    "relUrl": "/docs/data-science/notes/mallows-c.html#mallowss-c_p"
  },"949": {
    "doc": "Mallows's Cp",
    "title": "Mallows's Cp",
    "content": " ",
    "url": "/docs/data-science/notes/mallows-c.html",
    
    "relUrl": "/docs/data-science/notes/mallows-c.html"
  },"950": {
    "doc": "Mapping",
    "title": "Mapping",
    "content": "Quick recap of definitions. | Basic definitions . | Domain | Codomain | Image | Range | . | Surjection | Injection | Bijection | Inverse mapping | . ",
    "url": "/docs/compsci/math/mapping.html",
    
    "relUrl": "/docs/compsci/math/mapping.html"
  },"951": {
    "doc": "Mapping",
    "title": "Basic definitions",
    "content": "Let $f$ be a function or mapping from a set $A$ to a set $B$: . $$ f: X \\to Y $$ . ",
    "url": "/docs/compsci/math/mapping.html#basic-definitions",
    
    "relUrl": "/docs/compsci/math/mapping.html#basic-definitions"
  },"952": {
    "doc": "Mapping",
    "title": "Domain",
    "content": "The set $X$ is called the domain of $f$. ",
    "url": "/docs/compsci/math/mapping.html#domain",
    
    "relUrl": "/docs/compsci/math/mapping.html#domain"
  },"953": {
    "doc": "Mapping",
    "title": "Codomain",
    "content": "The set $Y$ is called the codomain of $f$. ",
    "url": "/docs/compsci/math/mapping.html#codomain",
    
    "relUrl": "/docs/compsci/math/mapping.html#codomain"
  },"954": {
    "doc": "Mapping",
    "title": "Image",
    "content": "When $f(x_i) = y_i$, we call $x_i$ the image of $y_i$ under $f$. ",
    "url": "/docs/compsci/math/mapping.html#image",
    
    "relUrl": "/docs/compsci/math/mapping.html#image"
  },"955": {
    "doc": "Mapping",
    "title": "Range",
    "content": "The set of all images of $f$ is called the range of $f$: . \\[\\{f(x_i) \\mid x_i \\in X\\}\\] Sometimes image and range are used interchangeably. ",
    "url": "/docs/compsci/math/mapping.html#range",
    
    "relUrl": "/docs/compsci/math/mapping.html#range"
  },"956": {
    "doc": "Mapping",
    "title": "Surjection",
    "content": "Let $f: X \\to Y$, $f$ is surjective if . $$ \\forall y \\in Y,\\; \\exists x \\in X \\mathbin{s.t.} f(x) = y $$ . In other words, if the range of $f$ is equal to its codomain. Also called onto mapping. ",
    "url": "/docs/compsci/math/mapping.html#surjection",
    
    "relUrl": "/docs/compsci/math/mapping.html#surjection"
  },"957": {
    "doc": "Mapping",
    "title": "Injection",
    "content": "Let $f: X \\to Y$, $f$ is injective if . $$ \\forall x_1, x_2 \\in X,\\; f(x_1) = f(x_2) \\Rightarrow x_1 = x_2 $$ . Also called one-to-one mapping. ",
    "url": "/docs/compsci/math/mapping.html#injection",
    
    "relUrl": "/docs/compsci/math/mapping.html#injection"
  },"958": {
    "doc": "Mapping",
    "title": "Bijection",
    "content": "Let $f: X \\to Y$, $f$ is bijective if it is both surjective and injective. Also called one-to-one correspondence. ",
    "url": "/docs/compsci/math/mapping.html#bijection",
    
    "relUrl": "/docs/compsci/math/mapping.html#bijection"
  },"959": {
    "doc": "Mapping",
    "title": "Inverse mapping",
    "content": "Let $f: X \\to Y$ be a bijection, then there exists a inverse mapping $f^{-1}: Y \\to X$ such that . $$ \\forall x \\in X,\\; f^{-1}(f(x)) = x $$ . And this inverse mapping is also a bijection. ",
    "url": "/docs/compsci/math/mapping.html#inverse-mapping",
    
    "relUrl": "/docs/compsci/math/mapping.html#inverse-mapping"
  },"960": {
    "doc": "Matrix Decomposition",
    "title": "Matrix Decomposition",
    "content": ". | LU decomposition . | Condition | How to find $L$ and $U$ . | Using elementary row operations | Doolittle algorithm | . | Using LU to solve linear equations | . | . ",
    "url": "/docs/linalg/notes/matrix-decomposition.html",
    
    "relUrl": "/docs/linalg/notes/matrix-decomposition.html"
  },"961": {
    "doc": "Matrix Decomposition",
    "title": "LU decomposition",
    "content": "The LU decomposition of any matrix $A$ is a factorization of $A$ into a product of a lower triangular matrix $L$ and an upper triangular matrix $U$. $$ A = LU $$ . $A$ does not have to be a square matrix. It is conventional to have the principal diagonal of $L$ to be all $1$. ",
    "url": "/docs/linalg/notes/matrix-decomposition.html#lu-decomposition",
    
    "relUrl": "/docs/linalg/notes/matrix-decomposition.html#lu-decomposition"
  },"962": {
    "doc": "Matrix Decomposition",
    "title": "Condition",
    "content": "For a matrix $A$ to have an LU decomposition, it must be possible to rewrite $A$ as an upper triangular matrix with only non-zero row scalings and row additions. So basically the elementary row operations except row exchange. If row exchange is needed, then $A$ has a PLU decomposition, where $P$ is a permutation matrix. ",
    "url": "/docs/linalg/notes/matrix-decomposition.html#condition",
    
    "relUrl": "/docs/linalg/notes/matrix-decomposition.html#condition"
  },"963": {
    "doc": "Matrix Decomposition",
    "title": "How to find $L$ and $U$",
    "content": "Using elementary row operations . As stated above, matrix $A$ must be able to be rewritten as an upper triangular matrix $U$ for it to have an LU decomposition. The elementary matrix multiplication $E_1 \\dots E_k$ that are used to transform $A$ has an inverse of $E_1^{-1} \\dots E_k^{-1}$ by its property. \\[E_k \\dots E_1 A = U \\Rightarrow A = E_1^{-1} \\dots E_k^{-1} U\\] therefore: . $$ L = E_1^{-1} \\dots E_k^{-1} $$ . Doolittle algorithm . The Doolittle algorithm is a method to find the LU decomposition of a matrix $A$. Assuming the principal diagonal of $L$ is all $1$. Starting from the top left corner of $A$, where $l_{1k} = [1, 0, \\dots, 0]$ is the first row vector of $L$, and $u_{k1} = [u_{11}, 0, \\dots, 0]^T$ is the first column vector of $U$: . \\[a_{11} = l_{1k} \\cdot u_{k1} = u_{11}\\] We iteratively find the following: . $$ \\begin{gather*} \\forall i &gt; j,\\; l_{ij} = \\frac{a_{ij} - \\sum_{k=1}^{j-1} l_{ik} u_{kj}}{u_{jj}} \\\\ \\forall i \\geq j,\\; u_{ij} = a_{ij} - \\sum_{k=1}^{j-1} l_{ik} u_{kj} \\end{gather*} $$ . ",
    "url": "/docs/linalg/notes/matrix-decomposition.html#how-to-find-l-and-u",
    
    "relUrl": "/docs/linalg/notes/matrix-decomposition.html#how-to-find-l-and-u"
  },"964": {
    "doc": "Matrix Decomposition",
    "title": "Using LU to solve linear equations",
    "content": "Let $A$ be a matrix that has an LU decomposition $LU$, . Then the linear equation $Ax = b$ can be solved by: . \\[Ax = b \\Rightarrow LUx = b \\Rightarrow Ly = b \\land Ux = y\\] where $y$ is a vector that can be found by solving $Ly = b$. We do this because with triangular matrices in augmented form, Gauss-Jordan elimination becomes much easier. ",
    "url": "/docs/linalg/notes/matrix-decomposition.html#using-lu-to-solve-linear-equations",
    
    "relUrl": "/docs/linalg/notes/matrix-decomposition.html#using-lu-to-solve-linear-equations"
  },"965": {
    "doc": "Basic Matrix Definitions",
    "title": "Basic Matrix Definitions",
    "content": "Basic definitions. | Matrix . | Elementary Row Operations . | Row Equivalence | . | Basic Matrix Math Operations | Matrix Multiplication | . | Square Matrix . | Identity Matrix | Elementary Matrix | Power of a Matrix | . | Transpose of a Matrix . | Symmetric Matrix | Skew-symmetric Matrix | Properties of Transpose | . | . ",
    "url": "/docs/linalg/basics/matrix.html",
    
    "relUrl": "/docs/linalg/basics/matrix.html"
  },"966": {
    "doc": "Basic Matrix Definitions",
    "title": "Matrix",
    "content": "Following is a $\\mathbf{m \\times n}$ matrix $A$, with $m$ rows and $n$ columns: . $$ A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\cdots &amp; a_{mn} \\end{bmatrix} $$ . | $a_ij$ is the $(i, j)$-th entry or element of $A$. | Often denoted in a short-hand notation: . \\[A = [a_{ij}]_{m \\times n}\\] | . ",
    "url": "/docs/linalg/basics/matrix.html#matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#matrix"
  },"967": {
    "doc": "Basic Matrix Definitions",
    "title": "Elementary Row Operations",
    "content": ". | Row exchange: swap two rows of a matrix. | Row scaling: multiply a row by a nonzero scalar. | Row addition: add a scalar multiple of one row to another row. | . Row Equivalence . Matrices $A$ and $B$ are row equivalent if there is a sequence of elementary row operations that transforms $A$ into $B$. We denote row equivalence by: . $$ A \\sim B $$ . ",
    "url": "/docs/linalg/basics/matrix.html#elementary-row-operations",
    
    "relUrl": "/docs/linalg/basics/matrix.html#elementary-row-operations"
  },"968": {
    "doc": "Basic Matrix Definitions",
    "title": "Basic Matrix Math Operations",
    "content": ". | Addition and subtraction of matrices are defined only for matrices of the same size. | Scalar multiplication is defined for any matrix and any scalar. | Transpose of a scalar is itself: $\\lambda^\\top = \\lambda$ | . | . Basic matrix calculations generally satisfy all the usual rules of algebra: commutative, associative, distributive, etc. ",
    "url": "/docs/linalg/basics/matrix.html#basic-matrix-math-operations",
    
    "relUrl": "/docs/linalg/basics/matrix.html#basic-matrix-math-operations"
  },"969": {
    "doc": "Basic Matrix Definitions",
    "title": "Matrix Multiplication",
    "content": "Do not confuse matrix multiplication with Hadamard product (element-wise product). Matrix multiplication $A \\times B$ is defined only if the number of columns of $A$ is equal to the number of rows of $B$: $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{n \\times p}$. If the resulting matrix $C = A \\times B$ is defined, then $C \\in \\mathbb{R}^{m \\times p}$. The $(i, j)$-th element of $C$ is the dot product of the $i$-th row of $A$ and the $j$-th column of $B$: . $$ c_{ij} = \\sum_{k=1}^n a_{ik} b_{kj} $$ . | Associative: $(A B) C = A (B C)$ | Distributive: $A (B + C) = A B + A C$ and $(A + B) C = A C + B C$ | Not commutative: $A B \\neq B A$ | Not cancellative: $A B = A C$ does not imply $B = C$ | $A B = 0$ does not imply $A = 0$ or $B = 0$ | . Expand $(A+B)^2$, etc. to check your understanding Given that $A$ and $B$ are square matrices of the same size, confirm that . \\[\\begin{gather*} (A+B)^2 = A^2 + AB + BA + B^2\\\\ (A-B)^2 = A^2 - AB - BA + B^2\\\\ (A+B)(A-B) = A^2 - AB + BA - B^2 \\end{gather*}\\] . ",
    "url": "/docs/linalg/basics/matrix.html#matrix-multiplication",
    
    "relUrl": "/docs/linalg/basics/matrix.html#matrix-multiplication"
  },"970": {
    "doc": "Basic Matrix Definitions",
    "title": "Square Matrix",
    "content": "A square matrix is a matrix with the same number of rows and columns. A $\\mathbf{n \\times n}$ matrix is called an $n$-dimensional square matrix. ",
    "url": "/docs/linalg/basics/matrix.html#square-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#square-matrix"
  },"971": {
    "doc": "Basic Matrix Definitions",
    "title": "Identity Matrix",
    "content": "An identity matrix (unit matrix) is a diagonal matrix whose principal diagonal elements are all one. The identity matrix is often denoted by $I$ or $I_n$. \\[I = \\begin{bmatrix} 1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; 1 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 1 \\end{bmatrix}\\] ",
    "url": "/docs/linalg/basics/matrix.html#identity-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#identity-matrix"
  },"972": {
    "doc": "Basic Matrix Definitions",
    "title": "Elementary Matrix",
    "content": "An elementary matrix is a square matrix that can be obtained from the identity matrix by a single elementary row operation (row exchange, linear combination of rows). From $I_3$, we could obtain the following few examples of elementary matrices: . \\[I = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\quad E_1 = \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\quad E_2 = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ -3 &amp; 0 &amp; 1 \\end{bmatrix} \\quad E_3 = \\begin{bmatrix} 2 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}\\] Multiplying a matrix by an elementary matrix is equivalent to performing the corresponding elementary row operation. Elementary matrices are invertible. Which makes sense, because elementary row operations are invertible. The inverse of an elementary matrix is also an elementary matrix which undoes the elementary row operation. ",
    "url": "/docs/linalg/basics/matrix.html#elementary-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#elementary-matrix"
  },"973": {
    "doc": "Basic Matrix Definitions",
    "title": "Power of a Matrix",
    "content": "For a square matrix $A$, $A^k$ is defined as the power of matrix $A$. It has the following properties: . | $A^0 = I$ | $(A^k)^l = A^{kl}$ | $A^k A^l = A^{k+l}$ | . ",
    "url": "/docs/linalg/basics/matrix.html#power-of-a-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#power-of-a-matrix"
  },"974": {
    "doc": "Basic Matrix Definitions",
    "title": "Transpose of a Matrix",
    "content": "The transpose of a matrix $A$ is denoted by $A^\\top$: . \\[A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\cdots &amp; a_{mn} \\end{bmatrix} \\quad A^\\top = \\begin{bmatrix} a_{11} &amp; a_{21} &amp; \\cdots &amp; a_{m1} \\\\ a_{12} &amp; a_{22} &amp; \\cdots &amp; a_{m2} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{1n} &amp; a_{2n} &amp; \\cdots &amp; a_{mn} \\end{bmatrix}\\] ",
    "url": "/docs/linalg/basics/matrix.html#transpose-of-a-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#transpose-of-a-matrix"
  },"975": {
    "doc": "Basic Matrix Definitions",
    "title": "Symmetric Matrix",
    "content": "A matrix $A$ is symmetric if $A = A^\\top$. | Only square matrices can be symmetric. | If $A$ is invertible, then $A^\\top$ is also invertible: $(A^{-1})^\\top = (A^\\top)^{-1}$ | $A^\\top A$ is always symmetric: $(A^\\top A)^\\top = A^\\top A$ . | Same for $A A^\\top$: $(A A^\\top)^\\top = A A^\\top$ | . | . ",
    "url": "/docs/linalg/basics/matrix.html#symmetric-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#symmetric-matrix"
  },"976": {
    "doc": "Basic Matrix Definitions",
    "title": "Skew-symmetric Matrix",
    "content": "A matrix $A$ is skew-symmetric if $A^\\top = -A$. ",
    "url": "/docs/linalg/basics/matrix.html#skew-symmetric-matrix",
    
    "relUrl": "/docs/linalg/basics/matrix.html#skew-symmetric-matrix"
  },"977": {
    "doc": "Basic Matrix Definitions",
    "title": "Properties of Transpose",
    "content": "For any matrices $A$ and $B$ and any scalar $c$: . | $(A^\\top)^\\top = A$ | $(A + B)^\\top = A^\\top + B^\\top$ | $(A B)^\\top = B^\\top A^\\top$ | $(c A)^\\top = c A^\\top$ | . ",
    "url": "/docs/linalg/basics/matrix.html#properties-of-transpose",
    
    "relUrl": "/docs/linalg/basics/matrix.html#properties-of-transpose"
  },"978": {
    "doc": "Maximum Likelihood",
    "title": "Maximum Likelihood",
    "content": "Most common method for estimating parameters of a statistical model. | Likelihood | Maximum Likelihood Estimation (MLE) . | Log-Likelihood | Properties of MLE . | Consistent | Asymptotically Normal | Asymptotically Optimal (Efficient) | Equivariant | . | . | Asymptotic Confidence Interval of MLE | . ",
    "url": "/docs/statistics/notes/maximum-likelihood.html",
    
    "relUrl": "/docs/statistics/notes/maximum-likelihood.html"
  },"979": {
    "doc": "Maximum Likelihood",
    "title": "Likelihood",
    "content": "Likelihood or likelihood function is a function of the parameters of a statistical model. It is essentially a joint PDF of the data given the parameters, but viewed as a function of the parameters. Why the name likelihood? We have a bunch of probability that some event happens. Assuming they are all independent, if all these events happened, and thus likely, the joint probability should be high. And the path to find the parameters that make this joint probability highest is maximum likelihood estimation. For RVs $X_1, \\dots, X_n$ where each $X_i$ is IID and has the PDF $f(x_i; \\theta)$, their joint PDF is: . \\[f(x_1, \\dots, x_n; \\theta) \\xlongequal{iid} \\prod_{i=1}^n f(x_i; \\theta)\\] Usually, this joint PDF would be seen as a function of the data $x_1, \\dots, x_n$ with the parameters $\\theta$ fixed, but likelihood sees this as a function of the parameters $\\theta$ given the data $x_1, \\dots, x_n$, and we denote: . $$ \\mathcal{L}(\\theta) = \\prod_{i=1}^n f(x_i; \\theta) $$ . The likelihood is not a probability, and $\\theta$ is not a random variable. ",
    "url": "/docs/statistics/notes/maximum-likelihood.html#likelihood",
    
    "relUrl": "/docs/statistics/notes/maximum-likelihood.html#likelihood"
  },"980": {
    "doc": "Maximum Likelihood",
    "title": "Maximum Likelihood Estimation (MLE)",
    "content": "Our goal is to find the parameter $\\theta$ that maximizes the likelihood function $\\mathcal{L}(\\theta)$. So given the data $x_1, \\dots, x_n$, we’re trying to find the parameter that makes the generation of this data most likely. ",
    "url": "/docs/statistics/notes/maximum-likelihood.html#maximum-likelihood-estimation-mle",
    
    "relUrl": "/docs/statistics/notes/maximum-likelihood.html#maximum-likelihood-estimation-mle"
  },"981": {
    "doc": "Maximum Likelihood",
    "title": "Log-Likelihood",
    "content": "Maximizing the likelihood is equivalent to maximizing the log-likelihood: . $$ \\ell(\\theta) = \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^n \\log f(x_i; \\theta) $$ . because the log function is monotonically increasing. Example with Bernoulli Distribution Let $X_1, \\dots, X_n \\sim \\text{Bernoulli}(p)$. The likelihood function is: . \\[\\begin{align*} \\mathcal{L}(p) &amp;= \\prod_{i=1}^n \\Pr(X_i = x_i; p) \\\\[1em] &amp;= \\prod_{i=1}^n p^{x_i} (1-p)^{1-x_i} \\\\[1em] &amp;= p^{\\sum_{i=1}^n x_i} (1-p)^{\\sum_{i=1}^n (1-x_i)} \\end{align*}\\] The log-likelihood function is: . \\[\\begin{align*} \\ell(p) &amp;= \\log \\mathcal{L}(p) \\\\[1em] &amp;= \\sum_{i=1}^n x_i \\log p + \\sum_{i=1}^n (1-x_i) \\log (1-p) \\end{align*}\\] Using calculus, we can find the value of $p$ that maximizes $\\ell(p)$: . \\[\\frac{d\\ell(p)}{dp} = 0\\] Take the derivative: . \\[\\begin{align*} \\frac{d\\ell(p)}{dp} &amp;= \\frac{\\sum_{i=1}^n x_i}{p} - \\frac{\\sum_{i=1}^n (1-x_i)}{1-p} \\\\[1em] &amp;= \\frac{\\sum_{i=1}^n x_i - np}{p(1-p)} = 0 \\end{align*}\\] We see that the derivative is zero when: . \\[\\sum_{i=1}^n x_i = np\\] Rearranging, we get the MLE for $p$: . \\[\\hat{p} = \\frac{1}{n} \\sum_{i=1}^n x_i = \\overline{x}_n\\] MLE is unaffected by constant factors in the likelihood function. Constants from joint PDFs can be dropped. ",
    "url": "/docs/statistics/notes/maximum-likelihood.html#log-likelihood",
    
    "relUrl": "/docs/statistics/notes/maximum-likelihood.html#log-likelihood"
  },"982": {
    "doc": "Maximum Likelihood",
    "title": "Properties of MLE",
    "content": "Let $\\hat{\\theta}$ be the MLE of $\\theta$. Consistent . \\[\\hat{\\theta} \\xrightarrow{P} \\theta\\] Asymptotically Normal . \\[\\frac{\\hat{\\theta} - \\theta}{\\hat{\\text{se}}} \\leadsto N(0, 1)\\] where $\\hat{\\text{se}}$ is the standard error of $\\hat{\\theta}$. We can use the Fisher Information to asymptotically estimate $\\hat{\\text{se}}$: . \\[\\hat{\\text{se}} \\approx \\frac{1}{\\sqrt{I_n(\\hat{\\theta})}}\\] Variance of MLE is the inverse of the Fisher Information. Asymptotically Optimal (Efficient) . For large samples, the MLE has the smallest possible variance among all well-behaved estimators. When $\\hat{\\theta}_{MLE}$ is the MLE of $\\theta$, and $\\tilde{\\theta}$ is another estimator, . \\[\\text{ARE}(\\tilde{\\theta}, \\hat{\\theta}_{MLE}) \\leq 1\\] See Asymptotically Optimal for more details. Equivariant . If $\\hat{\\theta}$ is the MLE of $\\theta$, then $g(\\hat{\\theta})$ is the MLE of $g(\\theta)$. Since the MLE is asymptotically normal, we can use the Delta method to find the standard error of $g(\\hat{\\theta})$: . \\[\\hat{\\text{se}}(g(\\hat{\\theta})) \\approx |g'(\\hat{\\theta})| \\hat{\\text{se}}(\\hat{\\theta})\\] Then we can construct a confidence interval for $g(\\theta)$: . \\[g(\\hat{\\theta}) \\pm z_{\\alpha/2} \\hat{\\text{se}}(g(\\hat{\\theta}))\\] . ",
    "url": "/docs/statistics/notes/maximum-likelihood.html#properties-of-mle",
    
    "relUrl": "/docs/statistics/notes/maximum-likelihood.html#properties-of-mle"
  },"983": {
    "doc": "Maximum Likelihood",
    "title": "Asymptotic Confidence Interval of MLE",
    "content": "Since the MLE is asymptotically normal, we can use the normal interval to construct a confidence interval for $\\hat{\\theta}$. $$ \\hat{\\theta} \\pm z_{\\alpha/2} \\hat{\\text{se}} $$ . Again, the standard error can be estimated using the Fisher Information: . \\[\\hat{\\text{se}} \\approx \\frac{1}{\\sqrt{I_n(\\hat{\\theta})}}\\] ",
    "url": "/docs/statistics/notes/maximum-likelihood.html#asymptotic-confidence-interval-of-mle",
    
    "relUrl": "/docs/statistics/notes/maximum-likelihood.html#asymptotic-confidence-interval-of-mle"
  },"984": {
    "doc": "4 - Median of Two Sorted Arrays - Hard",
    "title": "Median of Two Sorted Arrays",
    "content": ". | Problem | Explanation | Solution | . ",
    "url": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#median-of-two-sorted-arrays",
    
    "relUrl": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#median-of-two-sorted-arrays"
  },"985": {
    "doc": "4 - Median of Two Sorted Arrays - Hard",
    "title": "Problem",
    "content": "Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays. Input: nums1 = [1,3], nums2 = [2] Output: 2.00000 Explanation: merged array = [1,2,3] and median is 2. Input: nums1 = [1,2], nums2 = [3,4] Output: 2.50000 Explanation: merged array = [1,2,3,4] and median is (2 + 3) / 2 = 2.5. ",
    "url": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#problem"
  },"986": {
    "doc": "4 - Median of Two Sorted Arrays - Hard",
    "title": "Explanation",
    "content": "Let $A$ and $B$ be the two sorted arrays of size $m$ and $n$ respectively. Let’s assume that $m \\leq n$. Let $x$ be the median of the two sorted arrays. This $x$ will divide each array into two parts: . \\[\\begin{gather*} A_{left} \\mid A_{right} \\\\ B_{left} \\mid B_{right} \\end{gather*}\\] where $A_{left}$ and $B_{left}$ consist of respective elements $\\le x$, and $A_{right}$ and $B_{right}$ consist of respective elements $\\gt x$. For $x$ to be the median of the two sorted arrays, the following conditions must be satisfied: . | $\\max(A_{left}) \\le \\min(B_{right})$ and $\\max(B_{left}) \\le \\min(A_{right})$ | If $m + n$ is odd, then $|A_{left}| + |B_{left}| = |A_{right}| + |B_{right}| + 1$. If $m + n$ is even, then $|A_{left}| + |B_{left}| = |A_{right}| + |B_{right}|$ . | . Let $i$ be the number of elements in $A_{left}$, and $j$ be the number of elements in $B_{left}$. The first condition can be rewritten as: . \\[a_{i - 1} \\le b_j \\wedge b_{j - 1} \\le a_i\\] The notation follows the coding convention of 0-based indexing. The second condition can be rewritten as: . \\[\\begin{gather*} |A_{left}| + |B_{left}| = |A_{right}| + |B_{right}| + 1 \\\\[1em] i + j = (m - i) + (n - j) + 1 \\\\[1em] 2j = m + n + 1 - 2i \\\\[1em] j = \\frac{m + n + 1}{2} - i \\end{gather*}\\] Later in code, the integer division truncating (m + n + 1) / 2 takes care of both odd and even cases. We see that $j$ is predetermined by $i$, so our problem boils down to finding the right $i$ that satisfies the first condition. Once we find the right $i$ and $j$, we can compute the median $x$ as follows: . \\[x = \\begin{cases} \\max(a_{i-1}, b_{j-1}) &amp; \\text{if } m + n \\text{ is odd} \\\\[1em] \\operatorname{avg}(\\max(a_{i-1}, b_{j-1}), \\min(a_{i}, b_{j})) &amp; \\text{if } m + n \\text{ is even} \\end{cases}\\] . | Why $\\max(a_{i-1}, b_{j-1})$ for odd $m + n$? . Because we know the left side has one more element which is the median. | Why $\\operatorname{avg}(\\max(a_{i-1}, b_{j-1}), \\min(a_{i}, b_{j}))$ for even $m + n$? . Because we want the average of the two middle elements. | . Now we do a binary search on $i$ in the range $[0, m]$, to find the right $i$ that satisfies the conditions. ",
    "url": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#explanation",
    
    "relUrl": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#explanation"
  },"987": {
    "doc": "4 - Median of Two Sorted Arrays - Hard",
    "title": "Solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 . | public double findMedianSortedArrays(int[] A, int[] B) { int m = A.length; int n = B.length; // Because we want to do a binary search on the smaller array if (m &gt; n) return findMedianSortedArrays(B, A); // Setting candidate range for i int iMin = 0; int iMax = m; int lenCondition = (m + n + 1) / 2; while (iMin &lt;= iMax) { int i = (iMin + iMax) / 2; int j = lenCondition - i; int maxALeft = (i &lt; 1) ? Integer.MIN_VALUE : A[i - 1]; int maxBLeft = (j &lt; 1) ? Integer.MIN_VALUE : B[j - 1]; int minARight = (i &gt;= m) ? Integer.MAX_VALUE : A[i]; int minBRight = (j &gt;= n) ? Integer.MAX_VALUE : B[j]; if (maxALeft &lt;= minBRight &amp;&amp; maxBLeft &lt;= minARight) { if ((m + n) % 2 &gt; 0) { // When m + n is odd, return Math.max(maxALeft, maxBLeft); // Median is at the left } else { // When m + n is even, // Median is the average of the two middle elements return (Math.max(maxALeft, maxBLeft) + Math.min(minARight, minBRight)) / 2.0; } } else if (maxALeft &gt; minBRight) { // We overshot our partition for A iMax = i - 1; } else { // We undershot our partition for A iMin = i + 1; } } return 0.0; } . | . Everything is explained in the Explanation section, except for the lines 17-20. | maxALeft: $a_{i-1}$ | maxBLeft: $b_{j-1}$ | minARight: $a_i$ | minBRight: $b_j$ | . We must note that a partition of $A$ and $B$ by $x$ may be empty. Take $A = [1, 2]$ and $B = [3, 4]$, where the median $2.5$ is not in the middle of the two arrays. \\[\\begin{gather*} A_{left} = [1, 2] \\mid A_{right} = [] \\\\[1em] B_{left} = [] \\mid B_{right} = [3, 4] \\end{gather*}\\] We want $a_{i-1} \\le b_j$ and $b_{j-1} \\le a_i$, but we can’t compare $b_{j-1}$ and $a_i$ because $B_{left}$ and $A_{right}$ are empty. That is why we need to turn them into . \\[\\begin{gather*} A_{left} = [1, 2] \\mid A_{right} = [\\infty] \\\\[1em] B_{left} = [-\\infty] \\mid B_{right} = [3, 4] \\end{gather*}\\] By setting $a_{i-1}, b_{j-1} = -\\infty$ and $a_i, b_j = \\infty$, when indices are out of bound. The complexity is $O(\\log(\\min(m, n)))$. ",
    "url": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html#solution"
  },"988": {
    "doc": "4 - Median of Two Sorted Arrays - Hard",
    "title": "4 - Median of Two Sorted Arrays - Hard",
    "content": " ",
    "url": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html",
    
    "relUrl": "/docs/compsci/leetcode/median-of-two-sorted-arrays.html"
  },"989": {
    "doc": "SQL Advanced Aggregation",
    "title": "SQL Advanced Aggregation",
    "content": "To be added . | WITHIN GROUP | . ",
    "url": "/docs/db/sql/more-aggregation.html",
    
    "relUrl": "/docs/db/sql/more-aggregation.html"
  },"990": {
    "doc": "SQL Advanced Aggregation",
    "title": "WITHIN GROUP",
    "content": "WITHIN GROUP is used to aggregate on ordered data. This syntax simplifies some of the operations that would otherwise require workarounds with window functions. Some examples with PERCENTILE_DISC and PERCENTILE_CONT (discrete and continuous percentiles): . WITH temp AS (SELECT GENERATE_SERIES(1, 100) AS val) SELECT UNNEST(PERCENTILE_DISC(ARRAY [0.25, 0.5, 0.75, 1]) WITHIN GROUP ( ORDER BY val )) FROM temp; --- Result --- 25, 50, 75, 100 WITH temp AS (SELECT GENERATE_SERIES(1, 100) AS val) SELECT PERCENTILE_DISC(0.5) WITHIN GROUP ( ORDER BY val ) AS median FROM temp; -- Result -- 50 . UNNEST is used to convert an array into a set of rows. Apart from PERCENTILE_DISC and PERCENTILE_CONT, WITHIN GROUP can be used with the preexisting window functions and also MODE. ",
    "url": "/docs/db/sql/more-aggregation.html#within-group",
    
    "relUrl": "/docs/db/sql/more-aggregation.html#within-group"
  },"991": {
    "doc": "Mutivariate Distributions",
    "title": "Mutivariate Distributions",
    "content": ". | Multinomial Distribution . | Marginal Distribution of a Multinomial | . | Mean and Variance of Multinomial | Multivariate Normal Distribution . | Conversion from/to Standard Multivariate Normal | . | . ",
    "url": "/docs/statistics/notes/multivariate-distributions.html",
    
    "relUrl": "/docs/statistics/notes/multivariate-distributions.html"
  },"992": {
    "doc": "Mutivariate Distributions",
    "title": "Multinomial Distribution",
    "content": "Extension of the binomial distribution to more than two categories. Instead of have success/failure, we have $\\boldsymbol{k}$ categories (e.g. dice roll, preference surveys). We have a random vector $X = (X_1, \\dots, X_k)$, where $X_i$ is the number of times category $i$ occurs. For a given $n$ and a probability vector $p = (p_1, \\dots, p_k)$, . \\[n = \\sum_{i=1}^k X_i\\] Then the probability mass function is: . $$ p_X(x) = \\binom{n}{x_1 \\dots x_k} p_1^{x_1} \\dots p_k^{x_k} = \\frac{n!}{x_1! \\dots x_k!} p_1^{x_1} \\dots p_k^{x_k} $$ . And we denote: . $$ X \\sim \\text{Multinomial}(n, p) $$ . ",
    "url": "/docs/statistics/notes/multivariate-distributions.html#multinomial-distribution",
    
    "relUrl": "/docs/statistics/notes/multivariate-distributions.html#multinomial-distribution"
  },"993": {
    "doc": "Mutivariate Distributions",
    "title": "Marginal Distribution of a Multinomial",
    "content": "When $X \\sim \\text{Multinomial}(n, p)$, the marginal distribution of $X_i$ is: . $$ X_i \\sim \\text{Binomial}(n, p_i) $$ . ",
    "url": "/docs/statistics/notes/multivariate-distributions.html#marginal-distribution-of-a-multinomial",
    
    "relUrl": "/docs/statistics/notes/multivariate-distributions.html#marginal-distribution-of-a-multinomial"
  },"994": {
    "doc": "Mutivariate Distributions",
    "title": "Mean and Variance of Multinomial",
    "content": "The expected value of $X \\sim \\text{Multinomial}(n, p)$ is: . $$ n \\cdot p = \\begin{pmatrix} n \\cdot p_1 \\\\ \\vdots \\\\ n \\cdot p_k \\end{pmatrix} $$ . The variance of $X \\sim \\text{Multinomial}(n, p)$ is the covariance matrix. ",
    "url": "/docs/statistics/notes/multivariate-distributions.html#mean-and-variance-of-multinomial",
    
    "relUrl": "/docs/statistics/notes/multivariate-distributions.html#mean-and-variance-of-multinomial"
  },"995": {
    "doc": "Mutivariate Distributions",
    "title": "Multivariate Normal Distribution",
    "content": "We have a random vector $X = (X_1, \\dots, X_k)$. The parameters are: . | $\\mu = (\\mu_1, \\dots, \\mu_k)$: mean vector | $\\Sigma$: $k \\times k$ symmetric positive definite covariance matrix . \\[\\Sigma_{ij} = \\text{Cov}(X_i, X_j) = \\E[(X_i - \\mu_i)(X_j - \\mu_j)]\\] | . The probability density function is: . $$ f_X(x) = \\frac{1}{\\sqrt{(2\\pi)^k \\det(\\Sigma)}} \\exp\\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right) $$ . And we denote: . $$ X \\sim \\mathcal{N}(\\mu, \\Sigma) $$ . ",
    "url": "/docs/statistics/notes/multivariate-distributions.html#multivariate-normal-distribution",
    
    "relUrl": "/docs/statistics/notes/multivariate-distributions.html#multivariate-normal-distribution"
  },"996": {
    "doc": "Mutivariate Distributions",
    "title": "Conversion from/to Standard Multivariate Normal",
    "content": "It is similar to the univariate case, which looked like . \\[Z = \\frac{X - \\mu}{\\sigma} \\iff X = \\mu + \\sigma Z\\] Let’s just take for granted that $\\Sigma^{1/2}$ and $\\Sigma^{-1/2}$ exist. For standard multivariate normal random vector $Z \\sim \\mathcal{N}(0, I)$, . $$ X = \\mu + \\Sigma^{1/2} Z \\implies X \\sim \\mathcal{N}(\\mu, \\Sigma) $$ . And for multivariate normal random vector $X \\sim \\mathcal{N}(\\mu, \\Sigma)$: . $$ Z = \\Sigma^{-1/2} (X - \\mu) \\implies Z \\sim \\mathcal{N}(0, I) $$ . ",
    "url": "/docs/statistics/notes/multivariate-distributions.html#conversion-fromto-standard-multivariate-normal",
    
    "relUrl": "/docs/statistics/notes/multivariate-distributions.html#conversion-fromto-standard-multivariate-normal"
  },"997": {
    "doc": "Generate n-Length K-ary String",
    "title": "Generate n-Length K-ary String",
    "content": ". | Problem | Backtracking | . ",
    "url": "/docs/compsci/algo/n-bit-binary-string.html",
    
    "relUrl": "/docs/compsci/algo/n-bit-binary-string.html"
  },"998": {
    "doc": "Generate n-Length K-ary String",
    "title": "Problem",
    "content": "Generate all possible n-length k-ary strings. K-ary string is a string that only contains characters from the set $\\{0, 1, \\ldots, k-1\\}$. ",
    "url": "/docs/compsci/algo/n-bit-binary-string.html#problem",
    
    "relUrl": "/docs/compsci/algo/n-bit-binary-string.html#problem"
  },"999": {
    "doc": "Generate n-Length K-ary String",
    "title": "Backtracking",
    "content": ". | Create an array arr of length n, initialized with all zeros. | Have a helper function that wil print the array arr as a single string. | In the recursion: | . void generate(int[] arr, int n, int k) { if (n &lt; 1) { printArray(arr); } else { for (int i = 0; i &lt; k; i++) { arr[n - 1] = i; generate(arr, n - 1, k); } } } . The idea is to fix a single character at a time, and recursively generate all possible strings with the fixed character. Once all possibilities with the fixed character are exhausted, we move on to experiment with another character. The recurrence relation is . \\[T(n) = k T(n - 1) + O(n)\\] which is $O(k^n) \\cdot O(n)$. The $O(n)$ comes from naively printing the array as a string. ",
    "url": "/docs/compsci/algo/n-bit-binary-string.html#backtracking",
    
    "relUrl": "/docs/compsci/algo/n-bit-binary-string.html#backtracking"
  },"1000": {
    "doc": "Docker Networks",
    "title": "Docker Networks",
    "content": ". | Some useful commands | How do I talk to the container? | How can containers talk to each other? . | Default bridge network | User-defined bridge network | . | . ",
    "url": "/docs/docker/networks.html",
    
    "relUrl": "/docs/docker/networks.html"
  },"1001": {
    "doc": "Docker Networks",
    "title": "Some useful commands",
    "content": "# List all networks docker network ls . docker network inspect network-name . # Disconnect any containers using this network docker network disconnect network-name my-container docker network rm network-name . # Remove unused networks docker network prune . Link to documentation. ",
    "url": "/docs/docker/networks.html#some-useful-commands",
    
    "relUrl": "/docs/docker/networks.html#some-useful-commands"
  },"1002": {
    "doc": "Docker Networks",
    "title": "How do I talk to the container?",
    "content": "When a container is created, none of the ports inside the container are exposed. In order for the Docker host (your computer) or other containers to talk to it, it must first publish a port. The following maps a port 1234 inside a container to 4321 on Docker host. docker create -p 1234:4321 . Now you can communicate with the container via http://localhost:4321. ",
    "url": "/docs/docker/networks.html#how-do-i-talk-to-the-container",
    
    "relUrl": "/docs/docker/networks.html#how-do-i-talk-to-the-container"
  },"1003": {
    "doc": "Docker Networks",
    "title": "How can containers talk to each other?",
    "content": "If the containers are running on the same Docker daemon host (ie. all running on your computer), then the easiest way is to put them on the same bridge network. Default bridge network . Check the existing docker networks with . docker network ls . You will see a network with the name bridge. That is the default bridge network. Every started container is automatically added to the default bridge network if you didn’t specify anything else. With the default bridge you talk to other containers by using their IP Address. docker inspect my-container | grep IPAddress . Downsides to using the default bridge network: . | Using an IP address sucks: it is not immediate which container I’m referring to. | Every container can talk to every other container, which may cause security issues. | . User-defined bridge network . You can instead add a user-defined bridge network. It still uses the same bridge driver, but unlike the default bridge not everyone is invited to it. docker network create my-bridge # You can add after container creation docker network connect my-bridge my-container # Or when you create it docker create --network my-bridge . In user-defined bridge network, containers can talk to each other by using the container names as hostnames. So if my container was named my-db with port published at 1234, then the API would be: . http://my-db:1234 . References: . | Docker Networking | . ",
    "url": "/docs/docker/networks.html#how-can-containers-talk-to-each-other",
    
    "relUrl": "/docs/docker/networks.html#how-can-containers-talk-to-each-other"
  },"1004": {
    "doc": "Non-Parametric Inference",
    "title": "Non-Parametric Inference",
    "content": "Parametric inference assumes a specific distribution for the data. So all we have to do is estimate the parameters of the distribution. Non-parametric inference does not assume a specific distribution for the data, so we have to estimate the distribution itself (CDF). Why do we want to know the CDF? . It is because many statistics are functionals, or functions of the CDF. So if we know the CDF, we can estimate the statistics. | Empirical Distribution Function . | Relations to True CDF | . | Statistical Functional . | Linear Functional | . | Plug-In Estimator . | For Linear Functional | Finding the Sample Distribution of Plug-In Estimator | . | . ",
    "url": "/docs/statistics/notes/nonparametric-inference.html",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html"
  },"1005": {
    "doc": "Non-Parametric Inference",
    "title": "Empirical Distribution Function",
    "content": "When we have IID samples $X_1, \\dots, X_n \\sim F$, we estimate the CDF $F$ by giving mass $1/n$ at each data point. Think of it as guessing a distribution with a cumulative histogram. The empirical distribution function, also called the empirical CDF (eCDF), is defined as: . $$ \\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n I(X_i \\leq x) $$ . where $I(\\cdot)$ is the indicator function: . \\[I(A) = \\begin{cases} 1 &amp; \\text{if } A \\text{ is true} \\\\ 0 &amp; \\text{if } A \\text{ is false} \\end{cases}\\] So basically, sum over how many data points are less than or equal to $x$, and give them mass $1/n$ each. Empirical distribution function is a discrete step function. The expected value of indicator function One thing to note is: . $$ E[I(X_i \\leq x)] = \\Pr(X_i \\leq x) $$ . Proof is trivial because the only that gets left in the calculation is $1 \\cdot \\Pr(X_i \\leq x)$. ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#empirical-distribution-function",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#empirical-distribution-function"
  },"1006": {
    "doc": "Non-Parametric Inference",
    "title": "Relations to True CDF",
    "content": "Expected value: . \\[\\E(\\hat{F}_n(x)) = F(x)\\] Variance: . \\[\\Var(\\hat{F}_n(x)) = \\frac{F(x)(1 - F(x))}{n}\\] Convergence in probability: . \\[\\hat{F}_n(x) \\xrightarrow{P} F(x)\\] $\\hat{F}_n(x)$ is an unbiased and consistent estimator of $F(x)$. ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#relations-to-true-cdf",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#relations-to-true-cdf"
  },"1007": {
    "doc": "Non-Parametric Inference",
    "title": "Statistical Functional",
    "content": "A statistical functional is a function of the CDF $F$. It maps a distribution to a real number or vector. $$ T(F) $$ . Mean, variance, median Mean, variance, median are all statistical functionals. \\[\\begin{align*} \\mu &amp;= T(F) = \\int x dF(x) \\\\ \\sigma^2 &amp;= T(F) = \\int x^2 dF(x) - (\\int x dF(x))^2 \\\\ \\text{median} &amp;= T(F) = F^{-1}(\\frac{1}{2}) \\end{align*}\\] ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#statistical-functional",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#statistical-functional"
  },"1008": {
    "doc": "Non-Parametric Inference",
    "title": "Linear Functional",
    "content": "For some $r(x)$, . If $T(F) = \\int r(x) dF(x)$, then $T(F)$ is a linear functional. $\\int r(x) dF(x)$ is equivalent to $\\E[r(X)]$. Since $\\E$ is a linear operator, it makes sense that $T(F)$ is linear. As the name suggests, a linear functional satisfies the following: . $$ T(aF + bG) = aT(F) + bT(G) $$ . ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#linear-functional",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#linear-functional"
  },"1009": {
    "doc": "Non-Parametric Inference",
    "title": "Plug-In Estimator",
    "content": "When $\\theta = T(F)$ is a statistical functional, the plug-in estimator of $\\theta$ is: . $$ \\hat{\\theta}_n = T(\\hat{F}_n) $$ . Because we don’t know $F$, we’re just plugging in the empirical distribution $\\hat{F}_n$ instead. ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#plug-in-estimator",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#plug-in-estimator"
  },"1010": {
    "doc": "Non-Parametric Inference",
    "title": "For Linear Functional",
    "content": "If $T(F) = \\int r(x) dF(x)$, then the plug-in estimator is: . $$ T(\\hat{F}_n) = \\int r(x) d\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n r(X_i) $$ . ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#for-linear-functional",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#for-linear-functional"
  },"1011": {
    "doc": "Non-Parametric Inference",
    "title": "Finding the Sample Distribution of Plug-In Estimator",
    "content": "See Bootstrap . ",
    "url": "/docs/statistics/notes/nonparametric-inference.html#finding-the-sample-distribution-of-plug-in-estimator",
    
    "relUrl": "/docs/statistics/notes/nonparametric-inference.html#finding-the-sample-distribution-of-plug-in-estimator"
  },"1012": {
    "doc": "Comparing with Nonparametric Tests",
    "title": "Comparing with Nonparametric Tests",
    "content": "To be added . When it is hard to assume normality, we generally use nonparametric tests. In such cases, instead of comparing the means of the data, we use other representative statistics (such as the median, rank, etc.) that describes the position of the data. | Wilcoxon Rank Sum Test | . ",
    "url": "/docs/statistics/basics/nonparametric-test.html",
    
    "relUrl": "/docs/statistics/basics/nonparametric-test.html"
  },"1013": {
    "doc": "Comparing with Nonparametric Tests",
    "title": "Wilcoxon Rank Sum Test",
    "content": "Instead of the mean like in parametric tests, Wilcoxon rank sum test is based on the rank of the data. ",
    "url": "/docs/statistics/basics/nonparametric-test.html#wilcoxon-rank-sum-test",
    
    "relUrl": "/docs/statistics/basics/nonparametric-test.html#wilcoxon-rank-sum-test"
  },"1014": {
    "doc": "Ordinary Least Squares",
    "title": "Ordinary Least Squares",
    "content": ". | Ordinary Least Squares (OLS) Estimation | Closed-Form for Simple Linear Regression . | Closed-Form Standard Error for SLR | . | Confidence Intervals for OLS Estimators | Hypothesis Testing for OLS Estimators . | t-Test | . | Closed-Form for Multiple Linear Regression | Properties of OLS . | Consistent | Asymptotically Normal | . | Relation to MLE | . ",
    "url": "/docs/data-science/ml-dl/ols.html",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html"
  },"1015": {
    "doc": "Ordinary Least Squares",
    "title": "Ordinary Least Squares (OLS) Estimation",
    "content": "Least squares is a common estimation method for linear regression models. The idea is to fit a model that mimimizes some sum of squares (i.e. creates the least squares). Ordinary least squares (OLS) minimizes the residual sum of squares. $$ \\hat{\\beta} = \\underset{\\beta}{\\operatorname{argmin}} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$ . Since we are trying to minimize the sum of squares with respect to the parameters, we solve for the partial derivatives. If $\\varepsilon_i | X \\sim N(0, \\sigma^2)$, then OLS is the same as MLE. ",
    "url": "/docs/data-science/ml-dl/ols.html#ordinary-least-squares-ols-estimation",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#ordinary-least-squares-ols-estimation"
  },"1016": {
    "doc": "Ordinary Least Squares",
    "title": "Closed-Form for Simple Linear Regression",
    "content": "In simple linear regression: . \\[\\begin{align*} &amp;\\frac{\\partial}{\\partial \\hat{\\beta_0}} \\sum_{i=1}^{n} (y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i)^2 = 0 \\\\[1em] &amp;\\frac{\\partial}{\\partial \\hat{\\beta_1}} \\sum_{i=1}^{n} (y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i)^2 = 0 \\end{align*}\\] Given that some conditions hold, there is a closed-form estimation for $\\beta_0$ and $\\beta_1$: . $$ \\begin{gather*} \\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\\\[1em] \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1} \\bar{x} \\end{gather*} $$ . Derivation \\[\\begin{align*} &amp;\\frac{\\partial}{\\partial \\hat{\\beta_0}} \\sum_{i=1}^{n} (y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i)^2 = -2 \\sum_{i=1}^{n} (y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i) = 0 \\\\[0.5em] \\iff&amp; \\sum_{i=1}^{n} y_i - n \\hat{\\beta_0} - \\hat{\\beta_1} \\sum_{i=1}^{n} x_i = 0 \\\\[0.5em] \\iff&amp; \\hat{\\beta_0} = \\frac{1}{n} \\sum_{i=1}^{n} y_i - \\hat{\\beta_1} \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\bar{y} - \\hat{\\beta_1} \\bar{x} \\end{align*}\\] \\[\\begin{align*} &amp;\\frac{\\partial}{\\partial \\hat{\\beta_1}} \\sum_{i=1}^{n} (y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i)^2 = -2 \\sum_{i=1}^{n} x_i (y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i) = 0 \\\\[0.5em] \\iff&amp; \\sum_{i=1}^{n} x_i (y_i - \\bar{y} + \\hat{\\beta_1} \\bar{x} - \\hat{\\beta_1} x_i) = 0 \\\\[0.5em] \\iff&amp; \\sum_{i=1}^{n} x_i (y_i - \\bar{y}) - \\hat{\\beta_1} \\sum_{i=1}^{n} x_i (x_i - \\bar{x}) = 0 \\\\[0.5em] \\iff&amp; \\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n} x_i(y_i - \\bar{y})}{\\sum_{i=1}^{n} x_i(x_i - \\bar{x})} \\end{align*}\\] Now note that $\\sum_{i=1}^{n} (z_i - \\bar{z}) = 0$ for any variable $z$, where $\\bar{z} = \\frac{1}{n} \\sum_{i=1}^{n} z_i$ (sample mean) is a constant. Therefore, $\\sum_{i=1}^{n} \\bar{x} (y_i - \\bar{y}) = 0$ and $\\sum_{i=1}^{n} \\bar{x} (x_i - \\bar{x}) = 0$ since $\\bar{x}$ is a constant. Subtract each from the numerator and the denominator respectively to get the final form of $\\hat{\\beta_1}$. ",
    "url": "/docs/data-science/ml-dl/ols.html#closed-form-for-simple-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#closed-form-for-simple-linear-regression"
  },"1017": {
    "doc": "Ordinary Least Squares",
    "title": "Closed-Form Standard Error for SLR",
    "content": "The standard error of the OLS estimators $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ is: . \\[\\begin{gather*} \\hat{\\text{SE}}(\\hat{\\beta_1}) = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}} \\\\[1em] \\hat{\\text{SE}}(\\hat{\\beta_0}) = \\sqrt{\\hat{\\sigma}^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\right)} \\end{gather*}\\] Where $\\sigma^2 = \\Var(\\varepsilon)$, but this is usually unknown. So we use an estimate $\\hat{\\sigma}$, like the Residual Standard Error (RSE): . $$ \\text{RSE} = \\sqrt{\\frac{\\text{RSS}}{n-p-1}} $$ . Some geometrical intuition You will see that the standard errors are inversely proportional to the dispersion of the $x_i$’s from the mean $\\bar{x}$. A good estimator should have a small standard error. Which means that OLS estimators are more stable when the $x_i$’s are spread out. Imagine a 2D scatter plot of the data points. If all the points are clustered together like a ball, it would be hard to draw a definitive line that fits the data. Slightest change in observation would result in a large change in the line, hence high variance in the estimators. ",
    "url": "/docs/data-science/ml-dl/ols.html#closed-form-standard-error-for-slr",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#closed-form-standard-error-for-slr"
  },"1018": {
    "doc": "Ordinary Least Squares",
    "title": "Confidence Intervals for OLS Estimators",
    "content": "Knowing the standard errors, you can construct confidence intervals for the estimators: . $$ \\hat{\\beta}_j \\pm t_{\\alpha/2, n-2} \\cdot \\hat{\\text{SE}}(\\hat{\\beta}_j) $$ . ",
    "url": "/docs/data-science/ml-dl/ols.html#confidence-intervals-for-ols-estimators",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#confidence-intervals-for-ols-estimators"
  },"1019": {
    "doc": "Ordinary Least Squares",
    "title": "Hypothesis Testing for OLS Estimators",
    "content": "The null hypothesis: . $$ H_0: \\beta_j = 0 $$ . Can be interpreted as: . | In the presence of other predictors and the intercept, there is no significant relationship between $X_j$ and $Y$. | . For the intercept $\\beta_0$, however: . | In the absence of other predictors, $Y$ is not significantly different from zero. | . ",
    "url": "/docs/data-science/ml-dl/ols.html#hypothesis-testing-for-ols-estimators",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#hypothesis-testing-for-ols-estimators"
  },"1020": {
    "doc": "Ordinary Least Squares",
    "title": "t-Test",
    "content": "Null hypothesis is tested using the t-statistic: . $$ t = \\frac{\\hat{\\beta}_1 - \\beta_1}{\\hat{\\text{SE}}(\\hat{\\beta}_1)} $$ . Assuming that the null hypothesis is true, we substitute $\\beta_1 = 0$ and use the t-distribution to find the p-value. Under the null hypothesis, t-statistic is the ratio of the estimator and the standard error: . $$ t = \\frac{\\hat{\\beta}_1}{\\hat{\\text{SE}}(\\hat{\\beta}_1)} $$ . Relative ratio of estimator and standard error The estimate $\\hat{\\beta}$ itself is heavily influenced by the unit of measurement (i.e. whether you measure the height in cm or m matters). Therefore, linearity cannot be measured just by the estimate alone, but by the ratio of the estimate and the standard error. ",
    "url": "/docs/data-science/ml-dl/ols.html#t-test",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#t-test"
  },"1021": {
    "doc": "Ordinary Least Squares",
    "title": "Closed-Form for Multiple Linear Regression",
    "content": "For multiple linear regression: . \\[\\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\] We want to mimize the RSS, which is: . \\[\\text{RSS} = (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}})^T (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}})\\] Take the derivative w.r.t. $\\boldsymbol{\\hat{\\beta}}$ and set it to zero: . \\[\\frac{\\partial}{\\partial \\boldsymbol{\\hat{\\beta}}} \\text{RSS} = -2 \\boldsymbol{X}^\\top \\boldsymbol{y} + 2 \\boldsymbol{X}^\\top \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}} = 0\\] Derivation \\[\\begin{align*} \\text{RSS} &amp;= (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}})^\\top (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}}) \\\\[0.5em] &amp;= (\\boldsymbol{y}^\\top - \\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top) \\boldsymbol{y} - (\\boldsymbol{y}^\\top - \\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top) \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}} \\\\[0.5em] &amp;= \\boldsymbol{y}^\\top \\boldsymbol{y} - \\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top \\boldsymbol{y} - \\boldsymbol{y}^\\top \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}} + \\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top \\boldsymbol{X} \\boldsymbol{\\hat{\\beta}} \\end{align*}\\] Now take the derivative w.r.t. $\\boldsymbol{\\hat{\\beta}}$ (see vector calculus): . \\[\\begin{align*} \\frac{\\partial}{\\partial \\boldsymbol{\\hat{\\beta}}} \\text{RSS} &amp;= 0 - \\boldsymbol{y}^\\top \\boldsymbol{X} - \\boldsymbol{y}^\\top \\boldsymbol{X} + 2 \\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top \\boldsymbol{X} \\\\[0.5em] &amp;= -2 \\boldsymbol{y}^\\top \\boldsymbol{X} + 2 \\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top \\boldsymbol{X} = 0 \\end{align*}\\] (Numerator layout was used here) . \\[\\begin{align*} &amp;\\boldsymbol{\\hat{\\beta}}^\\top \\boldsymbol{X}^\\top \\boldsymbol{X} = \\boldsymbol{y}^\\top \\boldsymbol{X} \\\\[0.5em] \\iff &amp;\\boldsymbol{\\hat{\\beta}}^\\top = \\boldsymbol{y}^\\top \\boldsymbol{X} (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\\\[0.5em] \\iff &amp;\\boldsymbol{\\hat{\\beta}} = (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top \\boldsymbol{y} \\end{align*}\\] Note that $\\boldsymbol{X}^\\top \\boldsymbol{X}$ is a symmetric matrix. Solving for $\\boldsymbol{\\hat{\\beta}}$: . $$ \\boldsymbol{\\hat{\\beta}} = (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top \\boldsymbol{y} $$ . As discussed in linear regression, there must be no perfect colinearity between the features, i.e. $\\boldsymbol{X}$ must be full rank. Otherwise, $\\boldsymbol{X}^\\top \\boldsymbol{X}$ is also rank-deficient, and thus the inverse does not exist. ",
    "url": "/docs/data-science/ml-dl/ols.html#closed-form-for-multiple-linear-regression",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#closed-form-for-multiple-linear-regression"
  },"1022": {
    "doc": "Ordinary Least Squares",
    "title": "Properties of OLS",
    "content": " ",
    "url": "/docs/data-science/ml-dl/ols.html#properties-of-ols",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#properties-of-ols"
  },"1023": {
    "doc": "Ordinary Least Squares",
    "title": "Consistent",
    "content": "OLS estimators are consistent: . \\[\\hat{\\beta} \\xrightarrow{p} \\beta\\] ",
    "url": "/docs/data-science/ml-dl/ols.html#consistent",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#consistent"
  },"1024": {
    "doc": "Ordinary Least Squares",
    "title": "Asymptotically Normal",
    "content": "OLS estimators are asymptotically normal: . \\[\\frac{\\hat{\\beta} - \\beta}{\\hat{\\text{SE}}(\\hat{\\beta})} \\leadsto N(0, 1)\\] Hence you could find normal confidence intervals for $\\beta$. ",
    "url": "/docs/data-science/ml-dl/ols.html#asymptotically-normal",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#asymptotically-normal"
  },"1025": {
    "doc": "Ordinary Least Squares",
    "title": "Relation to MLE",
    "content": "As briefly mentioned in the beginning, if $\\varepsilon_i \\sim N(0, \\sigma^2)$ (or $\\varepsilon \\sim N(\\boldsymbol{0}, \\sigma^2 \\boldsymbol{I})$), then OLS estimation is equivalent to MLE. In the model: . \\[Y = X \\beta + \\varepsilon\\] The source of uncertainty is the error term $\\varepsilon$, and thus the likelihood function should come from the distribution of $\\varepsilon$. If $\\varepsilon_i \\sim N(0, \\sigma^2)$ and IID, then the likelihood function is: . \\[\\mathcal{L}(\\beta) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (y_i - \\boldsymbol{x}_i^\\top \\beta)^2\\right)\\] The log-likelihood function is: . \\[\\begin{align*} \\ell(\\beta) &amp;= \\sum_{i=1}^n \\left[ -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} (y_i - \\boldsymbol{x}_i^\\top \\beta)^2 \\right] \\\\[0.5em] \\end{align*}\\] Take the derivative of $\\ell(\\beta)$ w.r.t. $\\beta$ and set it to zero. With the constant terms removed, the MLE is equivalent to OLS: . \\[\\sum_{i=1}^n (y_i - \\boldsymbol{x}_i^\\top \\beta)^2 = 0\\] ",
    "url": "/docs/data-science/ml-dl/ols.html#relation-to-mle",
    
    "relUrl": "/docs/data-science/ml-dl/ols.html#relation-to-mle"
  },"1026": {
    "doc": "One-Standard-Error Rule",
    "title": "One-Standard-Error Rule",
    "content": "Within a certain range of test error, select the simplest model. During model selection, we plot the estimated test error against the model complexity, and we select a complexity at the minmum test error. However, when the test error is sort of plateaued (flattened out over a range of complexity), we can introduce a heuristic to choose the simplest model instead of the strictly minimum. This is because the test error is technically an estimate of the true test error. This rule is often quite helpful with validation set and cross-validation. Estimators that rely on randomness (e.g. validation set, cross-validation) have slightly varying results depending on the how the validation set is created. So to account for this variability, we calculate the standard error of the test error estimate at the lowest point of the test error curve. Then we choose the simplest model within one standard error of the minimum. In the diagram above, it would be leftmost model with error in the yellow region. ",
    "url": "/docs/data-science/notes/one-se-rule.html",
    
    "relUrl": "/docs/data-science/notes/one-se-rule.html"
  },"1027": {
    "doc": "Orthogonal Projections",
    "title": "Orthogonal Projections",
    "content": ". | Orthogonal Complement . | Decomposition of a Vector | . | Orthogonal Projection . | Projection . | Projection Matrix | . | . | One-Dimensional Projection . | Line | Projection onto a Line | Finding Coordinate of Projection | . | Projection onto a General Subspace | Why Orthogonal Projection? | . ",
    "url": "/docs/linalg/basics/orthogonal-projections.html",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html"
  },"1028": {
    "doc": "Orthogonal Projections",
    "title": "Orthogonal Complement",
    "content": "Let $V$ be an $d$-dimensional vector space. Let $U \\subseteq V$ be an $m$-dimensional subspace of $V$. Then the orthogonal complement of $U$ is the subspace $U^\\perp \\subseteq V$, the set of all vectors in $V$ that are orthogonal to $U$. Therefore, . $$ U \\cap U^\\perp = \\{\\mathbf{0}\\} $$ . $U^\\perp$ is a $(d-m)$-dimensional subspace. ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#orthogonal-complement",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#orthogonal-complement"
  },"1029": {
    "doc": "Orthogonal Projections",
    "title": "Decomposition of a Vector",
    "content": "Any $\\mathbf{x} \\in V$ can be decomposed into vectors in $U$ and $U^\\perp$. Let $(\\mathbf{b}_1, \\dots, \\mathbf{b}_i)$ be a basis for $U$, where $i \\in [1, m]$. Let $(\\mathbf{b}_1^\\perp, \\dots, \\mathbf{b}_j^\\perp)$ be a basis for $U^\\perp$, where $j \\in [1, d - m]$. Then $\\mathbf{x}$ can be decomposed as follows: . \\[\\mathbf{x} = \\sum_{i=1}^m \\lambda_i \\mathbf{b}_i + \\sum_{j=1}^{d-m} \\psi_j \\mathbf{b}_j^\\perp\\] . ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#decomposition-of-a-vector",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#decomposition-of-a-vector"
  },"1030": {
    "doc": "Orthogonal Projections",
    "title": "Orthogonal Projection",
    "content": "We can project a vector $\\mathbf{x}$ onto a subspace $U$. This concept is often used in dimensionality reduction, where we project a high-dimensional vector onto a lower-dimensional feature space. When mapping high-dimensional data to a lower subspace, orthogonal projection retains as much information as possible. ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#orthogonal-projection",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#orthogonal-projection"
  },"1031": {
    "doc": "Orthogonal Projections",
    "title": "Projection",
    "content": "Let $V$ be a vector space and $U \\subseteq V$ be a subspace. A linear mappinng $\\pi: V \\to U$ is called a projection if: . $$ \\pi^2 = \\pi \\circ \\pi = \\pi $$ . Projection Matrix . Equivalently, let $P_\\pi$ be the transformation matrix of $\\pi$. Then, . $$ P_\\pi^2 = P_\\pi $$ . Projection matrices are always symmetric. ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#projection",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#projection"
  },"1032": {
    "doc": "Orthogonal Projections",
    "title": "One-Dimensional Projection",
    "content": "Assume $V = \\mathbb{R}^n$. ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#one-dimensional-projection",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#one-dimensional-projection"
  },"1033": {
    "doc": "Orthogonal Projections",
    "title": "Line",
    "content": "Let $U \\subseteq \\mathbb{R}^n$ be a one-dimensional subspace spanned by a single basis vector $\\mathbf{b} \\in \\mathbb{R}^n$. This subspace $U$ is called a line. ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#line",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#line"
  },"1034": {
    "doc": "Orthogonal Projections",
    "title": "Projection onto a Line",
    "content": "We want to project a vector $\\mathbf{x} \\in \\mathbb{R}^n$ onto a line $U$, denoted: . $$ \\pi_U(\\mathbf{x}) $$ . This projection has the following properties: . | $\\pi_U(\\mathbf{x})$ is closest to $\\mathbf{x}$ $$ \\|\\mathbf{x} - \\pi_U(\\mathbf{x})\\| \\textrm{ is minimal} $$ . | The displacement vector $\\mathbf{x} - \\pi_U(\\mathbf{x})$ is orthogonal to $U$ $$ \\langle\\mathbf{x} - \\pi_U(\\mathbf{x}), \\mathbf{b}\\rangle = 0 $$ . | $\\pi_U(\\mathbf{x}) \\in U$ $$ \\exists \\lambda \\in \\mathbb{R},\\, \\pi_U(\\mathbf{x}) = \\lambda \\mathbf{b} $$ . | . ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#projection-onto-a-line",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#projection-onto-a-line"
  },"1035": {
    "doc": "Orthogonal Projections",
    "title": "Finding Coordinate of Projection",
    "content": "We mentioned that $\\pi_U(\\mathbf{x})$ is a scalar multiple of $\\mathbf{b}$: . \\[\\exists \\lambda \\in \\mathbb{R},\\, \\pi_U(\\mathbf{x}) = \\lambda \\mathbf{b}\\] Then to calculate the projection, it suffices to find $\\lambda$, which is the coordinate of $\\pi_U(\\mathbf{x})$ with respect to $\\mathbf{b}$. $$ \\lambda = \\frac{\\langle\\mathbf{b}, \\mathbf{x}\\rangle} {\\langle\\mathbf{b}, \\mathbf{b}\\rangle} $$ . Derivation \\[\\begin{align*} &amp;\\langle\\mathbf{x} - \\pi_U(\\mathbf{x}), \\mathbf{b}\\rangle = 0 \\tag{orthogonality} \\\\[1em] \\iff &amp;\\langle\\mathbf{x} - \\lambda \\mathbf{b}, \\mathbf{b}\\rangle = 0 \\tag{definition} \\\\[1em] \\iff &amp;\\langle\\mathbf{x}, \\mathbf{b}\\rangle - \\lambda \\langle\\mathbf{b}, \\mathbf{b}\\rangle = 0 \\tag{bilinearity} \\\\[1em] \\iff &amp;\\lambda = \\frac{\\langle\\mathbf{x}, \\mathbf{b}\\rangle} {\\langle\\mathbf{b}, \\mathbf{b}\\rangle} \\\\[1em] \\iff &amp;\\lambda = \\frac{\\langle\\mathbf{b}, \\mathbf{x}\\rangle} {\\langle\\mathbf{b}, \\mathbf{b}\\rangle} \\tag{symmetry} \\end{align*}\\] If the inner product is a dot product, then: . $$ \\lambda = \\frac{\\mathbf{b}^T \\mathbf{x}}{\\|\\mathbf{b}\\|^2} $$ . Further, if $\\mathbf{b}$ is a unit vector (orthonormal basis), then: . $$ \\lambda = \\mathbf{b}^T \\mathbf{x} $$ . Then the projection is: . $$ \\pi_U(\\mathbf{x}) = \\lambda \\mathbf{b} = \\frac{\\langle\\mathbf{b}, \\mathbf{x}\\rangle} {\\langle\\mathbf{b}, \\mathbf{b}\\rangle} \\mathbf{b} $$ . ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#finding-coordinate-of-projection",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#finding-coordinate-of-projection"
  },"1036": {
    "doc": "Orthogonal Projections",
    "title": "Projection onto a General Subspace",
    "content": "Overall logic is the same as projection onto a line, it’s just that while line only had one basis vector, general subspace has multiple basis vectors. Suppose we want to project a vector $\\mathbf{x} \\in \\mathbb{R}^n$ onto a subspace $U \\subseteq \\mathbb{R}^n$ where $\\dim(U) = m$. Let $B = (\\mathbf{b}_1, \\dots, \\mathbf{b}_m)$ be an ordered basis for $U$. We know that $\\pi_U(\\mathbf{x}) \\in U$, therefore $\\pi_U(\\mathbf{x})$ can be written as a linear combination of $B$: . \\[\\pi_U(\\mathbf{x}) = \\sum_{i=1}^m \\lambda_i \\mathbf{b}_i\\] Define: . \\[\\mathbf{B} = [\\mathbf{b_1} \\dots \\mathbf{b_m}] \\quad \\boldsymbol{\\lambda} = \\begin{bmatrix} \\lambda_1 \\\\ \\vdots \\\\ \\lambda_m \\end{bmatrix}\\] Then $\\pi_U(\\mathbf{x}) = \\mathbf{B} \\boldsymbol{\\lambda}$. $\\mathbf{B}$ is a $n \\times m$ matrix and $\\boldsymbol{\\lambda}$ is a $m \\times 1$ vector. The displacement vector $\\mathbf{x} - \\pi_U(\\mathbf{x}) = \\mathbf{x} - \\mathbf{B} \\boldsymbol{\\lambda}$ is orthogonal to $U$ (for all $\\mathbf{b}_i \\in B$): . \\[\\begin{gather*} \\langle\\mathbf{b}_i, \\mathbf{x} - \\mathbf{B} \\boldsymbol{\\lambda}\\rangle = 0\\\\[1em] \\mathbf{b}_i^\\top (\\mathbf{x} - \\mathbf{B} \\boldsymbol{\\lambda}) = 0\\\\ \\end{gather*}\\] These $m$ equations can be formed into a homogeneous linear system: . \\[\\begin{align*} \\begin{bmatrix} \\mathbf{b}_1^\\top \\\\ \\vdots \\\\ \\mathbf{b}_m^\\top \\end{bmatrix} (\\mathbf{x} - \\mathbf{B} \\boldsymbol{\\lambda}) = 0 &amp;\\iff \\mathbf{B}^\\top (\\mathbf{x} - \\mathbf{B} \\boldsymbol{\\lambda}) = 0\\\\ &amp;\\iff \\mathbf{B}^\\top \\mathbf{x} - \\mathbf{B}^\\top \\mathbf{B} \\boldsymbol{\\lambda} = 0\\\\[1em] &amp;\\iff \\mathbf{B}^\\top \\mathbf{B} \\boldsymbol{\\lambda} = \\mathbf{B}^\\top \\mathbf{x}\\\\[1em] &amp;\\iff \\boldsymbol{\\lambda} = (\\mathbf{B}^\\top \\mathbf{B})^{-1} \\mathbf{B}^\\top \\mathbf{x} \\end{align*}\\] $(\\mathbf{B}^\\top \\mathbf{B})^{-1} \\mathbf{B}^\\top$ is the pseudoinverse of $\\mathbf{B}$. It only exists if $\\mathbf{B}$ is a full-rank matrix. The projection is: . $$ \\pi_U(\\mathbf{x}) = \\mathbf{B} \\boldsymbol{\\lambda} = \\mathbf{B} (\\mathbf{B}^\\top \\mathbf{B})^{-1} \\mathbf{B}^\\top \\mathbf{x} $$ . It is easy to see that the projection matrix $P_\\pi$ is: . $$ P_\\pi = \\mathbf{B} (\\mathbf{B}^\\top \\mathbf{B})^{-1} \\mathbf{B}^\\top $$ . If $B$ is an orthonormal basis We saw that . \\[\\pi_U(\\mathbf{x}) = \\mathbf{B} (\\mathbf{B}^\\top \\mathbf{B})^{-1} \\mathbf{B}^\\top \\mathbf{x}\\] If the basis is orthonormal, or $\\mathbf{B}^\\top \\mathbf{B} = \\mathbf{I}$, the projection simplifies to: . \\[\\pi_U(\\mathbf{x}) = \\mathbf{B} \\mathbf{B}^\\top \\mathbf{x}\\] . ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#projection-onto-a-general-subspace",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#projection-onto-a-general-subspace"
  },"1037": {
    "doc": "Orthogonal Projections",
    "title": "Why Orthogonal Projection?",
    "content": "Orthogonal projection is used in dimensionality reduction and approximating solutions to unsovleable linear system $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$. Mapping high-dimensional data to a lower subspace seems quite intuitive after we’ve seen the projection formula. Approximating solutions to unsovleable linear systems comes from the idea of finding a vector in the column space of $\\mathbf{A}$ that is closest to $\\mathbf{b}$. This approximation is called the least squares solution when the inner product is a dot product. ",
    "url": "/docs/linalg/basics/orthogonal-projections.html#why-orthogonal-projection",
    
    "relUrl": "/docs/linalg/basics/orthogonal-projections.html#why-orthogonal-projection"
  },"1038": {
    "doc": "Python Package",
    "title": "Python Package",
    "content": "To be added . | Basic structure of a Python package | Install package . | Editable (development) mode | . | . ",
    "url": "/docs/python/package.html",
    
    "relUrl": "/docs/python/package.html"
  },"1039": {
    "doc": "Python Package",
    "title": "Basic structure of a Python package",
    "content": "To be added . ",
    "url": "/docs/python/package.html#basic-structure-of-a-python-package",
    
    "relUrl": "/docs/python/package.html#basic-structure-of-a-python-package"
  },"1040": {
    "doc": "Python Package",
    "title": "Install package",
    "content": "Editable (development) mode . To install a package in editable mode, you must have defined the package in a setup.py file. Navigate to the package directory and run: . pip3 install --editable . # OR pip3 install -e . References: . | setuptools | . ",
    "url": "/docs/python/package.html#install-package",
    
    "relUrl": "/docs/python/package.html#install-package"
  },"1041": {
    "doc": "9 - Palindrome Number - Easy",
    "title": "Palindrome Number",
    "content": ". | Problem | Explanation | Solution | . ",
    "url": "/docs/compsci/leetcode/palindrome-number.html#palindrome-number",
    
    "relUrl": "/docs/compsci/leetcode/palindrome-number.html#palindrome-number"
  },"1042": {
    "doc": "9 - Palindrome Number - Easy",
    "title": "Problem",
    "content": "Given an integer x, return true if x is a palindrome, and false otherwise. Input: x = 121 Output: true Explanation: 121 reads as 121 from left to right and from right to left. Input: x = -121 Output: false Explanation: From left to right, it reads -121. From right to left, it becomes 121-. Therefore it is not a palindrome. Input: x = 10 Output: false Explanation: Reads 01 from right to left. Therefore it is not a palindrome. ",
    "url": "/docs/compsci/leetcode/palindrome-number.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/palindrome-number.html#problem"
  },"1043": {
    "doc": "9 - Palindrome Number - Easy",
    "title": "Explanation",
    "content": "Things to note: . | Negative numbers are not palindromes. | First half of the digits must be the same as the reversed second half of the digits. | . Let $n$ be the number of digits in $x$. The first half of the digits can be obtained by dividing $x$ by $10^{n/2}$. When $n$ is odd, however, the middle digit does not matter, so we should divide $x$ by $10^{(n+1)/2}$ instead. \\[\\texttt{121 / 10^(4/2) = 1}\\] Then reverse sum the second half and compare it with the first half. ",
    "url": "/docs/compsci/leetcode/palindrome-number.html#explanation",
    
    "relUrl": "/docs/compsci/leetcode/palindrome-number.html#explanation"
  },"1044": {
    "doc": "9 - Palindrome Number - Easy",
    "title": "Solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 . | public static boolean isPalindrome(int x) { if (x &lt; 0) return false; // Calculate the number of digits in x int n = 0; int xx = x; while (xx &gt; 0) { n++; xx /= 10; } int halfN = n / 2; int front = x / (int) Math.pow(10, (n % 2) == 0 ? halfN : halfN + 1); int backSum = 0; xx = x; for (int i = 0; i &lt; halfN; i++) { backSum = backSum * 10 + xx % 10; xx /= 10; } return front == backSum; } . | . ",
    "url": "/docs/compsci/leetcode/palindrome-number.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/palindrome-number.html#solution"
  },"1045": {
    "doc": "9 - Palindrome Number - Easy",
    "title": "9 - Palindrome Number - Easy",
    "content": " ",
    "url": "/docs/compsci/leetcode/palindrome-number.html",
    
    "relUrl": "/docs/compsci/leetcode/palindrome-number.html"
  },"1046": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Comparing Means in Parametric Tests",
    "content": "With parametric tests, we often compare the representative value mean against a hypothesis. This page describes different methods of comparing means in parametric tests. You don’t have to know all the equations by heart because most of the time you will be using a software to do the calculations for you. However, it is important to know the differences between the methods and when to use which method. | One-Sample t-Test | Paired t-Test | Two-Sample t-Test . | Pooled Standard Deviation | Homogeneity of Variance | t-Statistic for Two Independent Samples | Degrees of Freedom | . | Paired t-Test vs. Unpaired t-Test | . ",
    "url": "/docs/statistics/basics/parametric-test-mean.html",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html"
  },"1047": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "One-Sample t-Test",
    "content": "One-sample t-test is a hypothesis test that determines an unknown mean of a population which the sample is drawn from. Because we use a t-distribution, we need to assume the normality of the population. For some value $m$, our null hypothesis would be: . $$ H_0: \\mu = m $$ . And our alternative hypothesis: . $$ H_A: \\mu \\ne m $$ . If $p &lt; \\alpha$, we would conclude that the population mean is unlikely to be $m$. It is important to note that the value $m$ must be selected so that it serves as a meaningful value to the researcher (there should be a reason why we chose $m$). For example, if we were testing for the population’s average height, there’s no point in just choosing $m = 170cm$, because that’s an arbitrary value. In this case, we are actually better off just calculating a confidence interval for the population mean. However, if there was a better reasoning behind $m = 170cm$ (such as, average height in a certain country was 170cm and we want to test if it is the same in this country), then our hypothesis test would be more meaningful. ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#one-sample-t-test",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#one-sample-t-test"
  },"1048": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Calculation",
    "content": ". | We assume $H_0$ is true and thus $\\mu = m$ | Calculate the sample mean $\\bar{x}$ and subtract $m$ to get $\\bar{x} - \\mu$. | Calculate the sample standard deviation $s$ | Calculate the standard error of the mean $\\text{SEM} = s/\\sqrt{n}$ | Calculate the t-statistic $t = (\\bar{x} - m) / \\text{SEM}$ | Obtain the t-score $t_{\\alpha/2, \\nu}$ (where $\\nu = n - 1$ is the degrees of freedom) | If our $t$ does not fall within the range $-t_{\\alpha/2, \\nu} \\le t \\le t_{\\alpha/2, \\nu}$, we know that $p &lt; \\alpha$ and thus we reject $H_0$. | . ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#calculation",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#calculation"
  },"1049": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Paired t-Test",
    "content": "Paired t-test is a hypothesis test that compares the means of two populations that are related in some way. Most common case is comparing the data of identical subjects before and after a treatment. This might seem like a new testing method, but it is actually just a special case of one-sample t-test. Instead of setting up a null hypothesis on the population mean, we set up a null hypothesis on the difference between the means before/after. Consider the following table: . | Subject | Before | After | Difference | . | A | 10 | 12 | 2 | . | B | 10 | 14 | 4 | . | C | 12 | 14 | 2 | . | D | 11 | 15 | 4 | . Let $X_0$ be the population of the data before the treatment, and $X_1$ be the population of the data after the treatment. Then our null hypothesis would be on the $\\Delta X = X_1 - X_0$: . $$ H_0: \\mu_{\\Delta X} = 0 $$ . I won’t go into the details of the calculation, but following the same steps as one-sample t-test, you will find that our difference in the table above is significantly different from 0 (with $\\alpha = 0.05$). You may wonder if we can just use a two-sample t-test (described below) to compare the means before/after. However, the problem is that the samples are not independent of each other, and this makes the two-sample t-test more prone to errors. When suitable, paired t-test has more power than two-sample t-test. ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#paired-t-test",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#paired-t-test"
  },"1050": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Two-Sample t-Test",
    "content": "Two-sample t-test is a hypothesis test that compares the means of two populations. The populations must have normality. Two-sample t-test is also known as unpaired t-test or independent t-test, where the samples are independent of each other. Our null hypothesis would be: . $$ H_0: \\mu_A = \\mu_B $$ . And our alternative hypothesis: . $$ H_A: \\mu_A \\ne \\mu_B $$ . ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#two-sample-t-test",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#two-sample-t-test"
  },"1051": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Pooled Standard Deviation",
    "content": "Pooled standard deviation is the weighted average of standard deviations of two or more sample groups. Larger samples are given more weight. We typically denote the pooled standard deviation as: . $$ s_p $$ . The unbiased pooled standard deviation for $k$ samples is: . $$ s_p = \\sqrt{\\frac{\\sum_{i=1}^k (n_i - 1) s_i^2}{\\sum_{i=1}^k n_i}} $$ . For equal sample sizes, the pooled standard deviation is simplified to: . $$ s_p = \\sqrt{\\frac{\\sum_{i=1}^k s_i^2}{k}} $$ . If sample size and sample standard deviation are the same for all samples, then the pooled standard deviation is the same as the sample standard deviation. Confirm this by plugging in $s_i = s$ for all $i$. ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#pooled-standard-deviation",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#pooled-standard-deviation"
  },"1052": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Homogeneity of Variance",
    "content": "When we perform a two-sample t-test, we generally assume that the two populations have the same variance. However, if this assumption cannot be met, we use a modified version of the t-test called Welch’s t-test. Normality is still assumed. ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#homogeneity-of-variance",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#homogeneity-of-variance"
  },"1053": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "t-Statistic for Two Independent Samples",
    "content": "For two-sample t-test where we assume equal population variance, we use the following formula for the t-statistic: . $$ \\begin{equation} \\label{eq:t-two-sample-homovar} t = \\frac{(\\bar{x}_A - \\bar{x}_B) - (\\mu_A - \\mu_B)} {s_p \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}} \\end{equation} $$ . And if we have a similar sample size $n_A = n_B = n$, the formula can be further simplified to: . $$ \\begin{equation} \\label{eq:t-two-sample-simple} t = \\frac{(\\bar{x}_A - \\bar{x}_B) - (\\mu_A - \\mu_B)}{s_p \\sqrt{2/n}} \\end{equation} $$ . ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#t-statistic-for-two-independent-samples",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#t-statistic-for-two-independent-samples"
  },"1054": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Degrees of Freedom",
    "content": "The degrees of freedom $\\nu$ for two-sample t-test is: . $$ \\nu = n_A + n_B - 2 $$ . Two freedom are lost because we use our sample standard deviations to estimate the population standard deviations (pooled standard deviation). ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#degrees-of-freedom",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#degrees-of-freedom"
  },"1055": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Calculation",
    "content": ". | We assume $H_0$ is true and thus $\\mu_A - \\mu_B = 0$ | Calculate the sample standard deviation $s_A$ and $s_B$ | Calculate the pooled standard deviation $s_p$ where $k = 2$ | Calculate the t-statistic $t$ using Equation \\eqref{eq:t-two-sample-homovar} with $\\mu_A - \\mu_B = 0$ substituted in | Obtain the t-score $t_{\\alpha/2, \\nu}$ (where $\\nu = n_A + n_B - 2$ is the degrees of freedom) | If our $t$ does not fall within the range $-t_{\\alpha/2, \\nu} \\le t \\le t_{\\alpha/2, \\nu}$, we know that $p &lt; \\alpha$ and thus we reject $H_0$. | . ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#calculation-1",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#calculation-1"
  },"1056": {
    "doc": "Comparing Means in Parametric Tests",
    "title": "Paired t-Test vs. Unpaired t-Test",
    "content": "For a recap, paired t-test is used when we have two samples that are dependent on each other, while unpaired t-test is used when we have two samples that are independent. The following figure illustrates in which situations either test should be used: . When applicable, it is always better to use paired t-test because it has more power. Just because there are two samples that need to be compared, it does not mean two-sample t-test is most appropriate. We should always consider the nature and relationship of the samples before deciding a testing method. ",
    "url": "/docs/statistics/basics/parametric-test-mean.html#paired-t-test-vs-unpaired-t-test",
    
    "relUrl": "/docs/statistics/basics/parametric-test-mean.html#paired-t-test-vs-unpaired-t-test"
  },"1057": {
    "doc": "Parity of a Permutation",
    "title": "Parity of a Permutation",
    "content": ". | Permutation . | Identity permutation | . | Parity | Even and odd permutations | . ",
    "url": "/docs/compsci/math/parity-of-permutation.html",
    
    "relUrl": "/docs/compsci/math/parity-of-permutation.html"
  },"1058": {
    "doc": "Parity of a Permutation",
    "title": "Permutation",
    "content": "Let $X$ be a finite set of $n &gt; 1$ elements. A permutation $\\sigma$ is a bijection from $X$ to $X$. Given a set $\\{a, b, c\\}$, the permutation $\\{b, c, a\\}$ is: . \\[\\begin{gather*} \\sigma(a) = b \\\\ \\sigma(b) = c \\\\ \\sigma(c) = a \\end{gather*}\\] It is often denoted in the following form: . \\[\\sigma = \\begin{pmatrix} a &amp; b &amp; c \\\\ b &amp; c &amp; a \\end{pmatrix}\\] ",
    "url": "/docs/compsci/math/parity-of-permutation.html#permutation",
    
    "relUrl": "/docs/compsci/math/parity-of-permutation.html#permutation"
  },"1059": {
    "doc": "Parity of a Permutation",
    "title": "Identity permutation",
    "content": "The identity permutation is the permutation that maps every element to itself. \\[\\begin{pmatrix} a &amp; b &amp; c \\\\ a &amp; b &amp; c \\end{pmatrix}\\] ",
    "url": "/docs/compsci/math/parity-of-permutation.html#identity-permutation",
    
    "relUrl": "/docs/compsci/math/parity-of-permutation.html#identity-permutation"
  },"1060": {
    "doc": "Parity of a Permutation",
    "title": "Parity",
    "content": "The parity of a permutation $\\sigma$ is the parity of the number of paired inversions in $\\sigma$ required to transform it into the identity permutation. The parity or the sign of a permutation $\\sigma$ is denoted: . $$ \\operatorname{sgn}(\\sigma) = (-1)^{\\text{number of inversions}} $$ . Continuing with the example above, the number of inversions need for . \\[\\begin{pmatrix} a &amp; b &amp; c \\\\ b &amp; c &amp; a \\end{pmatrix}\\] would be 2: . | Invert $a$ and $c$ | Invert $a$ and $b$ | . Therefore, the parity of the permutation is $(-1)^2 = 1$. ",
    "url": "/docs/compsci/math/parity-of-permutation.html#parity",
    
    "relUrl": "/docs/compsci/math/parity-of-permutation.html#parity"
  },"1061": {
    "doc": "Parity of a Permutation",
    "title": "Even and odd permutations",
    "content": "The set of permutations of $X$ can be partitioned into two subsets: . | Even permutations: $\\operatorname{sgn}(\\sigma) = 1$ | Odd permutations: $\\operatorname{sgn}(\\sigma) = -1$ | . ",
    "url": "/docs/compsci/math/parity-of-permutation.html#even-and-odd-permutations",
    
    "relUrl": "/docs/compsci/math/parity-of-permutation.html#even-and-odd-permutations"
  },"1062": {
    "doc": "Permutation Test",
    "title": "Permutation Test",
    "content": "Non-parametric hypothesis test, which tests for the equality of two population distributions. | Hypothesis | Test Statistic . | Idea | . | Procedure . | Realistically | . | . ",
    "url": "/docs/statistics/notes/permutation-test.html",
    
    "relUrl": "/docs/statistics/notes/permutation-test.html"
  },"1063": {
    "doc": "Permutation Test",
    "title": "Hypothesis",
    "content": "The null hypothesis is: . $$ H_0: F_X = F_Y $$ . where $F_X$ and $F_Y$ are the cumulative distribution functions of the two populations. The alternative hypothesis is: . $$ H_1: F_X \\neq F_Y $$ . ",
    "url": "/docs/statistics/notes/permutation-test.html#hypothesis",
    
    "relUrl": "/docs/statistics/notes/permutation-test.html#hypothesis"
  },"1064": {
    "doc": "Permutation Test",
    "title": "Test Statistic",
    "content": "Let $X_1, \\dots, X_m$ be the sample from population $X$, and $Y_1, \\dots, Y_n$ be the sample from population $Y$. The test statistic is the difference in means: . $$ t_{obs} = \\overline{X}_m - \\overline{Y}_n $$ . ",
    "url": "/docs/statistics/notes/permutation-test.html#test-statistic",
    
    "relUrl": "/docs/statistics/notes/permutation-test.html#test-statistic"
  },"1065": {
    "doc": "Permutation Test",
    "title": "Idea",
    "content": "If the null hypothesis is true, even when the samples are shuffled and resplit into two groups, the statistic should not change much. ",
    "url": "/docs/statistics/notes/permutation-test.html#idea",
    
    "relUrl": "/docs/statistics/notes/permutation-test.html#idea"
  },"1066": {
    "doc": "Permutation Test",
    "title": "Procedure",
    "content": "Let $Z = (X_1, \\dots, X_m, Y_1, \\dots, Y_n)$ be the combined sample. Let $N = m + n$. There are $N!$ possible permutations of the combined sample. Then, for each permutation $Z^\\ast$ of $Z$, define $\\overline{X}_m^\\ast$ and $\\overline{Y}_n^\\star$ as the means of the first $m$ and last $n$ elements of $Z^\\ast$. If the null hypothesis is true: . \\[T = \\overline{X}_m^\\ast - \\overline{Y}_n^\\ast\\] The probability that $T$ is more extreme than $t_{obs}$ is should be low. So our p-value is: . $$ p = \\Pr(T &gt; t_{obs}) = \\frac{1}{N!} \\sum_{i=1}^{N!} I(T_i &gt; t_{obs}) $$ . i.e. count the number of times $T_i &gt; t_{obs}$ to find the proportion of times this happens. What? Basically, we’re forming a distribution of $T$ by permuting the combined sample. In the distribution of $T$, we’re looking at the probability of observing a value as extreme as $t_{obs}$. If the null hypothesis is true, then the probability of observing more extreme values than $t_{obs}$ should be low. ",
    "url": "/docs/statistics/notes/permutation-test.html#procedure",
    
    "relUrl": "/docs/statistics/notes/permutation-test.html#procedure"
  },"1067": {
    "doc": "Permutation Test",
    "title": "Realistically",
    "content": "As $N$ gets large, performing $N!$ permutations becomes unreasonable. So we pick a large number $B$, and randomly sample $B$ permutations. Then, our p-value is: . $$ p = \\frac{1}{B} \\sum_{i=1}^{B} I(T_i &gt; t_{obs}) $$ . ",
    "url": "/docs/statistics/notes/permutation-test.html#realistically",
    
    "relUrl": "/docs/statistics/notes/permutation-test.html#realistically"
  },"1068": {
    "doc": "Pipenv",
    "title": "Pipenv",
    "content": ". | Advantage to venv | Basic usage . | Install | Create environment and install | Activate and deactivate environment . | Activate | Deactivate | . | Create Pipfile.lock | Delete environment | . | Use pipenv with a specific Python version | . ",
    "url": "/docs/python/envs/pipenv.html",
    
    "relUrl": "/docs/python/envs/pipenv.html"
  },"1069": {
    "doc": "Pipenv",
    "title": "Advantage to venv",
    "content": "Pipenv’s Pipfile serves as an upgrade to requirements.txt. It allows you to separately mark production and development dependencies. ",
    "url": "/docs/python/envs/pipenv.html#advantage-to-venv",
    
    "relUrl": "/docs/python/envs/pipenv.html#advantage-to-venv"
  },"1070": {
    "doc": "Pipenv",
    "title": "Basic usage",
    "content": "Install . brew install pipenv . Create environment and install . Go to the desired project folder. To create and use a virtual environment for this root: . pipenv pipenv install &lt;package-name&gt; # Install specific package . If there’s already a Pipfile, create env and install listed requirements: . pipenv install # With Pipfile . All the pipenv environments are in ~/.local/share/virtualenvs/root-dir-name-hash/ by default. Activate and deactivate environment . Activate . pipenv shell . Deactivate . exit . Do not use deactivate. Create Pipfile.lock . pipenv lock . Delete environment . To delete the environment for current directory: . pipenv --rm . ",
    "url": "/docs/python/envs/pipenv.html#basic-usage",
    
    "relUrl": "/docs/python/envs/pipenv.html#basic-usage"
  },"1071": {
    "doc": "Pipenv",
    "title": "Use pipenv with a specific Python version",
    "content": "You can set a specific version of Python when creating a pipenv virtual environment. pipenv --python 3.x . However, it requires that Python 3.x is already installed on your local machine unlike conda create -n myenv python=3.x. You can either, . | (Not recommended) brew install the desired Python 3.x | (Recommended) Use pyenv | (Meh..) Create a conda environment with the desired version and only use the binary | . Then navigate to the root of the project and make Pipenv use the active Python: . pipenv --python=$(which python) --site-packages # Creates an env in cwd pipenv run which python # It will point to a binary in `~/.local/share/virtualenvs/some-root-dir-hash/bin/python` pipenv run python -V # Check that it is indeed 3.x . ",
    "url": "/docs/python/envs/pipenv.html#use-pipenv-with-a-specific-python-version",
    
    "relUrl": "/docs/python/envs/pipenv.html#use-pipenv-with-a-specific-python-version"
  },"1072": {
    "doc": "Poetry",
    "title": "Poetry",
    "content": "Yet another Python virtual environment &amp; package manager! . | Installation | Enable tab completion | Using Poetry with a specific Python version . | Set Python binary | . | Managing environments . | See all virtual envs associated with this directory/project | Delete environments | . | Basic usage . | Activate environment | Deactivate environment | Add dependencies | Install dependencies | Remove dependencies | . | . ",
    "url": "/docs/python/envs/poetry.html",
    
    "relUrl": "/docs/python/envs/poetry.html"
  },"1073": {
    "doc": "Poetry",
    "title": "Installation",
    "content": "Use Homebrew: . brew install poetry . Check installation via . poetry --version . ",
    "url": "/docs/python/envs/poetry.html#installation",
    
    "relUrl": "/docs/python/envs/poetry.html#installation"
  },"1074": {
    "doc": "Poetry",
    "title": "Enable tab completion",
    "content": "You can enable poetry tab completion for various shells. Check poetry help completions for other shells. For Oh-My-Zsh: . mkdir $ZSH_CUSTOM/plugins/poetry poetry completions zsh &gt; $ZSH_CUSTOM/plugins/poetry/_poetry . Then go to ~/.zshrc and add the following plugin: . # ~/.zshrc plugins( ... poetry ) . ",
    "url": "/docs/python/envs/poetry.html#enable-tab-completion",
    
    "relUrl": "/docs/python/envs/poetry.html#enable-tab-completion"
  },"1075": {
    "doc": "Poetry",
    "title": "Using Poetry with a specific Python version",
    "content": "Have the Python version you want ready. Always check that you do indeed have the version you want by which python . You can set the version you want . | With pyenv (Recommended) | With conda | . Now init Poetry in project to create a pyproject.toml file. cd &lt;project-dir&gt; poetry init . By default, Poetry uses the currently active Python. Poetry virtual environments are created in ~/Library/Caches/pypoetry/virtualenvs. Set Python binary . If you’d like to change a version after init, activate a new Python binary and do: . poetry env use `pyenv which python3` . Check that it is using the right binary by: . poetry env info . ",
    "url": "/docs/python/envs/poetry.html#using-poetry-with-a-specific-python-version",
    
    "relUrl": "/docs/python/envs/poetry.html#using-poetry-with-a-specific-python-version"
  },"1076": {
    "doc": "Poetry",
    "title": "Managing environments",
    "content": "See all virtual envs associated with this directory/project . poetry env list . Delete environments . poetry env remove &lt;proj-hash--py3.x&gt; ## Check exact name with poetry env list . ",
    "url": "/docs/python/envs/poetry.html#managing-environments",
    
    "relUrl": "/docs/python/envs/poetry.html#managing-environments"
  },"1077": {
    "doc": "Poetry",
    "title": "Basic usage",
    "content": "Activate environment . poetry shell # Creates a new child shell # OR source `poetry env info --path`/bin/activate # Does not open a child shell . Deactivate environment . exit # If in child shell # OR deactivate # If activated with source &lt;path&gt;/bin/activate . Add dependencies . poetry add &lt;package&gt; # OR poetry add &lt;package&gt; --dev . Install dependencies . poetry install # OR poetry install --no-dev . Remove dependencies . poetry remove &lt;package&gt; # OR poetry remove &lt;package&gt; --dev . References: . | Poetry | Poetry Commands | . ",
    "url": "/docs/python/envs/poetry.html#basic-usage",
    
    "relUrl": "/docs/python/envs/poetry.html#basic-usage"
  },"1078": {
    "doc": "Pooled Variance",
    "title": "Pooled Variance",
    "content": "Suppose we have samples with different sample variances. If we have a good reason to believe that they come from the same population, we can pool the variances together to estimate the common variance. | Recap: Sample Variance | Pooling the Variances . | Uniform Sample Sizes | . | . ",
    "url": "/docs/statistics/notes/pooled-variance.html",
    
    "relUrl": "/docs/statistics/notes/pooled-variance.html"
  },"1079": {
    "doc": "Pooled Variance",
    "title": "Recap: Sample Variance",
    "content": "Let $X_1, \\dots, X_m$ be random samples. | $n_i$: number of observations in sample $i$. | $\\overline{X}_i$: sample mean of sample $i$. | . The (unbiased) sample variance of each $X_i$ is: . $$ S_{n_i}^2 = \\frac{1}{n_i - 1} \\sum_{j=1}^{n_i} (x_{j} - \\overline{X}_i)^2 $$ . ",
    "url": "/docs/statistics/notes/pooled-variance.html#recap-sample-variance",
    
    "relUrl": "/docs/statistics/notes/pooled-variance.html#recap-sample-variance"
  },"1080": {
    "doc": "Pooled Variance",
    "title": "Pooling the Variances",
    "content": "Pooled variance is the weighted average of the sample variances. Each variance is weighted by the degrees of freedom of each sample ($n_i - 1$): . $$ \\frac{n_i - 1}{\\sum_{i=1}^m (n_i - 1)} = \\frac{n_i - 1}{N - m} $$ . Summing them together we have the formula for pooled variance: . $$ S_p^2 = \\frac{1}{N-m} \\sum_{i=1}^m (n_i - 1) S_{n_i}^2 $$ . ",
    "url": "/docs/statistics/notes/pooled-variance.html#pooling-the-variances",
    
    "relUrl": "/docs/statistics/notes/pooled-variance.html#pooling-the-variances"
  },"1081": {
    "doc": "Pooled Variance",
    "title": "Uniform Sample Sizes",
    "content": "If $n_i = n$ for all $i$, then the formula simplifies to: . $$ S_p^2 = \\frac{1}{m} \\sum_{i=1}^m S_{n_i}^2 $$ . ",
    "url": "/docs/statistics/notes/pooled-variance.html#uniform-sample-sizes",
    
    "relUrl": "/docs/statistics/notes/pooled-variance.html#uniform-sample-sizes"
  },"1082": {
    "doc": "Post-Hoc Test",
    "title": "Post-Hoc Test",
    "content": "As the name suggests, post-hoc test is performed after a test to correct error rates and assess the significance of the results. | Error Rates in Multiple Comparison . | Family-Wise Error Rate | False Discovery Rate | Positive False Discovery Rate | . | Bonferroni Correction | Holm’s Method | q-Value | Benjamini-Hochberg Procedure . | Comparison to controlling FWER | . | Tukey’s HSD Test . | Studentized Range Distribution | HSD | . | Dunnett’s Test | Williams Test | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html"
  },"1083": {
    "doc": "Post-Hoc Test",
    "title": "Error Rates in Multiple Comparison",
    "content": "Suppose we are testing a family of $m$ hypotheses. Let’s denote: . |   | $H_0$ is true | $H_A$ is true |   | . | Test declared insignificant | $U$ | $T$ | $m - R$ | . | Test declared significant | $V$ | $S$ | $R$ | . |   | $m_0$ | $m - m_0$ | $m$ | . where each cell represents the number of hypotheses: . | $m_0$: the number of true null hypotheses | $R$: the number of rejected null hypotheses | $U$: the number of true negatives | $T$: the number of false negatives | $V$: the number of false positives | $S$: the number of true positives | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#error-rates-in-multiple-comparison",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#error-rates-in-multiple-comparison"
  },"1084": {
    "doc": "Post-Hoc Test",
    "title": "Family-Wise Error Rate",
    "content": "Family-wise error rate (FWER) is the probability of making at least one Type I error in a family of tests. $$ \\text{FWER} = P(\\text{at least one Type I error}) = P(V \\geq 1) $$ . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#family-wise-error-rate",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#family-wise-error-rate"
  },"1085": {
    "doc": "Post-Hoc Test",
    "title": "False Discovery Rate",
    "content": "False discovery rate (FDR) is the expected proportion of false positives among all rejected hypotheses. Simply: . $$ \\text{FDR} = E\\left[\\frac{V}{R}\\right] $$ . What if R = 0? Formally, . $$ \\text{FDR} = E\\left[\\frac{V}{R} \\mid R &gt; 0\\right] \\cdot P(R &gt; 0) $$ . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#false-discovery-rate",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#false-discovery-rate"
  },"1086": {
    "doc": "Post-Hoc Test",
    "title": "Positive False Discovery Rate",
    "content": "To be added . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#positive-false-discovery-rate",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#positive-false-discovery-rate"
  },"1087": {
    "doc": "Post-Hoc Test",
    "title": "Bonferroni Correction",
    "content": "As we’ve seen in the multiple comparisons problem, repeating the a pairwise test multiple times increases the FWER. The Bonferroni correction is a method to correct the FWER to $\\alpha$ by rejecting the null hypothesis less frequently in each test. The idea is simple, which is to correct each significance level to: . $$ \\alpha' = \\frac{\\alpha}{m} $$ . where $m$ is the number of pairwise tests. Bonferroni correction has pros: . | It is simple | It can be used in any test that produces a p-value | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#bonferroni-correction",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#bonferroni-correction"
  },"1088": {
    "doc": "Post-Hoc Test",
    "title": "Issues with Bonferroni Correction",
    "content": "The problem with the Bonferroni correction is that it is too conservative. Although it corrects the FWER to approximately $\\alpha$, the power of each test is reduced significantly as the number of tests increases. Suppose we have $\\alpha = 0.05$ and we perform 10 pairwise tests. Then our Bonferroni-corrected $\\alpha’$ for each test is 0.005, and this gets worse as the number of tests increases. It gets harder and harder to call any result significant. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#issues-with-bonferroni-correction",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#issues-with-bonferroni-correction"
  },"1089": {
    "doc": "Post-Hoc Test",
    "title": "Holm’s Method",
    "content": "Just like Bonferroni, Holm’s method tries to correct the Type I error rate by controlling the FWER. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#holms-method",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#holms-method"
  },"1090": {
    "doc": "Post-Hoc Test",
    "title": "Procedure",
    "content": "Let’s say we have $m$ hypotheses to test. Notice the difference in notation between $p_i$ and $p_{(j)}$. $p_i$ is the p-value of $H_i$, while $p_{(j)}$ is the $j$-th smallest p-value among $p_i$. | Calculate the p-value $p_i$ for each test ($1 \\leq i \\leq m$) | Sort the p-values in ascending order: $p_{(1)} \\leq p_{(2)} \\leq \\dots \\leq p_{(m)}$ | Calculate lowerbound rank $L$: $$ L = \\min\\left\\{j \\in \\{1, \\dots, m\\} \\mid p_{(j)} &gt; \\frac{\\alpha}{m + 1 - j}\\right\\} $$ . | Reject all null hypotheses with $p_i &lt; p_{(L)}$ | . Alternatively . | Calculate the p-value $p_i$ for each test ($1 \\leq i \\leq m$) | Sort the p-values in ascending order: $p_{(1)} \\leq p_{(2)} \\leq \\dots \\leq p_{(m)}$ | Reject all $p_{(j)}$ such that $$ p_{(j)} &lt; \\frac{\\alpha}{m + 1 - j} $$ . | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#procedure",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#procedure"
  },"1091": {
    "doc": "Post-Hoc Test",
    "title": "Comparison to Bonferroni",
    "content": "Both Bonferroni and Holm’s method control the FWER to $\\alpha$. However Holm’s method is at least as powerful as Bonferroni correction, and thus less conservative. Anything Bonferroni rejects, Holm’s method will also reject. Proof Suppose Bonferroni rejects $H_{0i}$ for some $i \\in [1, m]$. Then $p_i &lt; \\frac{\\alpha}{m}$. Because . \\[\\forall j \\in [1, m],\\; \\frac{\\alpha}{m} \\leq \\frac{\\alpha}{m + 1 - j}\\] We have $p_i &lt; \\frac{\\alpha}{m + 1 - L} &lt; p_{(L)}$ by definition. So Holm’s method will also reject $H_{0i}$. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#comparison-to-bonferroni",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#comparison-to-bonferroni"
  },"1092": {
    "doc": "Post-Hoc Test",
    "title": "q-Value",
    "content": "Remember that running multiple tests suffers increased overall Type I error. So we use correction methods on the p-value to stabilize the FWER. However, controlling the FWER to correct type I error often becomes too conservative. So we look for other methods to correct Type I errors. Instead of trying to control the FWER, we can try to control the false discovery rate (FDR), and use a q-value which is the FDR analogue of the p-value. For a recap, the FDR is the expected proportion of false positives among all rejected null hypotheses. So compared to FWER which measures the chance of making any false positives, FDR is more lenient. The q-value of a test is the minimum FDR at which the test may be called significant. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#q-value",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#q-value"
  },"1093": {
    "doc": "Post-Hoc Test",
    "title": "Benjamini-Hochberg Procedure",
    "content": "Benjamini-Hochberg procedure is a method to control the FDR. If we set a threshold $q$ and follow the procedure, $\\text{FDR} \\leq q$. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#benjamini-hochberg-procedure",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#benjamini-hochberg-procedure"
  },"1094": {
    "doc": "Post-Hoc Test",
    "title": "Procedure",
    "content": ". | Calculate the p-value $p_i$ for each test ($1 \\leq i \\leq m$) | Sort the p-values in ascending order: $p_{(1)} \\leq p_{(2)} \\leq \\dots \\leq p_{(m)}$ | Calculate the rank $L$ $$ \\begin{equation*} \\label{eq:bh_rank} \\tag{Maximum Rank} L = \\max\\left\\{j \\in \\{1, \\dots, m\\} \\mid p_{(j)} &lt; \\frac{q}{m}\\cdot j\\right\\} \\end{equation*} $$ . | Reject all null hypotheses with $p_i &lt; p_{(L)}$. | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#procedure-1",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#procedure-1"
  },"1095": {
    "doc": "Post-Hoc Test",
    "title": "Comparison to controlling FWER",
    "content": "The slope of Benjamini-Hochberge threshold is defined by $q/m$ (see \\ref{eq:bh_rank}). The p-values below each line are the rejected ones (discoveries). From the graph, we see that Benjamini-Hochberg procedure makes more discoveries than well-known methods that control FWER. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#comparison-to-controlling-fwer",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#comparison-to-controlling-fwer"
  },"1096": {
    "doc": "Post-Hoc Test",
    "title": "Tukey’s HSD Test",
    "content": "HSD stands for honestly significant difference, which is the minimum difference between two means that is considered (actually/honestly) statistically significant. So Tukey’s HSD test is a method that calculates the HSD, and checks which pair has a significant difference (i.e. greater than HSD). It works better than the Bonferroni correction in that it maintains the FWER at $\\alpha$ but without losing as much power. Typically, Tukey’s HSD test is used after ANOVA. However, it can be used standalone as well. The null hypothesis of Tukey’s HSD test is: . $$ H_0: \\forall i, j \\in [1, k],\\; \\mu_i = \\mu_j $$ . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#tukeys-hsd-test",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#tukeys-hsd-test"
  },"1097": {
    "doc": "Post-Hoc Test",
    "title": "Assumptions",
    "content": "Tukey’s test assumes the following: . | The observations are independent (within and among) | Each group follows a normal distribution | Homogeneity of variance in each group | The sample sizes are equal ($n_k = n$) If the sample sizes are unequal, Tukey's test becomes more conservative. | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#assumptions",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#assumptions"
  },"1098": {
    "doc": "Post-Hoc Test",
    "title": "Studentized Range Distribution",
    "content": "Suppose we have $k$ populations with normal distribution, and we each take a sample of size $n$. Let $\\bar{x}_{min}$ and $\\bar{x}_{max}$ be the smallest and largest sample means respectively, and $s_p$ the pooled standard deviation (with equal sample sizes). The following random variable has a Studentized range distribution: . $$ Q = \\frac{\\bar{x}_{max} - \\bar{x}_{min}}{s_p / \\sqrt{n}} $$ . Largest difference between two sample means measured by the standard error. ",
    "url": "/docs/statistics/basics/post-hoc-test.html#studentized-range-distribution",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#studentized-range-distribution"
  },"1099": {
    "doc": "Post-Hoc Test",
    "title": "HSD",
    "content": "Test Statistic . We use the following statistic to measure the difference in means: . $$ \\frac{\\mid\\bar{x}_i - \\bar{x}_j\\mid}{\\sqrt{MSE / n}} $$ . where $\\bar{x}_i$ and $\\bar{x}_j$ are the sample means of group $i$ and $j$ respectively. When null hypothesis is true, the statistic follows the studentized range distribution. Critical Value of Studentized Range Distribution . We denote the critical value as . $$ q_{\\alpha, \\nu, k} $$ . where: . | $\\alpha$ is the significance level | $\\nu$ is the degrees of freedom of the distribution | $k$ is the number of groups | . We then compare our statistic to a critical value of the distribution. If the statistic is greater than the critical value, we reject the null hypothesis. The Studentized range distribution is measured on the largest difference, so it makes sense that any difference measure greater than the critical value should be considered significant. Just like z-scores and t-scores, the values can be obtained from a table. Defining HSD . For our differences to be significant, we need the following to be true: . \\[\\frac{\\mid\\bar{x}_i - \\bar{x}_j\\mid}{\\sqrt{MSE / n}} \\geq q_{\\alpha, \\nu, k}\\] We can rearrange the inequality to get the following: . \\[\\mid\\bar{x}_i - \\bar{x}_j\\mid \\geq q_{\\alpha, \\nu, k} \\cdot \\sqrt{\\frac{MSE}{n}}\\] The right-hand side of the inequality is then defined HSD: . $$ HSD = q_{\\alpha, \\nu, k} \\cdot \\sqrt{\\frac{MSE}{n}} $$ . where: . | $q_{\\alpha, \\nu, N}$ is the critical value of the studentized range distribution with $\\alpha$ significance level, $\\nu$ degrees of freedom, and $k$ groups . | Standard error of the group mean: . | $MSE$ is the mean square errror (or within), which you can get from the ANOVA summary table | $n$ is the sample size of each group (which is assumed to be all equal) | . | . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#hsd",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#hsd"
  },"1100": {
    "doc": "Post-Hoc Test",
    "title": "Dunnett’s Test",
    "content": "To be added . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#dunnetts-test",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#dunnetts-test"
  },"1101": {
    "doc": "Post-Hoc Test",
    "title": "Williams Test",
    "content": "To be added . ",
    "url": "/docs/statistics/basics/post-hoc-test.html#williams-test",
    
    "relUrl": "/docs/statistics/basics/post-hoc-test.html#williams-test"
  },"1102": {
    "doc": "Properties of Expectation, Variance, and Covariance",
    "title": "Properties of Expectation, Variance, and Covariance",
    "content": "This is a quick summary of the properties of expectation, variance, and covariance. For details: . | Expectation | Variance | Conditional Expectation/Variance | Covariance | . | Expectation | Conditional Expectation | Variance | Conditional Variance | Covariance | . ",
    "url": "/docs/statistics/notes/properties-of-e-var.html",
    
    "relUrl": "/docs/statistics/notes/properties-of-e-var.html"
  },"1103": {
    "doc": "Properties of Expectation, Variance, and Covariance",
    "title": "Expectation",
    "content": "$$ \\begin{equation} \\tag{Expectated value of a constant} \\E[c] = c \\end{equation} $$ . For the same reason \\[\\E[\\E[X]] = \\E[X]\\] $$ \\begin{equation} \\tag{Linearity of expectation} \\E[aX + bY] = a\\E[X] + b\\E[Y] \\end{equation} $$ $$ \\begin{equation} \\tag{Expectation of joint RVs} \\E[XY] = \\E[X]\\E[Y] + \\Cov(X, Y) \\end{equation} $$ . Independence When $X$ and $Y$ are independent, . \\[\\begin{gather*} \\Cov(X, Y) = 0 \\\\[1em] \\E[XY] = \\E[X]\\E[Y] \\end{gather*}\\] . ",
    "url": "/docs/statistics/notes/properties-of-e-var.html#expectation",
    
    "relUrl": "/docs/statistics/notes/properties-of-e-var.html#expectation"
  },"1104": {
    "doc": "Properties of Expectation, Variance, and Covariance",
    "title": "Conditional Expectation",
    "content": "$$ \\begin{equation} \\tag{Law of total expectation} \\E[X] = \\E[\\E[X|Y]] \\end{equation} $$ . Conditional Expectation as RV $\\E[X|Y]$ is a random variable of $Y$. Hence $\\E[\\E[X|Y]]$ is aggregating over all possible values of $Y$, that’s why we are left with $\\E[X]$. $$ \\begin{gather*} \\E[a | X] = a \\\\[0.5em] \\E[aX + bY | Z] = a\\E[X|Z] + b\\E[Y|Z] \\\\[0.5em] \\end{gather*} $$ . The above are linearity. $$ \\begin{gather*} \\E[X | X] = X \\\\[0.5em] \\E[g(X) | X] = g(X) \\\\[0.5em] \\end{gather*} $$ . The above are obvious. If you have $X$, you’re expected to get $X$. $$ \\E[X | Y, g(Y)] = \\E[X | Y] \\\\[0.5em] $$ . The above is also obvious: if you already know $Y$, knowing $g(Y)$ doesn’t change anything. $$ \\begin{equation*} \\E[X g(Y) | Y] = g(Y)\\E[X|Y] \\end{equation*} $$ $$ \\begin{equation*} \\E[\\E[X|Y, Z]| Y] = \\E[X|Y] \\end{equation*} $$ . These need a bit more thought. ",
    "url": "/docs/statistics/notes/properties-of-e-var.html#conditional-expectation",
    
    "relUrl": "/docs/statistics/notes/properties-of-e-var.html#conditional-expectation"
  },"1105": {
    "doc": "Properties of Expectation, Variance, and Covariance",
    "title": "Variance",
    "content": "$$ \\begin{align*} \\Var(X) &amp;= \\E[(X - \\E[X])^2] \\\\[0.5em] &amp;= \\E[X^2] - \\E[X]^2 \\end{align*} $$ . Derivation Just remember that $\\E[\\E[X]] = \\E[X]$ and $\\E[\\E[X]^2] = \\E[X]^2$, because $\\E[X]$ is a constant. \\[\\begin{align*} \\Var(X) &amp;= \\E[(X - \\E[X])^2] \\\\[0.5em] &amp;= \\E[X^2 - 2X\\E[X] + \\E[X]^2] \\\\[0.5em] &amp;= \\E[X^2] - 2\\E[X]\\E[X] + \\E[X]^2 \\\\[0.5em] &amp;= \\E[X^2] - \\E[X]^2 \\end{align*}\\] $$ \\begin{gather*} \\Var(aX + b) = a^2\\Var(X) \\\\[0.5em] \\Var(aX + bY) = a^2\\Var(X) + b^2\\Var(Y) + 2ab\\Cov(X, Y) \\\\[0.5em] \\Var(aX - bY) = a^2\\Var(X) + b^2\\Var(Y) - 2ab\\Cov(X, Y) \\end{gather*} $$ . ",
    "url": "/docs/statistics/notes/properties-of-e-var.html#variance",
    
    "relUrl": "/docs/statistics/notes/properties-of-e-var.html#variance"
  },"1106": {
    "doc": "Properties of Expectation, Variance, and Covariance",
    "title": "Conditional Variance",
    "content": "$$ \\begin{align*} \\Var(X|Y) &amp;= \\E[(X - \\E[X|Y])^2|Y] \\\\[0.5em] &amp;= \\E[X^2|Y] - \\E[X|Y]^2 \\end{align*} $$ . Derivation \\[\\begin{align*} \\Var(X|Y) &amp;= \\E[(X - \\E[X|Y])^2|Y] \\\\[0.5em] &amp;= \\E[X^2 - 2X\\E[X|Y] + \\E[X|Y]^2|Y] \\\\[0.5em] &amp;= \\E[X^2|Y] - 2\\E[X\\E[X|Y]|Y] + \\E[\\E[X|Y]^2|Y] \\tag{$\\ast$} \\\\[0.5em] &amp;= \\E[X^2|Y] - 2\\E[X|Y]\\E[X|Y] + \\E[X|Y]^2 \\\\[0.5em] &amp;= \\E[X^2|Y] - \\E[X|Y]^2 \\end{align*}\\] In $(\\ast)$, remember that $\\E[X|Y]$ is a RV of $Y$. See above: . \\[\\begin{gather*} \\E[Xg(Y)|Y] = g(Y)\\E[X|Y] \\\\[0.5em] \\E[g(Y)|Y] = g(Y) \\end{gather*}\\] $$ \\begin{equation} \\tag{Law of total variance} \\Var(X) = \\E[\\Var(X|Y)] + \\Var(\\E[X|Y]) \\end{equation} $$ . Derivation \\[\\begin{align*} \\E[\\Var(X|Y)] &amp;= \\E[\\E[X^2|Y] - \\E[X|Y]^2] \\\\[0.5em] &amp;= \\E[\\E[X^2|Y]] - \\E[\\E[X|Y]^2] \\\\[0.5em] &amp;= \\E[X^2] - \\E[\\E[X|Y]^2] \\\\[0.5em] \\end{align*}\\] and, . \\[\\begin{align*} \\Var(\\E[X|Y]) &amp;= \\E[\\E[X|Y]^2] - \\E[\\E[X|Y]]^2 \\\\[0.5em] &amp;= \\E[\\E[X|Y]^2] - \\E[X]^2 \\end{align*}\\] Then, . \\[\\E[\\Var(X|Y)] + \\Var(\\E[X|Y]) = \\E[X^2] - \\E[X]^2 = \\Var(X)\\] . ",
    "url": "/docs/statistics/notes/properties-of-e-var.html#conditional-variance",
    
    "relUrl": "/docs/statistics/notes/properties-of-e-var.html#conditional-variance"
  },"1107": {
    "doc": "Properties of Expectation, Variance, and Covariance",
    "title": "Covariance",
    "content": "$$ \\begin{align*} \\Cov(X, Y) &amp;= \\E[(X - \\E[X])(Y - \\E[Y])] \\\\[0.5em] &amp;= \\E[XY] - \\E[X]\\E[Y] \\end{align*} $$ . ",
    "url": "/docs/statistics/notes/properties-of-e-var.html#covariance",
    
    "relUrl": "/docs/statistics/notes/properties-of-e-var.html#covariance"
  },"1108": {
    "doc": "pyenv",
    "title": "pyenv",
    "content": "Python version manager . GitHub . | What is pyenv | Installation | Typical usage | Basic commands . | Check activated Python version | List installed Python versions | List all available Python for install | Install a Python version | Uninstall a Python version | Show installed directory | Set Python version | Show Python binary | . | Uninstall pyenv . | Remove all shell startup configuration | Remove all Python versions | Remove pyenv | . | . ",
    "url": "/docs/python/envs/pyenv.html",
    
    "relUrl": "/docs/python/envs/pyenv.html"
  },"1109": {
    "doc": "pyenv",
    "title": "What is pyenv",
    "content": "pyenv is a version manager for Python. As it started off as a fork of rbenv, the syntax and usage are very similar. It is a Python version manager not a virtual environment manager. To manage a virtual environment for Python libraries, use in junction with venv, poetry, pipenv, etc. ",
    "url": "/docs/python/envs/pyenv.html#what-is-pyenv",
    
    "relUrl": "/docs/python/envs/pyenv.html#what-is-pyenv"
  },"1110": {
    "doc": "pyenv",
    "title": "Installation",
    "content": "Easiest way is to use Homebrew: . brew install pyenv . Then, . echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.zshrc echo '[[ -d $PYENV_ROOT/bin ]] &amp;&amp; export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.zshrc echo 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.zshrc . You could also add the above to .zprofile as well. Restart shell and install Python build dependencies: . brew install openssl readline sqlite3 xz zlib tcl-tk . ",
    "url": "/docs/python/envs/pyenv.html#installation",
    
    "relUrl": "/docs/python/envs/pyenv.html#installation"
  },"1111": {
    "doc": "pyenv",
    "title": "Typical usage",
    "content": "To install a specific Python version for a project, navigate to your project root and do: . pyenv intall -l # Decide a version number pyenv install -s 3.x.x # -s means skip installation if it already exists pyenv rehash # Makes all Python binaries available to system pyenv local 3.x.x # Make sure you're in project root . ",
    "url": "/docs/python/envs/pyenv.html#typical-usage",
    
    "relUrl": "/docs/python/envs/pyenv.html#typical-usage"
  },"1112": {
    "doc": "pyenv",
    "title": "Basic commands",
    "content": "Full commands are listed here . Check activated Python version . pyenv version . Do not confuse with below. Notice the plural. List installed Python versions . pyenv versions . List all available Python for install . pyenv install -l . Install a Python version . pyenv install 3.x.x pyenv rehash . Uninstall a Python version . pyenv uninstall 3.x.x . Show installed directory . pyenv prefix 3.x.x . Set Python version . pyenv global 3.x.x pyenv local 3.x.x . Show Python binary . pyenv which python3 . ",
    "url": "/docs/python/envs/pyenv.html#basic-commands",
    
    "relUrl": "/docs/python/envs/pyenv.html#basic-commands"
  },"1113": {
    "doc": "pyenv",
    "title": "Uninstall pyenv",
    "content": "Remove all shell startup configuration . Remove the following from .zprofile and .zshrc: . echo 'eval \"$(pyenv init --path)\"' echo 'eval \"$(pyenv init -)\"' . Remove all Python versions . rm -rf $(pyenv root) . Remove pyenv . brew uninstall pyenv . ",
    "url": "/docs/python/envs/pyenv.html#uninstall-pyenv",
    
    "relUrl": "/docs/python/envs/pyenv.html#uninstall-pyenv"
  },"1114": {
    "doc": "SQL Query Basics",
    "title": "SQL Query Basics",
    "content": "Examples are written with PostgreSQL dialect. | Overall Order of Clauses | SELECT Clause . | SELECT DISTINCT | . | Range Variables / Tuple Variables | Column Aliases . | Using Arithmetic Expressions as Column | . | LIMIT Clause | ORDER BY | WHERE Clause . | Comparison Operators | Logical Operators . | LIKE | ILIKE | REGEXP_LIKE | AND, OR, NOT | BETWEEN | IS NULL | . | . | Set Operators . | Set Comparison Operators . | IN / NOT IN | EXISTS / NOT EXISTS | ANY | ALL | . | . | Aggregate Functions | GROUP BY Clause . | HAVING Clause | Caveats with LIMIT | . | CASE Expressions . | With GROUP BY | In Aggregate Functions | . | . ",
    "url": "/docs/db/sql/query-basics.html",
    
    "relUrl": "/docs/db/sql/query-basics.html"
  },"1115": {
    "doc": "SQL Query Basics",
    "title": "Overall Order of Clauses",
    "content": "The overall clause order is: . | SELECT | FROM | WHERE | GROUP BY | HAVING | ORDER BY | LIMIT | . ",
    "url": "/docs/db/sql/query-basics.html#overall-order-of-clauses",
    
    "relUrl": "/docs/db/sql/query-basics.html#overall-order-of-clauses"
  },"1116": {
    "doc": "SQL Query Basics",
    "title": "SELECT Clause",
    "content": "SELECT target_list FROM relations WHERE qualification . ",
    "url": "/docs/db/sql/query-basics.html#select-clause",
    
    "relUrl": "/docs/db/sql/query-basics.html#select-clause"
  },"1117": {
    "doc": "SQL Query Basics",
    "title": "SELECT DISTINCT",
    "content": "SELECT DISTINCT release_year, rating FROM film; . When multiple columns are selected, SELECT DISTINCT applies across all those columns. SELECT DISTINCT does not rule out NULL value. It includes NULL value in the result set. ",
    "url": "/docs/db/sql/query-basics.html#select-distinct",
    
    "relUrl": "/docs/db/sql/query-basics.html#select-distinct"
  },"1118": {
    "doc": "SQL Query Basics",
    "title": "Range Variables / Tuple Variables",
    "content": "Basically, table aliases. It is optional in unambiguous situations, but considered good practice to use them. SELECT f.title FROM film AS f; . Also, AS is optional, but I prefer to use it for clarity: . SELECT f.title FROM film f; . ",
    "url": "/docs/db/sql/query-basics.html#range-variables--tuple-variables",
    
    "relUrl": "/docs/db/sql/query-basics.html#range-variables--tuple-variables"
  },"1119": {
    "doc": "SQL Query Basics",
    "title": "Column Aliases",
    "content": "SELECT DISTINCT release_year AS year, rating r FROM film; . Again, AS is optional. Aliasing with = Not many RDBMS support using assignment operator = for aliasing, but it is a thing… . SELECT year=release_year ... To use keywords, special characters, or whitespace in aliases, you need to enclose the alias in double quotes: . SELECT something AS \"this is a column\" . ",
    "url": "/docs/db/sql/query-basics.html#column-aliases",
    
    "relUrl": "/docs/db/sql/query-basics.html#column-aliases"
  },"1120": {
    "doc": "SQL Query Basics",
    "title": "Using Arithmetic Expressions as Column",
    "content": "SELECT length / 60 AS hours, length % 60 AS minutes FROM film; . ",
    "url": "/docs/db/sql/query-basics.html#using-arithmetic-expressions-as-column",
    
    "relUrl": "/docs/db/sql/query-basics.html#using-arithmetic-expressions-as-column"
  },"1121": {
    "doc": "SQL Query Basics",
    "title": "LIMIT Clause",
    "content": "SELECT title FROM film LIMIT 5; . ",
    "url": "/docs/db/sql/query-basics.html#limit-clause",
    
    "relUrl": "/docs/db/sql/query-basics.html#limit-clause"
  },"1122": {
    "doc": "SQL Query Basics",
    "title": "ORDER BY",
    "content": "SELECT title, length FROM film ORDER BY length DESC, title; . Ordered by length in descending order, then by title in ascending order. In PostgreSQL, default is ASC. You can actually use column numbers in ORDER BY: . SELECT title, length FROM film ORDER BY 2 DESC, 1 ASC; . These numbers refer to the order of columns in SELECT, starting from 1. When to use column numbers? It can make the query less readable, but it can be useful in situations where the column names are too verbose or subject to change. Technically, you should alias columns of complex expressions, but if you left them anonymous, you could use numbers. Example with CASE: . SELECT title, CASE WHEN length &gt;= 120 THEN 'LONG' ELSE 'SHORT' END FROM film ORDER BY 2; . Without the numbers and alias, you’d have to repeat the CASE expression. ",
    "url": "/docs/db/sql/query-basics.html#order-by",
    
    "relUrl": "/docs/db/sql/query-basics.html#order-by"
  },"1123": {
    "doc": "SQL Query Basics",
    "title": "WHERE Clause",
    "content": "Logic in SQL is actually three-valued: . | TRUE | FALSE | UNKNOWN | . The UNKNOWN value is returned when comparing or performing arithmetic operations with NULL. WHERE filters rows that do not evaluate to TRUE. So NULL values are also filtered out. ",
    "url": "/docs/db/sql/query-basics.html#where-clause",
    
    "relUrl": "/docs/db/sql/query-basics.html#where-clause"
  },"1124": {
    "doc": "SQL Query Basics",
    "title": "Comparison Operators",
    "content": ". | = Equal . SELECT title FROM film WHERE rating = 'PG-13'; . Use single quotes for text. | &lt;&gt; or != Not equal . SELECT title FROM film WHERE rating &lt;&gt; 'R'; . | &gt;, &gt;=, &lt;, &lt;= . SELECT title FROM film WHERE length &gt; 120; . With non-numeric data, comparison is lexicographical. | . ",
    "url": "/docs/db/sql/query-basics.html#comparison-operators",
    
    "relUrl": "/docs/db/sql/query-basics.html#comparison-operators"
  },"1125": {
    "doc": "SQL Query Basics",
    "title": "Logical Operators",
    "content": "LIKE . String matching with wildcards. | _ matches any single character. | % matches 0 or more arbitrary characters. | . SELECT title FROM film where title LIKE 'KI_________%'; . You can enforce certain number of characters with _. LIKE is case-sensitive in PostgreSQL. ILIKE . Case-insensitive version of LIKE. SELECT title FROM film WHERE title ILIKE 'ki_________%'; . REGEXP_LIKE . SELECT title FROM film WHERE REGEXP_LIKE(title, '[A-Z]') LIMIT 10; . AND, OR, NOT . SELECT title FROM film WHERE rating = 'PG-13' AND length &gt; 120; . NOT . | IS NOT NULL | NOT IN | NOT BETWEEN | NOT LIKE | . BETWEEN . SELECT title FROM film WHERE length BETWEEN 120 AND 150; . IS NULL . SELECT title FROM film WHERE original_language_id IS NULL; . ",
    "url": "/docs/db/sql/query-basics.html#logical-operators",
    
    "relUrl": "/docs/db/sql/query-basics.html#logical-operators"
  },"1126": {
    "doc": "SQL Query Basics",
    "title": "Set Operators",
    "content": "By default, set operators UNION, INTERSECT, and EXCEPT remove duplicates. UNION ALL, INTERSECT ALL, and EXCEPT ALL retain duplicates. SELECT cols FROM table1 UNION [UNION ALL / INTERSECT / INTERSECT ALL / EXCEPT / EXCEPT ALL] SELECT cols FROM table1 . The SELECT statements must be union-compatible. ",
    "url": "/docs/db/sql/query-basics.html#set-operators",
    
    "relUrl": "/docs/db/sql/query-basics.html#set-operators"
  },"1127": {
    "doc": "SQL Query Basics",
    "title": "Set Comparison Operators",
    "content": "IN / NOT IN . Unlike the other ones, you can use IN with an expression list: . SELECT title FROM film WHERE rating IN ('PG', 'PG-13'); . Or with a subquery like the others. EXISTS / NOT EXISTS . SELECT f.title FROM film AS f WHERE EXISTS ( SELECT * FROM language AS l WHERE l.language_id = f.language_id AND l.name = 'English' ); . This is an awkward example, but you get the idea. EXISTS returns TRUE if the subquery returns any rows. It is often used with correlated subqueries. By correlated, I mean the subquery refers to the relation in the outer query, which is f in this case. ANY . ANY is used with leading comparison operators: op ANY (= ANY, &lt;&gt; ANY, &lt;= ANY, etc.). The following uses = ANY: . SELECT length FROM film WHERE length = ANY ( SELECT length FROM film WHERE length = 60 OR length = 120 ); . Semantically, = ANY is equivalent to IN. However, you cannot use expression lists with = ANY. ALL . ALL is used with leading comparison operators: op ALL (= ALL, &lt;&gt; ALL, &lt;= ALL, etc.). The following uses &lt;&gt; ALL: . SELECT length FROM film WHERE length &lt;&gt; ALL ( SELECT length FROM film WHERE length = 60 OR length = 120 ); . Semantically, &lt;&gt; ALL is equivalent to NOT IN. However, you cannot use expression lists with &lt;&gt; ALL. ",
    "url": "/docs/db/sql/query-basics.html#set-comparison-operators",
    
    "relUrl": "/docs/db/sql/query-basics.html#set-comparison-operators"
  },"1128": {
    "doc": "SQL Query Basics",
    "title": "Aggregate Functions",
    "content": "You can only use aggregate functions in SELECT and HAVING clauses. Except for COUNT(*), aggregate functions ignore NULL values. Except for COUNT(*), aggregate functions take a single column. COUNT(*) / COUNT(col) / COUNT(DISTINCT col) SUM(col) / SUM(DISTINCT col) AVG(col) / AVG(DISTINCT col) MAX(col) MIN(col) . DISTINCT does not ignore NULL values, but the aggregate function does. ",
    "url": "/docs/db/sql/query-basics.html#aggregate-functions",
    
    "relUrl": "/docs/db/sql/query-basics.html#aggregate-functions"
  },"1129": {
    "doc": "SQL Query Basics",
    "title": "GROUP BY Clause",
    "content": "To use aggregate functions across only certain groups of rows, we use GROUP BY clause. SELECT rating, COUNT(title), AVG(length) from film GROUP BY rating; . | rating | count | avg | . | R | 195 | 118.6615384615384615 | . | PG | 194 | 112.0051546391752577 | . | G | 178 | 111.050561797752809 | . | PG-13 | 223 | 120.4439461883408072 | . | NC-17 | 210 | 113.2285714285714286 | . You can also group by multiple columns: . SELECT rating, category_id, COUNT(*) AS count FROM film JOIN film_category USING (film_id) GROUP BY rating, category_id; . GROUP BY col1, col2 means group rows by unique joints of col1 and col2. Which also means ordering of columns in GROUP BY does not matter, in terms of results (may or may not affect performance). If you specified two columns in GROUP BY, and each column has n and m unique values, the result will have n * m rows. Non-aggregated columns in SELECT must appear in GROUP BY. In this example, rating and category_id. Just like ORDER BY, you can use column numbers in GROUP BY. See Using Column Numbers. ",
    "url": "/docs/db/sql/query-basics.html#group-by-clause",
    
    "relUrl": "/docs/db/sql/query-basics.html#group-by-clause"
  },"1130": {
    "doc": "SQL Query Basics",
    "title": "HAVING Clause",
    "content": "WHERE filters rows before grouping, HAVING filters groups after grouping. SELECT rating, category_id, COUNT(*) AS count FROM film JOIN film_category USING (film_id) GROUP BY category_id, rating HAVING COUNT(*) &gt;= 15; . Other than aggregate functions, you can also have subqueries in HAVING clause. ",
    "url": "/docs/db/sql/query-basics.html#having-clause",
    
    "relUrl": "/docs/db/sql/query-basics.html#having-clause"
  },"1131": {
    "doc": "SQL Query Basics",
    "title": "Caveats with LIMIT",
    "content": "LIMIT is applied after GROUP BY and HAVING. So LIMIT is applied to the result set, after grouping, filtering, and aggregation. You should really think about whether you’d actually want to use LIMIT with GROUP BY, because it often doesn’t make sense. ",
    "url": "/docs/db/sql/query-basics.html#caveats-with-limit",
    
    "relUrl": "/docs/db/sql/query-basics.html#caveats-with-limit"
  },"1132": {
    "doc": "SQL Query Basics",
    "title": "CASE Expressions",
    "content": "Basic syntax: . CASE WHEN condition1 THEN true_case_1 WHEN condition2 THEN true_case_2 ... ELSE false_case END . In SELECT statement: . SELECT title, CASE WHEN length &gt;= 120 THEN 'LONG' ELSE 'SHORT' END AS is_long FROM film; . ",
    "url": "/docs/db/sql/query-basics.html#case-expressions",
    
    "relUrl": "/docs/db/sql/query-basics.html#case-expressions"
  },"1133": {
    "doc": "SQL Query Basics",
    "title": "With GROUP BY",
    "content": "You can use CASE expressions in GROUP BY to create custom groups; basically preprocess group labels to deal with NULL values, etc. before aggregation. SELECT CASE WHEN last_name LIKE 'A%' THEN 'A' WHEN last_name LIKE 'B%' THEN 'B' WHEN last_name LIKE 'C%' THEN 'C' ELSE 'Other' END AS last_name_starts_with, COUNT(*) AS actor_count FROM actor GROUP BY 1 ORDER BY 2; . ",
    "url": "/docs/db/sql/query-basics.html#with-group-by",
    
    "relUrl": "/docs/db/sql/query-basics.html#with-group-by"
  },"1134": {
    "doc": "SQL Query Basics",
    "title": "In Aggregate Functions",
    "content": "You can use CASE expressions in aggregate functions to filter or transform values before aggregation: . SELECT COUNT(CASE WHEN length &gt;= 120 THEN 1 ELSE NULL END) AS long_film_cnt FROM film; . Here we used the fact that aggregate functions except COUNT(*) ignore NULL values. ",
    "url": "/docs/db/sql/query-basics.html#in-aggregate-functions",
    
    "relUrl": "/docs/db/sql/query-basics.html#in-aggregate-functions"
  },"1135": {
    "doc": "Vue Quick Notes",
    "title": "Vue Quick Notes",
    "content": "Quick notes for dummies. Using &lt;script setup lang=\"ts\"&gt;. | Props . | To use props in child component . | Without default values | With default values | . | . | Ref / Reactive | Computed / Watch | Event / Emits . | To use emits | . | v-model . | Parent-Child usage example | . | Provide / Inject | Etc . | $keyword equivalent in the script tag | . | . ",
    "url": "/docs/vue/quick-notes.html",
    
    "relUrl": "/docs/vue/quick-notes.html"
  },"1136": {
    "doc": "Vue Quick Notes",
    "title": "Props",
    "content": ". | Props are reactive by default | You don’t explicitly import defineProps; it is a compiler macro for &lt;script setup&gt; | If you don’t pass optional props, they have a value of undefined | In the template, you can access the props without having to do props.someVarName, just use someVarName. | Even if you toRef a prop, they will not become a copy. If you modify the toRef-ed prop, it will affect the original. | . To use props in child component . Without default values . const props = defineProps&lt;{ a: string b: number }&gt;() . With default values . interface MyProps { a: strings b?: number } const props = withDefaults(defineProps&lt;MyProps&gt;(), { b: 0 }) . ",
    "url": "/docs/vue/quick-notes.html#props",
    
    "relUrl": "/docs/vue/quick-notes.html#props"
  },"1137": {
    "doc": "Vue Quick Notes",
    "title": "Ref / Reactive",
    "content": ". | You can use ref with primitive types like string and number but not with reactive | You access refs by refObj.value and reactives by reactiveObj | Everything that belonged in the data part before the Composition API should be wrapped with ref or reactive. (Unless they’re nonchanging in value.) | . ",
    "url": "/docs/vue/quick-notes.html#ref--reactive",
    
    "relUrl": "/docs/vue/quick-notes.html#ref--reactive"
  },"1138": {
    "doc": "Vue Quick Notes",
    "title": "Computed / Watch",
    "content": "See details here. | watch watches for a specific set of changes, and runs a function. | With watch you can also get the prev and new value. | You can watch ref like a normal variable, but you gotta use () =&gt; reactiveObj instead for reactive objects. | watchEffect watches for all change in every variable used in its function. | watchEffect is kinda more like computed except it’s purpose is not to to get or set a variable. | computed with a single arrow function creates a getter (so immutable). If you give it instead an object with get and set, it will be writable. | If you store watch and watchEffect in a variable named myVar for example, you can stop its watch behavior by calling myVar(). | There exists, onTrack and onTrigger for debugging. | . ",
    "url": "/docs/vue/quick-notes.html#computed--watch",
    
    "relUrl": "/docs/vue/quick-notes.html#computed--watch"
  },"1139": {
    "doc": "Vue Quick Notes",
    "title": "Event / Emits",
    "content": "To use emits . const emits = defineEmits&lt;{ (e: 'myEvent', valueImGivingBack: string): void }&gt;( // Then later function onEvent(e: Event) { const newVal = (e.target as HTMLTextAreaElement).value emits('myEvent', newVal) } . ",
    "url": "/docs/vue/quick-notes.html#event--emits",
    
    "relUrl": "/docs/vue/quick-notes.html#event--emits"
  },"1140": {
    "doc": "Vue Quick Notes",
    "title": "v-model",
    "content": ". | Syntax changed since Vue2, see here for details. | v-model is a syntactic sugar: you can always do the same thing with regular propping and emitting. | Basically, if you use the vanilla v-model as is, the name of the prop and the event will have to be modelValue and update:modelValue. | If you give it a name like v-model:childProp, it will be childProp and update:childProp. | You can use multiple v-models with a child component; just give it different names. | Remember, v-model needs to be used with ref or reactive variable | . Parent-Child usage example . // Parent.vue &lt;template&gt; &lt;Child v-model:childProp=\"parentVar\"&gt; &lt;/template&gt; &lt;script setup lang=\"ts\"&gt; const parentVar = ref('hey child') &lt;/script&gt; . // Child.vue &lt;template&gt; &lt;input @keyup.enter=\"onEnterPressed\"&gt; &lt;/template&gt; &lt;script setup lang=\"ts\"&gt; const defineProps&lt;{ childProp: string }&gt;() const emits = defineEmits&lt;{ (e: 'update:childProp', childProp: string): void }&gt;() function onEnterPressed(e: Event) { const someVal = 'sup' emits('update:childProp', someVal) } &lt;/script&gt; . ",
    "url": "/docs/vue/quick-notes.html#v-model",
    
    "relUrl": "/docs/vue/quick-notes.html#v-model"
  },"1141": {
    "doc": "Vue Quick Notes",
    "title": "Provide / Inject",
    "content": ". | To make typing work, you gotta use the InjectionKey&lt;T&gt;. See here for details. | To update provided reactive props, make the parent component provide mutation functions as well. Always recommended to have the root (providing) component to be in charge of mutations. | . ",
    "url": "/docs/vue/quick-notes.html#provide--inject",
    
    "relUrl": "/docs/vue/quick-notes.html#provide--inject"
  },"1142": {
    "doc": "Vue Quick Notes",
    "title": "Etc",
    "content": ". | You can use $event, $router, $route, $slots, $attrs, $emit in the template tag, but not in the script tag. | ref, reactive, toRef, toRefs, computed, watch, watchEffect are all in vue | attrs are basically all the stuff passed down to a child naturally from being an HTML element, but not actually a Vue prop. Ex) class | You can use the normal &lt;script&gt; tag along with the &lt;script setup&gt;. Two things you’ll have to do within the normal &lt;script&gt; tag is setting name and inheritAttrs. | . $keyword equivalent in the script tag . See here for details. But basically: . import { useSlots, useAttrs } from 'vue import { useRouter, useRoute } from 'vue-router' const slots = useSlots() const attrs = useAttrs() const router = useRouter() const route = useRoute() . ",
    "url": "/docs/vue/quick-notes.html#etc",
    
    "relUrl": "/docs/vue/quick-notes.html#etc"
  },"1143": {
    "doc": "R-Squared",
    "title": "R-Squared",
    "content": ". | Coefficient of Determination $R^2$ . | Explained Variation | Interpretation | Relationship with Correlation | . | Adjusted $R^2$ . | The issue with regular $R^2$ | Adjustment | . | . ",
    "url": "/docs/data-science/ml-dl/r-squared.html",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html"
  },"1144": {
    "doc": "R-Squared",
    "title": "Coefficient of Determination $R^2$",
    "content": "Coefficient of determination ($R^2$) is a statistical measure of how well the model captures the variation in the dependent variable. So essentially, goodness of fit. To understand $R^2$, we need to refer back to sum of squares. ",
    "url": "/docs/data-science/ml-dl/r-squared.html#coefficient-of-determination-r2",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#coefficient-of-determination-r2"
  },"1145": {
    "doc": "R-Squared",
    "title": "Explained Variation",
    "content": "In cases like linear regression with OLS, we have seen that the following decomposition is true: . \\[SS_{tot} = SS_{exp} + SS_{res}\\] Since we want to know how much of the variation is explained by the model, we solve for the proportion of the explained variation among the total variation. \\[\\frac{SS_{exp}}{SS_{tot}} = \\frac{SS_{tot} - SS_{res}}{SS_{tot}} = 1 - \\frac{SS_{res}}{SS_{tot}}\\] This is the definition of $R^2$. $$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} $$ . ",
    "url": "/docs/data-science/ml-dl/r-squared.html#explained-variation",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#explained-variation"
  },"1146": {
    "doc": "R-Squared",
    "title": "Interpretation",
    "content": "If the model captures all the variation in the dependent variable, the variation caused by error ($SS_{res}$) is zero, which would make $R^2$ equal to 1. This indicates that the model perfectly fits the data. The baseline model, which is just the mean of the dependent variable, results in $R^2$ equal to 0. Any model that performs worse than the baseline model will have a negative $R^2$. $$ \\begin{align*} R^2 = 1 &amp;\\Rightarrow \\text{perfect fit} \\\\[0.5em] R^2 = 0 &amp;\\Rightarrow \\text{baseline model} \\\\[0.5em] R^2 &lt; 0 &amp;\\Rightarrow \\text{worse than baseline model} \\end{align*} $$ . So generally, the higher the $R^2$ the better the model fits the data. Anything below 0 means you should really reconsider your model or check if you have a mistake, because you’re doing worse than the bare minimum which is just always predicting the mean. Just because a model has a high $R^2$ doesn’t mean it’s a good model. $R^2$ is not a good measure for non-linear models, because the sum of squares decomposition doesn’t hold for them. ",
    "url": "/docs/data-science/ml-dl/r-squared.html#interpretation",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#interpretation"
  },"1147": {
    "doc": "R-Squared",
    "title": "Relationship with Correlation",
    "content": "Review correlation from here. The Pearson’s correlation coefficient $r$ is basically the covariance of $X$ and $Y$ fit into a scale of $[-1, 1]$. For simple linear regression models, $R^2 = r^2$. ",
    "url": "/docs/data-science/ml-dl/r-squared.html#relationship-with-correlation",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#relationship-with-correlation"
  },"1148": {
    "doc": "R-Squared",
    "title": "Adjusted $R^2$",
    "content": " ",
    "url": "/docs/data-science/ml-dl/r-squared.html#adjusted-r2",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#adjusted-r2"
  },"1149": {
    "doc": "R-Squared",
    "title": "The issue with regular $R^2$",
    "content": "When you add more predictors/features to your model, $R^2$ will always increase. This is because as your model gets more complex, the $SS_{tot}$ stays the same, . Remember $SS_{tot}$ has nothing to do with the model, but only the data. but $SS_{res}$ can only decrease (to be more precise, it does not increase). Intuition Think of what it means to increase the complexity of the model. You had just a rigid line to fit your model before, but now you’ve added some features in so that it’s more flexible to fit a more complex curve. You should have been able to decrease your error squares, so $SS_{res}$ should have decreased. This results in multiple issues: . | $R^2$ is a positively biased estimator (always overshoots) | Bias towards complex models | Overfitting | . ",
    "url": "/docs/data-science/ml-dl/r-squared.html#the-issue-with-regular-r2",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#the-issue-with-regular-r2"
  },"1150": {
    "doc": "R-Squared",
    "title": "Adjustment",
    "content": "To account for the bias, we penalize the $R^2$ by the number of predictors $k$ used in the model. The penalty is defined as: . \\[\\frac{n - 1}{n - k - 1}\\] where $n$ is the sample size. Notice that the penalty is 1 when $k = 0$, and it increases as $k$ increases. Remembering that $R^2$ is defined as: . \\[R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\\] We can penalize $R^2$ by bumping up the subtracted term with the penalty: . \\[\\frac{SS_{res}}{SS_{tot}} \\times \\frac{n-1}{n-k-1}\\] Through substitution, we get the definition for adjusted $R^2$: . $$ R^2_{adj} = 1 - (1 - R^2) \\cdot \\frac{n-1}{n-k-1} $$ . ",
    "url": "/docs/data-science/ml-dl/r-squared.html#adjustment",
    
    "relUrl": "/docs/data-science/ml-dl/r-squared.html#adjustment"
  },"1151": {
    "doc": "Setup R & R Markdown",
    "title": "Setup R &amp; R Markdown",
    "content": ". | Installation . | Install R Markdown | . | Set Up in VS Code . | R Extensions | Useful User Settings | . | Tidyverse | . ",
    "url": "/docs/data-science/r/r-vscode.html#setup-r--r-markdown",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#setup-r--r-markdown"
  },"1152": {
    "doc": "Setup R & R Markdown",
    "title": "Installation",
    "content": "With homebrew: . brew install r brew install pandoc . pandoc is required to render R Markdown. ",
    "url": "/docs/data-science/r/r-vscode.html#installation",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#installation"
  },"1153": {
    "doc": "Setup R & R Markdown",
    "title": "Install R Markdown",
    "content": "Open R in terminal: . &gt; R . Capital R. Install rmarkdown package: . install.packages(\"rmarkdown\") . ",
    "url": "/docs/data-science/r/r-vscode.html#install-r-markdown",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#install-r-markdown"
  },"1154": {
    "doc": "Setup R & R Markdown",
    "title": "Set Up in VS Code",
    "content": "For more details, refer to this document. ",
    "url": "/docs/data-science/r/r-vscode.html#set-up-in-vs-code",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#set-up-in-vs-code"
  },"1155": {
    "doc": "Setup R & R Markdown",
    "title": "R Extensions",
    "content": "Install extensions in VS Code. Extension IDs: . REditorSupport.r ms-vscode.live-server . ms-vscode.live-server is to enable live preview of R Markdown. ",
    "url": "/docs/data-science/r/r-vscode.html#r-extensions",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#r-extensions"
  },"1156": {
    "doc": "Setup R & R Markdown",
    "title": "Useful User Settings",
    "content": "... \"[r]\": { \"editor.defaultFormatter\": \"REditorSupport.r\", \"editor.formatOnSave\": true }, \"[rmd]\": { \"editor.defaultFormatter\": \"REditorSupport.r\", \"editor.formatOnSave\": true }, \"r.rmarkdown.preview.autoRefresh\": true, ... ",
    "url": "/docs/data-science/r/r-vscode.html#useful-user-settings",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#useful-user-settings"
  },"1157": {
    "doc": "Setup R & R Markdown",
    "title": "Tidyverse",
    "content": "brew install harfbuzz fribidi # Needed for textshaping package R &gt; install.packages(\"tidyverse\") . ",
    "url": "/docs/data-science/r/r-vscode.html#tidyverse",
    
    "relUrl": "/docs/data-science/r/r-vscode.html#tidyverse"
  },"1158": {
    "doc": "Setup R & R Markdown",
    "title": "Setup R & R Markdown",
    "content": " ",
    "url": "/docs/data-science/r/r-vscode.html",
    
    "relUrl": "/docs/data-science/r/r-vscode.html"
  },"1159": {
    "doc": "Random Forest",
    "title": "Random Forest",
    "content": "Random forest is an ensemble learning that combines several decision trees to mitigate overfitting and reduce the variance of the model. | Ensemble Methods | Procedure . | Bootstrap Sampling | Tree Building | Aggregating | . | Measuring the Importance of Predictors | Drawbacks | . ",
    "url": "/docs/data-science/ml-dl/random-forest.html",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html"
  },"1160": {
    "doc": "Random Forest",
    "title": "Ensemble Methods",
    "content": "As described above, decision trees tend to overfit and are unstable upon slightly varying data. To mitigate these issues, random forest utilizes two ensemble methods: . | Bootstrap aggregating (bagging) | Random subspace method | . We know that an ensemble reduces the variance of the estimator by averaging over multiple samples. However, unlike the idealistic case where the samples are independent, bagging is an ensemble over highly-correlated bootstrap samples, which increases variance when averaging. So we combine random subspace method to reduce the correlation between ensembled trees. Hyperparameters would be the number of trees $B$ and the number of features to use for each tree $m &lt; p$. ",
    "url": "/docs/data-science/ml-dl/random-forest.html#ensemble-methods",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#ensemble-methods"
  },"1161": {
    "doc": "Random Forest",
    "title": "Procedure",
    "content": " ",
    "url": "/docs/data-science/ml-dl/random-forest.html#procedure",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#procedure"
  },"1162": {
    "doc": "Random Forest",
    "title": "Bootstrap Sampling",
    "content": ". | Generate $B$ bootstrap samples from the original data set: $Z^{*b}$. | . ",
    "url": "/docs/data-science/ml-dl/random-forest.html#bootstrap-sampling",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#bootstrap-sampling"
  },"1163": {
    "doc": "Random Forest",
    "title": "Tree Building",
    "content": ". | Train a decision tree on each of the $B$ bootstrap samples | When training each tree, for every split, randomly select $m &lt; p$ candidate features from the total $p$ features. Usually $m \\approx \\sqrt{p}$. These candidates are newly selected for each split. This is why there is not much of a accuracy drop compared to when we select from the full $p$. | Select the (greedy) best split from the $m$ features. | . Pruning is unnecessary in random forests, because bagging and random subspacing already mitigate overfitting. ",
    "url": "/docs/data-science/ml-dl/random-forest.html#tree-building",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#tree-building"
  },"1164": {
    "doc": "Random Forest",
    "title": "Aggregating",
    "content": "Prediction is averaged over the $B$ trees. ",
    "url": "/docs/data-science/ml-dl/random-forest.html#aggregating",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#aggregating"
  },"1165": {
    "doc": "Random Forest",
    "title": "Measuring the Importance of Predictors",
    "content": "In regular decision trees, we can measure the importance of predictors by the order in which they are selected for splitting. But in random forests or bagged trees (one with no random subspacing), we don’t have an explicit tree, we just know the average prediction. When training each tree, we greedily minimize either RSS for regression or Gini impurity (entropy, etc.) for classification on each split. For each predictor, when we branch on it, we keep a sum of the decrease in RSS or Gini impurity resulting from that split. Then we average over all $B$ trees to get the importance of each predictor. FYI, you cannot do this for boosted trees. ",
    "url": "/docs/data-science/ml-dl/random-forest.html#measuring-the-importance-of-predictors",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#measuring-the-importance-of-predictors"
  },"1166": {
    "doc": "Random Forest",
    "title": "Drawbacks",
    "content": ". | We lose interpretability, which is a strength of decision trees. | Obviously, it’s computationally expensive. | But not really a problem these days. | . | . ",
    "url": "/docs/data-science/ml-dl/random-forest.html#drawbacks",
    
    "relUrl": "/docs/data-science/ml-dl/random-forest.html#drawbacks"
  },"1167": {
    "doc": "Regression",
    "title": "Regression",
    "content": ". | Regression Function | . ",
    "url": "/docs/data-science/ml-dl/regression-function.html",
    
    "relUrl": "/docs/data-science/ml-dl/regression-function.html"
  },"1168": {
    "doc": "Regression",
    "title": "Regression Function",
    "content": "We define models as functions that map inputs to outputs: . \\[Y = f(X) + \\epsilon\\] An observation is often a pair of response and predictor: . \\[(X, Y)\\] For given $X = x$, the realization of $Y$ may not be unique (people with same weight can have different heights). Then what should our model $f$ spit out? We’ll say ideally: . $$ f(x) = \\E[Y | X=x] $$ . A regression function $f(x) = \\E[Y | X=x]$ is one that minimizes $\\E[(Y - f(X))^2 | X=x]$ (MSE) . Why do we use mean squared error? There are few reasons to why squared error is beneficial: . | It is differentiable everywhere | It explodes penalties for large errors | It handles both negative and positive errors | . We do not know the true model $f$. Therefore, we use an estimate $\\hat{f}$: . $$ \\begin{align*} \\E[(Y - \\hat{f}(X))^2 | X=x] &amp;= \\E[(f(X) + \\epsilon - \\hat{f}(X))^2 | X=x] \\\\[1em] &amp;= [f(x) - \\hat{f}(x)]^2 + \\Var(\\epsilon) \\end{align*} $$ . Derivation First remember that $\\E[\\epsilon] = 0$ and that $\\epsilon$ is independent of $X$. \\[\\begin{align*} &amp;\\E[(f(X) + \\epsilon - \\hat{f}(X))^2 | X=x] \\\\[0.5em] =\\; &amp;\\E[(f(X) - \\hat{f}(X))^2 + 2\\epsilon(f(X) - \\hat{f}(X)) + \\epsilon^2 | X=x] \\\\[0.5em] =\\; &amp;(f(x) - \\hat{f}(x))^2 + 2(f(x) - \\hat{f}(x))\\E[\\epsilon | X=x] + \\E[\\epsilon^2 | X=x] \\end{align*}\\] We know that $\\E[\\epsilon | X = x] = \\E[\\epsilon] = 0$ and: . \\[\\E[\\epsilon^2 | X = x] = \\E[\\epsilon^2] = \\E[\\epsilon^2] - \\E[\\epsilon]^2 = \\Var(\\epsilon)\\] The first part: . \\[[f(x) - \\hat{f}(x)]^2\\] is called the reducible error and the second part: . \\[\\Var(\\epsilon)\\] is, of course, the irreducible error. So the goal of regression is to estimate $f$ while minimizing the reducible error. ",
    "url": "/docs/data-science/ml-dl/regression-function.html#regression-function",
    
    "relUrl": "/docs/data-science/ml-dl/regression-function.html#regression-function"
  },"1169": {
    "doc": "Regression",
    "title": "Regression",
    "content": ". | Regression Function | Linear Regression | OLS | R-Squared | Prediction . | Variance of Prediction | Prediction Interval | . | . ",
    "url": "/docs/statistics/notes/regression.html",
    
    "relUrl": "/docs/statistics/notes/regression.html"
  },"1170": {
    "doc": "Regression",
    "title": "Regression Function",
    "content": "Let $Y$ be the response variable and $X$ be the predictor variable. The regression function $r(x)$ is: . $$ r(x) = E(Y | X = x) = \\int y f(y | x) dy $$ . The goal of regression is to estimate $r(x)$ from the data $(X_1, Y_1), \\dots, (X_n, Y_n)$. ",
    "url": "/docs/statistics/notes/regression.html#regression-function",
    
    "relUrl": "/docs/statistics/notes/regression.html#regression-function"
  },"1171": {
    "doc": "Regression",
    "title": "Linear Regression",
    "content": "See here . ",
    "url": "/docs/statistics/notes/regression.html#linear-regression",
    
    "relUrl": "/docs/statistics/notes/regression.html#linear-regression"
  },"1172": {
    "doc": "Regression",
    "title": "OLS",
    "content": "See here . ",
    "url": "/docs/statistics/notes/regression.html#ols",
    
    "relUrl": "/docs/statistics/notes/regression.html#ols"
  },"1173": {
    "doc": "Regression",
    "title": "R-Squared",
    "content": "See here . ",
    "url": "/docs/statistics/notes/regression.html#r-squared",
    
    "relUrl": "/docs/statistics/notes/regression.html#r-squared"
  },"1174": {
    "doc": "Regression",
    "title": "Prediction",
    "content": "Let $x^\\ast$ be a new observation. For a simple linear regression model, the prediction is: . $$ \\hat{Y}^\\ast = \\hat{\\beta}_0 + \\hat{\\beta}_1 x^\\ast $$ . ",
    "url": "/docs/statistics/notes/regression.html#prediction",
    
    "relUrl": "/docs/statistics/notes/regression.html#prediction"
  },"1175": {
    "doc": "Regression",
    "title": "Variance of Prediction",
    "content": "Variance of $\\hat{Y}^\\ast$ is a variance of a sum of two estimators $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$. Using the properties of variance, . $$ \\Var(\\hat{Y}^\\ast) = \\Var(\\hat{\\beta}_0) + x^{\\ast 2} \\Var(\\hat{\\beta}_1) + 2 x^\\ast \\Cov(\\hat{\\beta}_0, \\hat{\\beta}_1) $$ . ",
    "url": "/docs/statistics/notes/regression.html#variance-of-prediction",
    
    "relUrl": "/docs/statistics/notes/regression.html#variance-of-prediction"
  },"1176": {
    "doc": "Regression",
    "title": "Prediction Interval",
    "content": "In the prediction above, the error term is ommitted. However, when we construct the prediction interval, we consider the variance of the error term as well: . \\[\\hat{\\mathcal{E}}^2 = \\Var(\\hat{Y}^\\ast) + \\Var(\\varepsilon) = \\Var(\\hat{Y}^\\ast) + \\sigma^2\\] The prediction interval is: . $$ \\hat{Y}^\\ast \\pm z_{\\alpha/2}\\, \\hat{\\mathcal{E}} $$ . ",
    "url": "/docs/statistics/notes/regression.html#prediction-interval",
    
    "relUrl": "/docs/statistics/notes/regression.html#prediction-interval"
  },"1177": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "Regular Expression Matching",
    "content": ". | Problem | Using recursion . | Recursive solution | . | Using dynamic programming . | DP solution | . | . ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html#regular-expression-matching",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html#regular-expression-matching"
  },"1178": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "Problem",
    "content": "Given an input string s and a pattern p, implement regular expression matching with support for . and * where: . | . Matches any single character.​​​​ | * Matches zero or more of the preceding element. | . The matching should cover the entire input string (not partial). Input: s = \"aa\", p = \"a\" Output: false . Input: s = \"aa\", p = \"a*\" Output: true . Input: s = \"ab\", p = \".*\" Output: true . ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html#problem"
  },"1179": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "Using recursion",
    "content": "The key thing to first note is that the * character is a wildcard that can match zero or more of the preceding character. This means even when s is empty, it can still match p. So when do we know whether s and p match? . The base case is when p is empty. | If p is empty and s is empty, then they match. | If p is empty and s is not empty, then they don’t match. | . If p is not empty, we need to see if the next pattern is an x*: . x is any character. | p[1] == '*' ? | . If the next pattern is not an x*, then we just need to see if the current characters match: . Let’s call this isFirstMatch: . isFirstMatch = !s.isEmpty() &amp;&amp; s[0] == p[0] || p[0] == '.' . However, if the next pattern is an x*, then we have two additional scenarios to consider: . | The * matches zero characters, so we skip this pattern (advance p by 2). | The * matches the current character (isFirstMatch), so we advance s by one character and p stays with the pattern. | . ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html#using-recursion",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html#using-recursion"
  },"1180": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "Recursive solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 . | public boolean isMatch(String s, String p) { // Base case if (p.isEmpty()) return s.isEmpty(); boolean isFirstMatch; if (s.isEmpty()) isFirstMatch = false; else { Character cs = s.charAt(0); Character cp = p.charAt(0); isFirstMatch = cs.equals(cp) || cp.equals('.'); } // Are we in a '*' pattern? if (p.length() &gt; 1) { Character cp2 = p.charAt(1); if (cp2.equals('*')) { boolean noMatch = isMatch(s, p.substring(2)); boolean yesMatch = isFirstMatch &amp;&amp; isMatch(s.substring(1), p); return noMatch || yesMatch; } } // Not in a '*' pattern return isFirstMatch &amp;&amp; isMatch(s.substring(1), p.substring(1)); } . | . This solution is $O(2^n)$. ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html#recursive-solution",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html#recursive-solution"
  },"1181": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "Using dynamic programming",
    "content": "It is easy to see that in order to check whether s and p match, the previous parts of s and p must match. Since having a solution for the subproblem helps us solve the bigger problem, we can use dynamic programming. Let M where M[i][j] is true if s[0:i] and p[0:j] match. M is s.length() + 1 by p.length() + 1 because we need to account for the empty string. There are two base cases: . | As seen in the recursive solution, if p is empty, then s must also be empty for them to match. Hence, only M[0][0] = true in the first column. | If s is empty, then p must be empty or have a * pattern with zero matches. Hence, M[0][j] = true if p[j - 1] == '*' &amp;&amp; M[i][j - 2]. | . Then we can fill in the rest of the table by: . | If we are not in a * pattern, then we can just check if the current characters match (or .) and if the previous parts of s and p match. | If we are in a * pattern, then we need to check if s matches the previous character in p via * or if it was a zero match case. | . ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html#using-dynamic-programming",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html#using-dynamic-programming"
  },"1182": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "DP solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 . | public static boolean isMatch(String s, String p) { int n = s.length(); int m = p.length(); // Additional row and column for empty string boolean[][] M = new boolean[n + 1][m + 1]; // Rest of the first column is already false M[0][0] = true; // Base case for when s is empty for (int j = 1; j &lt; m + 1; j++) { Character pc = p.charAt(j - 1); M[0][j] = pc.equals('*') &amp;&amp; M[0][j - 2]; } for (int i = 1; i &lt; n + 1; i++) { // Current character of s Character sc = s.charAt(i - 1); for (int j = 1; j &lt; m + 1; j++) { // Current character of p Character pc = p.charAt(j - 1); boolean isFirstMatch; // Are we in a '*' pattern? if (pc.equals('*')) { // Previous character of p Character pcp = p.charAt(j - 2); // Current character of s matches previous character of p isFirstMatch = sc.equals(pcp) || pcp.equals('.'); // Zero match, pretend it doesn't exist // As long as the previous parts before '*' pattern matches we're good boolean noMatch = M[i][j - 2]; // There was a match, so check if this wildcard match was valid previously boolean yesMatch = isFirstMatch &amp;&amp; M[i - 1][j]; M[i][j] = noMatch || yesMatch; } else { // Not in a '*' pattern // Check if current characters match and previous parts match isFirstMatch = sc.equals(pc) || pc.equals('.'); M[i][j] = isFirstMatch &amp;&amp; M[i - 1][j - 1]; } } } return M[n][m]; } . | . This solution is $O(nm)$. ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html#dp-solution",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html#dp-solution"
  },"1183": {
    "doc": "10 - Regular Expression Matching - Hard",
    "title": "10 - Regular Expression Matching - Hard",
    "content": " ",
    "url": "/docs/compsci/leetcode/regular-expression-matching.html",
    
    "relUrl": "/docs/compsci/leetcode/regular-expression-matching.html"
  },"1184": {
    "doc": "Regularization",
    "title": "Regularization",
    "content": "Feature selection methods try to reduce variance and avoid overfitting by selecting a subset of predictors. Regularization methods keep all predictors in the model, but reduce variance by shrinking the coefficients towards zero. | Shrinkage Methods | Ridge Regression . | Tuning Parameter $\\lambda$ | Cross-Validation for $\\lambda$ | . | Regularization is NOT Scale Equivariant | Lasso Regression . | Difference from Ridge | . | . ",
    "url": "/docs/data-science/ml-dl/regularization.html",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html"
  },"1185": {
    "doc": "Regularization",
    "title": "Shrinkage Methods",
    "content": "Compared to subset selection methods which select a subset of predictors, shrinkage methods or regularization methods keep all predictors, but try to shrink the coefficients towards zero. Shrinking coefficients can significantly reduce the variance of the model. Why does shrinkage reduce variance? In regression, we try to estimate the coefficients $\\beta$. Shrinking the coefficients means we’re forcing our estimates to be closer to zero. Then we are introducing or adding bias to our estimates. Recall back to the bias-variance tradeoff: Increasing bias reduces variance. Regularized OLS is more rigid than regular OLS, hence the increased bias with reduced variance. ",
    "url": "/docs/data-science/ml-dl/regularization.html#shrinkage-methods",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#shrinkage-methods"
  },"1186": {
    "doc": "Regularization",
    "title": "Ridge Regression",
    "content": "Examples are explained in the context of OLS, but it can be generalized to other regression models. OLS’s objective is to minimize the residual sum of squares (RSS). Now we add an additional penalty term to the objective to control the magnitude of the coefficients: . $$ \\min_{\\beta} \\left\\{ \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - x_i^\\top \\beta \\right)^2 + \\lambda \\lVert \\beta \\rVert_2^2 \\right\\} $$ . Where the first part is just the RSS, and the second part is the shrinkage penalty and $\\lambda \\geq 0$ is the tuning parameter. The intercept $\\beta_0$ is usually not penalized, i.e. not included in the penalty term. Shrinkage Penalty of Ridge Shrinkage penalty of ridge relies on the squared L2-norm of the coefficient vector $\\beta$: . \\[\\lVert \\beta \\rVert_2^2 = \\sum_{j=1}^{p} \\beta_j^2\\] Some texts denote regularized coeffficents as: . $$ \\hat{\\beta}_{j,\\lambda}^{R} $$ . ",
    "url": "/docs/data-science/ml-dl/regularization.html#ridge-regression",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#ridge-regression"
  },"1187": {
    "doc": "Regularization",
    "title": "Tuning Parameter $\\lambda$",
    "content": "As $\\lambda$ increases, we impose a larger penalty on the size of the coefficients, making the model more rigid and forces coefficients to shrink more towards zero: . \\[\\lambda \\to \\infty \\implies \\hat{\\beta} \\to \\boldsymbol{0}\\] Then we are left with the mean baseline model, or the intercept $\\beta_0$. In the figure above, notice how each predictor’s standardized (why?) coefficient converges towards zero as $\\lambda$ increases. However, in reality, we cannot make $\\lambda$ infinitely large. So we never get a model with all coefficients exactly zero. In addition, no coefficient $\\beta_j$ becomes exactly zero in the ridge regression model. This is not the case for Lasso regression. See details in the later sections. On the other hand, if $\\lambda = 0$, there is no regularization and we get back OLS estimates. ",
    "url": "/docs/data-science/ml-dl/regularization.html#tuning-parameter-lambda",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#tuning-parameter-lambda"
  },"1188": {
    "doc": "Regularization",
    "title": "Cross-Validation for $\\lambda$",
    "content": "In the figure above: . | Pink: MSE | Green: variance | Black: bias squared | . Regularization reduces variance and thus lowers the MSE up to a certain point (MSE is lowest near the middle, lower than when $\\lambda = 0$). However, as $\\lambda$ increases further, the bias shoots up and MSE increases. Therefore, we need to find the optimal $\\lambda$. We usually do this by cross-validation. We would create folds and hold out a validation set, then for each $\\lambda$ value, we perform cross-validation to estimate the test error and select the $\\lambda$ that minimizes the test error. ",
    "url": "/docs/data-science/ml-dl/regularization.html#cross-validation-for-lambda",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#cross-validation-for-lambda"
  },"1189": {
    "doc": "Regularization",
    "title": "Regularization is NOT Scale Equivariant",
    "content": "OLS estimates are scale equivariant. Multiplying a predictor by a constant $c$ only scales the coefficient by $1/c$, and thus: . \\[c X_j \\cdot \\frac{\\hat{\\beta}_j}{c} = X_j \\hat{\\beta}_j\\] Therefore, our predictions remain the same. However, regularization methods, such as ridge and lasso, are not scale equivariant. The unit of measurement of the predictors affects the coefficients, so whether you use 1 kilometer or 1000 meters matters. Therefore, it is important to standardize the predictors before you apply regularization: . \\[\\tilde{X}_j = \\frac{X_j}{\\text{SD}(X_j)}\\] Dividing each predictor by its sample standard deviation. ",
    "url": "/docs/data-science/ml-dl/regularization.html#regularization-is-not-scale-equivariant",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#regularization-is-not-scale-equivariant"
  },"1190": {
    "doc": "Regularization",
    "title": "Lasso Regression",
    "content": "Again, examples are explained in the context of OLS, but it can be generalized to other regression models. Unlike ridge regression, we use the L1-norm of the coefficient vector $\\beta$ as the penalty term: . $$ \\min_{\\beta} \\left\\{ \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - x_i^\\top \\beta \\right)^2 + \\lambda \\lVert \\beta \\rVert_1 \\right\\} $$ . Again, with the tuning parameter $\\lambda \\geq 0$. Shrinkage Penalty of Lasso Shrinkage penalty of lasso relies on the L1-norm of the coefficient vector $\\beta$: . \\[\\lVert \\beta \\rVert_1 = \\sum_{j=1}^{p} \\lvert \\beta_j \\rvert\\] Similarly, some texts denote lasso regularized coeffficents as: . $$ \\hat{\\beta}_{j,\\lambda}^{L} $$ . ",
    "url": "/docs/data-science/ml-dl/regularization.html#lasso-regression",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#lasso-regression"
  },"1191": {
    "doc": "Regularization",
    "title": "Difference from Ridge",
    "content": "We mentioned above that no coefficient $\\beta_j$ becomes exactly zero in the ridge regression model. However, in the lasso regression model, coefficients can be exactly zero. This has the effect of subset selection, because the influence of some predictors is completely removed from the model. You should not be refitting the model with the non-zero predictors. Doing so would be a type of data leakage. The regularized coefficients are the final estimates. Our objective function is represented by the red level curves. The first green diamond is our L1 constraint and the second is our L2 constraint: . \\[\\lVert \\beta \\rVert_1 \\leq s \\quad \\text{and} \\quad \\lVert \\beta \\rVert_2^2 \\leq t\\] From lagrange multipliers, we know that the optimal minimum occurs when the level curves are tangent to the constraint region. In Lasso, $\\hat{\\beta}$ has the potential to hit the upper corner of the constraint where (in this example) $\\beta_1 = 0$. However, that is not the case for Ridge. ",
    "url": "/docs/data-science/ml-dl/regularization.html#difference-from-ridge",
    
    "relUrl": "/docs/data-science/ml-dl/regularization.html#difference-from-ridge"
  },"1192": {
    "doc": "Resampling Methods",
    "title": "Resampling Methods",
    "content": "Two common resampling methods: . | Cross-validation: to estimate the test error of a model. | Bootstrap: to estimate the uncertainty of an estimator. | . Resampling methods tend to be computationally expensive (typically not an issue these days), but they are very useful in practice. | Cross-Validation | Bootstrap | . ",
    "url": "/docs/data-science/ml-dl/resampling.html",
    
    "relUrl": "/docs/data-science/ml-dl/resampling.html"
  },"1193": {
    "doc": "Resampling Methods",
    "title": "Cross-Validation",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/resampling.html#cross-validation",
    
    "relUrl": "/docs/data-science/ml-dl/resampling.html#cross-validation"
  },"1194": {
    "doc": "Resampling Methods",
    "title": "Bootstrap",
    "content": "See details here . Short Summary: . This method is most commonly used to estimate the uncertainty of an estimator (e.g. standard error of an estimator). Unlike cross-validation, we sample with replacement to create multiple datasets, each dataset possibly containing the same data point multiple times. With the diagram above, . | We have an original dataset $|Z| = n$ | Bootstrap samples $Z^{\\ast r}$ where $r \\in \\{1, \\dots, B\\}$ are . $B$ is usually a large number . | Sampled with replacement (duplicates exist in each sample) | Same size as the original dataset $n$ | . | Bootstrap estimates $\\hat{\\alpha}^{\\ast r}$ are calculated from each sample | . Then we can estimate the standard error of the estimator $\\hat{\\alpha}$: . $$ \\text{SE}(\\hat{\\alpha}) = \\sqrt{ \\frac{1}{B-1} \\sum_{r=1}^B \\left( \\hat{\\alpha}^{\\ast r} - \\frac{1}{B} \\sum_{r'=1}^B \\hat{\\alpha}^{\\ast r'} \\right)^2 } $$ . ",
    "url": "/docs/data-science/ml-dl/resampling.html#bootstrap",
    
    "relUrl": "/docs/data-science/ml-dl/resampling.html#bootstrap"
  },"1195": {
    "doc": "7 - Reverse Integer - Medium",
    "title": "Reverse Integer",
    "content": ". | Problem | Explanation | Solution | . ",
    "url": "/docs/compsci/leetcode/reverse-integer.html#reverse-integer",
    
    "relUrl": "/docs/compsci/leetcode/reverse-integer.html#reverse-integer"
  },"1196": {
    "doc": "7 - Reverse Integer - Medium",
    "title": "Problem",
    "content": "Given a signed 32-bit integer x, return x with its digits reversed. If reversing x causes the value to go outside the signed 32-bit integer range [-2^31, 2^31 - 1], then return 0. Assume the environment does not allow you to store 64-bit integers (signed or unsigned). Input: x = 123 Output: 321 . Input: x = -123 Output: -321 . Input: x = 120 Output: 21 . ",
    "url": "/docs/compsci/leetcode/reverse-integer.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/reverse-integer.html#problem"
  },"1197": {
    "doc": "7 - Reverse Integer - Medium",
    "title": "Explanation",
    "content": "Everything else is pretty straightforward, but the tricky part is checking for overflow. Because of the assumption, we cannot use a long to store the reversed integer, and then check if it is within the range of a 32-bit integer. So I decided to store the reversed integer as a string, and then if we fail to parse it as an integer, we know it is out of range. ",
    "url": "/docs/compsci/leetcode/reverse-integer.html#explanation",
    
    "relUrl": "/docs/compsci/leetcode/reverse-integer.html#explanation"
  },"1198": {
    "doc": "7 - Reverse Integer - Medium",
    "title": "Solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | public int reverse(int x) { int sign = (x &lt; 0) ? -1 : 1; x = sign * x; StringBuilder sb = new StringBuilder(); while (x &gt; 0) { sb.append(x % 10); x /= 10; } try { return sign * Integer.parseInt(sb.toString()); } catch (NumberFormatException e) { return 0; } } . | . The complexity is $O(\\log x)$. ",
    "url": "/docs/compsci/leetcode/reverse-integer.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/reverse-integer.html#solution"
  },"1199": {
    "doc": "7 - Reverse Integer - Medium",
    "title": "7 - Reverse Integer - Medium",
    "content": " ",
    "url": "/docs/compsci/leetcode/reverse-integer.html",
    
    "relUrl": "/docs/compsci/leetcode/reverse-integer.html"
  },"1200": {
    "doc": "ROC Curve",
    "title": "ROC Curve",
    "content": ". | Errors in classfication . | Quick Recap of Terms | . | Receiver Operating Characteristic (ROC) Curve . | Area under the curve (AUC) | . | Selecting the threshold | PR Curve using precision | . ",
    "url": "/docs/data-science/ml-dl/roc.html",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html"
  },"1201": {
    "doc": "ROC Curve",
    "title": "Errors in classfication",
    "content": "In machine learning, classifiers cannot be perfect and there will be errors. Blue64701, CC BY-SA 4.0, via Wikimedia Commons There is usually a trade-off between sensitivity and specificity. You may attempt to reduce as many false negatives in expense of false positives, or reduce false positives in expense of false negatives. This decision, or threshold, depends on the domain and the business decision. ",
    "url": "/docs/data-science/ml-dl/roc.html#errors-in-classfication",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html#errors-in-classfication"
  },"1202": {
    "doc": "ROC Curve",
    "title": "Quick Recap of Terms",
    "content": ". | False Positive Rate (FPR) = $\\frac{FP}{FP + TN}$ . | Among the negatives, how many were incorrectly classified as positives? | The probability of false positive is often called $\\alpha$ or Type I error. | . | False Negative Rate (FNR) = $\\frac{FN}{TP + FN}$ . | Among the positives, how many were incorrectly classified as negatives? | The probability of false negative is often called $\\beta$ or Type II error. | . | Sensitivity (Recall, True Positive Rate) = $1 - FNR$ | Specificity (True Negative Rate) = $1 - FPR$ | . ",
    "url": "/docs/data-science/ml-dl/roc.html#quick-recap-of-terms",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html#quick-recap-of-terms"
  },"1203": {
    "doc": "ROC Curve",
    "title": "Receiver Operating Characteristic (ROC) Curve",
    "content": "Because threshold is up to discretion, we need a threshold-invariant way to evaluate the model. We use the ROC curve to do so. cmglee, MartinThoma, CC BY-SA 4.0, via Wikimedia Commons The basic idea is, as we tweak the classifier’s threshold, we plot the True Positive Rate (sensitivity) against the False Positive Rate. \\[TPR \\text{ (recall)} = \\frac{TP}{TP+FN}\\] \\[FPR = \\frac{FP}{FP + TN} = 1 - TNR \\text{ (specificity)}\\] The collection of these points will form a curve for that classifier. Each point on the ROC curve is a performance measure of a threshold. ",
    "url": "/docs/data-science/ml-dl/roc.html#receiver-operating-characteristic-roc-curve",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html#receiver-operating-characteristic-roc-curve"
  },"1204": {
    "doc": "ROC Curve",
    "title": "Area under the curve (AUC)",
    "content": "The red dotted line indicates a curve of a random classifier which just randomly assigns classes with a uniform distribution. Any sane classifier should be above this line. For any classifier above the random classifier, the number of correctly classified positives is greater than the number of incorrectly classified positives. Area under the curve (AUC) ($\\le 1$) is an aggregate performance measure across all thresholds of a model. Higher AUC indicates higher accuracy of the model. AUC is a useful metric even when the class distributions are highly unbalanced. AUC is for comparing models not thresholds. ",
    "url": "/docs/data-science/ml-dl/roc.html#area-under-the-curve-auc",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html#area-under-the-curve-auc"
  },"1205": {
    "doc": "ROC Curve",
    "title": "Selecting the threshold",
    "content": "In every classification problem, a business decision must be made. Which of the two are more detrimental? . If the normal/abnormal classification was performed in a medical setting, a False Negative might be a patient who is diagnosed as normal, but is actually sick. Here we prefer to avoid False Negatives (or maximize True Positives) at the expense of more False Positives. In the below figure, think about moving the green bar to the far left. However, if the classification was about whether an email is spam or not, we’d pretty much prefer spam mails occasionally ending up in your inbox rather than having your job offer email sent to spam. In this case, we prefer to avoid False Positives at the expense of more False Negatives. In the below figure, think about moving the green bar to the far right. The business decision at hand is then: . | Maximize True Positive Rate | Minimize False Positive Rate | . Sharpr for svg version. original work by kakau in a png, CC BY-SA 3.0, via Wikimedia Commons The ROC curve is a visual illustration of the impact of different thresholds and helps you make these business decisions. If you increase the threshold towards right, the point on the ROC curve moves towards bottom left, because $FP$ decreases. If you decrease the threshold towards left, the point on the ROC curve moves towards top right, because $TP$ increases. ",
    "url": "/docs/data-science/ml-dl/roc.html#selecting-the-threshold",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html#selecting-the-threshold"
  },"1206": {
    "doc": "ROC Curve",
    "title": "PR Curve using precision",
    "content": "Sometimes the curve is drawn with recall (TPR, sensitivity) and precision (PPV) instead. \\[precision = \\frac{TP}{TP + FP}\\] \\[FPR = \\frac{FP}{N} = \\frac{FP}{TN+FP}\\] Suppose the number of actual Condition Negative ($N$) dominates ($N \\rightarrow \\infty$; high imbalance towards class Negative). As you can see from the equation, while precision is significantly affected by the number of False Positives regardless, FPR does not change as much if $N$ is too large. Therefore, if the class distributions are highly imbalanced, precision may be more sensitive to False Positives than FPR. AUC for ROC curve is sometimes called AUROC and AUC for PR curve is called AUPR. Both AUC metrics bear analogous meaning: higher the better. If you increase the threshold towards right, the point on PR curve moves top left. References: . | Ten quick tips for machine learning in computational biology - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/a-Example-of-Precision-Recall-curve-with-the-precision-score-on-the-y-axis-and-the_fig1_321672019 [accessed 4 Dec, 2021] | . ",
    "url": "/docs/data-science/ml-dl/roc.html#pr-curve-using-precision",
    
    "relUrl": "/docs/data-science/ml-dl/roc.html#pr-curve-using-precision"
  },"1207": {
    "doc": "Row Echelon Form / Reduced Row Echelon Form",
    "title": "Row Echelon Form / Reduced Row Echelon Form",
    "content": ". | Row Echelon Form | Reduced Row Echelon Form | . ",
    "url": "/docs/linalg/basics/row-echelon.html",
    
    "relUrl": "/docs/linalg/basics/row-echelon.html"
  },"1208": {
    "doc": "Row Echelon Form / Reduced Row Echelon Form",
    "title": "Row Echelon Form",
    "content": "A row echelon form matrix satisfies the following conditions: . A pivot entry is the first non-zero entry of a row in a row echelon form matrix. | All-zero rows are at the bottom of the matrix. | All pivot entries are $1$. | The pivot entries of rows are strictly to the right of the pivot entries of rows above them. | All entries below a pivot entry are zero. | . \\[\\begin{bmatrix} \\mathbf{1} &amp; 0 &amp; 3 &amp; 4 \\\\ 0 &amp; \\mathbf{1} &amp; 2 &amp; 3 \\\\ 0 &amp; 0 &amp; 0 &amp; \\mathbf{1} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix}\\] . ",
    "url": "/docs/linalg/basics/row-echelon.html#row-echelon-form",
    
    "relUrl": "/docs/linalg/basics/row-echelon.html#row-echelon-form"
  },"1209": {
    "doc": "Row Echelon Form / Reduced Row Echelon Form",
    "title": "Reduced Row Echelon Form",
    "content": "A reduced row echelon form matrix satisfies the following conditions: . | All the conditions of a row echelon form matrix. | The pivot entries are the only non-zero entries in their columns. | . \\[\\begin{bmatrix} \\mathbf{1} &amp; 0 &amp; 3 &amp; 0 \\\\ 0 &amp; \\mathbf{1} &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\mathbf{1} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix}\\] Common methods to find the reduced row echelon form of a matrix are Gaussian elimination and Gauss-Jordan elimination, which involve elementary row operations (row switching and linear combinations of rows). ",
    "url": "/docs/linalg/basics/row-echelon.html#reduced-row-echelon-form",
    
    "relUrl": "/docs/linalg/basics/row-echelon.html#reduced-row-echelon-form"
  },"1210": {
    "doc": "Random Variable Transformation",
    "title": "Random Variable Transformation",
    "content": ". | Defining Random Variable Transformation | Discrete Random Variable Transformation | Continuous Random Variable Transformation | Multivariate Transformation | Expectation of Transformed Random Variable . | The Law of the Unconscious Statistician (LOTUS) . | Univariate Case | Multivariate Case | . | . | . ",
    "url": "/docs/statistics/notes/rv-transformation.html",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html"
  },"1211": {
    "doc": "Random Variable Transformation",
    "title": "Defining Random Variable Transformation",
    "content": "Let $X$ be a random variable. Let $Y = r(X)$ be a function of $X$ (e.g. $Y = X^2$). Then $Y$ is a random variable transformation of $X$. ",
    "url": "/docs/statistics/notes/rv-transformation.html#defining-random-variable-transformation",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html#defining-random-variable-transformation"
  },"1212": {
    "doc": "Random Variable Transformation",
    "title": "Discrete Random Variable Transformation",
    "content": "Let $X$ be a discrete random variable with probability mass function $p_X(x)$. Then the mass function of $Y = r(X)$ is: . $$ p_Y(y) = P(Y = y) = P(r(X) = y) = P(X \\in r^{-1}(y)) = \\sum_{x \\in r^{-1}(y)} p_X(x) $$ . So it really boils down to solving for $r^{-1}(y)$. ",
    "url": "/docs/statistics/notes/rv-transformation.html#discrete-random-variable-transformation",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html#discrete-random-variable-transformation"
  },"1213": {
    "doc": "Random Variable Transformation",
    "title": "Continuous Random Variable Transformation",
    "content": "For continuous random variables, in order to find the probability density function (PDF) $f_Y(y)$, we first solve for the cumulative distribution function (CDF) $F_Y(y)$, and then take the derivative. To do that, we first find the set: . $$ A_y = \\{ x \\mid r(x) \\leq y \\} $$ . Then find the CDF: . $$ F_Y(y) = P(Y \\leq y) = P(r(X) \\leq y) = P(X \\in A_y) = \\int_{A_y} f_X(x) dx $$ . Then take the derivative: . $$ f_Y(y) = \\frac{d}{dy} F_Y(y) $$ . ",
    "url": "/docs/statistics/notes/rv-transformation.html#continuous-random-variable-transformation",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html#continuous-random-variable-transformation"
  },"1214": {
    "doc": "Random Variable Transformation",
    "title": "Multivariate Transformation",
    "content": "Examples of multivariate transformation would be: . | $Z = X + Y$ | $Z = \\min(X, Y)$ | etc. | . The general idea is the same as the univariate case. For $Z = r(X, Y)$, we first find the set: . $$ A_z = \\{ (x, y) \\mid r(x, y) \\leq z \\} $$ . Then find the CDF: . $$ F_Z(z) = P(Z \\leq z) = P(r(X, Y) \\leq z) = P((X, Y) \\in A_z)= \\int \\int_{A_z} f_{X, Y}(x, y) dx dy $$ . Then take the derivative: . $$ f_Z(z) = \\frac{d}{dz} F_Z(z) $$ . ",
    "url": "/docs/statistics/notes/rv-transformation.html#multivariate-transformation",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html#multivariate-transformation"
  },"1215": {
    "doc": "Random Variable Transformation",
    "title": "Expectation of Transformed Random Variable",
    "content": " ",
    "url": "/docs/statistics/notes/rv-transformation.html#expectation-of-transformed-random-variable",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html#expectation-of-transformed-random-variable"
  },"1216": {
    "doc": "Random Variable Transformation",
    "title": "The Law of the Unconscious Statistician (LOTUS)",
    "content": "Univariate Case . When $Y = r(X)$: . $$ \\E(Y) = \\E(r(X)) = \\int r(x) p_X(x) $$ . Multivariate Case . When $Z = r(X, Y)$: . $$ \\E(Z) = \\E(r(X, Y)) = \\int \\int r(x, y) dF_{X, Y}(x, y) $$ . ",
    "url": "/docs/statistics/notes/rv-transformation.html#the-law-of-the-unconscious-statistician-lotus",
    
    "relUrl": "/docs/statistics/notes/rv-transformation.html#the-law-of-the-unconscious-statistician-lotus"
  },"1217": {
    "doc": "Sample Mean and Variance",
    "title": "Sample Mean and Variance",
    "content": ". | Sample Mean . | Converges in Probability to Population Mean | Unbiased Estimator of Population Mean | Consistent Estimator of Population Mean | Variance of the Sample Mean | . | Sample Variance . | Converges in Probability to Population Variance | Unbiased Estimator of Population Variance | Consistent Estimator of Population Variance | . | Standard Error of the Sample Mean | . ",
    "url": "/docs/statistics/notes/sample-mean-variance.html",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html"
  },"1218": {
    "doc": "Sample Mean and Variance",
    "title": "Sample Mean",
    "content": "For $X1, \\dots, X_n$ IID random variables, the sample mean is defined as: . $$ \\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i $$ . ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#sample-mean",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#sample-mean"
  },"1219": {
    "doc": "Sample Mean and Variance",
    "title": "Converges in Probability to Population Mean",
    "content": "The weak law of large numbers states that sample mean $\\overline{X}_n$ converges in probability to the population mean $\\mu$ as number of samples $n$ increases. \\[\\overline{X}_n \\xrightarrow{P} \\mu\\] ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#converges-in-probability-to-population-mean",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#converges-in-probability-to-population-mean"
  },"1220": {
    "doc": "Sample Mean and Variance",
    "title": "Unbiased Estimator of Population Mean",
    "content": "When $\\E[X_i] = \\mu$, . The expected value of the sample mean can be easily calculated using linearity of expectation: . $$ \\E[\\overline{X}_n] = \\E\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right] = \\frac{1}{n} \\sum_{i=1}^n \\E[X_i] = \\mu $$ . So $\\overline{X}_n$ is an unbiased estimator of the population mean $\\mu$. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#unbiased-estimator-of-population-mean",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#unbiased-estimator-of-population-mean"
  },"1221": {
    "doc": "Sample Mean and Variance",
    "title": "Consistent Estimator of Population Mean",
    "content": "Since the sample mean converges in probability to the population mean, the sample mean is said to be consistent. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#consistent-estimator-of-population-mean",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#consistent-estimator-of-population-mean"
  },"1222": {
    "doc": "Sample Mean and Variance",
    "title": "Variance of the Sample Mean",
    "content": "When $\\Var(X_i) = \\sigma^2$, . The variance of the sample mean can be easily calculated using this property of variance: . $$ \\Var(\\overline{X}_n) = \\Var\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\Var(X_i) = \\frac{\\sigma^2}{n} $$ . The variance of the sample mean decreases as the sample size increases, which matches the intuition that the sample mean becomes more accurate. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#variance-of-the-sample-mean",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#variance-of-the-sample-mean"
  },"1223": {
    "doc": "Sample Mean and Variance",
    "title": "Sample Variance",
    "content": "Do not confuse sample variance with variance of the sample mean above. For $X1, \\dots, X_n$ IID random variables, the (unbiased) sample variance is defined as: . $$ S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X}_n)^2 $$ . Why $n-1$ in the denominator? You may be wondering why we divide by $n-1$ instead of $n$. Refer to this link for details. But in short: it is to make the sample variance an unbiased estimator of the population variance. Division by $n$ is good enough when we’re only measuring the dispersion in descriptive statistics, but when we’re using the statistic to estimate the population parameter in inferential statistics, it results in an underestimation of the population variance/standard deviation. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#sample-variance",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#sample-variance"
  },"1224": {
    "doc": "Sample Mean and Variance",
    "title": "Converges in Probability to Population Variance",
    "content": "The sample variance converges in probability to the population variance $\\sigma^2$ as number of samples $n$ increases. \\[S_n^2 \\xrightarrow{P} \\sigma^2\\] Since square root is a continuous function, by the property of convergence in probability, . \\[S_n \\xrightarrow{P} \\sigma\\] holds as well. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#converges-in-probability-to-population-variance",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#converges-in-probability-to-population-variance"
  },"1225": {
    "doc": "Sample Mean and Variance",
    "title": "Unbiased Estimator of Population Variance",
    "content": "When $\\E[X_i] = \\mu$ and $\\Var(X_i) = \\sigma^2$, . The expected value of the sample variance is: . $$ \\E[S_n^2] = \\sigma^2 $$ . So $S^2$ is an unbiased estimator of the population variance $\\sigma^2$. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#unbiased-estimator-of-population-variance",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#unbiased-estimator-of-population-variance"
  },"1226": {
    "doc": "Sample Mean and Variance",
    "title": "Consistent Estimator of Population Variance",
    "content": "Since the sample variance converges in probability to the population variance, the sample variance is said to be consistent. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#consistent-estimator-of-population-variance",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#consistent-estimator-of-population-variance"
  },"1227": {
    "doc": "Sample Mean and Variance",
    "title": "Standard Error of the Sample Mean",
    "content": "Standard error of the sample mean (SEM) is the standard deviation of the sample mean. “Standard error” does not always relate to the sample mean. This term is used to describe the standard deviation of any statistic. We calculated above that: . \\[\\Var[\\overline{X}_n] = \\frac{\\sigma^2}{n}\\] And thus standard error should be: . \\[\\text{SEM} = \\sqrt{\\Var[\\overline{X}_n]} = \\frac{\\sigma}{\\sqrt{n}}\\] However, in many cases, population standard deviation $\\sigma$ is unknown. So, we use the sample standard deviation $S_n$ from above to estimate the standard error: . $$ \\text{SEM} \\approx \\frac{S_n}{\\sqrt{n}} $$ . We already mentioned that $S_n \\xrightarrow{P} \\sigma$ above. ",
    "url": "/docs/statistics/notes/sample-mean-variance.html#standard-error-of-the-sample-mean",
    
    "relUrl": "/docs/statistics/notes/sample-mean-variance.html#standard-error-of-the-sample-mean"
  },"1228": {
    "doc": "Storybook UI",
    "title": "Storybook UI",
    "content": ". | Install and add Storybook UI | Start Storybook locally | Error: PostCSS plugin tailwindcss requires PostCSS 8 | . ",
    "url": "/docs/vue/sb.html",
    
    "relUrl": "/docs/vue/sb.html"
  },"1229": {
    "doc": "Storybook UI",
    "title": "Install and add Storybook UI",
    "content": "Inside the Vue project root, . npx sb init . ",
    "url": "/docs/vue/sb.html#install-and-add-storybook-ui",
    
    "relUrl": "/docs/vue/sb.html#install-and-add-storybook-ui"
  },"1230": {
    "doc": "Storybook UI",
    "title": "Start Storybook locally",
    "content": "yarn storybook . ",
    "url": "/docs/vue/sb.html#start-storybook-locally",
    
    "relUrl": "/docs/vue/sb.html#start-storybook-locally"
  },"1231": {
    "doc": "Storybook UI",
    "title": "Error: PostCSS plugin tailwindcss requires PostCSS 8",
    "content": "Tailwind CSS depends on PostCSS 8. As of now, Storybook have not yet been updated to support PostCSS 8. Therefore, you must install a compatibility build of Tailwind to use it with Storybook. See here for detail. If you already have Tailwind installed, remove by . yarn remove tailwindcss postcss autoprefixer . ",
    "url": "/docs/vue/sb.html#error-postcss-plugin-tailwindcss-requires-postcss-8",
    
    "relUrl": "/docs/vue/sb.html#error-postcss-plugin-tailwindcss-requires-postcss-8"
  },"1232": {
    "doc": "Score Function and Fisher Information",
    "title": "Score Function and Fisher Information",
    "content": ". | Score Function | Fisher Information . | Interpretation of Fisher Information | Inverse of Fisher Information | . | . ",
    "url": "/docs/statistics/notes/score-fisher.html",
    
    "relUrl": "/docs/statistics/notes/score-fisher.html"
  },"1233": {
    "doc": "Score Function and Fisher Information",
    "title": "Score Function",
    "content": "The score function is the first derivative (gradient) of the log-likelihood function with respect to the parameter $\\theta$. The way we find MLE is by taking the derivative of $\\ell(\\theta)$ with respect to $\\theta$, and see which value of $\\theta$ makes the derivative zero. So it makes sense to want to have a gradient of $\\ell(\\theta)$. The log-likelihood function is: . \\[\\ell(\\theta) = \\sum_{i=1}^n \\log f(x_i; \\theta)\\] The score function is: . $$ s(\\theta) = \\nabla_\\theta \\ell(\\theta) = \\sum_{i=1}^n \\nabla_\\theta \\log f(x_i; \\theta) $$ . Other notation Some people like to define the score function for a single observation $X_i$: . \\[s(\\theta; x_i) = \\frac{\\partial \\log f(x_i; \\theta)}{\\partial \\theta}\\] And say that the score function for the entire sample is: . \\[s(\\theta) = \\sum_{i=1}^n s(\\theta; x_i)\\] Expected Value of the Score Function When $\\theta^*$ is the true parameter of $X_i$, . \\[E[s(\\theta^*; x_i)] = 0\\] Which makes sense, because we want all the partial derivatives to be zero (at a maxima) when we have the true parameter. ",
    "url": "/docs/statistics/notes/score-fisher.html#score-function",
    
    "relUrl": "/docs/statistics/notes/score-fisher.html#score-function"
  },"1234": {
    "doc": "Score Function and Fisher Information",
    "title": "Fisher Information",
    "content": "The Fisher information is the variance of the score function. $$ I_n(\\theta) = \\Var(s(\\theta)) = \\sum_{i=1}^n \\Var(s(\\theta; x_i)) $$ . For IID samples, it suffices to calculate the variance of the score function for a single observation: . \\[I(\\theta) = \\Var(s(\\theta; x_i))\\] And then $I_n(\\theta) = n I(\\theta)$. There are several other ways to define the Fisher information. First one is to use the fact that the score function has expected value 0 around the true parameter: . \\[I(\\theta) = E[s^2(\\theta; x_i)] - E[s(\\theta; x_i)]^2 = E[s^2(\\theta; x_i)] = \\E \\left[ \\left( \\frac{\\partial \\log f(x_i; \\theta)}{\\partial \\theta} \\right)^2 \\right]\\] Furthermore, you could also derive the fact that: . \\[\\frac{\\partial^2 \\log f(x_i; \\theta)}{\\partial \\theta^2} = - \\left( \\frac{\\partial \\log f(x_i; \\theta)}{\\partial \\theta} \\right)^2\\] And then you could define the Fisher information for a single observation as: . $$ I(\\theta) = -E \\left[ \\frac{\\partial^2 \\log f(x_i; \\theta)}{\\partial \\theta^2} \\right] $$ . Don’t forget $I_n(\\theta) = n I(\\theta)$ (for IID samples). ",
    "url": "/docs/statistics/notes/score-fisher.html#fisher-information",
    
    "relUrl": "/docs/statistics/notes/score-fisher.html#fisher-information"
  },"1235": {
    "doc": "Score Function and Fisher Information",
    "title": "Interpretation of Fisher Information",
    "content": "We know that the second derivative of a function is a measure of curvature. So the Fisher information is a measure of the curvature of the log-likelihood function around $\\theta$. If the curve is shallow, then the Fisher information is small, meaning, this may have been just a local maxima and we may not be very confident with our MLE. It turns out that $\\theta$ is easier to estimate with MLE when the Fisher information is large. ",
    "url": "/docs/statistics/notes/score-fisher.html#interpretation-of-fisher-information",
    
    "relUrl": "/docs/statistics/notes/score-fisher.html#interpretation-of-fisher-information"
  },"1236": {
    "doc": "Score Function and Fisher Information",
    "title": "Inverse of Fisher Information",
    "content": "The inverse of the Fisher information is the variance of the MLE: . $$ \\Var(\\hat{\\theta}) \\approx \\frac{1}{I_n(\\hat{\\theta})} $$ . This matches up with the interpretation above: larger Fisher information means smaller variance of the MLE, meaning our estimate is more precise. ",
    "url": "/docs/statistics/notes/score-fisher.html#inverse-of-fisher-information",
    
    "relUrl": "/docs/statistics/notes/score-fisher.html#inverse-of-fisher-information"
  },"1237": {
    "doc": "Seasonality",
    "title": "Seasonality",
    "content": "Seasonality is a characteristic of time series data where the data exhibits a repeating pattern at regular intervals (e.g. higher number of visitors on weekends, etc). The most intuitive way to notice seasonality is to visualize the data. However, the type of plot you use can affect how you perceive seasonality. Sometimes it is harder to notice seasonality with a scatter plot than with a line plot. Aside from visualization, there are other statistical methods to detect seasonality. | Difference between seasonality and cyclicity | Different types of time series models . | Additive model | Multiplicative model | . | Decomposition | . ",
    "url": "/docs/data-science/notes/seasonality.html",
    
    "relUrl": "/docs/data-science/notes/seasonality.html"
  },"1238": {
    "doc": "Seasonality",
    "title": "Difference between seasonality and cyclicity",
    "content": "They are similar in that they both exhibit a repeating pattern. However, cyclicity has variable periods. ",
    "url": "/docs/data-science/notes/seasonality.html#difference-between-seasonality-and-cyclicity",
    
    "relUrl": "/docs/data-science/notes/seasonality.html#difference-between-seasonality-and-cyclicity"
  },"1239": {
    "doc": "Seasonality",
    "title": "Different types of time series models",
    "content": "A time series data can be thought of as a combination of . | Level (average) | Trend (upward or downward movement) | Seasonality (repeating pattern) | Residual (random noise) | . We must first identify how these components combine to form the data. Then we can use the appropriate decomposition model to extract seasonality. ",
    "url": "/docs/data-science/notes/seasonality.html#different-types-of-time-series-models",
    
    "relUrl": "/docs/data-science/notes/seasonality.html#different-types-of-time-series-models"
  },"1240": {
    "doc": "Seasonality",
    "title": "Additive model",
    "content": "If a time series data is best modeled by adding the above components, then it is called an additive model. $$ y = \\text{Level} + \\text{Trend} + \\text{Seasonality} + \\text{Residual} $$ . ",
    "url": "/docs/data-science/notes/seasonality.html#additive-model",
    
    "relUrl": "/docs/data-science/notes/seasonality.html#additive-model"
  },"1241": {
    "doc": "Seasonality",
    "title": "Multiplicative model",
    "content": "If a time series data is best modeled by multiplying the above components, then it is called a multiplicative model. $$ y = \\text{Level} \\times \\text{Trend} \\times \\text{Seasonality} \\times \\text{Residual} $$ . ",
    "url": "/docs/data-science/notes/seasonality.html#multiplicative-model",
    
    "relUrl": "/docs/data-science/notes/seasonality.html#multiplicative-model"
  },"1242": {
    "doc": "Seasonality",
    "title": "Decomposition",
    "content": " ",
    "url": "/docs/data-science/notes/seasonality.html#decomposition",
    
    "relUrl": "/docs/data-science/notes/seasonality.html#decomposition"
  },"1243": {
    "doc": "Flutter Setup",
    "title": "Flutter Setup",
    "content": ". | Installation . | Xcode | Android Studio / Android SDK | CocoaPods | . | . ",
    "url": "/docs/flutter/setup.html",
    
    "relUrl": "/docs/flutter/setup.html"
  },"1244": {
    "doc": "Flutter Setup",
    "title": "Installation",
    "content": "If you’re using Apple Sillicon Mac, first install Rosetta. Install Flutter via Homebrew: . brew install --cask flutter . Run the following command to see the components installed or missing: . flutter doctor # -v for verbose . You can opt out of analytics and crash reporting by running flutter config --no-analytics. Xcode . Install Xcode from the App Store. Then, run the following commands to configure Xcode command-line tools: . sudo xcode-select --install sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer sudo xcodebuild -runFirstLaunch sudo xcodebuild -license . Android Studio / Android SDK . Install Android Studio via Homebrew: . brew install --cask android-studio . If not already, install Android SDK via Android Studio: . And Android SDK Command-line Tools: . Accept Android SDK licenses: . flutter doctor --android-licenses . CocoaPods . To use Flutter plugins with native iOS code, you need to install CocoaPods: . brew install cocoapods . References: . | Flutter: Get Started | . ",
    "url": "/docs/flutter/setup.html#installation",
    
    "relUrl": "/docs/flutter/setup.html#installation"
  },"1245": {
    "doc": "Sparse Checkout",
    "title": "Sparse Checkout",
    "content": ". | Monorepo | Checkout only the necessary folders | Check the status | . ",
    "url": "/docs/git-hub/git/sparse.html",
    
    "relUrl": "/docs/git-hub/git/sparse.html"
  },"1246": {
    "doc": "Sparse Checkout",
    "title": "Monorepo",
    "content": "A monorepo a single repository that contains multiple logical root directories or microservices (e.g. frontend subfolder and a backend subfolder.) . As a monorepo grows in size, tracking can become slow. However, a frontend developer may not have to consistently pull and push with the changes in a backend folder and vice versa. We don’t need them, so why keep them? . If the logics of difference microservices can be isolated, version control can prune down unnecessary structures. ",
    "url": "/docs/git-hub/git/sparse.html#monorepo",
    
    "relUrl": "/docs/git-hub/git/sparse.html#monorepo"
  },"1247": {
    "doc": "Sparse Checkout",
    "title": "Checkout only the necessary folders",
    "content": "First clone a project without checking them out: . git clone &lt;URL&gt; --no-checkout # For efficient cloning use partial clone git clone &lt;URL&gt; --no-checkout --filter=blob:none # Or if you also don't need the commit history git clone &lt;URL&gt; --no-checkout --depth 1 . cd into the cloned project and init only the root files: . git sparse-checkout init --cone . Yes it is --cone not a typo of --clone. Set subfolders that you’d like to checkout: . git sparse-checkout set backend db/config . Then checkout: . git checkout . ",
    "url": "/docs/git-hub/git/sparse.html#checkout-only-the-necessary-folders",
    
    "relUrl": "/docs/git-hub/git/sparse.html#checkout-only-the-necessary-folders"
  },"1248": {
    "doc": "Sparse Checkout",
    "title": "Check the status",
    "content": "Try: . git status . Now your git status will indicate that you are in sparse checkout mode. You will see that your project is still up to date with the remote even though all the other subfolders are not locally present. References: . | Bring your monorepo down to size with sparse-checkout | . ",
    "url": "/docs/git-hub/git/sparse.html#check-the-status",
    
    "relUrl": "/docs/git-hub/git/sparse.html#check-the-status"
  },"1249": {
    "doc": "Stationarity",
    "title": "Stationarity",
    "content": "Although it seems like an intuitive concept, identifying stationarity is not as easy as it seems. Identifying stationarity is important because many statistical models assume stationarity. Also because stationarity means that some important metrics, such as mean and variance, are constant over time, it is often a desirable property for analysis. | Understanding stationarity | Quick rule of thumb to identify stationarity | Unit root test . | Unit root | Augmented Dickey-Fuller test . | Caveats of ADF | . | . | Ways to correct non-stationarity | Different types of stationarity | . ",
    "url": "/docs/data-science/notes/stationarity.html",
    
    "relUrl": "/docs/data-science/notes/stationarity.html"
  },"1250": {
    "doc": "Stationarity",
    "title": "Understanding stationarity",
    "content": "Suppose a time series data $y_t$ is generated by a random variable of some unknown joint probability distribution. For any time lag $k$, if the joint probability distribution of $y_{t+k}$ remains the same as $y_t$, then the time series data is stationary. ",
    "url": "/docs/data-science/notes/stationarity.html#understanding-stationarity",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#understanding-stationarity"
  },"1251": {
    "doc": "Stationarity",
    "title": "Quick rule of thumb to identify stationarity",
    "content": ". | Mean is constant over time | Variance is constant over time | There is no seasonality | . You can identify these from visualizing the data. White noise is a special type of staionary time series data, where the mean is zero and variance is constant over time. ",
    "url": "/docs/data-science/notes/stationarity.html#quick-rule-of-thumb-to-identify-stationarity",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#quick-rule-of-thumb-to-identify-stationarity"
  },"1252": {
    "doc": "Stationarity",
    "title": "Unit root test",
    "content": "Most statistical tests for stationarity looks for the presence of a unit root. If a time series data has a unit root, it is non-stationary. ",
    "url": "/docs/data-science/notes/stationarity.html#unit-root-test",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#unit-root-test"
  },"1253": {
    "doc": "Stationarity",
    "title": "Unit root",
    "content": "If a time series has a characteristic equation with a root equal to 1, it is said to have a unit root. Let’s define a autoregressive process of order 1 (AR(1)) as follows: . \\[y_t = \\phi y_{t-1} + \\epsilon_t\\] The characteristic equation of this process is: . \\[1 - \\phi z = 0\\] If $\\phi = 1$, the root of this equation is $z = 1$ and thus a unit root. Then we would say this process is non-stationary. ",
    "url": "/docs/data-science/notes/stationarity.html#unit-root",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#unit-root"
  },"1254": {
    "doc": "Stationarity",
    "title": "Augmented Dickey-Fuller test",
    "content": "Augmented Dickey-Fuller (ADF) is the most commonly used hypothesis test for stationarity. The null hypothesis is that the time series data has a unit root. If the test result is significant, we reject the null hypothesis and conclude that the time series data is stationary. As the name suggests, ADF is an extension of the Dickey-Fuller test. The main difference is that ADF can handle higher order autoregressive processes. Caveats of ADF . | Struggles to distinguish between near-unit root and unit root | High false positive rate when sample size is small | . ",
    "url": "/docs/data-science/notes/stationarity.html#augmented-dickey-fuller-test",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#augmented-dickey-fuller-test"
  },"1255": {
    "doc": "Stationarity",
    "title": "Ways to correct non-stationarity",
    "content": "Although it is not always possible to correct non-stationarity (and not always what you want to do), there are some methods that can be applied to correct non-stationarity. | Differencing: gets rid of trend, fixes non-constant mean | Log transformation: fixes non-constant variance | Square root transformation: fixes non-constant variance | . ",
    "url": "/docs/data-science/notes/stationarity.html#ways-to-correct-non-stationarity",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#ways-to-correct-non-stationarity"
  },"1256": {
    "doc": "Stationarity",
    "title": "Different types of stationarity",
    "content": "To be added . There are different types of stationarity depending on the constraints enforced on the joint probability distribution. e.g. First moment (mean) and second moment (variance) should be constant, but other statistical moments can be allowed to vary, e.g. The stationary constraint has to hold only for certain time lags but not throughout. | Strict stationarity | Weak stationarity | N-th order stationarity | . ",
    "url": "/docs/data-science/notes/stationarity.html#different-types-of-stationarity",
    
    "relUrl": "/docs/data-science/notes/stationarity.html#different-types-of-stationarity"
  },"1257": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Intro to Statistical Machine Learning",
    "content": ". | Response, Predictors, and Model . | True Model | Goals of Model Learning . | Prediction | Inference | . | Noise / Error | . | Parametric / Non-parametric Models . | Parametric and Structured Models | Non-parametric Models . | Important Trade-Offs | . | . | Regression / Classification | Supervised / Unsupervised Learning | Measuring Goodness of Fit . | Training and Testing | Goodness of Fit in Classification | . | . ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html"
  },"1258": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Response, Predictors, and Model",
    "content": "We often denote the response or target as: . $$ Y $$ . and features, input, or predictors as: . $$ X_i $$ . and these predictors are often collected in to a input vector: . $$ X = (X_1, X_2, \\ldots, X_p) $$ . ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#response-predictors-and-model",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#response-predictors-and-model"
  },"1259": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "True Model",
    "content": "The true model is a function $f$ that maps the input to the response: . $$ Y = f(X) + \\epsilon $$ . | True model $f$ is deterministic and unknown | . ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#true-model",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#true-model"
  },"1260": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Goals of Model Learning",
    "content": "Our goal is to learn $\\hat{f}$, an estimate of $f$. In terms of regression, we usually do this by minimizing the mean squared error (MSE) (expectation of the squared differences): . \\[\\begin{equation} \\label{eq:mse-dec} \\overbrace{\\E[(Y - \\hat{Y})^2]}^{\\text{MSE}} = \\underbrace{(f(X) - \\hat{f}(X))^2}_\\text{Reducible Error} + \\underbrace{\\Var(\\epsilon)}_\\text{Irreducible Error} \\end{equation}\\] Do not worry about how we get this decomposition for now (there are some assumptions that need to be made), more will be in regression. Just some blabbering about notation Sometimes people write the expectation as: . \\[\\E[Y - \\hat{Y}]^2\\] To mean the same thing as above. I personally find this notation confusing because it is not clear whether it is taking the expectation of the squared difference or squaring the expectation of the difference. As the name suggests, irreducible error is indeed irreducible, so we try to minimize the reducible error to minimize the MSE. That is the process of learning $\\hat{f}$. Prediction . The prediction of response given observations is: . $$ \\hat{Y} = \\hat{f}(X) $$ . Specifically, we are interested in getting $\\hat{Y}$ upon learning $\\hat{f}$. So in prediction, our end goal is not the model itself, but rather the prediction of the response. Inference . In inference, we are interested in the relationship between the predictors and the response. Same stuff about learning $\\hat{f}$, but compared to prediction, we are more interested in the model itself rather than the prediction value. ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#goals-of-model-learning",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#goals-of-model-learning"
  },"1261": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Noise / Error",
    "content": "$\\epsilon$ or noise is a random variable that captures the variability in the response not explained by true model: . \\[Y = f(X) + \\epsilon\\] Note the emphasis on true, this means that even if we correctly identify the true model, there still will be some uncertainty in the response. Take a look at the decomposition \\eqref{eq:mse-dec} above again. Because the noise is the source of the irreducible uncertainty, . Noise is also called an irreducible error. Important assumptions about $\\epsilon$: . Random variable $\\epsilon$ is independent of $X$ and has a mean of 0. This becomes critical in certain models and methods. ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#noise--error",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#noise--error"
  },"1262": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Parametric / Non-parametric Models",
    "content": " ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#parametric--non-parametric-models",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#parametric--non-parametric-models"
  },"1263": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Parametric and Structured Models",
    "content": "One example of parametric and structured model is the linear model. The parameters are the coefficients of the predictors and the structure is the linear relationship between the predictors and the response. Parametric models are effective when the true $f$ approximately follows the structure assumed by the model. ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#parametric-and-structured-models",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#parametric-and-structured-models"
  },"1264": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Non-parametric Models",
    "content": "Non-parametric models, on the other hand, do not make strong assumptions about the structure of $f$. Unlike the parametric models, which carry the risk of completely missing the beat, non-parametric models are generally more flexible and can capture more complex relationships. However, non-parametric models require more data to estimate the model. Important Trade-Offs . Parametric models and non-parametric models have different trade-offs and are prone to different types of errors: . | Interpretability vs Accuracy/Flexibility | Underfitting vs Overfitting | Efficiency (in terms of data/model size) vs Complexity | . ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#non-parametric-models",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#non-parametric-models"
  },"1265": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Regression / Classification",
    "content": "When the response is quantitative, we call it regression. When the response is qualitative, we call it classification. Not exactly, but let’s keep it simple for now. ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#regression--classification",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#regression--classification"
  },"1266": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Supervised / Unsupervised Learning",
    "content": "When there is a given response variable, we call it supervised learning. | Regression and classification | . When there is no given response variable, we call it unsupervised learning. | Clustering | . ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#supervised--unsupervised-learning",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#supervised--unsupervised-learning"
  },"1267": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Measuring Goodness of Fit",
    "content": "As discussed above, in regression, the most common way to measure the goodness of fit is the mean squared error (MSE): . \\[\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{f}(x_i))^2\\] ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#measuring-goodness-of-fit",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#measuring-goodness-of-fit"
  },"1268": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Training and Testing",
    "content": "We estimate the model by minimizing the MSE over training data, or the training MSE. However, this measurement is obviously biased towards overfit models. Therefore, in order to evaluate the model’s performance, we need to introduce another set of observations called testing data, i.e. ones that were not involved in the training process, and calculate the testing MSE. ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#training-and-testing",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#training-and-testing"
  },"1269": {
    "doc": "Intro to Statistical Machine Learning",
    "title": "Goodness of Fit in Classification",
    "content": "While MSE is a common measure for regression, the error rate or the misclassification rate is a common measure for classification. \\[\\text{Error Rate} = \\frac{1}{n} \\sum_{i=1}^{n} I(y_i \\neq \\hat{f}(x_i))\\] where $I(\\cdot)$ is the indicator function that returns 1 if the condition is true. So out of total $n$, how many were misclassified? That is the error rate. Just like regression, we estimate the model with training error rate, and evaluate the model with testing error rate. ",
    "url": "/docs/data-science/ml-dl/statistical-ml.html#goodness-of-fit-in-classification",
    
    "relUrl": "/docs/data-science/ml-dl/statistical-ml.html#goodness-of-fit-in-classification"
  },"1270": {
    "doc": "Statistical Model for Time Series",
    "title": "Statistical Model for Time Series",
    "content": ". | Shortcomings of linear regression in time series | Autoregressive (AR) Model | . ",
    "url": "/docs/data-science/time-series/statistical-model.html",
    
    "relUrl": "/docs/data-science/time-series/statistical-model.html"
  },"1271": {
    "doc": "Statistical Model for Time Series",
    "title": "Shortcomings of linear regression in time series",
    "content": "Linear regression assumes that the data points are i.i.d. which is not true for time series data where proximate data points are likely strongly correlated. ",
    "url": "/docs/data-science/time-series/statistical-model.html#shortcomings-of-linear-regression-in-time-series",
    
    "relUrl": "/docs/data-science/time-series/statistical-model.html#shortcomings-of-linear-regression-in-time-series"
  },"1272": {
    "doc": "Statistical Model for Time Series",
    "title": "Autoregressive (AR) Model",
    "content": "Go to page . ",
    "url": "/docs/data-science/time-series/statistical-model.html#autoregressive-ar-model",
    
    "relUrl": "/docs/data-science/time-series/statistical-model.html#autoregressive-ar-model"
  },"1273": {
    "doc": "Sum of Squares",
    "title": "Sum of Squares",
    "content": ". | What is Sum of Squares? | Total Sum of Squares | Residual Sum of Squares | Explained Sum of Squares | Relationship Between Sum of Squares | . ",
    "url": "/docs/data-science/ml-dl/sum-of-squares.html",
    
    "relUrl": "/docs/data-science/ml-dl/sum-of-squares.html"
  },"1274": {
    "doc": "Sum of Squares",
    "title": "What is Sum of Squares?",
    "content": "Sum of squares is a concept frequently used in regression analysis. Depending on what we choose to square, we end up with many different sums of squares. ",
    "url": "/docs/data-science/ml-dl/sum-of-squares.html#what-is-sum-of-squares",
    
    "relUrl": "/docs/data-science/ml-dl/sum-of-squares.html#what-is-sum-of-squares"
  },"1275": {
    "doc": "Sum of Squares",
    "title": "Total Sum of Squares",
    "content": "The total sum of squares (TSS) $SS_{tot}$ is the sum of the squared differences between the observed dependent variable $y_i \\in Y$ and its mean $\\bar{y}$: . $$ SS_{tot} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 $$ . where $n$ is the number of observations. Why is the comparison with the mean? The mean $\\bar{y}$ is basically the baseline model, or the most obvious and naive model that we can think of. So any model that we fit later should be better than simply calculating the mean. In that sense, $SS_{tot}$ is the sum of squares that we would get in the (sanely) worst model. Graphically, in a simple linear regression with one independent variable, $SS_{tot}$ is the sum of the areas of the purple squares in the figure below. ",
    "url": "/docs/data-science/ml-dl/sum-of-squares.html#total-sum-of-squares",
    
    "relUrl": "/docs/data-science/ml-dl/sum-of-squares.html#total-sum-of-squares"
  },"1276": {
    "doc": "Sum of Squares",
    "title": "Residual Sum of Squares",
    "content": "Also known as sum of squared errors (SSE). The residual sum of squares (RSS) $SS_{res}$ is the sum of the squared differences between the observed dependent variable $y_i \\in Y$ and the predicted value $\\hat{y}_i$ from the regression line: . $$ SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$ . Graphically, in a simple linear regression with one independent variable, $SS_{res}$ is the sum of the areas of the red squares in the figure below. ",
    "url": "/docs/data-science/ml-dl/sum-of-squares.html#residual-sum-of-squares",
    
    "relUrl": "/docs/data-science/ml-dl/sum-of-squares.html#residual-sum-of-squares"
  },"1277": {
    "doc": "Sum of Squares",
    "title": "Explained Sum of Squares",
    "content": "Also known as model sum of squares. The explained sum of squares ($SS_{exp}$) is the sum of the squared differences between the predicted value $\\hat{y}_i$ from the regression line and the mean $\\bar{y}$: . $$ SS_{exp} = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2 $$ . Graphically, in a simple linear regression with one independent variable, $SS_{exp}$ is the sum of the areas of the blue squares in the figure below. ",
    "url": "/docs/data-science/ml-dl/sum-of-squares.html#explained-sum-of-squares",
    
    "relUrl": "/docs/data-science/ml-dl/sum-of-squares.html#explained-sum-of-squares"
  },"1278": {
    "doc": "Sum of Squares",
    "title": "Relationship Between Sum of Squares",
    "content": "For linear regression models using Ordinary Least Squares (OLS) estimation, the following relationship holds: . $$ SS_{tot} = SS_{exp} + SS_{res} $$ . ",
    "url": "/docs/data-science/ml-dl/sum-of-squares.html#relationship-between-sum-of-squares",
    
    "relUrl": "/docs/data-science/ml-dl/sum-of-squares.html#relationship-between-sum-of-squares"
  },"1279": {
    "doc": "Spurious Correlation",
    "title": "Spurious Correlation",
    "content": "If two variables are correlated, but there is no causal relationship between them, then the correlation is said to be spurious. Spurious correlation is common in time series data because chances of finding a false causal relationship increases as intermediate variables increase. In addition, temporal variables are common confounders that can cause spurious correlation. It is very tricky to avoid spurious correlation. | Things that can cause spurious correlation . | Trend | Confounder | Dependency in variables | Pure luck | . | . ",
    "url": "/docs/statistics/notes/suprious-correlation.html",
    
    "relUrl": "/docs/statistics/notes/suprious-correlation.html"
  },"1280": {
    "doc": "Spurious Correlation",
    "title": "Things that can cause spurious correlation",
    "content": " ",
    "url": "/docs/statistics/notes/suprious-correlation.html#things-that-can-cause-spurious-correlation",
    
    "relUrl": "/docs/statistics/notes/suprious-correlation.html#things-that-can-cause-spurious-correlation"
  },"1281": {
    "doc": "Spurious Correlation",
    "title": "Trend",
    "content": "Data with a trend is more likely to produce a spurious correlation. Compared to stationary data where nothing new is really happening, it makes sense that moving data is more likely to be falsely connected with other moving data. ",
    "url": "/docs/statistics/notes/suprious-correlation.html#trend",
    
    "relUrl": "/docs/statistics/notes/suprious-correlation.html#trend"
  },"1282": {
    "doc": "Spurious Correlation",
    "title": "Confounder",
    "content": "A confounder is a variable that is correlated with both the independent and dependent variables. | Increase in ice cream sales leads to increase in drowning deaths? . | Summer is the confounder | . | Increase in temperature leads to increase in divorce rates? . | Time is the confounder. Things typically increase over time. | . | . ",
    "url": "/docs/statistics/notes/suprious-correlation.html#confounder",
    
    "relUrl": "/docs/statistics/notes/suprious-correlation.html#confounder"
  },"1283": {
    "doc": "Spurious Correlation",
    "title": "Dependency in variables",
    "content": "It is easy to mistake two variables that are dependent on each other to be independent. If one is a calculated value of the other, for example, you would expect them to be highly correlated. ",
    "url": "/docs/statistics/notes/suprious-correlation.html#dependency-in-variables",
    
    "relUrl": "/docs/statistics/notes/suprious-correlation.html#dependency-in-variables"
  },"1284": {
    "doc": "Spurious Correlation",
    "title": "Pure luck",
    "content": "Sometimes, things may seem like that just because of pure luck. ",
    "url": "/docs/statistics/notes/suprious-correlation.html#pure-luck",
    
    "relUrl": "/docs/statistics/notes/suprious-correlation.html#pure-luck"
  },"1285": {
    "doc": "Singular Value Decomposition",
    "title": "Singular Value Decomposition",
    "content": ". | Gram Matrix | Singular Values . | Rank of a Matrix in Terms of Singular Values | . | Singular Value Decomposition (SVD) . | Orthonormal Basis Produced By SVD | . | . ",
    "url": "/docs/linalg/basics/svd.html",
    
    "relUrl": "/docs/linalg/basics/svd.html"
  },"1286": {
    "doc": "Singular Value Decomposition",
    "title": "Gram Matrix",
    "content": "For $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$, the Gram matrix of $\\boldsymbol{A}$ is: . $$ \\boldsymbol{A}^\\top \\boldsymbol{A} $$ . It has the following properties: . | Symmetric | Positive semi-definite | . ",
    "url": "/docs/linalg/basics/svd.html#gram-matrix",
    
    "relUrl": "/docs/linalg/basics/svd.html#gram-matrix"
  },"1287": {
    "doc": "Singular Value Decomposition",
    "title": "Singular Values",
    "content": "For $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$, the singular values of $\\boldsymbol{A}$ are the positive square roots of the eigenvalues of $\\boldsymbol{A}^\\top \\boldsymbol{A}$. $$ \\sigma_i = \\sqrt{\\lambda_i} $$ . where $\\lambda_i$ are the eigenvalues of $\\boldsymbol{A}^\\top \\boldsymbol{A}$. Because $\\boldsymbol{A}^\\top \\boldsymbol{A}$ is symmetric and positive semi-definite, all eigenvalues are non-negative. It is customary to sort the singular values in descending order. This is to ensure a unique SVD. ",
    "url": "/docs/linalg/basics/svd.html#singular-values",
    
    "relUrl": "/docs/linalg/basics/svd.html#singular-values"
  },"1288": {
    "doc": "Singular Value Decomposition",
    "title": "Rank of a Matrix in Terms of Singular Values",
    "content": "The rank of $\\boldsymbol{A}$ is the number of non-zero singular values. You must count the duplicates too. So if you see two eigenvalues that are the same, that counts as $+2$ towards the rank. ",
    "url": "/docs/linalg/basics/svd.html#rank-of-a-matrix-in-terms-of-singular-values",
    
    "relUrl": "/docs/linalg/basics/svd.html#rank-of-a-matrix-in-terms-of-singular-values"
  },"1289": {
    "doc": "Singular Value Decomposition",
    "title": "Singular Value Decomposition (SVD)",
    "content": "Any matrix $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$ can be decomposed as: . $$ \\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T $$ . First we will define the following: . | $r = \\rank(\\boldsymbol{A}^\\top \\boldsymbol{A})$ | . Now let’s look at the components of the SVD: . | $\\boldsymbol{U} \\in \\mathbb{R}^{m \\times m}$ is an orthogonal matrix whose columns are the normalized eigenvectors of $\\boldsymbol{A} \\boldsymbol{A}^\\top$. | $\\boldsymbol{U}$ is also called the left singular matrix. | The column vectors $\\boldsymbol{u}_i$ are called the left singular vectors. | Left singular vectors form an orthonormal basis that spans $\\mathbb{R}^m$. | . | $\\boldsymbol{V} \\in \\mathbb{R}^{n \\times n}$ is an orthogonal matrix whose columns are the normalized eigenvectors of $\\boldsymbol{A}^\\top \\boldsymbol{A}$. | $\\boldsymbol{V}$ is also called the right singular matrix. | The column vectors $\\boldsymbol{v}_i$ are called the right singular vectors. | Right singular vectors form an orthonormal basis that spans $\\mathbb{R}^n$. | . | $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{m \\times n}$ is a rectangular diagonal matrix . | $\\boldsymbol{\\Sigma}$ is also called the singular value matrix. | The diagonal elements $\\sigma_i$ are the singular values. | There are $r$ non-zero singular values. | For $\\boldsymbol{\\Sigma}$ to be unique, we require that the singular values are sorted in descending order. | . | . ",
    "url": "/docs/linalg/basics/svd.html#singular-value-decomposition-svd",
    
    "relUrl": "/docs/linalg/basics/svd.html#singular-value-decomposition-svd"
  },"1290": {
    "doc": "Singular Value Decomposition",
    "title": "Orthonormal Basis Produced By SVD",
    "content": "$\\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_r\\}$ is an orthonormal basis for the column space of $\\boldsymbol{A}$. $\\{\\boldsymbol{u}_{r+1}, \\ldots, \\boldsymbol{u}_m\\}$ is an orthonormal basis for the null space of $\\boldsymbol{A}^\\top$. $\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_r\\}$ is an orthonormal basis for the row space of $\\boldsymbol{A}$. $\\{\\boldsymbol{v}_{r+1}, \\ldots, \\boldsymbol{v}_n\\}$ is an orthonormal basis for the null space of $\\boldsymbol{A}$. ",
    "url": "/docs/linalg/basics/svd.html#orthonormal-basis-produced-by-svd",
    
    "relUrl": "/docs/linalg/basics/svd.html#orthonormal-basis-produced-by-svd"
  },"1291": {
    "doc": "Support Vector Machine",
    "title": "Support Vector Machine",
    "content": ". | Basic concept of SVM | Support Vector Classifier . | Training data | Hyperplane | Support vectors | Optimization problem . | Hard margin SVC | Soft margin SVC | . | SVC as an Inner Product | Kernel trick . | Radial basis function (RBF) kernel | . | . | Support Vector Regression | . ",
    "url": "/docs/data-science/ml-dl/svm.html",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html"
  },"1292": {
    "doc": "Support Vector Machine",
    "title": "Basic concept of SVM",
    "content": "Support vector machine (SVM) is a supervised machine learning algorithm that can be used for both classification and regression. ",
    "url": "/docs/data-science/ml-dl/svm.html#basic-concept-of-svm",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#basic-concept-of-svm"
  },"1293": {
    "doc": "Support Vector Machine",
    "title": "Support Vector Classifier",
    "content": "Support vector classifier (SVC) is a binary classifier that finds the optimal hyperplane that separates the two classes. Although SVC is inherently a binary classifier, it can be extended to multi-class classification (Lookup: one-vs-one, one-vs-rest, multiclass SVM). ",
    "url": "/docs/data-science/ml-dl/svm.html#support-vector-classifier",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#support-vector-classifier"
  },"1294": {
    "doc": "Support Vector Machine",
    "title": "Training data",
    "content": ". | For $i = 1, \\dots, n$, . | $\\mathbf{x}_i \\in \\mathbb{R}^p$ is the $i$-th observation. Do not confuse this notation with the $x_1$ and $x_2$ in the figure below. The $x_1$ and $x_2$ in the figure are notating the two hypothetical features just to illustrate the concept of SVC in a 2D space. In our case, each $\\mathbf{x}_i$ is a $p$-dimensional vector that represents the $p$ features of the $i$-th observation (so each colored dots in the figure below). | $y_i \\in \\{ -1, 1 \\}$ is the (binary) class label of $x_i$. | . | . ",
    "url": "/docs/data-science/ml-dl/svm.html#training-data",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#training-data"
  },"1295": {
    "doc": "Support Vector Machine",
    "title": "Hyperplane",
    "content": ". | A hyperplane is an affine subspace of dimension $p-1$ in $\\mathbb{R}^p$. A hyperplane in $\\mathbb{R}^2$ is a line (1-dimensional subspace) and in $\\mathbb{R}^3$ is a plane (2-dimensional subspace). | We want to find the optimal hyperplane that separates the two classes. | The optimal hyperplane is the one that maximizes the margin (Maximal Margin Classifier), which is the distance between the hyperplane and the closest observations. | . We want to estimate a hyperplane defined by, . | $\\mathbf{w} \\in \\mathbb{R}^p$ is the vector normal to the hyperplane. | $b \\in \\mathbb{R}$ is the bias of the hyperplane. | If $b = 0$, the hyperplane passes through the origin. | . | . $$ \\mathbf{w}^\\top \\mathbf{x} + b = 0 $$ . Equation looks different As in the figure above, sometimes people define the hyperplane with a negative bias term: . \\[\\mathbf{w}^\\top \\mathbf{x} - b = 0\\] This is just a matter of notation and does not affect the estimation. ",
    "url": "/docs/data-science/ml-dl/svm.html#hyperplane",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#hyperplane"
  },"1296": {
    "doc": "Support Vector Machine",
    "title": "Support vectors",
    "content": "Support vectors are $\\mathbf{x}_i$ that satisfy the following conditions: . $$ \\begin{align*} \\mathbf{w}^\\top \\mathbf{x}_i + b = 1 &amp;\\wedge y_i = 1 \\\\ \\mathbf{w}^\\top \\mathbf{x}_i + b = -1 &amp;\\wedge y_i = -1 \\end{align*} $$ . More details More generally, the support vectors are the observations that satisfy: . \\[\\begin{align*} \\mathbf{w}^\\top \\mathbf{x}_i + b = a &amp;\\wedge y_i = 1 \\\\ \\mathbf{w}^\\top \\mathbf{x}_i + b = -a &amp;\\wedge y_i = -1 \\end{align*}\\] However, with data normalization, we can simplify $a = 1$. In the figure above the support vectors are the points on the dotted margin lines (two of which are blue and one green). Support vectors are actual observations and not some hypothetical values that satisfy the conditions. ",
    "url": "/docs/data-science/ml-dl/svm.html#support-vectors",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#support-vectors"
  },"1297": {
    "doc": "Support Vector Machine",
    "title": "Optimization problem",
    "content": "Hard margin SVC . If the data are linearly separable, we can find a hyperplane that perfectly separates the two classes with a hard margin. In order for classification to be perfect, we want the observations with label $y_i = 1$ to be above the blue support vectors and the observations with label $y_i = -1$ to be below the green support vector. \\[\\begin{align*} \\mathbf{w}^\\top \\mathbf{x}_i + b &amp;\\geq 1 &amp; \\text{if } y_i = +1 \\\\ \\mathbf{w}^\\top \\mathbf{x}_i + b &amp;\\leq -1 &amp; \\text{if } y_i = -1 \\end{align*}\\] This hard-margin contraint can be compactly written as: . \\[y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1\\] $y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b)$ is sometimes called the confidence, i.e. the distance from the hyperplane to the observation. We want this distance to be at least 1 to be classified correctly. Also, higher the distance, the more confident we are in the classification, hence the name. Now we need to find a hyperplane maximizing the margin while adhering to the constraint above, where the size of the margin is defined as: . \\[\\frac{2}{\\lVert \\mathbf{w} \\rVert}\\] What? Let $\\mathbf{x}_{+1}$ be the support vector that satisfies . \\[\\mathbf{w}^\\top \\mathbf{x}_{+1} + b = 1\\] Let $d$ be the distance from this support vector to the hyperplane. We know that $\\frac{\\mathbf{w}}{\\lVert \\mathbf{w} \\rVert}$ is the unit vector normal to the hyperplane. If we start at $\\mathbf{x}_{+1}$ and move along the negative direction of this unit vector by $d$, we will reach the hyperplane: . \\[\\mathbf{w}^\\top \\left( \\mathbf{x}_{+1} - d \\frac{\\mathbf{w}}{\\lVert \\mathbf{w} \\rVert} \\right) + b = 0 \\\\\\] We want to solve for $d$: . \\[\\begin{gather*} \\mathbf{w}^\\top \\mathbf{x}_{+1} - d \\frac{\\lVert \\mathbf{w} \\rVert^2}{\\lVert \\mathbf{w} \\rVert} + b = 0 \\tag{Dot product} \\\\[0.5em] \\mathbf{w}^\\top \\mathbf{x}_{+1} - d \\lVert \\mathbf{w} \\rVert + b = 0 \\\\[0.5em] d \\lVert \\mathbf{w} \\rVert = \\mathbf{w}^\\top \\mathbf{x}_{+1} + b \\\\[0.5em] d \\lVert \\mathbf{w} \\rVert = 1 \\tag{By definition} \\\\[0.5em] d = \\frac{1}{\\lVert \\mathbf{w} \\rVert} \\end{gather*}\\] Since the margin is twice the distance $d$, . $$ \\frac{2}{\\lVert \\mathbf{w} \\rVert} $$ . So our maximization problem is: . \\[\\begin{gather*} \\max_{\\mathbf{w}, b} \\frac{2}{\\lVert \\mathbf{w} \\rVert} \\quad s.t.\\quad y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 \\end{gather*}\\] We instead solve a minimization problem of: . $$ \\begin{gather*} \\min_{\\mathbf{w}, b} \\frac{1}{2} \\lVert \\mathbf{w} \\rVert^2 \\quad s.t.\\quad y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 \\end{gather*} $$ . We use $\\frac{1}{2} \\lVert \\mathbf{w} \\rVert^2$ instead of $\\lVert \\mathbf{w} \\rVert$ just so that the derivative is easier to calculate. This primal problem can be solved using Lagrange multipliers. Soft margin SVC . In reality, the data are not always linearly separable with a hard margin. We can relax the constraint to allow some mistakes, but instead penalize the misclassification. To account for the misclassifications, we introduce a slack variable $\\xi_i \\ge 0$ for each observation: . $$ \\xi_i \\approx \\max(0, 1 - y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b)) $$ . The right side of the $\\approx$ is called the hinge loss. We use the approximate sign because the slack variable is not exactly the hinge loss, but some constant times the hinge loss. If the observation is misclassified $y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b)$ will be negative, and the slack variable will be greater than 1. If the observation is correctly classified, but is within the margin, the slack variable will be between 0 and 1. The rest of the observations will have $\\xi_i = 0$. Geometrically, $\\xi_i$ captures the distance from the correct side of the margin defined by the support vectors to the observation, which is an intuitive penalty for misclassification. We obviously want this slack variable to be minimized. With this slack variable, we now have a new constraint: . \\[\\begin{align*} \\mathbf{w}^\\top \\mathbf{x}_i + b &amp;\\geq 1 - \\xi_i &amp; \\text{if } y_i = +1 \\\\ \\mathbf{w}^\\top \\mathbf{x}_i + b &amp;\\leq -1 + \\xi_i &amp; \\text{if } y_i = -1 \\end{align*}\\] This soft-margin contraint can be compactly written as: . \\[y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 - \\xi_i\\] Notice that now our constraint is now loosened by its misclassified distance. Since now we have two things to minimize, the original objective in addition to the sum of the slack variables, so we solve the following minimization problem: . $$ \\min_{\\mathbf{w}, b, \\xi} \\frac{1}{2} \\lVert \\mathbf{w} \\rVert^2 + C \\sum_{i=1}^{n} \\xi_i \\quad s.t.\\quad y_i (\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0 $$ . where $C$ is a hyperparameter that controls the trade-off between having a large, complex model (added $\\xi_i$) and allowing more mistakes. This $C$, much like a regularization variable, is chosen by cross-validation. | With a huge $C$, we are essentially solving a hard-margin problem. | Because in attempt to minimize the slack sum with a huge $C$, we will end up allowing slacks of near-zero values which is as rigid as a hard-margin. | . | With a small $C$, we are giving more rooms for slack during the minimization. | . ",
    "url": "/docs/data-science/ml-dl/svm.html#optimization-problem",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#optimization-problem"
  },"1298": {
    "doc": "Support Vector Machine",
    "title": "SVC as an Inner Product",
    "content": "SVM optimization problem can be solved by Lagrange multiplier method. Which leads to a inner product representation of the SVC. Long story long We have the objective function to minimize and a constraint function. The objective function is bound to the constraint, meaning it’s gotta touch the constraint function at some point. At this tangent point, the gradient of the objective function and the gradient of the constraint function are parallel (may be different directions and magnitudes, but on a same line). Lagrange multiplier is a $\\lambda$ multiplied to the constraint gradient to make it identical to the objective gradient. The objective, constraint, and the Lagrange multiplier are combined to form a Lagrangian function, and we try to minimize this Lagrangian. For the optimal solution, just like any minimization, we just solve for when the gradient of the Lagrangian is zero. This Lagrangian is the called the primal form of the optimization problem, or primal problem. There is actually a dual form of the optimization problem. This is a very rough idea of what’s going on. The objective function and the multipliers kind of fight each other just like models with regularization fight between the objective and the penalty. In the primal sense, we try to minimize the Lagrangian by minimizing over original variables. But we could achieve the same by maximizing over the multipliers. Why the hell do we do this? Because turns out the dual form for SVM linear support vector classifier can be computed simply with inner products of the observations $\\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle$. The classifier can also be expressed as: . \\[f(\\mathbf{x}) = \\beta_0 + \\sum_{i \\in S} \\hat{\\alpha}_i \\langle \\mathbf{x}, \\mathbf{x}_i \\rangle\\] where $S$ is the support set indices where ${\\alpha}_i &gt; 0$ (observations on and within the margin). This is great computationally, but also essential for the kernel trick that we will see in the next section. ",
    "url": "/docs/data-science/ml-dl/svm.html#svc-as-an-inner-product",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#svc-as-an-inner-product"
  },"1299": {
    "doc": "Support Vector Machine",
    "title": "Kernel trick",
    "content": "Another way to solve non-linearly separable classifications is to use the kernel trick to transform the data. Commonly used method to solve non-linearly separable classifications is to use the kernel trick in conjunction with the soft-margin SVC. Let feature map $\\Phi$ be a non-linear transformation that maps the data from a lower-dimensional input space to a higher-dimensional feature space. $$ \\Phi: \\mathbb{R}^p \\rightarrow \\mathbb{R}^q \\quad \\text{where}\\quad q &gt; p $$ . Cover's theorem Cover’s theorem states that a linearly non-separable dataset in a lower-dimensional space may be linearly separable in a higher-dimensional space. Kernel $K(\\cdot)$ is a generalization of an inner product that satisfies the following: . $$ K(\\mathbf{x}_i, \\mathbf{x}_j) = \\Phi(\\mathbf{x}_i)^\\top \\Phi(\\mathbf{x}_j) \\quad \\forall \\mathbf{x}_i, \\mathbf{x}_j \\in \\mathbb{R}^p $$ . In other words, the kernel function is a function that given any two vectors in the input space, computes the dot product of them in the feature space. Loose intuition In the usual input space, the optimal solution given by the Lagrange multiplier method involves calculating the dot product of the observations $\\mathbf{x}_i^\\top \\mathbf{x}_j$. Since we now inflate the input space to a higher-dimensional feature space, we need to calculate the dot product of the observations in the feature space. So in order to replace the inner product of inputs, we need to find a kernel that can compute the dot product of the observations in the feature space for all possible pairs of observations. One key point is that as long as we can find a kernel with output that lives in the inner product space, we don’t have to have an explicitly defined feature map $\\Phi$. Radial basis function (RBF) kernel . Most commonly used kernel for SVC is the radial basis function (RBF) kernel. The RBF kernel is defined as: . \\[K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp \\left( -\\frac{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert^2}{2 \\sigma^2} \\right)\\] $\\sigma$ is a free variable that controls the flexibility of the decision boundary. Oftentimes, we define . \\[\\gamma = \\frac{1}{2 \\sigma^2}\\] Again, $\\frac{1}{2}$ in the denominator is just for convenience. You may find $\\gamma = \\frac{1}{\\sigma^2}$ in other sources. so that the RBF kernel is defined as: . $$ K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp \\left( -\\gamma \\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert^2 \\right) $$ . where $\\gamma &gt; 0$. Intuition When two observations are close to each other, the sum of squared differences will be small, making the entire kernel value larger. When two observations are far from each other, the sum of squared differences will be large, making the entire kernel value smaller. SVC replaced with the RBF kernel is represented as: . \\[f(\\mathbf{x}) = \\beta_0 + \\sum_{i \\in S} \\hat{\\alpha}_i K(\\mathbf{x}, \\mathbf{x}_i)\\] If the new observation $\\mathbf{x}$ is far from the support vectors, the kernel value will be small, and the contribution to the prediction will be small. So the RBF kernel shrinks the contribution of the support vectors as observation moves away from them. | Low $\\gamma$: decision boundary is less flexible, more linear | High $\\gamma$: decision boundary is more flexible | . ",
    "url": "/docs/data-science/ml-dl/svm.html#kernel-trick",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#kernel-trick"
  },"1300": {
    "doc": "Support Vector Machine",
    "title": "Support Vector Regression",
    "content": "Support vector regression (SVR) is a regression model using the similar concept as the soft margin SVC. What we do is try to fit a hyperplane that minimizes the residuals, while allowing some slack. In soft margin SVC, we had the hinge loss to define the slack variable. In SVR, we use the $\\varepsilon$-insensitive loss to define the slack variable: . $$ \\xi_i \\approx max(0, \\lvert y_i - \\hat{y}_i \\rvert - \\varepsilon) $$ . where $\\hat{y}_i$ is the predicted value for $y_i$: . \\[\\hat{y}_i = \\mathbf{w}^\\top \\mathbf{x}_i + b\\] While the hinge loss penalizes any deviation from the correct side of the margin, the $\\varepsilon$-insensitive loss only penalizes the deviation that is greater than the tube of width $2\\varepsilon$ around the hyperplane. We are insensitive to the residuals within $\\varepsilon$ distance. Hence the name. ",
    "url": "/docs/data-science/ml-dl/svm.html#support-vector-regression",
    
    "relUrl": "/docs/data-science/ml-dl/svm.html#support-vector-regression"
  },"1301": {
    "doc": "Symmetric, Positive Definite Matrix",
    "title": "Symmetric, Positive Definite Matrix",
    "content": "Related topics: . | Bi-Linear Mapping | General Inner Product | . | Relation to Inner Product . | Symmetric, Positive Semi-Definite Matrix | . | Nullspace of Symmetric, Positive Definite Matrix | Diagonal Elements of Symmetric, Positive Definite Matrix | . ",
    "url": "/docs/linalg/basics/sym-pos-def-matrix.html",
    
    "relUrl": "/docs/linalg/basics/sym-pos-def-matrix.html"
  },"1302": {
    "doc": "Symmetric, Positive Definite Matrix",
    "title": "Relation to Inner Product",
    "content": "Any general inner product can be represented as a matrix multiplication. The matrix that uniquely defines the inner product is called the symmetric, positive definite matrix. Let $V$ be an $n$-dimensional inner product space with inner product $\\langle\\cdot,\\cdot\\rangle: V \\times V \\rightarrow \\mathbb{R}$. Let $B = (\\mathbf{b}_1, \\dots, \\mathbf{b}_n)$ be an ordered basis of $V$. Any vector $\\mathbf{x}, \\mathbf{y} \\in V$ can be represented as a linear combination of the basis vectors: . \\[\\mathbf{x} = \\sum_{i=1}^n \\lambda_i \\mathbf{b}_i \\quad\\quad\\quad \\mathbf{y} = \\sum_{j=1}^n \\psi_j \\mathbf{b}_j\\] for some $\\lambda_i, \\psi_j \\in \\mathbb{R}$. Also, let $\\mathbf{\\hat{x}} = [\\lambda_1 \\dots \\lambda_n]^T$ and $\\mathbf{\\hat{y}} = [\\psi_1 \\dots \\psi_n]^T$, which are the coordinate vectors of $\\mathbf{x}$ and $\\mathbf{y}$ with respect to the ordered basis $B$. Often also denoted $[\\mathbf{x}]_B$ and $[\\mathbf{y}]_B$. See coordinate vectors with respect to orderded bases. The inner product $\\langle\\mathbf{x},\\mathbf{y}\\rangle$ have three properties: . | Bilinear | Symmetric | Positive definite | . First using bilinearity: . \\[\\langle\\mathbf{x},\\mathbf{y}\\rangle = \\left\\langle\\sum_{i=1}^n \\lambda_i \\mathbf{b}_i, \\sum_{j=1}^n \\psi_j \\mathbf{b}_j\\right\\rangle = \\sum_{i=1}^n \\sum_{j=1}^n \\lambda_i \\langle\\mathbf{b}_i, \\mathbf{b}_j\\rangle \\psi_j = \\mathbf{\\hat{x}}^T \\mathbf{A} \\mathbf{\\hat{y}}\\] $\\mathbf{\\hat{x}}, \\mathbf{\\hat{y}}$ are just coordinates, so $\\mathbf{A}$ is the matrix that uniquely defines the inner product operation. Because an inner product is symmetric, $\\mathbf{A}$ is also a symmetric matrix. Now using positive definiteness: . \\[\\begin{equation} \\label{eq:posdef} \\tag{Positive Definite} \\forall \\mathbf{x} \\in V\\setminus\\{\\mathbf{0}\\},\\, \\mathbf{x}^T \\mathbf{A} \\mathbf{x} &gt; 0 \\end{equation}\\] Such $\\mathbf{A}$ is called the symmetric, positive definite matrix. Hence, $\\langle\\mathbf{x},\\mathbf{y}\\rangle$ is a valid inner product if and only if there exists a symmetric, positive definite matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ such that . $$ \\langle\\mathbf{x},\\mathbf{y}\\rangle = \\mathbf{\\hat{x}}^T \\mathbf{A} \\mathbf{\\hat{y}} $$ . Again, remember that $\\hat{\\mathbf{x}}$ and $\\hat{\\mathbf{y}}$ are coordinate vectors of each respect to the ordered basis $B$. ",
    "url": "/docs/linalg/basics/sym-pos-def-matrix.html#relation-to-inner-product",
    
    "relUrl": "/docs/linalg/basics/sym-pos-def-matrix.html#relation-to-inner-product"
  },"1303": {
    "doc": "Symmetric, Positive Definite Matrix",
    "title": "Symmetric, Positive Semi-Definite Matrix",
    "content": "In equation \\eqref{eq:posdef}, if the inequality is loosened to $\\geq$, then $\\mathbf{A}$ is called the symmetric, positive semi-definite matrix. ",
    "url": "/docs/linalg/basics/sym-pos-def-matrix.html#symmetric-positive-semi-definite-matrix",
    
    "relUrl": "/docs/linalg/basics/sym-pos-def-matrix.html#symmetric-positive-semi-definite-matrix"
  },"1304": {
    "doc": "Symmetric, Positive Definite Matrix",
    "title": "Nullspace of Symmetric, Positive Definite Matrix",
    "content": "By definition, we know that $\\mathbf{x}^T \\mathbf{A} \\mathbf{x} &gt; 0$ for all $\\mathbf{x} \\neq \\mathbf{0}$. So trivially, $\\mathbf{A} \\mathbf{x} = \\mathbf{0}$ only when $\\mathbf{x} = \\mathbf{0}$. Therefore, the kernel of $\\mathbf{A}$ only contains the zero vector. In other words, the columns of $\\mathbf{A}$ are linearly independent. Also, $\\mathbf{A}$ is invertible. ",
    "url": "/docs/linalg/basics/sym-pos-def-matrix.html#nullspace-of-symmetric-positive-definite-matrix",
    
    "relUrl": "/docs/linalg/basics/sym-pos-def-matrix.html#nullspace-of-symmetric-positive-definite-matrix"
  },"1305": {
    "doc": "Symmetric, Positive Definite Matrix",
    "title": "Diagonal Elements of Symmetric, Positive Definite Matrix",
    "content": "Diagonal elements of $\\mathbf{A}$ are positive, because $a_{ii} = \\mathbf{e}_i^T \\mathbf{A} \\mathbf{e}_i &gt; 0$. ",
    "url": "/docs/linalg/basics/sym-pos-def-matrix.html#diagonal-elements-of-symmetric-positive-definite-matrix",
    
    "relUrl": "/docs/linalg/basics/sym-pos-def-matrix.html#diagonal-elements-of-symmetric-positive-definite-matrix"
  },"1306": {
    "doc": "Systems of Linear Equations",
    "title": "Systems of Linear Equations",
    "content": ". | Basic Terms . | System of Linear Equations | As a Matrix Equation | Solution | Augmented matrix | Pivots / Row Echelon / Reduced Row Echelon Form | Basic / Free Variables | Homogeneous System | . | Particular Solution | General Solution . | Minus-1 Trick | . | Solving Systems of Linear Equations in Practice . | Direct Methods | Iterative Methods | . | . ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html"
  },"1307": {
    "doc": "Systems of Linear Equations",
    "title": "Basic Terms",
    "content": " ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#basic-terms",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#basic-terms"
  },"1308": {
    "doc": "Systems of Linear Equations",
    "title": "System of Linear Equations",
    "content": "\\[\\begin{align*} a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n &amp;= b_1 \\\\ &amp;\\vdots \\\\ a_{m1}x_1 + a_{m2}x_2 + \\cdots + a_{mn}x_n &amp;= b_m \\end{align*}\\] . | $x_1, x_2, \\cdots, x_n$ are the unknowns. | . ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#system-of-linear-equations",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#system-of-linear-equations"
  },"1309": {
    "doc": "Systems of Linear Equations",
    "title": "As a Matrix Equation",
    "content": "System of linear equations can be compacted to: . \\[A\\mathbf{x} = \\mathbf{b}\\] where . | $A$ is the coefficient matrix | $\\mathbf{x}$ is the unknown vector | $\\mathbf{b}$ is the constant vector | . $\\mathbf{b}$ is a linear combination of the columns of $A$. ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#as-a-matrix-equation",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#as-a-matrix-equation"
  },"1310": {
    "doc": "Systems of Linear Equations",
    "title": "Solution",
    "content": "Every $n$-tuple $(x_1, x_2, \\cdots, x_n)$ that satisfies the system of linear equations is called a solution. Every system of linear equations has either: . | No solution: This is when we resort to approximation such as regression. | Unique solution | Infinitely many solutions | . ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#solution",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#solution"
  },"1311": {
    "doc": "Systems of Linear Equations",
    "title": "Augmented matrix",
    "content": "Matrix equation $A\\mathbf{x} = \\mathbf{b}$ can be further compacted as an augmented matrix: . e.g. \\[\\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\\\ \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\\\ \\end{bmatrix} = \\begin{bmatrix} 10 \\\\ 11 \\\\ 12 \\\\ \\end{bmatrix}\\] can be represented as an augmented matrix: . \\[\\left[ \\begin{array}{ccc|c} 1 &amp; 2 &amp; 3 &amp; 10 \\\\ 4 &amp; 5 &amp; 6 &amp; 11 \\\\ 7 &amp; 8 &amp; 9 &amp; 12 \\\\ \\end{array} \\right]\\] Finding the solution of a system of linear equations is equivalent to finding the reduced row echelon form of the augmented matrix. ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#augmented-matrix",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#augmented-matrix"
  },"1312": {
    "doc": "Systems of Linear Equations",
    "title": "Pivots / Row Echelon / Reduced Row Echelon Form",
    "content": "More here . ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#pivots--row-echelon--reduced-row-echelon-form",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#pivots--row-echelon--reduced-row-echelon-form"
  },"1313": {
    "doc": "Systems of Linear Equations",
    "title": "Basic / Free Variables",
    "content": "Take the following system: . \\[\\left[ \\begin{array}{cccc|c} 1 &amp; 0 &amp; 8 &amp; -4 &amp; 42 \\\\ 0 &amp; 1 &amp; 2 &amp; 12 &amp; 8 \\\\ \\end{array} \\right]\\] Which is a compact form of: . \\[\\begin{bmatrix} 1 &amp; 0 &amp; 8 &amp; -4 \\\\ 0 &amp; 1 &amp; 2 &amp; 12 \\\\ \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ \\end{bmatrix} = \\begin{bmatrix} 42 \\\\ 8 \\\\ \\end{bmatrix}\\] Basic variables are the variables corresponding to the pivot columns. The pivot columns are the columns with the pivot entries, which in this case are the first two columns. Free variables are the variables corresponding to the non-pivot columns. So in this case, $x_1$ and $x_2$ are basic variables, and $x_3$ and $x_4$ are free variables. ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#basic--free-variables",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#basic--free-variables"
  },"1314": {
    "doc": "Systems of Linear Equations",
    "title": "Homogeneous System",
    "content": "A system of linear equations is homogeneous if the constant vector $\\mathbf{b}$ is the zero vector. \\[A\\mathbf{x} = \\mathbf{0}\\] A homogeneous system always has at least one solution, which is the trivial solution $\\mathbf{x} = \\mathbf{0}$. Why homogeneous? In math, equations are homogeneous if all the terms are of the same degree. Let’s expand the system $A\\mathbf{x} = \\mathbf{b}$: . The equations are of the form: . \\[a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n = b_1\\] The other variables are of degree $1$. If $b_1$ is a constant, then it is not homogeneous. The only way to make it homogeneous is to have $b_1 = 0$. Therefore, a homogeneous system is of the form $A\\mathbf{x} = \\mathbf{0}$. ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#homogeneous-system",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#homogeneous-system"
  },"1315": {
    "doc": "Systems of Linear Equations",
    "title": "Particular Solution",
    "content": "A particular solution or special solution of a system can be any solution that satisfies the system (perhaps one of the many). The easiest way to identify one is to first bring your augmented matrix to a reduced row echelon form. e.g. \\[\\left[ \\begin{array}{ccccc|c} 1 &amp; -2 &amp; 0 &amp; 0 &amp; -2 &amp; 2 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -2 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right]\\] . | Basic variables: $x_1, x_3, x_4$ | Free variables: $x_2, x_5$ | . Setting the free variables to $0$, and solving for the basic variables will give you a particular solution: . \\[x = \\begin{bmatrix} 2 \\\\ 0 \\\\ -1 \\\\ 1 \\\\ 0 \\\\ \\end{bmatrix}\\] since . \\[2c_1 + 0c_2 - 1c_3 + 1c_4 + 0c_5 = \\begin{bmatrix} 2 \\\\ -1 \\\\ 1 \\\\ 0 \\\\ \\end{bmatrix}\\] . ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#particular-solution",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#particular-solution"
  },"1316": {
    "doc": "Systems of Linear Equations",
    "title": "General Solution",
    "content": "A general solution is the set of all possible solutions. A particular solution combined with the null space or kernel of the coefficient matrix forms the general solution set. Say we have a particular solution $\\mathbf{x_p}$, s.t. $A\\mathbf{x_p} = \\mathbf{b}$. $\\forall \\mathbf{u_i} \\in \\ker(A)$, $A\\mathbf{u_i} = \\mathbf{0}$. Then $A(\\mathbf{x_p} + \\mathbf{u_i}) = \\mathbf{b}$. Furthermore, $A(\\mathbf{x_p} + \\lambda_i \\mathbf{u_i}) = \\mathbf{b}$. Then the general solution set is: . \\[\\set{ x \\in \\mathbb{R}^n \\mid \\forall \\lambda_i \\in \\mathbb{R},\\, x = \\mathbf{x_p} + \\lambda_i \\mathbf{u_i} }\\] ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#general-solution",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#general-solution"
  },"1317": {
    "doc": "Systems of Linear Equations",
    "title": "Minus-1 Trick",
    "content": "There is a quick trick to identify the kernel of a matrix, or finding the solutions to a homogeneous system $A\\mathbf{x} = \\mathbf{0}$. First reduce the matrix to a reduced row echelon form, e.g. \\[A = \\left[ \\begin{array}{ccccc} 1 &amp; 3 &amp; 0 &amp; 0 &amp; 3 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 9 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -4 \\\\ \\end{array} \\right]\\] Then augment the matrix to a square matrix so that the diagonal elements are $1$ for the pivot columns, and $-1$ for the non-pivot columns. \\[\\tilde{A} = \\left[ \\begin{array}{ccccc} 1 &amp; 3 &amp; 0 &amp; 0 &amp; 3 \\\\ 0 &amp; \\mathbf{-1} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 9 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -4 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\mathbf{-1} \\\\ \\end{array} \\right]\\] Then the solutions to the homogeneous system consists of the columns with $-1$: . \\[\\ker(A) = \\left\\{ \\begin{bmatrix} 3 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix}, \\begin{bmatrix} 3 \\\\ 0 \\\\ 9 \\\\ -4 \\\\ -1 \\\\ \\end{bmatrix} \\right\\}\\] . ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#minus-1-trick",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#minus-1-trick"
  },"1318": {
    "doc": "Systems of Linear Equations",
    "title": "Solving Systems of Linear Equations in Practice",
    "content": " ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#solving-systems-of-linear-equations-in-practice",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#solving-systems-of-linear-equations-in-practice"
  },"1319": {
    "doc": "Systems of Linear Equations",
    "title": "Direct Methods",
    "content": "To solve a system of linear equations $Ax = b$, one often resorts to calculating the inverse matrix $A^{-1}$. However, inverse matrix is not defined for most matrices. Moore-Penrose pseudoinverse Moore-Penrose pseudoinverse is a more loose version of the inverse under the mild assumption that $A$ has linearly independent columns. It is defined as $(A^TA)^{-1}A^T$. Quick derivation is: . \\[A\\mathbf{x} = \\mathbf{b} \\Leftrightarrow A^TA\\mathbf{x} = A^T\\mathbf{b} \\Leftrightarrow \\mathbf{x} = (A^TA)^{-1}A^T\\mathbf{b}\\] However, this is also not recommended because it is computationally expensive. Gaussian elimination is also impractical for large in real-life matrices. ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#direct-methods",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#direct-methods"
  },"1320": {
    "doc": "Systems of Linear Equations",
    "title": "Iterative Methods",
    "content": "In practice, iterative methods are used to find the solutions indirectly. ",
    "url": "/docs/linalg/basics/systems-of-linear-equations.html#iterative-methods",
    
    "relUrl": "/docs/linalg/basics/systems-of-linear-equations.html#iterative-methods"
  },"1321": {
    "doc": "Terraform Module",
    "title": "Terraform Module",
    "content": ". | What is a Terraform module | Typical file structure | Module structure | Module input variables | How to call a module | Itty Bitties | . ",
    "url": "/docs/terraform/terraform-module.html",
    
    "relUrl": "/docs/terraform/terraform-module.html"
  },"1322": {
    "doc": "Terraform Module",
    "title": "What is a Terraform module",
    "content": "It is sort of like a class in programming. Given input variables, it can be reused to create multiple instances of the infra described in the module. For example, when you’re creating an AWS lambda resource, there are typically some other resources associated with it, such as the REST API, IAM role, etc. If you think you’re going to be using this pattern often, you can create a module containing all the common resources and only expose some input variables that need to be configured at the top level. ",
    "url": "/docs/terraform/terraform-module.html#what-is-a-terraform-module",
    
    "relUrl": "/docs/terraform/terraform-module.html#what-is-a-terraform-module"
  },"1323": {
    "doc": "Terraform Module",
    "title": "Typical file structure",
    "content": "The main Terraform execution point is called the root module. This is often the main.tf file in the top level driectory. Modules are often placed in a folder called modules. ├── README.md ├── main.tf ├── modules ├── outputs.tf └── variables.tf . ",
    "url": "/docs/terraform/terraform-module.html#typical-file-structure",
    
    "relUrl": "/docs/terraform/terraform-module.html#typical-file-structure"
  },"1324": {
    "doc": "Terraform Module",
    "title": "Module structure",
    "content": "Inside modules directory, create a child directory with a name of your module: e.g. mymodule. ├── main.tf ├── modules │   └── mymodule │      ├── main.tf │      ├── outputs.tf │      └── variables.tf ├── outputs.tf └── variables.tf . The structure inside mymodule is optional. They can be separated as above or smashed into a single file. ",
    "url": "/docs/terraform/terraform-module.html#module-structure",
    
    "relUrl": "/docs/terraform/terraform-module.html#module-structure"
  },"1325": {
    "doc": "Terraform Module",
    "title": "Module input variables",
    "content": "Unless you plan to reuse your module as-is every single time, you typically provide input variables to modules. Any variables defined with variable must be provided by the calling module or an error will be raised. ",
    "url": "/docs/terraform/terraform-module.html#module-input-variables",
    
    "relUrl": "/docs/terraform/terraform-module.html#module-input-variables"
  },"1326": {
    "doc": "Terraform Module",
    "title": "How to call a module",
    "content": "All you need to do is feed the necessary input variables. In main.tf, . # main.tf module \"module_a\" { source = \"./modules/mymodule\" my_input_var = \"Here you go\" } . Notice that the source attribute points the the directory of the module, not any specific files . If you defined any output variables in the module with output, you can access them by: . module.module_a.my_output_var . ",
    "url": "/docs/terraform/terraform-module.html#how-to-call-a-module",
    
    "relUrl": "/docs/terraform/terraform-module.html#how-to-call-a-module"
  },"1327": {
    "doc": "Terraform Module",
    "title": "Itty Bitties",
    "content": ". | Although you can nest your modules in multiple levels, it is recommended to keep the entire Terraform module as flat as possible. | Even if you don’t access them, module output variables is always output after terraform apply. | Think about whether a module is absolutely necessary. Sometimes you may end up feeding in as many input variablesas the original resource. | . ",
    "url": "/docs/terraform/terraform-module.html#itty-bitties",
    
    "relUrl": "/docs/terraform/terraform-module.html#itty-bitties"
  },"1328": {
    "doc": "Provision with Terraform",
    "title": "Provision with Terraform",
    "content": ". | Configuration | . ",
    "url": "/docs/demo/flask-login-app/terraform.html",
    
    "relUrl": "/docs/demo/flask-login-app/terraform.html"
  },"1329": {
    "doc": "Provision with Terraform",
    "title": "Configuration",
    "content": "Folder structure . flask-mongodb ├── backend │   ├── .gitignore │   ├── .dockerignore │   ├── app.py │   ├── back.dev.Dockerfile │   ├── requirements.txt │   └── venv │   └── flaskmongo └── terraform ├── main.tf └── providers.tf . We are going to be using a docker provider. # flask-mongodb/terraform/main.tf terraform { required_providers { docker = { source = \"kreuzwerker/docker\" version = \"~&gt; 2.11.0\" } } required_version = \"~&gt; 0.15.3\" } . # flask-mongodb/terraform/providers.tf provider \"docker\" { host = \"unix:///var/run/docker.sock\" } resource \"docker_container\" \"backend_tf\" { name = \"backend-tf\" image = docker_image.flask_back.latest volumes { container_path = \"/www\" host_path = \"/full/path/to/flask-mongodb/backend\" read_only = true } ports { internal = 5000 external = 5000 } } resource \"docker_image\" \"flask_back\" { name = \"flask-back:latest\" build { path = \"../backend\" dockerfile = \"back.dev.Dockerfile\" force_remove = true } } . Now initialize to download and install providers in .terraform and apply to create . terraform init terraform apply --auto-approve . To verify that docker image has been built and container is running . docker images | grep flask-back docker ps | grep backend-tf . Because volume is mounted, any change in directory backend will be reflected in the container. To destroy all resources created . terraform destroy . ",
    "url": "/docs/demo/flask-login-app/terraform.html#configuration",
    
    "relUrl": "/docs/demo/flask-login-app/terraform.html#configuration"
  },"1330": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Test Error Estimation / Model Selection",
    "content": ". | What is Test Error Estimation? . | Test Set | Test Error | Model Selection | . | Validation Set Approach | Cross-Validation | Bootstrap Underestimates Test Error | Adjusted Training Error . | Mallows’s $C_p$ | AIC and BIC | Adjusted $R^2$ | Comparison to Cross-Validation | . | One-Standard-Error Rule | . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html"
  },"1331": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "What is Test Error Estimation?",
    "content": " ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#what-is-test-error-estimation",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#what-is-test-error-estimation"
  },"1332": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Test Set",
    "content": "A test set is the set of data specifically designated for testing only. Except for some special occasions, the data we have is often limited and barely enough to train the model, let alone to test it. ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#test-set",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#test-set"
  },"1333": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Test Error",
    "content": "Because we don’t have enough data to test the model, test error is technically an unknown. That is why we need a method to estimate the test error. There are two common approaches: . | Directly estimate the test error by holding out a subset of the data . | Validation Set Approach, Cross-Validation | . | Indirectly estimate the test error with adjusted training error . Adjustment is necessary since training errors can grossly underestimate the test error. | $C_p$, AIC, BIC, Adjusted $R^2$ | . | . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#test-error",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#test-error"
  },"1334": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Model Selection",
    "content": "Estimates of test error allow us to compare different models, and thus it is crucial for model selection. Validation set approach, cross-validation, and adjusted training error methods all ultimately aim to help us choose the best model. ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#model-selection",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#model-selection"
  },"1335": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Validation Set Approach",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#validation-set-approach",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#validation-set-approach"
  },"1336": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Cross-Validation",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#cross-validation",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#cross-validation"
  },"1337": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Bootstrap Underestimates Test Error",
    "content": "You will see that bootstrap is also a resampling method like cross-validation. Bootstrap is more commonly used to estimate the variance of an estimator, while cross-validation is used to estimate the test error of a model. | Why not use bootstrap to estimate the test error? | . If we were to use bootstrap, what can we use as a validation set? One idea is to use the original dataset as the validation set. Each bootstrap sample contains about $2/3$ of the original data. Why? Let $n$ be the number of samples in the original dataset. The probability of a sample $i$ not being selected in a bootstrap sample (sampled with replacement and also of size $n$) is: . \\[\\lim_{n \\to \\infty} \\left(\\frac{n-1}{n}\\right)^n \\approx \\frac{1}{e} \\approx 0.368\\] So the probability of sample $i$ being in a bootstrap sample is about $2/3$. Cross-validation works because it makes sure there is no overlap between training and validation sets. However, with this validation set, there is a significant correlation between the bootstrap training set and the validation set, which leads to huge underestimation of the test error. So, for bootstrapping to work, we’d actually have to cherry-pick the samples that were by luck not included in the bootstrap training sets, and use them as a validation set (known as out-of-bag error). But this gets messy, so we stick to cross-validation for test error estimation. ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#bootstrap-underestimates-test-error",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#bootstrap-underestimates-test-error"
  },"1338": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Adjusted Training Error",
    "content": "Validation set approach and cross-validation tries to estimate the performance of the model by directly estimating the test error. There are ways to estimate the performance indirectly, mainly by doing some calculations on the training error. Since training error can be minimized by overfitting complex models, these methods usually include penalty terms for complexity. ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#adjusted-training-error",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#adjusted-training-error"
  },"1339": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Mallows’s $C_p$",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#mallowss-c_p",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#mallowss-c_p"
  },"1340": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "AIC and BIC",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#aic-and-bic",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#aic-and-bic"
  },"1341": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Adjusted $R^2$",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#adjusted-r2",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#adjusted-r2"
  },"1342": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "Comparison to Cross-Validation",
    "content": ". | CV makes fewer assumptions about the true model. | Adjusted training error estimates require an estimate of $\\Var(\\epsilon)$, the variance of the error term. | CV is better when it is hard to estimate $\\Var(\\epsilon)$. | . | CV is computationally more expensive. | . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#comparison-to-cross-validation",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#comparison-to-cross-validation"
  },"1343": {
    "doc": "Test Error Estimation / Model Selection",
    "title": "One-Standard-Error Rule",
    "content": "See here . ",
    "url": "/docs/data-science/ml-dl/test-error-estimation.html#one-standard-error-rule",
    
    "relUrl": "/docs/data-science/ml-dl/test-error-estimation.html#one-standard-error-rule"
  },"1344": {
    "doc": "tfenv",
    "title": "tfenv",
    "content": "Much like rbenv, pyenv . | Installation | Usage . | List all versions available | Install and uninstall | List all installed versions | Use a specific version | Print current version | Pin current version to project | . | . ",
    "url": "/docs/terraform/tfenv.html",
    
    "relUrl": "/docs/terraform/tfenv.html"
  },"1345": {
    "doc": "tfenv",
    "title": "Installation",
    "content": "brew install tfenv . tfenv conflicts with terraform, so if you have terraform installed, you need to uninstall it first. ",
    "url": "/docs/terraform/tfenv.html#installation",
    
    "relUrl": "/docs/terraform/tfenv.html#installation"
  },"1346": {
    "doc": "tfenv",
    "title": "Usage",
    "content": "List all versions available . tfenv list-remote . Install and uninstall . tfenv install [version] tfenv uninstall [version] . List all installed versions . tfenv list . Use a specific version . tfenv use [version] . Print current version . tfenv version-name . Pin current version to project . tfenv pin . Command above will create a .terraform-version file in the current directory. References: . | tfenv Github | . ",
    "url": "/docs/terraform/tfenv.html#usage",
    
    "relUrl": "/docs/terraform/tfenv.html#usage"
  },"1347": {
    "doc": "Exploring Time Series Data",
    "title": "Exploring Time Series Data",
    "content": ". | What is Time Series Data? . | Univariate vs Multivariate | Obtaining prepared data | . | Collecting Time Series Data from Database | Characteristics of Time Series Data | Basic Exploratory Data Analysis on Time Series . | Line plot | Difference histogram | Scatter plot of features | Rolling windows | . | . ",
    "url": "/docs/data-science/time-series/time-series-data.html",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html"
  },"1348": {
    "doc": "Exploring Time Series Data",
    "title": "What is Time Series Data?",
    "content": "Time series data is a sequence of observations. It does not matter what the unit of time is, what matters is: . | Unique and meaningful ordering | Intervals at which the observations were made | . ",
    "url": "/docs/data-science/time-series/time-series-data.html#what-is-time-series-data",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#what-is-time-series-data"
  },"1349": {
    "doc": "Exploring Time Series Data",
    "title": "Univariate vs Multivariate",
    "content": ". | Univariate: If a single variable is measured against time | Multivariate: If multiple variables are measured against time. Useful for analysis of interrelations. | . ",
    "url": "/docs/data-science/time-series/time-series-data.html#univariate-vs-multivariate",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#univariate-vs-multivariate"
  },"1350": {
    "doc": "Exploring Time Series Data",
    "title": "Obtaining prepared data",
    "content": "Easiest way to begin an analysis is to obtain prepared data: . | Competition data (i.e. Kaggle) | Repository of research labs (i.e. UCI Machine Learning Repository) | Data from government agencies | . For beginners, government data is not suitable for learning. Even experts devote their entire career to analyze the data due to its complexity. For starters, it is better to use them only for exploratory analysis or visualization. ",
    "url": "/docs/data-science/time-series/time-series-data.html#obtaining-prepared-data",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#obtaining-prepared-data"
  },"1351": {
    "doc": "Exploring Time Series Data",
    "title": "Collecting Time Series Data from Database",
    "content": "It is common to collect time series data from sources not originally intended for time series. Most common example is extracting analysis data from database. Often called data wrangling or data munging. The following are some of the DOs and DON’Ts: . | Integrating data from various tables to create a single time series brings about interesting analysis topics, but caution is needed due to: . | Disparate timestamp conventions | Different levels of granularity | . | Clarify whether each column of the data is really what you think it is . | For example, does the column status refer to the current status or the status at the time of the observation? | If a column says time, does it refer to the created time or the updated time? | . | Avoid lookahead | Understand recording conventions | Understand whether null values are included in the records . | If the DB does not record zero values, you may have to fill in the missing values with zeros. | . | Decide if you want to omit the start and end of the records . | Often, the start and end of the records are anomalous which only brings noise to the analysis. | . | Beware of time zone differences . | Although most databases store timestamps in UTC, it is not always the case. | . | Know whether the data was human-generated or machine-generated | . ",
    "url": "/docs/data-science/time-series/time-series-data.html#collecting-time-series-data-from-database",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#collecting-time-series-data-from-database"
  },"1352": {
    "doc": "Exploring Time Series Data",
    "title": "Characteristics of Time Series Data",
    "content": ". | Seasonality | Stationarity | Autocorrelation | Spurious correlation | . ",
    "url": "/docs/data-science/time-series/time-series-data.html#characteristics-of-time-series-data",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#characteristics-of-time-series-data"
  },"1353": {
    "doc": "Exploring Time Series Data",
    "title": "Basic Exploratory Data Analysis on Time Series",
    "content": "Various exploratory methods applied to time series data. ",
    "url": "/docs/data-science/time-series/time-series-data.html#basic-exploratory-data-analysis-on-time-series",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#basic-exploratory-data-analysis-on-time-series"
  },"1354": {
    "doc": "Exploring Time Series Data",
    "title": "Line plot",
    "content": "The most obvious thing you would do. Simply drawing a line plot of time series data actually reveals a lot of insight due to the temporal nature of the data. Stacking multiple time series data on top of each other can reveal interesting patterns. ",
    "url": "/docs/data-science/time-series/time-series-data.html#line-plot",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#line-plot"
  },"1355": {
    "doc": "Exploring Time Series Data",
    "title": "Difference histogram",
    "content": "When you use a value-frequency histogram for a time series, it is often beneficial to plot the histogram of the difference between adjacent values. Because each value by itself may not be very informative. It is also important to choose the right bin size. Otherwise you’ll just get a bunch of meaningless spikes that mask the underlying distribution, which is not very informative. Plotting the difference histogram can also be used to determine long-term bias in the data: whether the values tend to increase or decrease in the long run. ",
    "url": "/docs/data-science/time-series/time-series-data.html#difference-histogram",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#difference-histogram"
  },"1356": {
    "doc": "Exploring Time Series Data",
    "title": "Scatter plot of features",
    "content": "If we have multiple time series data, we can match the data points by timestamp and plot them against each other using a scatter plot. This can reveal correlations between different features or indexes. However, just like the histogram, each value in a time series data are not very informative. So it is often better to plot using the difference between adjacent values. Instead of matching the data points by timestamp, you can do another correlation analysis by giving a time lag to one of the time series data. Doing so can reveal whether one feature can be a predictor of another. ",
    "url": "/docs/data-science/time-series/time-series-data.html#scatter-plot-of-features",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#scatter-plot-of-features"
  },"1357": {
    "doc": "Exploring Time Series Data",
    "title": "Rolling windows",
    "content": "The rolling window method can be used to identify important characteristics like stationarity, etc. ",
    "url": "/docs/data-science/time-series/time-series-data.html#rolling-windows",
    
    "relUrl": "/docs/data-science/time-series/time-series-data.html#rolling-windows"
  },"1358": {
    "doc": "Towers of Hanoi",
    "title": "Towers of Hanoi",
    "content": "One of the most famous recursive problems. | Gist of the problem | Recursive solution . | Base case | Inductive step | . | Pseudocode | . ",
    "url": "/docs/compsci/algo/towers-of-hanoi.html",
    
    "relUrl": "/docs/compsci/algo/towers-of-hanoi.html"
  },"1359": {
    "doc": "Towers of Hanoi",
    "title": "Gist of the problem",
    "content": "There are three pegs (source, goal, auxiliary), and $n$ disks of different sizes. The disks are initially sorted on the source peg, with the largest disk at the bottom. The goal is to move all the disks to the target peg, in the same sorted order. You can only move one disk at a time (the one on the top of a peg), and you cannot place a larger disk on top of a smaller disk. ",
    "url": "/docs/compsci/algo/towers-of-hanoi.html#gist-of-the-problem",
    
    "relUrl": "/docs/compsci/algo/towers-of-hanoi.html#gist-of-the-problem"
  },"1360": {
    "doc": "Towers of Hanoi",
    "title": "Recursive solution",
    "content": " ",
    "url": "/docs/compsci/algo/towers-of-hanoi.html#recursive-solution",
    
    "relUrl": "/docs/compsci/algo/towers-of-hanoi.html#recursive-solution"
  },"1361": {
    "doc": "Towers of Hanoi",
    "title": "Base case",
    "content": "When there is one disk, move it from the source peg to the target peg. ",
    "url": "/docs/compsci/algo/towers-of-hanoi.html#base-case",
    
    "relUrl": "/docs/compsci/algo/towers-of-hanoi.html#base-case"
  },"1362": {
    "doc": "Towers of Hanoi",
    "title": "Inductive step",
    "content": "Note our base case for a single disk. We can move the single disk from the source peg to the target peg. It is important to note that a solution is not limited to just moving the disk from the source peg to the target peg. It is a solution that can be used to move the disk from one peg to another peg (given the help of the auxiliary peg). Now what if there was actually a larger second disk at the bottom of the source peg? . Since this is the largest disk, it does not invalidate our previous solution. We can still use our solution for the single disk, so that one disk is now on the auxiliary peg. Then, we can move the second disk (the largest disk) from the source peg to the target peg. It is important to understand that once you’ve moved the current largest disk to the target peg, it essentially disappears from the problem as if it was never there in the first place. Now we have a single disk on the auxiliary peg, which means we can use our base case solution to move the disk to the target peg. Then we have solved the problem for two disks. There exists a way to move the two disks from one peg to another peg in the same sorted order. What if there was actually a third disk at the bottom of the initial source peg? . For the top two disks, we can use the previous solution to move them to the auxiliary peg. Then we move the third disk (largest disk) from the source peg to the target peg. Since the largest disk is on the target peg, it disappears from the problem. Now we have two disks on the auxiliary peg, we can use the previous solution to move them to the target peg. Then we have solved the problem for three disks. With $n$ disks, the same thing happens. We move the top $n-1$ disks to the auxiliary peg, using a previous solution. We move the largest disk left on the source peg to the target peg. Then this target peg disappears from the problem. We can move the $n-1$ disks from the auxiliary peg to the target peg, because we’re back to our previous case of $n-1$ disks. ",
    "url": "/docs/compsci/algo/towers-of-hanoi.html#inductive-step",
    
    "relUrl": "/docs/compsci/algo/towers-of-hanoi.html#inductive-step"
  },"1363": {
    "doc": "Towers of Hanoi",
    "title": "Pseudocode",
    "content": "def move_disk(from, to): print \"Move disk from \" + from + \" to \" + to def towers_of_hanoi(n, source, target, aux): if n &lt; 0: return if n == 1: return move_disk(source, target) towers_of_hanoi(n - 1, source, aux, target) move_disk(source, target) towers_of_hanoi(n - 1, aux, target, source) . ",
    "url": "/docs/compsci/algo/towers-of-hanoi.html#pseudocode",
    
    "relUrl": "/docs/compsci/algo/towers-of-hanoi.html#pseudocode"
  },"1364": {
    "doc": "1 - Two Sum - Easy",
    "title": "Two Sum",
    "content": ". | Problem | With a hash map | With sorting | . ",
    "url": "/docs/compsci/leetcode/two-sum.html#two-sum",
    
    "relUrl": "/docs/compsci/leetcode/two-sum.html#two-sum"
  },"1365": {
    "doc": "1 - Two Sum - Easy",
    "title": "Problem",
    "content": "Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. Input: nums = [2,7,11,15], target = 9 Output: [0,1] . ",
    "url": "/docs/compsci/leetcode/two-sum.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/two-sum.html#problem"
  },"1366": {
    "doc": "1 - Two Sum - Easy",
    "title": "With a hash map",
    "content": ". | Create a hash map that maps each number in nums to its index. | Go through the elements of num and check if target - num[i] is in the map. | If you found a match, return the indices i and hashmap[target - num[i]]. | . This approach is $O(n)$. ",
    "url": "/docs/compsci/leetcode/two-sum.html#with-a-hash-map",
    
    "relUrl": "/docs/compsci/leetcode/two-sum.html#with-a-hash-map"
  },"1367": {
    "doc": "1 - Two Sum - Easy",
    "title": "With sorting",
    "content": ". | Sort the array in ascending order. | Initialize two pointers i and j at the beginning and the end of the array, respectively. | If nums[i] + nums[j] &gt; target, decrement j. | If nums[i] + nums[j] &lt; target, increment i. | If nums[i] + nums[j] == target, return i and j. | . The caveat is i and j are not the indices of the original array. You need to find the indices of nums[i] and nums[j] in the original array. This approach is $O(n \\log n)$ because of the sorting. ",
    "url": "/docs/compsci/leetcode/two-sum.html#with-sorting",
    
    "relUrl": "/docs/compsci/leetcode/two-sum.html#with-sorting"
  },"1368": {
    "doc": "1 - Two Sum - Easy",
    "title": "1 - Two Sum - Easy",
    "content": " ",
    "url": "/docs/compsci/leetcode/two-sum.html",
    
    "relUrl": "/docs/compsci/leetcode/two-sum.html"
  },"1369": {
    "doc": "Useful Commands",
    "title": "Useful CLI Commands",
    "content": ". | lsbom | networksetup | netstat | ifconfig | system_profiler | fzf (+ Oh-My-Zsh) . | Usage example | . | fasd (+ Oh-My-Zsh) | . ",
    "url": "/docs/learned/useful.html#useful-cli-commands",
    
    "relUrl": "/docs/learned/useful.html#useful-cli-commands"
  },"1370": {
    "doc": "Useful Commands",
    "title": "lsbom",
    "content": "Lists the contents of an installer’s bom (bill of materials) file, which contains information on what files were added to the system. My preferred usage: . lsbom -f -l -s -pf /var/db/receipts/&lt;some-package-name&gt;.bom &gt;&gt; package-bom.txt # Inspect manually vim package-bom.txt # Then pipe it to some rm code, etc. # cat package-bom.txt | while read f; do ...; done . ",
    "url": "/docs/learned/useful.html#lsbom",
    
    "relUrl": "/docs/learned/useful.html#lsbom"
  },"1371": {
    "doc": "Useful Commands",
    "title": "networksetup",
    "content": "To see all hardware ports (Wi-Fi, Bluetooth, Thunderbolt, etc.) . networksetup -listallhardwareports . ",
    "url": "/docs/learned/useful.html#networksetup",
    
    "relUrl": "/docs/learned/useful.html#networksetup"
  },"1372": {
    "doc": "Useful Commands",
    "title": "netstat",
    "content": "To see all current in/outbound network connections . netstat -i . ",
    "url": "/docs/learned/useful.html#netstat",
    
    "relUrl": "/docs/learned/useful.html#netstat"
  },"1373": {
    "doc": "Useful Commands",
    "title": "ifconfig",
    "content": "To see all network devices on machine . ifconfig . ",
    "url": "/docs/learned/useful.html#ifconfig",
    
    "relUrl": "/docs/learned/useful.html#ifconfig"
  },"1374": {
    "doc": "Useful Commands",
    "title": "system_profiler",
    "content": "Command line version of the GUI System Profiler on macOS. To list USB devices, . system_profiler SPUSBDataType . ",
    "url": "/docs/learned/useful.html#system_profiler",
    
    "relUrl": "/docs/learned/useful.html#system_profiler"
  },"1375": {
    "doc": "Useful Commands",
    "title": "fzf (+ Oh-My-Zsh)",
    "content": "Usage example . vim $(fzf) . ",
    "url": "/docs/learned/useful.html#fzf--oh-my-zsh",
    
    "relUrl": "/docs/learned/useful.html#fzf--oh-my-zsh"
  },"1376": {
    "doc": "Useful Commands",
    "title": "fasd (+ Oh-My-Zsh)",
    "content": "To be added . ",
    "url": "/docs/learned/useful.html#fasd--oh-my-zsh",
    
    "relUrl": "/docs/learned/useful.html#fasd--oh-my-zsh"
  },"1377": {
    "doc": "Useful Commands",
    "title": "Useful Commands",
    "content": " ",
    "url": "/docs/learned/useful.html",
    
    "relUrl": "/docs/learned/useful.html"
  },"1378": {
    "doc": "Useful Notes",
    "title": "Useful Notes",
    "content": ". | Use multiple GitHub accounts with SSH . | Generate a new SSH key | Add the new SSH key to GitHub account | Modify config | Local config per repository | Add remote | . | . ",
    "url": "/docs/git-hub/github/useful.html",
    
    "relUrl": "/docs/git-hub/github/useful.html"
  },"1379": {
    "doc": "Useful Notes",
    "title": "Use multiple GitHub accounts with SSH",
    "content": "First navigate to ~/.ssh. For organization, create a directory and name it github. All private and public keys for GitHub connection will be placed here. Generate a new SSH key . Follow the ssh-keygen prompt. It will ask you to decide on a name for the file, passphrase, etc. # If Ed25519 algorithm is supported ssh-keygen -t ed25519 -C \"your_github@email.com\" . # Legacy RSA ssh-keygen -t rsa -b 4096 -C \"your_github@email.com\" . Add the new SSH key to GitHub account . Easiest part. Refer to GitHub documentation for step-by-step screencaps. Modify config . Suppose I have two GitHub accounts each associated with personal_email@address.com and work_email@address.com. I’ll assume the private keys are named github-personal and github-work respectively. Now append the following to ~/.ssh/config . Host github-personal HostName github.com User git IdentityFile ~/.ssh/github/github-personal Host github-work HostName github.com User git IdentityFile ~/.ssh/github/github-work . You can define custom host for both as such or have one of them keep the default github.com. Local config per repository . First start a local repo with . git init . Then config local name and email that will be used for that repo . git config --local user.name \"work_name\" git config --local user.email \"work_email@address.com\" . Add remote . Normally you would add an ssh remote by . git remote add origin git@github.com:github_username:repo_name # OR git remote add origin github.com:github_username:repo_name . But this time, . git remote add origin github-work:work_username:repo_name . References: . | GitHub: SSH | . ",
    "url": "/docs/git-hub/github/useful.html#use-multiple-github-accounts-with-ssh",
    
    "relUrl": "/docs/git-hub/github/useful.html#use-multiple-github-accounts-with-ssh"
  },"1380": {
    "doc": "Useful Git Commands",
    "title": "Useful Commands",
    "content": ". | Configuration . | See current configuration | Global user config | Local user config | Command alias | Global ignore | . | Untrack file | Fix previous commit | Rebase | Cherry Pick | Remove or modify a commit with rebase | Reset status . | To remove all uncommitted changes | Undo last (few) commit(s) without losing changes | . | Prune remote branches | . ",
    "url": "/docs/git-hub/git/useful.html#useful-commands",
    
    "relUrl": "/docs/git-hub/git/useful.html#useful-commands"
  },"1381": {
    "doc": "Useful Git Commands",
    "title": "Configuration",
    "content": "See current configuration . git config --list . Global user config . git config --global user.name \"myname\" git config --global user.email \"myemail@example.com\" . Local user config . Useful when you need to use different identity per project, . git config --local user.name \"anothername\" git config --local user.email \"anotheremail@example.com\" . Command alias . If you’re tired of writing long git commands that you frequently use, . git config --global alias.youralias \"command to shorten (without 'git')\" . Global ignore . First create a ~/.gitignore_global file. Then, . git config --global core.excludeFile ~/.gitignore_global . ",
    "url": "/docs/git-hub/git/useful.html#configuration",
    
    "relUrl": "/docs/git-hub/git/useful.html#configuration"
  },"1382": {
    "doc": "Useful Git Commands",
    "title": "Untrack file",
    "content": "When you have a file that you would like to untrack, . git rm -r --cached &lt;file-or-dir&gt; . ",
    "url": "/docs/git-hub/git/useful.html#untrack-file",
    
    "relUrl": "/docs/git-hub/git/useful.html#untrack-file"
  },"1383": {
    "doc": "Useful Git Commands",
    "title": "Fix previous commit",
    "content": "This comes in handy when you make a small change in your code after you’ve committed, but you realize you probably wanted it included in your last commit. # Modify commit message as well git commit --amend . # Keep the commit message git commit --amend --no-edit . If you already pushed the commit to a remote before the ammend, then you need to force push the new changes by git push -f origin master. ",
    "url": "/docs/git-hub/git/useful.html#fix-previous-commit",
    
    "relUrl": "/docs/git-hub/git/useful.html#fix-previous-commit"
  },"1384": {
    "doc": "Useful Git Commands",
    "title": "Rebase",
    "content": "To rebase from a remote, . git fetch git rebase origin/main . Or simply . git pull --rebase . ",
    "url": "/docs/git-hub/git/useful.html#rebase",
    
    "relUrl": "/docs/git-hub/git/useful.html#rebase"
  },"1385": {
    "doc": "Useful Git Commands",
    "title": "Cherry Pick",
    "content": "To cherry pick a single commit from anothe branch, first check the hash of the commit. Then, . git cherry-pick &lt;hash&gt; . ",
    "url": "/docs/git-hub/git/useful.html#cherry-pick",
    
    "relUrl": "/docs/git-hub/git/useful.html#cherry-pick"
  },"1386": {
    "doc": "Useful Git Commands",
    "title": "Remove or modify a commit with rebase",
    "content": "To modify a commit from the past, first check the number of commits you must go back to find the commit you want to modify. Then, . git rebase -i HEAD~&lt;num-commits-to-target-inclusive&gt; . Then you can choose an action for each commit by editing the text editor which looks like: . pick &lt;hash&gt; A Commit Message4 pick &lt;hash&gt; A Commit Message3 pick &lt;hash&gt; A Commit Message2 pick &lt;hash&gt; A Commit Message1 . Modify pick to a command listed in the editor comments. ",
    "url": "/docs/git-hub/git/useful.html#remove-or-modify-a-commit-with-rebase",
    
    "relUrl": "/docs/git-hub/git/useful.html#remove-or-modify-a-commit-with-rebase"
  },"1387": {
    "doc": "Useful Git Commands",
    "title": "Reset status",
    "content": "There are 5 types of reset: --soft, --mixed, --hard, --merge, and --keep. Each type of reset has different effects on the index, working tree, and HEAD. The first three are the most commonly used, and --mixed is the default. | All of them move HEAD to the specified commit. | --soft leaves changes in the staging area. | --mixed keeps the changes in an unstaged state. | --hard discards all changes. | . To remove all uncommitted changes . Changes reset by following commands will be unrecoverable unless you have already pushed to remote. git reset --hard # Reset tracked files to your latest commit git clean -fd # Remove untracked files . Undo last (few) commit(s) without losing changes . git reset HEAD^ # Undo last commit git reset HEAD^^ # Undo last two commits git reset HEAD~3 # Undo last three commits . ",
    "url": "/docs/git-hub/git/useful.html#reset-status",
    
    "relUrl": "/docs/git-hub/git/useful.html#reset-status"
  },"1388": {
    "doc": "Useful Git Commands",
    "title": "Prune remote branches",
    "content": "If you have deleted a remote branch, but it still shows up when you run git branch -a, then you can prune it by, . git remote prune $remote_name # --dry-run to see what will be pruned . If you have a local branch that is still tracking the deleted remote, then you need to delete the local branch first. References: . | Git: Reset | . ",
    "url": "/docs/git-hub/git/useful.html#prune-remote-branches",
    
    "relUrl": "/docs/git-hub/git/useful.html#prune-remote-branches"
  },"1389": {
    "doc": "Useful Git Commands",
    "title": "Useful Git Commands",
    "content": " ",
    "url": "/docs/git-hub/git/useful.html",
    
    "relUrl": "/docs/git-hub/git/useful.html"
  },"1390": {
    "doc": "Validation Set Approach",
    "title": "Validation Set Approach",
    "content": " ",
    "url": "/docs/data-science/notes/validation-set.html",
    
    "relUrl": "/docs/data-science/notes/validation-set.html"
  },"1391": {
    "doc": "Validation Set Approach",
    "title": "Validation Set",
    "content": "A validation set or holdout set is a subset of samples held out from the original training set for testing. How is this different from the test set? I guess the difference lies in the practicality and the purpose. If a test set is an unknown final evaluation for the model, a validation set is more of an intermediate evaluation during the model development process. We use the validation-set error to estimate the test error: . | MSE for quantitative response | Misclassification rate for qualitative response | . ",
    "url": "/docs/data-science/notes/validation-set.html#validation-set",
    
    "relUrl": "/docs/data-science/notes/validation-set.html#validation-set"
  },"1392": {
    "doc": "Validation Set Approach",
    "title": "Validation Process",
    "content": ". | Shuffle the data. | Randomly split the data into two parts: . | Training set | Validation set | . The ratio of the split is up to discretion. | . ",
    "url": "/docs/data-science/notes/validation-set.html#validation-process",
    
    "relUrl": "/docs/data-science/notes/validation-set.html#validation-process"
  },"1393": {
    "doc": "Validation Set Approach",
    "title": "Drawbacks",
    "content": "High Variability in Estimation . Depending on how the validation set is split, validation-set error can vary significantly, leading to unstable estimate of the test error. We Lose Data for Training . Part of the data that could’ve been used for training is now used for validation, which can lower the accuracy of the model and overestimate the test error. ",
    "url": "/docs/data-science/notes/validation-set.html#drawbacks",
    
    "relUrl": "/docs/data-science/notes/validation-set.html#drawbacks"
  },"1394": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Types of Variable / Statistic / Visualizing Data",
    "content": ". | Variable . | Quantitative Variable . | Discrete Variable | Continuous Variable | . | Qualitative Variable (Categorical Variable) | . | Statistic . | Representative Value . | Mean | Median | Mode | . | Dispersion . | Variance | Standard Deviation | . | . | Visualizing Distribution of Data . | Histogram . | For Discrete Data | For Continuous Data | . | Box and Whisker Plot . | Quartile | Box | Whiskers | Outliers | . | Error Bar | Violin Plot | Swarm Plot | . | . ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html"
  },"1395": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Variable",
    "content": ". | A variable is a characteristic of an object or an event. | Set of values obtained by a common measurement of the characteristic. | Univariate or multivariate . The number of variables is sometimes called the dimension of the data. | Quantitative or qualitative | . ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#variable",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#variable"
  },"1396": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Quantitative Variable",
    "content": "Variable that can be measured numerically. Discrete Variable . | Can only take on a finite number of values. | . Continuous Variable . | Can take on an infinite number of values. | . ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#quantitative-variable",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#quantitative-variable"
  },"1397": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Qualitative Variable (Categorical Variable)",
    "content": "Variable that cannot be measured numerically. Also called a categorical variable. Examples of qualitative variable include: yes/no, gender, country, etc. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#qualitative-variable-categorical-variable",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#qualitative-variable-categorical-variable"
  },"1398": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Statistic",
    "content": "A statistic is a number obtained via some calculations on the data. Such calculations are called descriptive statistics or summary statistics. If histogram is a visualization of the distribution of data, then statistic is a numerical characterization of the data. Obviously enough, descriptive statistics is mostly performed on quantitative variables. Some common descriptive statistics include: . | Representative Value: shows the tendency of the data in a distribution . | Mean | Median | Mode | . | Dispersion: shows the spread of the data in a distribution . | Variance | Standard Deviation | . | . ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#statistic",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#statistic"
  },"1399": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Representative Value",
    "content": "In a perfectly normal distribution, the mean, median, and mode are all the same. However, if the distribution is skewed, these representative values will be different. We can use these values to understand the tendency of the data, hence the name “representative value”. The representative value is not always the best way to understand the data. For example, if the data is skewed, the mean will be greatly affected by the outliers. Therefore it is important to understand the distribution of the data with the help of i.e. histogram, before using the representative value to understand the data. Mean . The mean is the average of the data. We often use the bar above a variable $\\overline{X}$ to denote the mean of a sample, and $\\mu$ to denote the mean of a population. Median . The median is the middle value of the data. When the sample size is even, the median is the average of the two middle values. Due to its nature, unlike the mean, the median is not greatly affected by outliers. Mode . The mode is the most frequent value of the data. This statistic is not used as often as the mean or the median. When the sample is from a continuous variable, we must first group the data into bins just like in a histogram. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#representative-value",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#representative-value"
  },"1400": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Dispersion",
    "content": "Variance . The variance is the average of the squared difference between each value and the mean. | Variance $\\geq 0$ | Variance $= 0$ if and only if all values are the same | Higher the dispersion, higher the variance | . Standard Deviation . The standard deviation is the square root of the variance. Population standard deviation is denoted by $\\sigma$. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#dispersion",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#dispersion"
  },"1401": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Visualizing Distribution of Data",
    "content": "The distribution of data is the pattern of the data. By looking at the distribution, we can understand its tendency and dispersion. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#visualizing-distribution-of-data",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#visualizing-distribution-of-data"
  },"1402": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Histogram",
    "content": "Histogram is one common way to visualize the distribution of data. The purpose of a histogram is to understand the general overview of the data, not to confirm any specific observation. For Discrete Data . For discrete data, the histogram is a bar graph with the value on the x-axis and the frequency on the y-axis. For Continuous Data . For continuous data, the histogram is a bar graph with the range of values (“bin width”) on the x-axis and the frequency on the y-axis. It is important to choose the bin width wisely, because it can greatly affect the shape of the histogram and hence the interpretation of the data. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#histogram",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#histogram"
  },"1403": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Box and Whisker Plot",
    "content": "Box and whisker plot is another common way to visualize the distribution of data. Quartile . A quartile is a value that divides the data into four equal parts. To find the quartiles, we first need to sort the data in ascending order. Then, we can find the quartiles as follows: . | The first quartile $Q_1$ divides the data into the bottom 25%. | The second quartile $Q_2$ divides the data into the bottom 50%. | This is the same as the median. | . | The third quartile $Q_3$ divides the data into the bottom 75%. | . Box . The box in the box and whisker plot is a rectangle that shows the quartiles. The length of the box is the interquartile range (IQR), which is the difference between the third and first quartiles: . $$ IQR = Q_3 - Q_1 $$ . The median is shown as a line inside the box. Whiskers . The whiskers in the box and whisker plot are the lines that extend from the box. The ends of the whiskers end at an observed data point. There are many different ways to define the whiskers. One way to draw the whiskers is to extend them to the minimum and maximum values. Another way is to extend them to the values that are within $1.5 \\times IQR$ from the box (see the image above), and all other values are considered outliers. Whiskers are not always drawn in the same way. They may be even or uneven depending on the definition and data. Outliers . An outlier is a data point that is far away from the rest of the data. There really is no single definition of what an outlier exactly is. It could be points that are outside the whiskers, or data points that are more than 2 or 3 standard deviations away from the mean. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#box-and-whisker-plot",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#box-and-whisker-plot"
  },"1404": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Error Bar",
    "content": "Error bar is a line that shows some range of values. Depending on the context, the range may be the standard deviation, the standard error, or the confidence interval. Because it can mean different things, it is important to describe via a legend what the error bar represents. In descriptive statistics, the error bar is often used to show the standard deviation. In this case, the longer the error bar, the higher the dispersion. In inferential statistics, the error bar is often used to show the standard error or the confidence interval. In this case, the error bars shows you a sense of “significant difference” between two groups. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#error-bar",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#error-bar"
  },"1405": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Violin Plot",
    "content": "Violin plot is a combination of a box and whisker plot and a plot of a probability density function. Read more about violin plots here. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#violin-plot",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#violin-plot"
  },"1406": {
    "doc": "Types of Variable / Statistic / Visualizing Data",
    "title": "Swarm Plot",
    "content": "Each data point is plotted along an axis in a swarm plot. Can be used with other plots such as box and whisker plot. ",
    "url": "/docs/statistics/basics/variable-statistic-visualize.html#swarm-plot",
    
    "relUrl": "/docs/statistics/basics/variable-statistic-visualize.html#swarm-plot"
  },"1407": {
    "doc": "Vector Space",
    "title": "Vector Space",
    "content": ". | Matrix as a Group | Definition | Vector Subspace . | Nullspace (Kernel) | . | Dimension of Vector Space | . ",
    "url": "/docs/linalg/basics/vector-space.html",
    
    "relUrl": "/docs/linalg/basics/vector-space.html"
  },"1408": {
    "doc": "Vector Space",
    "title": "Matrix as a Group",
    "content": "Read more about groups here. | $(\\mathbb{R}^{m \\times n}, +)$ is an Abelian group | $(\\mathbb{R}^{n \\times n}, \\cdot)$ is a general linear group $GL(n, \\mathbb{R})$, if the square matrix is invertible (regular, non-singular) . | Closure, associativity, neutral element (identity matrix) are already satisfied | However, it is not commutative, so it is not an Abelian group | . | . ",
    "url": "/docs/linalg/basics/vector-space.html#matrix-as-a-group",
    
    "relUrl": "/docs/linalg/basics/vector-space.html#matrix-as-a-group"
  },"1409": {
    "doc": "Vector Space",
    "title": "Definition",
    "content": "A real-valued vector space $V = (\\mathcal{V}, +, \\cdot)$ is a set $\\mathcal{V}$ with two operations: . $$ \\begin{align*} +: \\mathcal{V} \\times \\mathcal{V} &amp;\\to \\mathcal{V} \\\\ \\cdot: \\mathbb{R} \\times \\mathcal{V} &amp;\\to \\mathcal{V} \\end{align*} $$ . where: . | $(\\mathcal{V}, +)$ is an Abelian group | Distributive . | In short, stuff like $\\lambda \\cdot (\\mathbf{x} + \\mathbf{y})$ and $(\\lambda + \\psi) \\cdot \\mathbf{x}$ | . | Associative (scalar multiplication only) . | $(\\lambda \\psi) \\cdot \\mathbf{x} = \\lambda \\cdot (\\psi \\cdot \\mathbf{x})$ | . | Neutral element with respect to scalar multiplication . | $1 \\cdot \\mathbf{x} = \\mathbf{x}$ | . | . Then $\\mathbf{x} \\in V$ is called vector. ",
    "url": "/docs/linalg/basics/vector-space.html#definition",
    
    "relUrl": "/docs/linalg/basics/vector-space.html#definition"
  },"1410": {
    "doc": "Vector Space",
    "title": "Vector Subspace",
    "content": ". | Subspace is contained in a vector space, but has closure within itself. | Also called linear subspace. | . Let $V = (\\mathcal{V}, +, \\cdot)$ be a vector space and $\\mathcal{U} \\subseteq \\mathcal{V}$ and $\\mathcal{U} \\neq \\emptyset$. Then $U = (\\mathcal{U}, +, \\cdot)$ is a vector subspace of $V$, or $U \\subseteq V$. As long as the following holds: . | $\\mathbf{0} \\in \\mathcal{U}$ | Closure of $U$ with respect to both inner and outer operations | . Just like subsets, the trivial subspace of any vector space $V$ is $\\{\\mathbf{0}\\}$ and $V$ itself. The intersection of any number of subspaces of a vector space $V$ is also a subspace of $V$. ",
    "url": "/docs/linalg/basics/vector-space.html#vector-subspace",
    
    "relUrl": "/docs/linalg/basics/vector-space.html#vector-subspace"
  },"1411": {
    "doc": "Vector Space",
    "title": "Nullspace (Kernel)",
    "content": "The solution space of a homogeneous system of linear equation (also called nullspace or kernel) $A \\mathbf{x} = \\mathbf{0}$ is a vector subspace of $\\mathbb{R}^n$. However, the solution space of a inhomogeneous system of linear equation $A \\mathbf{x} = \\mathbf{b}$ where $\\mathbf{b} \\neq \\mathbf{0}$ is not a vector subspace of $\\mathbb{R}^n$. Because the zero vector is not in the solution space of an inhomogeneous system. ",
    "url": "/docs/linalg/basics/vector-space.html#nullspace-kernel",
    
    "relUrl": "/docs/linalg/basics/vector-space.html#nullspace-kernel"
  },"1412": {
    "doc": "Vector Space",
    "title": "Dimension of Vector Space",
    "content": "Basis and Rank . ",
    "url": "/docs/linalg/basics/vector-space.html#dimension-of-vector-space",
    
    "relUrl": "/docs/linalg/basics/vector-space.html#dimension-of-vector-space"
  },"1413": {
    "doc": "venv",
    "title": "venv",
    "content": ". | What is venv | Basic usage . | Create environment | Activate environment | Deactivate environment | . | . ",
    "url": "/docs/python/envs/venv.html",
    
    "relUrl": "/docs/python/envs/venv.html"
  },"1414": {
    "doc": "venv",
    "title": "What is venv",
    "content": "venv is Python’s default virtual environment tool. ",
    "url": "/docs/python/envs/venv.html#what-is-venv",
    
    "relUrl": "/docs/python/envs/venv.html#what-is-venv"
  },"1415": {
    "doc": "venv",
    "title": "Basic usage",
    "content": "Create environment . venv creates a virtual environment for the Python version used to invoke it. # If you only need one environment for the project python -m venv venv # If you are going to need multiple environments python -m venv venv/myenv # Creates a nested dir . python -m venv &lt;name-of-env&gt; creates a directory in cwd. The &lt;name-of-env&gt; can be anything you like, but venv is used the most by convention. Just like node_modules, because venv exists within the project root, it is almost always added to .gitignore. Activate environment . Assuming cwd is project root where venv directory exists, . source venv/bin/activate . Once activated, which python will point to . /Path/To/Project/venv/bin/python . Deactivate environment . deactivate . ",
    "url": "/docs/python/envs/venv.html#basic-usage",
    
    "relUrl": "/docs/python/envs/venv.html#basic-usage"
  },"1416": {
    "doc": "vim-plug",
    "title": "vim-plug",
    "content": "To be added . vim-plug Tutorial . ",
    "url": "/docs/others/vim/vim-plug.html",
    
    "relUrl": "/docs/others/vim/vim-plug.html"
  },"1417": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Stats Vocabulary / Short Notes",
    "content": "TBA . | Group | Memorylessness | Parametric Models . | Parameters of Interest and Nuisance Parameters | . | Regression Function | Prediction vs Classification | TBA | . ",
    "url": "/docs/statistics/notes/vocabs.html",
    
    "relUrl": "/docs/statistics/notes/vocabs.html"
  },"1418": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Group",
    "content": "In hypothesis testing, we often compare two groups of data. | Control group: the group that does not receive the treatment | Treatment group: the group that receives the treatment | . ",
    "url": "/docs/statistics/notes/vocabs.html#group",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#group"
  },"1419": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Memorylessness",
    "content": "When a probability distribution modeling a “wait time” is memoryless, the probability of “waiting” for a certain amount of time until an event occurs is the same regardless of how much time has already passed. $$ P(X &gt; s + t | X &gt; s) = P(X &gt; t) $$ . For example, if time $s$ has already passed, you’d think that the probability of waiting for another $t$ time until an event occurs would be different from the probability of waiting for $t$ time until an event occurs. However, if the distribution is memoryless, the probability of waiting for $t$ more time until an event occurs is the same regardless of how much time has already passed. Two common distributions that are memoryless are: . | Geometric distribution | Exponential distribution | . ",
    "url": "/docs/statistics/notes/vocabs.html#memorylessness",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#memorylessness"
  },"1420": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Parametric Models",
    "content": "A model is a set of distributions. A parametric model is a set of distributions that can be parameterized by a finite number of parameters. When $\\theta$ is a vector of parameters in the parameter space $\\Theta$, we denote parametric models: . $$ \\mathcal{P} = \\{ f(x; \\theta) : \\theta \\in \\Theta \\} $$ . ",
    "url": "/docs/statistics/notes/vocabs.html#parametric-models",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#parametric-models"
  },"1421": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Parameters of Interest and Nuisance Parameters",
    "content": "When we do statistical inference, we are often interested in only the subset of parameters (e.g. the mean of a Gaussian) which are called parameters of interest. The remaining parameters that defines the distribution but are not of our interest are called nuisance parameters. ",
    "url": "/docs/statistics/notes/vocabs.html#parameters-of-interest-and-nuisance-parameters",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#parameters-of-interest-and-nuisance-parameters"
  },"1422": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Regression Function",
    "content": "In supervised learning, we have pairs of data $(X_i, Y_i)$ for $i=1,\\dots,n$. A regression function is a function that maps the predictor variable $X$ to the response variable $Y$: . $$ r(x) = \\E[Y | X=x] $$ . Estimating the regression function is the goal of regression. ",
    "url": "/docs/statistics/notes/vocabs.html#regression-function",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#regression-function"
  },"1423": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "Prediction vs Classification",
    "content": "For a new predictor $X$, we want to predict the response $Y$. If $Y$ is a continuous variable, we call it prediction. If $Y$ is a categorical variable, we call it classification. ",
    "url": "/docs/statistics/notes/vocabs.html#prediction-vs-classification",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#prediction-vs-classification"
  },"1424": {
    "doc": "Stats Vocabulary / Short Notes",
    "title": "TBA",
    "content": ". | skewnewss | kurtosis | . ",
    "url": "/docs/statistics/notes/vocabs.html#tba",
    
    "relUrl": "/docs/statistics/notes/vocabs.html#tba"
  },"1425": {
    "doc": "Docker Volumes",
    "title": "Docker Volumes",
    "content": ". | What is a Docker volume | Cases where Docker volume comes in handy . | You want some live-reloading features | You want to persist data upon container shutdown | . | . ",
    "url": "/docs/docker/volumes.html",
    
    "relUrl": "/docs/docker/volumes.html"
  },"1426": {
    "doc": "Docker Volumes",
    "title": "What is a Docker volume",
    "content": "In short, it maps the volume inside a container with some local directory on your computer. If you set the volume to read-only, every change in local directory will be reflected in the container but not vice versa. If you set read-only to false, the contents inside the container and the local directory will remain same throughout the container execution. ",
    "url": "/docs/docker/volumes.html#what-is-a-docker-volume",
    
    "relUrl": "/docs/docker/volumes.html#what-is-a-docker-volume"
  },"1427": {
    "doc": "Docker Volumes",
    "title": "Cases where Docker volume comes in handy",
    "content": "You want some live-reloading features . During development, it is really painful if you have to rebuild or rerun everytime you make a change. By mapping your container volume to a local build context, the container will update itself everytime you make a change to your local code. You want to persist data upon container shutdown . For example if you’re running a DB as a container without a volume mapped, each time the container restarts, the contents of the DB will be erased. However, if you map your container volume to a local directory, the data will be kept even after shutdown. ",
    "url": "/docs/docker/volumes.html#cases-where-docker-volume-comes-in-handy",
    
    "relUrl": "/docs/docker/volumes.html#cases-where-docker-volume-comes-in-handy"
  },"1428": {
    "doc": "Wald Test",
    "title": "Wald Test",
    "content": ". | Hypothesis | Distribution / Test Statistic | Asymptotic Test | . ",
    "url": "/docs/statistics/notes/wald-test.html",
    
    "relUrl": "/docs/statistics/notes/wald-test.html"
  },"1429": {
    "doc": "Wald Test",
    "title": "Hypothesis",
    "content": "Let $\\theta$ be the parameter of interest. The null hypothesis is: . $$ H_0: \\theta = \\theta_0 $$ . The alternative hypothesis is: . $$ H_1: \\theta \\neq \\theta_0 $$ . ",
    "url": "/docs/statistics/notes/wald-test.html#hypothesis",
    
    "relUrl": "/docs/statistics/notes/wald-test.html#hypothesis"
  },"1430": {
    "doc": "Wald Test",
    "title": "Distribution / Test Statistic",
    "content": "Let $\\hat{\\theta}$ be the MLE of $\\theta$. Using the fact that MLE is asymptomatically normal, and assuming that the null hypothesis is true, . \\[\\frac{\\hat{\\theta} - \\theta_0}{\\hat{\\text{se}}(\\hat{\\theta})} \\leadsto N(0, 1)\\] The Wald statistic is: . $$ W = \\frac{\\hat{\\theta} - \\theta_0}{\\hat{\\text{se}}(\\hat{\\theta})} $$ . And at the significance level $\\alpha$, we reject the null hypothesis if: . $$ |W| &gt; z_{\\alpha/2} $$ . ",
    "url": "/docs/statistics/notes/wald-test.html#distribution--test-statistic",
    
    "relUrl": "/docs/statistics/notes/wald-test.html#distribution--test-statistic"
  },"1431": {
    "doc": "Wald Test",
    "title": "Asymptotic Test",
    "content": "Wald test is an asymptotic test, meaning that it is valid for large sample sizes. When the sample size is small, consider using other tests like the t-test. ",
    "url": "/docs/statistics/notes/wald-test.html#asymptotic-test",
    
    "relUrl": "/docs/statistics/notes/wald-test.html#asymptotic-test"
  },"1432": {
    "doc": "Welch's t-Test",
    "title": "Welch’s t-Test",
    "content": "To be added . ",
    "url": "/docs/statistics/basics/welch-t-test.html#welchs-t-test",
    
    "relUrl": "/docs/statistics/basics/welch-t-test.html#welchs-t-test"
  },"1433": {
    "doc": "Welch's t-Test",
    "title": "Welch's t-Test",
    "content": " ",
    "url": "/docs/statistics/basics/welch-t-test.html",
    
    "relUrl": "/docs/statistics/basics/welch-t-test.html"
  },"1434": {
    "doc": "SQL Window Function",
    "title": "SQL Window Function",
    "content": ". | Reference: PostgreSQL Tutorial | . | Window Function vs Aggregate Function | Window Function Syntax . | Window Functions | Window and Partition . | Partitioning | WINDOW Clause | Ordering within Partition | Frame Clause | . | . | . ",
    "url": "/docs/db/sql/window-function.html",
    
    "relUrl": "/docs/db/sql/window-function.html"
  },"1435": {
    "doc": "SQL Window Function",
    "title": "Sample Data",
    "content": "SQL CREATE SCHEMA IF NOT EXISTS win; SET search_path TO win; CREATE TABLE product_groups ( group_id serial PRIMARY KEY, group_name VARCHAR (255) NOT NULL ); CREATE TABLE products ( product_id serial PRIMARY KEY, product_name VARCHAR (255) NOT NULL, price DECIMAL (11, 2), group_id INT NOT NULL, FOREIGN KEY (group_id) REFERENCES product_groups (group_id) ); INSERT INTO product_groups (group_name) VALUES ('Smartphone'), ('Laptop'), ('Tablet'); INSERT INTO products (product_name, group_id,price) VALUES ('Microsoft Lumia', 1, 200), ('HTC One', 1, 400), ('Nexus', 1, 500), ('iPhone', 1, 900), ('HP Elite', 2, 1200), ('Lenovo Thinkpad', 2, 700), ('Sony VAIO', 2, 700), ('Dell Vostro', 2, 800), ('iPad', 3, 700), ('Kindle Fire', 3, 150), ('Samsung Galaxy Tab', 3, 200); . Additional View CREATE VIEW product_and_groups AS SELECT * FROM products JOIN product_groups USING (group_id); . ",
    "url": "/docs/db/sql/window-function.html#sample-data",
    
    "relUrl": "/docs/db/sql/window-function.html#sample-data"
  },"1436": {
    "doc": "SQL Window Function",
    "title": "Window Function vs Aggregate Function",
    "content": "A window refers to the set of rows that the function will operate on. | Aggregate functions operate on a group of rows and return a single value. | Window functions operate on a set of rows (window) and return value for each row in window. | . With aggregate functions and group by: . SELECT group_name, AVG(price) AS avg_price FROM product_and_groups GROUP BY group_name ORDER BY 2 DESC; . | group_name | avg_price | . | Laptop | 850 | . | Smartphone | 500 | . | Tablet | 350 | . With window functions: . SELECT product_name, group_name, AVG(price) OVER (PARTITION BY group_name) AS avg_price FROM product_and_groups ORDER BY 3 DESC; . | product_name | group_name | avg_price | . | HP Elite | Laptop | 850 | . | Lenovo Thinkpad | Laptop | 850 | . | Sony VAIO | Laptop | 850 | . | Dell Vostro | Laptop | 850 | . | Microsoft Lumia | Smartphone | 500 | . | HTC One | Smartphone | 500 | . | Nexus | Smartphone | 500 | . | iPhone | Smartphone | 500 | . | iPad | Tablet | 350 | . | Kindle Fire | Tablet | 350 | . | Samsung Galaxy Tab | Tablet | 350 | . ",
    "url": "/docs/db/sql/window-function.html#window-function-vs-aggregate-function",
    
    "relUrl": "/docs/db/sql/window-function.html#window-function-vs-aggregate-function"
  },"1437": {
    "doc": "SQL Window Function",
    "title": "Window Function Syntax",
    "content": "WINDOW_FUNC(args) OVER ( [PARTITION BY partition_expression] [ORDER BY sort_expression] [NULLS {FIRST | LAST}] [frame_clause] ) . ",
    "url": "/docs/db/sql/window-function.html#window-function-syntax",
    
    "relUrl": "/docs/db/sql/window-function.html#window-function-syntax"
  },"1438": {
    "doc": "SQL Window Function",
    "title": "Window Functions",
    "content": "Called window functions because they perform a calculation while sliding a window row by row over the partition. Any aggregate function or window function can be used in place of WINDOW_FUNC. | Aggregate functions . | AVG, SUM, COUNT, MIN, MAX | . | ROW_NUMBER(): Assigns a unique sequential integer to each row in each partition | RANK(): Assigns a integer rank to each row in each partition . | Ties are assigned the same rank, with the next rank skipped (1, 1, 3…) | . | DENSE_RANK(): Similar to RANK(), but no ranks are skipped (1, 1, 2…) | FIRST_VALUE(column_expression): Returns the first evaluated value in the partition | LAST_VALUE(column_expression): Returns the last evaluated value in the partition | NTILE(bucket_count): Distributes rows into a specified number of buckets evenly (as much as possible) | PERCENT_RANK(): In terms of percent, rank the standing of each row in a partition | LAG(column_expression, offset, default): Accesses data from an earlier row . | default is used when the offset goes beyond the partition | . | LEAD(column_expression, offset, default): Accesses data from a later row | CUME_DIST, LAG, LEAD, NTH_VALUE | . ",
    "url": "/docs/db/sql/window-function.html#window-functions",
    
    "relUrl": "/docs/db/sql/window-function.html#window-functions"
  },"1439": {
    "doc": "SQL Window Function",
    "title": "Window and Partition",
    "content": "The window and partition is defined by the parentheses after the OVER clause. Partitioning . PARTITION BY describes how the result set should be divided into groups. You can partition by multiple columns as well: . SELECT product_name, group_name, price, ROW_NUMBER() OVER (PARTITION BY group_name, price) AS row_num FROM product_and_groups; . PARTITION BY is optional. Omitting it will treat all result rows as a single group: . SELECT product_name, group_name, AVG(price) OVER () AS avg_price FROM product_and_groups ORDER BY 3 DESC; -- The third column will be SELECT AVG(price) FROM product_and_groups; . WINDOW Clause . There is an alternate syntax to define the window: . SELECT product_name, group_name, AVG(price) OVER w AS avg_price FROM product_and_groups WINDOW w AS (PARTITION BY group_name) ORDER BY 3 DESC; . Useful when reusing the same window definition multiple times. Ordering within Partition . ORDER BY specifies how the rows in each partition should be ordered. Additional NULLS FIRST or NULLS LAST (default) controls whether NULL values should be ordered first or last. The effect of ORDER BY makes more sense with window functions like ROW_NUMBER(): . SELECT product_name, group_name, price, ROW_NUMBER() OVER w AS row_num FROM product_and_groups WINDOW w AS (PARTITION BY group_name ORDER BY price); . | product_name | group_name | price | row_num | . | Sony VAIO | Laptop | 700.00 | 1 | . | Lenovo Thinkpad | Laptop | 700.00 | 2 | . | Dell Vostro | Laptop | 800.00 | 3 | . | HP Elite | Laptop | 1200.00 | 4 | . | Microsoft Lumia | Smartphone | 200.00 | 1 | . | HTC One | Smartphone | 400.00 | 2 | . | Nexus | Smartphone | 500.00 | 3 | . | iPhone | Smartphone | 900.00 | 4 | . | Kindle Fire | Tablet | 150.00 | 1 | . | Samsung Galaxy Tab | Tablet | 200.00 | 2 | . | iPad | Tablet | 700.00 | 3 | . Remember that you can use ORDER BY without PARTITION BY: . SELECT product_name, group_name, price, RANK() OVER w AS price_rank FROM product_and_groups WINDOW w AS (ORDER BY price DESC); . | product_name | group_name | price | price_rank | . | HP Elite | Laptop | 1200.00 | 1 | . | iPhone | Smartphone | 900.00 | 2 | . | Dell Vostro | Laptop | 800.00 | 3 | . | Lenovo Thinkpad | Laptop | 700.00 | 4 | . | Sony VAIO | Laptop | 700.00 | 4 | . | iPad | Tablet | 700.00 | 4 | . | Nexus | Smartphone | 500.00 | 7 | . | HTC One | Smartphone | 400.00 | 8 | . | Samsung Galaxy Tab | Tablet | 200.00 | 9 | . | Microsoft Lumia | Smartphone | 200.00 | 9 | . | Kindle Fire | Tablet | 150.00 | 11 | . Frame Clause . You can refine a sliding window only if the partition has an order imposed by ORDER BY. You can further refine the window with a frame clause: . ROWS BETWEEN start AND end -- Uses row numbers for calculating window size -- or RANGE BETWEEN start AND end -- Uses column values for calculating window size . Special keywords for start and end: . | CURRENT ROW: . | Current row number | Current row value | . | UNBOUNDED PRECEDING: Start of the partition | UNBOUNDED FOLLOWING: End of the partition | n PRECEDING . | n row numbers before the current row | n less than the current row value | . | n FOLLOWING . | n row numbers after the current row | n greater than the current row value | . | Time-range frame clauses for date and time columns: . | 'n' MONTH, 'n' DAY, 'n' HOUR, 'n' MINUTE, 'n' SECOND + PRECEDING or FOLLOWING | . | . For example, if you wanted to calculate the running total of prices (have the window grow as it goes down the rows in the partition): . SELECT product_name, group_name, price, SUM(price) OVER ( ORDER BY price ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total FROM product_and_groups; . | product_name | group_name | price | running_total | . | Kindle Fire | Tablet | 150.00 | 150 | . | Microsoft Lumia | Smartphone | 200.00 | 350 | . | Samsung Galaxy Tab | Tablet | 200.00 | 550 | . | HTC One | Smartphone | 400.00 | 950 | . | Nexus | Smartphone | 500.00 | 1450 | . | iPad | Tablet | 700.00 | 2150 | . | Lenovo Thinkpad | Laptop | 700.00 | 2850 | . | Sony VAIO | Laptop | 700.00 | 3550 | . | Dell Vostro | Laptop | 800.00 | 4350 | . | iPhone | Smartphone | 900.00 | 5250 | . | HP Elite | Laptop | 1200.00 | 6450 | . Or a window containing the previous, current, and next row: . SELECT product_name, group_name, price, SUM(price) OVER ( ORDER BY price ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS windowed_sum FROM product_and_groups; . | product_name | group_name | price | windowed_sum | . | Kindle Fire | Tablet | 150.00 | 350 | . | Microsoft Lumia | Smartphone | 200.00 | 550 | . | Samsung Galaxy Tab | Tablet | 200.00 | 800 | . | HTC One | Smartphone | 400.00 | 1100 | . | Nexus | Smartphone | 500.00 | 1600 | . | iPad | Tablet | 700.00 | 1900 | . | Lenovo Thinkpad | Laptop | 700.00 | 2100 | . | Sony VAIO | Laptop | 700.00 | 2200 | . | Dell Vostro | Laptop | 800.00 | 2400 | . | iPhone | Smartphone | 900.00 | 2900 | . | HP Elite | Laptop | 1200.00 | 2100 | . ",
    "url": "/docs/db/sql/window-function.html#window-and-partition",
    
    "relUrl": "/docs/db/sql/window-function.html#window-and-partition"
  },"1440": {
    "doc": "Homebrew x86_64",
    "title": "Homebrew x86_64",
    "content": ". | Installing Homebrew for both arm and x86 . | Install for x86 | Set alias | Opt out of analytics (Optional) | . | . ",
    "url": "/docs/others/homebrew/x86.html",
    
    "relUrl": "/docs/others/homebrew/x86.html"
  },"1441": {
    "doc": "Homebrew x86_64",
    "title": "Installing Homebrew for both arm and x86",
    "content": "Install for x86 . After having installed Homebrew natively, install for x86: . arch -x86_64 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" . x86 Homebrew will be located in /usr/local/Homebrew while native Homebrew is in /opt/homebrew. Set alias . In your .zshrc, . # .zshrc alias xbrew='arch -x86_64 /usr/local/Homebrew/bin/brew' . Opt out of analytics (Optional) . xbrew analytics off . ",
    "url": "/docs/others/homebrew/x86.html#installing-homebrew-for-both-arm-and-x86",
    
    "relUrl": "/docs/others/homebrew/x86.html#installing-homebrew-for-both-arm-and-x86"
  },"1442": {
    "doc": "6 - Zigzag Conversion - Medium",
    "title": "Zigzag Conversion",
    "content": ". | Problem | Explanation | Solution | . ",
    "url": "/docs/compsci/leetcode/zigzag-conversion.html#zigzag-conversion",
    
    "relUrl": "/docs/compsci/leetcode/zigzag-conversion.html#zigzag-conversion"
  },"1443": {
    "doc": "6 - Zigzag Conversion - Medium",
    "title": "Problem",
    "content": "The string PAYPALISHIRING is written in a zigzag pattern on a given number of rows like this: . P A H N A P L S I I G Y I R . And then read line by line: PAHNAPLSIIGYIR. Input: s = \"PAYPALISHIRING\", numRows = 4 Output: \"PINALSIGYAHRPI\" Explanation: P I N A L S I G Y A H R P I . ",
    "url": "/docs/compsci/leetcode/zigzag-conversion.html#problem",
    
    "relUrl": "/docs/compsci/leetcode/zigzag-conversion.html#problem"
  },"1444": {
    "doc": "6 - Zigzag Conversion - Medium",
    "title": "Explanation",
    "content": "Since the final answer string is built by reading the rows line by line, we should start by thinking our loops should to the same. for (int r = 0; r &lt; numRows; r++) . We need to find a pattern in each row. Take a loot at the example with numRows = 4: . Let’s forget about the diagonals for now and focus on the gray columns. They are evenly spaced out by $6$ each starting from their respective row index. This is because the distance between is . \\[\\text{numRows} + (\\text{numRows} - 2) = 2 * \\text{numRows} - 2\\] where $\\text{numRows}$ comes from traversing vertically along the columns, and the $\\text{numRows} - 2$ comes from traversing diagonally. For the first and last rows, there are no diagonals, so this is the only pattern that matters. For the rows in between the first and last, there are additional indices in between the gray columns. Let’s define . \\[\\text{skip} = 2 * \\text{numRows} - 2\\] At each row $r$, the additional indices can be found by traversing $r + 1$ less vertically and $r - 1$ less diagonally. Therefore, the auxiliary skips are . \\[\\text{auxSkip} = \\text{skip} - (r + 1 + r - 1) = \\text{skip} - 2r\\] . ",
    "url": "/docs/compsci/leetcode/zigzag-conversion.html#explanation",
    
    "relUrl": "/docs/compsci/leetcode/zigzag-conversion.html#explanation"
  },"1445": {
    "doc": "6 - Zigzag Conversion - Medium",
    "title": "Solution",
    "content": "| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 . | public String convert(String s, int numRows) { if (numRows == 1) return s; int n = s.length(); StringBuilder sb = new StringBuilder(n); int skip = numRows + (numRows - 2); for (int r = 0; r &lt; numRows; r++) { int auxSkip = skip - 2 * r; for (int i = r; i &lt; n; i += skip) { // Gray columns sb.append(s.charAt(i)); // Auxiliary diagonals for the middle rows if (r &gt; 0 &amp;&amp; r &lt; numRows - 1) { int aux = i + auxSkip; // Don't go out of bounds if (aux &lt; n) sb.append(s.charAt(aux)); } } } return sb.toString(); } . | . The complexity is $O(n)$. ",
    "url": "/docs/compsci/leetcode/zigzag-conversion.html#solution",
    
    "relUrl": "/docs/compsci/leetcode/zigzag-conversion.html#solution"
  },"1446": {
    "doc": "6 - Zigzag Conversion - Medium",
    "title": "6 - Zigzag Conversion - Medium",
    "content": " ",
    "url": "/docs/compsci/leetcode/zigzag-conversion.html",
    
    "relUrl": "/docs/compsci/leetcode/zigzag-conversion.html"
  }
}
